% This is part of Mes notes de mathématique
% Copyright (c) 2011-2017
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Exponentielle et logarithme}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

La méthode adoptée ici est la suivante :
\begin{itemize}
    \item L'exponentielle est définie par la série.
    \item Nous démontrons qu'elle vérifie l'équation différentielle \( y'=y\), \( y(0)=1\).
    \item Nous démontrons l'unicité de la solution à cette équation différentielle.
    \item Nous démontrons qu'elle est égale à \( x\mapsto y(1)^x\). Cela est une définition du nombre \( e=\) comme valant \( y(1)\).
    \item Nous définissons le logarithme comme l'application réciproque de l'exponentielle (définition \ref{DefDXPRooExiCpx}).
\end{itemize}

\begin{theorem}[Existence de l'exponentielle] \label{ThoKRYAooAcnTut}
    La série entière
    \begin{equation}    \label{EqEIGZooKWSvPS}
        y(x)=\sum_{k=0}^{\infty}\frac{ x^k }{ k! }
    \end{equation}
    définit une fonction dérivable solution de
    \begin{subequations}
        \begin{numcases}{}
            y'=y\\
            y(0)=1.
        \end{numcases}
    \end{subequations}
\end{theorem}
\index{exponentielle!existence}

\begin{proof}
    La formule de Hadamard (théorème \ref{ThoSerPuissRap}) donne le rayon de convergence de la série \eqref{EqEIGZooKWSvPS} par
    \begin{equation}
        \frac{1}{ R }=\lim_{k\to \infty} \frac{ \frac{1}{ (k+1)! } }{ \frac{1}{ k! } }=\lim_{k\to \infty} \frac{1}{ k+1 }=0.
    \end{equation}
    Donc nous avons un rayon de convergence infini. La fonction \( y\) est définie sur \( \eR\) et la proposition \ref{ProptzOIuG} nous dit que \( y\) est dérivable. Nous pouvons aussi dériver terme à terme :
    \begin{equation}
            y'(x)=\sum_{k=0}^{\infty}\frac{ kx^{k-1} }{ k! }=\sum_{k=1}^{\infty}\frac{ kx^{k-1} }{ k! }=\sum_{k=1}^{\infty}\frac{ x^{k-1} }{ (k-1)! }=\sum_{k=0}^{\infty}\frac{ x^k }{ k! }=y(x).
    \end{equation}
    Notez le petit jeu d'indice de départ de \( k\). Dans un premier temps, nous remarquons que \( k=0\) donne un terme nul et nous le supprimons, et dans un second temps nous effectuons la simplification des factorielles (qui ne fonctionne pas avec \( k=0\)).
\end{proof}

Pour la suite nous notons \( y\) une solution de l'équation \( y'=y\), \( y(0)=1\), et nous allons en donner des propriétés indépendamment de l'existence, donnée par le théorème \ref{ThoKRYAooAcnTut}.

\begin{proposition} \label{PropTLECooEiLbPP}
    Quelques propriétés de \( y\) (si elle existe) :
    \begin{enumerate}
        \item
            Pour tout \( x\in \eR\) nous avons \( y(x)y(-x)=1\).
        \item
            \( y(x)>0\) pour tout \( x\).
        \item
            \( y\) est strictement croissante.
    \end{enumerate}
\end{proposition}

\begin{proof}
    Nous posons \( \varphi(x)=y(x)y(-x)\) et nous dérivons :
    \begin{equation}
        \varphi'(x)=y'(x)y(-x)-y(x)y'(-x)=0.
    \end{equation}
    Donc \( \varphi\) est constante\footnote{Proposition \ref{PropGFkZMwD}.}. Vu que \( \varphi(0)=1\) nous avons automatiquement \( y(x)y(-x)=1\) pour tout \( x\).

Les deux autres allégations sont simples : si \( y(x_0)<0\) alors il existe \( t\in\mathopen] x_0 , 1 \mathclose[\) tel que \( y(t)=0\), ce qui est impossible parce que \( y(t)y(-t)=1\). La stricte croissance de \( y\) s'ensuit.
\end{proof}

\begin{proposition}[Unicité de l'exponentielle] \label{PropDJQSooYIwwhy}
    Si elle existe, la solution au problème 
    \begin{subequations}
        \begin{numcases}{}
            y'=y\\
            y(0)=1
        \end{numcases}
    \end{subequations}
    est unique.
\end{proposition}
\index{exponentielle!unicité}

\begin{proof}
    Soient \( y\) et \( g\) deux solutions et considérions la fonction \( h(x)=g(x)y(-x)\). Un calcul immédiat donne
    \begin{equation}
        h'(x)=0
    \end{equation}
    et donc \( h\) est constante. Vu que \( h(0)=1\) nous avons \( g(x)y(-x)=1\) pour tout \( x\), c'est à dire
    \begin{equation}
        g(x)=\frac{1}{ y(-x) }=y(x).
    \end{equation}
\end{proof}

\begin{proposition}     \label{PROPooGGUIooExVHPM}
    Quelques formules pour tout \( a,b\in \eR\) et \( n\in \eZ\) :
    \begin{enumerate}
        \item       \label{ITEMooMPSUooWQpVQJ}
            \( y(a+b)=y(a)y(b)\)
        \item
            \( y(na)=y(a)^n\)
        \item
            \( y\left( \frac{ a }{ n } \right)=\sqrt[n]{y(a)}\).
    \end{enumerate}
\end{proposition}

\begin{proof}
    Nous posons \( h(x)=y(a+b-x)y(x)\) et nous avons encore \( h'(x)=0\) dont nous déduisons que $h$ est constante. De plus
    \begin{equation}
        h(0)=y(a+b)y(0)=y(a+b)
    \end{equation}
    et
    \begin{equation}
        h(b)=y(a)y(b).
    \end{equation}
    Vu que \( h\) est constante, ces deux expressions sont égales : \( y(a+b)=y(a)y(b)\).

    Forts de cette relation, une récurrence donne \( y(na)=y(a)^n\) pour tout \( n\in \eN\). De plus
    \begin{equation}
        y(a)=y\left( \frac{ a }{ n }\times n \right)=y\left( \frac{ a }{ n } \right)^n,
    \end{equation}
    ce qui donne \( y(a)=y(a/n)^n\) ou encore \( y(a/n)=\sqrt[n]{y(a)}\).

    Enfin pour les négatifs, si \( n\in \eN\),
    \begin{equation}
        y(-na)=\frac{1}{ y(na) }=\frac{1}{ y(a)^n }=y(a)^{-n}.
    \end{equation}
    Et de la même façon,
    \begin{equation}
        y\left( -\frac{ a }{ n } \right)=\frac{1}{ y\left( \frac{ a }{ n } \right) }=\sqrt[n]{\frac{1}{ y(a) }}=\sqrt[-n]{y(a)}.
    \end{equation}
\end{proof}

\begin{proposition} \label{PropCELWooLBSYmS}
    Pour tout \( x\in \eR\), nous avons
    \begin{equation}
        y(x)=y(1)^x.
    \end{equation}
\end{proposition}

\begin{proof}
    Si \( q\in \eQ\) alors \( q=a/b\) et
    \begin{equation}
        y(q)=y\left( \frac{ a }{ b } \right)=y\left( a\times \frac{1}{ b } \right)=y\left( \frac{1}{ b } \right)^a=\big( \sqrt[b]{y(1)} \big)^a=y(1)^{a/b}=y(1)^{q}.
    \end{equation}

    Par ailleurs si \( a\in \eR\), alors la fonction \( x\mapsto a^x\) est continue. Les fonctions \( y\) et \( x\mapsto y(1)^x\) sont deux fonctions continues égales sur \( \eQ\). Elles sont donc égales par la proposition \ref{PropCJGIooZNpnGF}.
\end{proof}
Nous notons \( y(1)=e\), le \defe{nombre de Néper}{nombre!de Néper}, de telle sorte que
\begin{equation}
    y(x)=e^x.
\end{equation}

Une conséquence est que 
\begin{subequations}    \label{EqLOIUooHxnEDn}
    \begin{align}
        \lim_{x\to -\infty}  e^{x}=0\\
        \lim_{x\to +\infty}  e^{x}=+\infty,
    \end{align}
\end{subequations}
et en particulier, 
\begin{equation}
    \begin{aligned}
    \exp\colon \eR&\to \mathopen] 0 , \infty \mathclose[ \\
        x&\mapsto  e^{x} 
    \end{aligned}
\end{equation}
est une bijection.

\begin{theorem}[Définition de l'exponentielle]  \label{ThoRWOZooYJOGgR}
    Les choses que nous savons sur l'exponentielle :
    \begin{enumerate}
        \item
            Il y a unicité de la solution à l'équation différentielle
            \begin{subequations}    \label{subeqBKJNooJQtbBD}
        \begin{numcases}{}
            y'=y\\
            y(0)=1.
        \end{numcases}
    \end{subequations}
    \item
        L'équation différentielle \eqref{subeqBKJNooJQtbBD} possède une solution donnée par la série entière\nomenclature[Y]{\( \exp\)}{exponentielle}
        \begin{equation}    \label{EqUARSooKXnQxu}
        \exp(x)=\sum_{k=0}^{\infty}\frac{ x^k }{ k! }
    \end{equation}
\item
    Cette solution est une bijection \( y\colon \eR\to \mathopen] 0 , \infty \mathclose[\).
    \item   \label{ItemYTLTooSnfhOu}
        La fonction \( y\) ainsi définie est de classe \(  C^{\infty}\).
\item
    Elle est également donnée par la formule
    \begin{equation}
        \exp(x)=e^x
    \end{equation}
    où \( e\) est définit par \( e=\exp(1)\).
\item
    Elle vérifie
    \begin{equation}        \label{EQooVFXUooBfwjJY}
        e^{a+b}= e^{a} e^{b}
    \end{equation}
    \end{enumerate}
\end{theorem}
Nous nommons \defe{exponentielle}{exponentielle} cette fonction.

\begin{proof}
    \begin{enumerate}
        \item
            C'est la proposition \ref{PropDJQSooYIwwhy}.
        \item 
            C'est le théorème \ref{ThoKRYAooAcnTut}.
        \item
            Le rayon de convergence de la série \eqref{EqUARSooKXnQxu} est infini (théorème \ref{ThoKRYAooAcnTut}); elle est donc définie sur \( \eR\). Le fait que ce soit une bijection est dû au fait qu'elle est strictement croissante (proposition \ref{PropTLECooEiLbPP}) ainsi qu'aux limite \eqref{EqLOIUooHxnEDn}.
        \item
            Vu que \( y=y'\), \( y\) est dérivable. Mais comme \( y'\) est alors égale à une fonction dérivable, \( y'\) est dérivable. En dérivant l'égalité \( y'=y\) nous obtenons \( y''=y'\) et le jeu continue.
        \item
            C'est la proposition \ref{PropCELWooLBSYmS}.
        \item
            C'est la proposition \ref{PROPooGGUIooExVHPM}\ref{ITEMooMPSUooWQpVQJ}.
    \end{enumerate}
\end{proof}

\begin{example}[Un endomorphisme sans polynôme annulateur\cite{RombaldiO}]     \label{ExooLRHCooMYLQTU}
    l'exponentielle permet de donner un exemple d'un endomorphisme n'ayant pas de polynôme annulateur\footnote{Voir la définition \ref{DefooOHUXooNkPWaB} et ce qui suit.} : l'endomorphisme de dérivation
    \begin{equation}
        \begin{aligned}
            D\colon C^{\infty}(\eR,\eR)&\to  C^{\infty}(\eR,\eR) \\
            f&\mapsto f' 
        \end{aligned}
    \end{equation}
    n'a pas de polynôme annulateur. En effet supposons que \( P=\sum_{k=0}^{p}a_kX^k\) en soit un, et considérons les fonction \( f_{\lambda}\colon t\mapsto  e^{\lambda t}\). Nous avons
    \begin{equation}
            0=P(D)f_{\lambda}
            =\sum_ka_kD^k(f_{\lambda})
            =\sum_ka_k\lambda^kf_{\lambda}
            =P(\lambda)f_{\lambda}.
    \end{equation}
    Par conséquent \( \lambda\) est une racine de \( P\) pour tout \( \lambda\in \eR\). Cela implique que \( P=0\).
    
    D'ailleurs si on y pense bien, cet exemple n'est qu'un habillage de l'exemple \ref{ExooDTUJooIMqSKn}.
\end{example}

\begin{definition}[Logarithme]  \label{DefDXPRooExiCpx}
    La fonction \( \exp\colon \eR\to \mathopen] 0 , \infty \mathclose[\) étant une bijection, elle admet une application réciproque que nous nommons \defe{logarithme}{logarithme} et que nous notons
\begin{equation}
    \ln\colon \mathopen] 0 , \infty \mathclose[\to \eR.
\end{equation}
\end{definition}

\begin{example}[Exponentielle et logarithme]    \label{ExZLMooMzYqfK}
    Nous savons que la fonction
    \begin{equation}
        \begin{aligned}
        \exp\colon \eR&\to \mathopen] 0 , \infty \mathclose[ \\
            x&\mapsto e^x 
        \end{aligned}
    \end{equation}
    est croissante et dérivable. Elle est donc bijective, d'inverse continue et dérivable par le théorème \ref{ThoKBRooQKXThd} et la proposition \ref{PropMRBooXnnDLq}. Nous nommons \defe{logarithme}{logarithme} la fonction inverse de l'exponentielle :
    \begin{equation}
    \ln\colon \mathopen] 0 , \infty \mathclose[\to \eR.
    \end{equation}
    La proposition \ref{PropMRBooXnnDLq} nous enseigne que la fonction logarithme est croissante et que sa dérivée peut être calculée\footnote{Nous savons que \( \exp'(x)=\exp(x)\) : la dérivée de l'exponentielle est l'exponentielle elle-même.} : si \( y= e^{x}\) alors
    \begin{equation}
        \ln'(y)=\frac{1}{ \exp'(x) }=\frac{1}{ y }.
    \end{equation}
    Nous retrouvons ainsi la formule très connue comme quoi la dérivée du logarithme est l'inverse\footnote{Ou encore que le logarithme est une primitive de la fonction inverse.}.
\end{example}

\begin{lemma}
    Le logarithme est la primitive de \( x\mapsto\frac{1}{ x }\) qui s'annule en \( x=1\).
\end{lemma}

\begin{proof}
    L'existence d'une primitive est justement le sujet de ce lemme\footnote{C'est l'avantage de notre approche, qui construit la primitive sans devoir invoquer le théorème \ref{PropKKGAooDQYGKg} pour en assurer l'existence.}. En tant qu'application réciproque nous avons pour tout \( x\in \eR\) :
    \begin{equation}
        \ln\big( \exp(x) \big)=x,
    \end{equation}
    que nous pouvons dériver en utilisant le théorème de dérivation des fonctions composées :
    \begin{equation}
        \ln'\big( \exp(x) \big)\exp'(x)=1.
    \end{equation}
    Mais \( \exp'(x)=x\), donc
    \begin{equation}
        \ln'(y)=\frac{1}{ y }
    \end{equation}
    pour tout \( y\) dans l'image de \( \exp\), c'est à dire pour tout \( y\) dans l'ensemble de définition de \( \ln\).

    Par ailleurs, \( \exp(0)=1\) donc
    \begin{equation}
        \ln(1)=\ln\big( \exp(0) \big)=0.
    \end{equation}

    En ce qui concerne l'unicité d'une primitive s'annulant en \( x=1\), c'est le corollaire \ref{CorZeroCst}.
\end{proof}

\begin{lemma}
Si \( u\colon \eR\to \mathopen] 0 , \infty \mathclose[\) est dérivable alors \( \ln(u)'=\dfrac{ u' }{ u }\).
\end{lemma}

\begin{proof}
    Cela est une conséquence du théorème de dérivation des fonctions composées : si \( g(x)=\ln(u(x))\) alors
    \begin{equation}
        g'(x)=\ln'\big( u(x) \big)u'(x)=\frac{1}{ u(x) }u'(x).
    \end{equation}
\end{proof}

\begin{lemma}   \label{LemPEYJooEZlueU}
Si \( a,b\in\mathopen] 0 , \infty \mathclose[\) alors
    \begin{equation}
        \ln(ab)=\ln(a)+\ln(b)
    \end{equation}
    et
    \begin{equation}    \label{EqOOZGooOWkGlA}
        \ln\left( \frac{1}{ b } \right)=-\ln(b).
    \end{equation}
\end{lemma}

\begin{proof}
    Nous posons \( f(x)=\ln(ax)\) qui est une fonction dérivable. Alors \( f'(x)=\frac{ a }{ ax }=\frac{1}{ x }\). Cette fonction \( f\) est donc une primitive de \( \frac{1}{ x }\) et il existe une constante \( K\) telle que
    \begin{equation}
        f(x)=\ln(x)+K.
    \end{equation}
    Vu que \( \ln(1)=0\) nous avons \( K=f(1)= \ln(a)\). Donc
    \begin{equation}
        \ln(ax)=\ln(x)+\ln(a).
    \end{equation}

    En ce qui concerne la seconde formule à démontrer, nous avons
    \begin{equation}
        \ln(1)=\ln\left( \frac{1}{ b }b \right)=\ln\left( \frac{1}{ b } \right)+\ln(b).
    \end{equation}
    Étant donné que $\ln(1)=0$ nous en déduisons la formule \eqref{EqOOZGooOWkGlA}.
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Trigonométrie}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Définitions}
%---------------------------------------------------------------------------------------------------------------------------

\begin{propositionDef}[Défintion du cosinus]
    La série
    \begin{equation}
        \cos(x)=\sum_{n=0}^{\infty}\frac{ (-1)^n }{ (2n)! }x^{2n}
    \end{equation}
    définit une fonction \( \cos\colon \eR\to \eR\) de classe \(  C^{\infty}\). Nous l'appelons \defe{cosinus}{cosinus}

    La série
    \begin{equation}
        \sin(x)=\sum_{n=0}^{\infty}\frac{ (-1)^n }{ (2n+1)! }x^{2n+1}
    \end{equation}
    définit une fonction \( \sin\colon \eR\to \eR\) de classe \(  C^{\infty}\). Nous l'appelons \defe{sinus}{sinus}
\end{propositionDef}

\begin{proof}
    La série entière définissant \( \cos(x)\) a pour coefficients
    \begin{equation}
        a_n=\begin{cases}
            0    &   \text{si } n\text{ est impair}\\
            \frac{ (-1)^{n/2} }{ n! }    &   \text{si } n\text{ est pair}.
        \end{cases}
    \end{equation}
    Nous pouvons la majorer par la série entière donnée par les coefficients
    \begin{equation}
        b_n=\begin{cases}
            1/n!    &   \text{si } n\text{ est impair}\\
            \frac{ (-1)^{n/2} }{ n! }    &   \text{si } n\text{ est pair}.
        \end{cases}
    \end{equation}
    Quelle que soit la parité de \( k\) nous avons toujours
    \begin{equation}
        | \frac{ b_{k+1} }{ b_k } |=\frac{1}{ k+1 },
    \end{equation}
    de telle sorte que la formule d'Hadamard \eqref{EqAlphaSerPuissAtern} nous donne \( R=\infty\) pour la série \( \sum_{k=0}^{\infty}b_kx^k\). A fortiori\footnote{Remarque \ref{REMooYOTEooKvxHSf}.} le rayon de convergence pour la série du cosinus est infini.

    L'assertion concernant le sinus se démontre de même.

    En ce qui concerne le fait que les fonctions \( \sin\) et \( \cos\) sont de classe \(  C^{\infty}\) sur \( \eR\), il faut invoquer le corollaire \ref{CorCBYHooQhgara}.
\end{proof}

\begin{lemma}
    En ce qui concerne la dérivation, nous avons
    \begin{subequations}
        \begin{align}
            \sin'&=\cos\\
            \cos'&=-\sin.
        \end{align}
    \end{subequations}
\end{lemma}

\begin{proof}
    Il s'agit de se permettre de dériver terme à terme (proposition \ref{ProptzOIuG}) les séries qui définissent le sinus et le cosinus.
\end{proof}

\begin{lemma}
    Les fonctions sinus et cosinus vérifient
    \begin{equation}
        \cos^2(x)+\sin^2(x)=1
    \end{equation}
    pour tout \( x\in \eR\).
\end{lemma}

\begin{proof}
    Posons \( f(x)=\sin^2(x)+\cos^2(x)\) et dérivons :
    \begin{equation}
        f'(x)=2\sin(x)\cos(x)+2\cos(x)(-)\sin(x)=0.
    \end{equation}
    La fonction \( f\) est donc constante par le corollaire \ref{CORooEOERooYprteX}. Nous avons donc pour tout \( x\) :
    \begin{equation}
        f(x)=f(0)=\sin^2(0)+\cos^2(0)=1.
    \end{equation}
    Le dernier calcul s'obtient en substituant directement \( x\) par zéro dans les séries : \( \sin(0)=0\) et \( \cos(0)=1\).
\end{proof}

\begin{lemma}
    Nous avons la formule
    \begin{equation}        \label{EQooRVPJooTMwNTU}
        e^{ix}=\cos(x)+i\sin(x)
    \end{equation}
    pour tout \( x\in \eR\).
\end{lemma}

\begin{proof}
    Il faut partir de la définition de l'exponentielle \eqref{EqEIGZooKWSvPS}, et remarquer que \( i^k\) vaut \( 1\), \( i\), \( -1\), \( -i\). Donc un terme sur deux est imaginaire pur et parmi ceux-là, un sur deux est positif. À bien y regarder, les termes imaginaires purs forment la série du sinus et ceux réels la série du cosinus.
\end{proof}

\begin{lemma}
    Nous avons les formules d'addition d'angles
    \begin{subequations}
        \begin{align}
            \cos(a+b)=\cos(a)\cos(b)-\sin(a)\sin(b)\\
            \sin(a+b)=\cos(a)\sin(b)+\sin(a)\cos(b).
        \end{align}
    \end{subequations}
    pour tout \( a\), \( b\) réels.
\end{lemma}

\begin{proof}
    Nous utilisons la formule d'addition dans l'exponentielle, proposition \eqref{EQooVFXUooBfwjJY} et la formule \eqref{EQooRVPJooTMwNTU} avant de séparer les parties réelles et imaginaires :
    \begin{equation}
        e^{i(a+b)}= e^{ia} e^{ib}=\cos(a)\cos(b)-\sin(a)\sin(b)+i\big( \cos(a)\sin(b)+\sin(a)\cos(b) \big).
    \end{equation}
    Cela est également égal à
    \begin{equation}
        \cos(a+b)+i\sin(a+b).
    \end{equation}
    En identifiant les parties réelle et imaginaires, nous obtenons les formules annoncées.
\end{proof}

\begin{proposition}
    La fonction \( \cos\) est périodique et le nombre \( T>0\) est une période si et seulement si \( \cos(T)=1\) et \( \sin(T)=0\).
\end{proposition}

\begin{proof}
    Plusieurs étapes.
    \begin{subproof}
        \item[La fonction cosinus n'est pas toujours positive]
    Supposons d'abord que \( \cos(x)>0\) pour tout \( x\in \eR\). Dans ce cas, la fonction \( \sin\) est strictement croissante. Mais les deux fonctions sont bornées par \( 1\) du fait de la formule \( \cos^2(x)+\sin^2(x)=1\). La fonction \( \sin\) étant croissante et bornée, elle est convergente vers un réel par la proposition \ref{PropMTmBYeU} :
    \begin{equation}
        \lim_{x\to \infty} \sin(x)=\ell
    \end{equation}
    pour un certain \( \ell>0\). Avec ça nous avons aussi (pour cause de dérivée) \( \lim_{x\to \infty} \sin'(x)=0\), c'est à dire \( \lim_{x\to \infty} \cos(x)=0\). Mais vu que \( \cos^2(x)+\sin^2(x)=1\) nous avons \( \lim_{x\to \infty} \sin(x)=1\). Mézalor \( \lim_{x\to \infty} \cos'(x)=-1\), ce qui donne que la fonction \( \cos\) n'est pas bornée. Cela est impossible. Nous en déduisons que \( \cos(x)\) n'est pas toujours positive.
    \end{subproof}

\end{proof}
<++>

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Cercle trigonométrique}
%---------------------------------------------------------------------------------------------------------------------------

Le \href{http://fr.wikiversity.org/wiki/Trigonométrie/Cosinus_et_sinus_dans_le_cercle_trigonométrique}{cercle trigonométrique} est le cercle de rayon $1$ représenté à la figure \ref{LabelFigCercleTrigono}. Sa longueur est $2\pi$.
\newcommand{\CaptionFigCercleTrigono}{Le cercle trigonométrique.}
\input{auto/pictures_tex/Fig_CercleTrigono.pstricks}

Nous verrons plus tard que la longueur de l'arc de cercle intercepté par un angle $\theta$ est égal à $\theta$. Les radians sont donc l'unité d'angle les plus adaptés au calcul de longueurs sur le cercle. 

%TODO : remettre ce lien après le fork
%Voir exercice \ref{exoGeomAnal-0034}.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Les fonctions sinus et cosinus}
%---------------------------------------------------------------------------------------------------------------------------

La longueur de la projection du point $P$ sur la droite horizontale va naturellement être égale à $\cos(\theta)$. En effet, si nous notons $X$ un vecteur horizontal de norme $1$, cette projection est donné par $P\cdot X$. Mais en reprenant l'équation \eqref{eqPropCosThet}, nous voyons que
\begin{equation}
	P\cdot X=\| P \|\| X \|\cos(\theta),
\end{equation}
tandis qu'ici nous avons $\| P \|=\| X \|=1$.

Nous appelons $\sin(\theta)$ la longueur de la projection sur l'axe vertical.

Quelques dessins nous convainquent que 
\begin{equation}
	\begin{aligned}[]
		\sin(\theta+2\pi)&=\sin(\theta)&\cos(\theta+2\pi)&=\sin(\theta),\\
		\sin(\theta+\frac{ \pi }{2})&=\cos(\theta)&\cos(\theta+\frac{ \pi }{2})&=-\sin(\theta),\\
		\sin(\pi-\theta)&=\sin(\theta)&\cos(\pi-\theta)&=-\cos(\theta).
	\end{aligned}
\end{equation}
Le théorème de Pythagore nous montre aussi l'importante relation
\begin{equation}
	\sin^2(\theta)+\cos^2(\theta)=1.
\end{equation}

Quelques valeurs remarquables pour les sinus et cosinus :
\begin{equation}
	\begin{aligned}[]
		\sin 0&=0,&\sin\frac{ \pi }{ 6 }&=\frac{ 1 }{2},&\sin\frac{ \pi }{ 4 }&=\frac{ \sqrt{2} }{2},&\sin\frac{ \pi }{ 3 }&=\frac{ \sqrt{3} }{2},&\sin\frac{ \pi }{2}&=1,&\sin\pi&=0\\
		\cos 0&=1,&\cos\frac{ \pi }{ 6 }&=\frac{ \sqrt{3} }{2},&\cos\frac{ \pi }{ 4 }&=\frac{ \sqrt{2} }{2},&\cos\frac{ \pi }{ 3 }&=\frac{ 1 }{2},&\cos\frac{ \pi }{2}&=0,&\cos\pi&=-1
	\end{aligned}
\end{equation}

Nous pouvons prouver simplement que $\sin(\unit{30}{\degree})=\frac{ 1 }{2}$ et $\cos(\unit{30}{\degree})=\frac{ \sqrt{3} }{2}$ en s'inspirant de la figure \ref{LabelFigGVDJooYzMxLW}. % From file GVDJooYzMxLW
\newcommand{\CaptionFigGVDJooYzMxLW}{Un triangle équilatéral de côté $1$.}
\input{auto/pictures_tex/Fig_GVDJooYzMxLW.pstricks}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{La fonction tangente}
%---------------------------------------------------------------------------------------------------------------------------

La définition de la \defe{tangente}{tangente} est :
\begin{equation}
	\tan\theta=\frac{ \sin\theta }{ \cos\theta }.
\end{equation}
Cette fonction a une interprétation géométrique donnée sur la figure \ref{LabelFigTgCercleTrigono}.
\newcommand{\CaptionFigTgCercleTrigono}{Interprétation géométrique de la fonction tangente. La tangente de l'angle $\theta$ est positive (et un peu plus grande que $1$) tandis que celle de la tangente de l'angle $\varphi$ est négative.}
\input{auto/pictures_tex/Fig_TgCercleTrigono.pstricks}

La restriction de la fonction tangente à l'intervalle $\mathopen] -\frac{ \pi }{2} , \frac{ \pi }{2} \mathclose[$ est une bijection vers $\eR$. Nous avons donc une fonction inverse
\begin{equation}
	\begin{aligned}
		\tan^{-1}\colon \eR&\to \mathopen] -\frac{ \pi }{2} , \frac{ \pi }{2} \mathclose[ \\
        x&\mapsto y \text{ tel que } \tan(y)=x.
	\end{aligned}
\end{equation}
Notez que cette définition, bien qu'elle ait un sens, ne dit pas comment \emph{calculer} le nombre $\tan^{-1}(x)$ pour un nombre $x$ donné\footnote{Si vous utilisez votre calculatrice, n'oubliez pas que les formules que vous connaissez ne sont valables qu'en radian.}.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Les coordonnées polaires}
%---------------------------------------------------------------------------------------------------------------------------

On a vu qu'un point $M$ dans $\eR^2$ peut être représenté par ses abscisses $x$ et ses ordonnées $y$. Nous pouvons également déterminer le même point $M$ en donnant un angle et une distance comme montré sur la figure \ref{LabelFigJWINooSfKCeA}.
\newcommand{\CaptionFigJWINooSfKCeA}{Un point en coordonnées polaires est donné par sa distance à l'origine et par l'angle qu'il faut avec l'horizontale.}
\input{auto/pictures_tex/Fig_JWINooSfKCeA.pstricks}


Le même point $M$ peut être décrit indifféremment avec les coordonnées $(x,y)$ ou bien avec $(r,\theta)$.

\begin{remark}
	L'angle $\theta$ d'un point n'étant a priori défini qu'à un multiple de $2\pi$ près, nous convenons de toujours choisir un angle $0\leq\theta<2\pi$. Par ailleurs l'angle $\theta$ n'est pas défini si $(x,y)=(0,0)$.

	La coordonnée $r$ est toujours positive.
\end{remark}

En utilisant la trigonométrie, il est facile de trouver le changement de variable qui donne $(x,y)$ en fonction de $(r,\theta)$:
\begin{subequations}		\label{EqrthetaxyPoal}
	\begin{numcases}{}
		x=r\cos(\theta)\\
		y=r\sin(\theta).
	\end{numcases}
\end{subequations}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Transformation inverse : théorie}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Voyons la question inverse : comment retrouver $r$ et $\theta$ si on connais $x$ et $y$ ? Tout d'abord,
\begin{equation}
	r=\sqrt{x^2+y^2}
\end{equation}
parce que la coordonnée $r$ est la distance entre l'origine et $(x,y)$. Comment trouver l'angle ? Nous supposons $(x,y)\neq (0,0)$. Si $x=0$, alors le point est sur l'axe vertical et nous avons
\begin{equation}
	\theta=\begin{cases}
		\pi/2	&	\text{si }y>0\\
		3\pi/2	&	 \text{si }y<0
	\end{cases}
\end{equation}
Notez que si $y<0$, conformément à notre convention $\theta\geq 0$, nous avons noté $\frac{ 3\pi }{2}$ et non $-\frac{ \pi }{ 2 }$.

Supposons maintenant le cas général avec $x\neq 0$. Les équations \eqref{EqrthetaxyPoal} montrent que
\begin{equation}
	\tan(\theta)=\frac{ y }{ x }.
\end{equation}
Nous avons donc
\begin{equation}
	\theta=\tan^{-1}\left( \frac{ y }{ x } \right).
\end{equation}
La fonction inverse de la fonction tangente est celle définie plus haut.

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Transformation inverse : pratique}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Le code suivant utilise \href{http://www.sagemath.org}{Sage}.

\lstinputlisting{tex/frido/calculAngle.py}

Son exécution retourne :
\begin{verbatim}
(sqrt(2), 1/4*pi)
(sqrt(5), pi - arctan(1/2))
(6, 1/6*pi)
\end{verbatim}
Notez que ce sont des valeurs \emph{exactes}. Ce ne sont pas des approximations, ce logiciel travaille de façon symbolique ! Merci donc de jeter vos vieilles calculatrices à la poubelle\footnote{Pensez au recyclage : c'est plein de métaux lourds !} : c'est de la technologie qui n'a plus cours en 2011.


%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Rappels de trigonométrie}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\label{secHTVooJuBtam}

Dans ce cours tous les angles sont exprimés en radiants. 

\begin{definition}
  La fonction \defe{tangente}{tangente} est la fonction
  \begin{equation}
      \begin{aligned}
          \tan\colon \eR\setminus \eZ\pi&\to \eR \\
          x&\mapsto \frac{ \sin(x) }{ \cos(x) }. 
      \end{aligned}
  \end{equation}
\end{definition} 
  
\begin{proposition}
    Quelque propriétés de la fonction tangente.
    \begin{enumerate}
        \item
            L'image de la fonction tangente est $\eR$. 
        \item
            La fonction tangente est périodique, de période $\pi$.
        \item
            Son graphe est un réunion dénombrable de courbes disjointes, voir la figure \ref{LabelFigPVJooJDyNAg}. 
    \end{enumerate}
\end{proposition}

Voici un tableau qui rappelle les valeurs à retenir pour les fonctions sinus, cosinus et tangente.
\begin{equation*}
    \begin{array}[]{|c|c|c|c|}
      \hline
      x&\sin(x)&\cos(x)&\tan(x)\\
      \hline
      0&0&1&0\\
      \hline
      \pi/6&1/2&\sqrt{3}/2&\sqrt{3}/3\\
      \hline
      \pi/6&1/2&\sqrt{3}/2&\sqrt{3}/3\\
      \hline
      \pi/4&\sqrt{2}/2&\sqrt{2}/2&1\\
      \hline
      \pi/3&\sqrt{3}/2&1/2&\sqrt{3}\\
      \hline
      \pi/2&1&0&\text{N.D.}\\
      \hline
    \end{array}
\end{equation*}
où «N.D.»  signifie «non défini».

Rappelons le graphe de la fonction sinus :
\begin{center}
   \input{auto/pictures_tex/Fig_TWHooJjXEtS.pstricks}
\end{center}
celui de la fonction cosinus :
\begin{center}
   \input{auto/pictures_tex/Fig_JJAooWpimYW.pstricks}
\end{center}

The result is on figure \ref{LabelFigPVJooJDyNAg}. % From file PVJooJDyNAg
\newcommand{\CaptionFigPVJooJDyNAg}{<+Type your caption here+>}
\input{auto/pictures_tex/Fig_PVJooJDyNAg.pstricks}

Nous allons donner une preuve géométrique de la limite remarquable (vue en terminale) 
\begin{equation}\label{sinsurx}
  \lim_{x\to 0} \frac{\sin(x)}{x} = 1.
\end{equation}
Cette preuve peut vous servir pour reviser la signification géométrique des fonction trigonométriques et leur propriétés de base. 
\begin{description}
  \item{Première étape : } On montre que 
    \begin{lemma}
      Pour toute valeur de $x\in \eR$ on a $|\sin(x)|\leq |x|$. 
    \end{lemma}
    \begin{itemize}
    \item Si $0\leq x\leq \pi/2$ alors le sinus de $x$ est la longueur du cathète verticale du triangle rectangle de sommets $O = (0,0)$, $A = (\cos(x), \sin(x))$ et $B = (\cos(x), 0)$. Le triangle de sommets $A$, $B$ et $C = (1, 0)$ est aussi rectangle et nous savons que chacun des cathètes ne peut pas \^etre plus long que l'hypoténuse. Donc $\sin(x)$ est inférieur à la longueur du segment $AC$. À son tour le segment $AC$ ne peut pas \^etre plus long que l'arc de cercle $\wideparen{A0C}$, car le chemin le plus court entre deux points du plan est toujours donné par un morceau de droite. La longueur de l'arc du cercle $\frown{AC}$ est \emph{par définition} la mesure en radiants de l'angle $\widehat{AOC}$, qui est $x$ et on a l'inégalité $\sin(x)\leq x$. 
    \item Si $-\pi/2\leq x\leq 0$ le m\^eme raisonnement que au point précedent permet de conclure que $\sin(x)\leq |x|$.
    \item Nous savons par ailleurs que la fonction sinus prend ses valeurs dans l'intervalle $[-1,1]$ et donc pour tout $x$ tel que $|x|\geq \pi/2 \equiv 1,57\ldots$ on a forcement $|\sin(x)|\leq |x|$.  
    \end{itemize}
  \item{Deuxième étape :} On commence par observer que la fonction $g(x)=\frac{\sin(x)}{x}$ est un rapport entre deux fonction impairers et est donc une fonction paire. Nous pouvons alors nous réduire à considèrer le cas où $x$ est positif. La première étape de cette preuve nous dit que $g(x)\leq 1$ pour tout $x\in\eR^{+,*}$. 

Nous voulons étudier le comportement de $g$ dans un voisinage de $0$. Nous pouvons alors supposer que $x$ soit inférieur à $\pi/2$. Soit $D = (1, \tan (x))$. On voit très bien dans le dessin que l'aire du triange de sommets $O$, $D$ et $C$ est supérieure à l'aire du secteur circulaire de sommets $O$, $A$ et $C$. Ces deux aires peuvent \^etre calculées très facilement et nous obtenons
\begin{equation*}
  \frac{\sin(x)}{2\cos(x)} \geq \frac{x}{2}.
\end{equation*}
À partir de cette dernière inégalité nous pouvons écrire 
\begin{equation*}
  1\geq \frac{\sin(x)}{x}\geq \cos(x).
\end{equation*}
En prenant la limite lorsque $x$ tend vers $0$ dans les trois membres de l'inégalité la règle de l'étau nous permet d'obtenir la limite remarquable  \eqref{sinsurx}. 
\end{description}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{La fonction arc sinus}
%---------------------------------------------------------------------------------------------------------------------------

Nous voulons étudier la fonction
\begin{equation}
    \begin{aligned}
        \sin\colon \eR&\to \mathopen[ -1 , 1 \mathclose] \\
        x&\mapsto \sin(x) 
    \end{aligned}
\end{equation}
et sa réciproque éventuelle.

La fonction sinus est continue sur \( \eR\) mais n'est pas bijective : elle prend une infinité de fois chaque valeur de \( J=\mathopen[ -1 , 1 \mathclose]\). Pour définir une bijection réciproque de la fonction sinus en utilisant le théorème \ref{ThoKBRooQKXThd}, nous devons donc choisir un intervalle à partir duquel la fonction sinus est monotone. Nous choisissons l'intervalle
\begin{equation}
    I=\mathopen[ -\frac{ \pi }{ 2 } , \frac{ \pi }{2} \mathclose].
\end{equation}
La fonction
\begin{equation}
    \begin{aligned}
        \sin\colon \mathopen[ -\frac{ \pi }{2} , \frac{ \pi }{2} \mathclose]&\to \mathopen[ -1 , 1 \mathclose] \\
        x&\mapsto \sin(x) 
    \end{aligned}
\end{equation}
est une bijection croissante et continue. Nous avons donc le résultat suivant.
\begin{theorem}[Définition et propriétés de arc sinus]
    Nous nommons \defe{arc sinus}{arc sinus} la bijection inverse de la fonction \( \sin\colon I\to J\). La fonction
    \begin{equation}
        \begin{aligned}
            \arcsin\colon \mathopen[ -1 , 1 \mathclose]&\to \mathopen[ -\frac{ \pi }{2} , \frac{ \pi }{2} \mathclose] \\
            x&\mapsto \arcsin(x) 
        \end{aligned}
    \end{equation}
    ainsi définie est
    \begin{enumerate}
        \item
            continue et strictement croissante;
        \item
            impaire : pour tout \( x\in\mathopen[ -1 , 1 \mathclose]\) nous avons \( \arcsin(-x)=-\arcsin(x)\).
    \end{enumerate}
\end{theorem}

\begin{proof}
    Nous prouvons le fait que \( \arcsin\) est impaire. Un élément de l'ensemble de définition de \( \arcsin\) est de la forme \( y=\sin(x)\) avec \( x\in\mathopen[ -\pi/2 , \pi/2 \mathclose]\). La relation \eqref{EqHQRooNmLYbF} s'écrit dans notre cas
    \begin{equation}    \label{EqVUWooUwVxVp}
        x=\arcsin\big( \sin(x) \big).
    \end{equation}
    Nous écrivons d'une part cette équation avec \( -x\) au lieu de \( x\) :
    \begin{equation}    \label{EqRLYooIwOvSz}
        -x=\arcsin\big( \sin(-x) \big)=\arcsin\big( -\sin(x) \big)=\arcsin(-y);
    \end{equation}
    et d'autre part nous multiplions \eqref{EqVUWooUwVxVp} par \( -1\) :
    \begin{equation}    \label{EqTGIooDeRYyT}
        -x=-\arcsin\big( \sin(x) \big)=-\arcsin(y).
    \end{equation}
    En égalisant les valeurs \eqref{EqRLYooIwOvSz} et \eqref{EqTGIooDeRYyT} nous trouvons
    \begin{equation}
        \arcsin(-y)=-\arcsin(y),
    \end{equation}
    ce qui signifie que \( \arcsin\) est une fonction impaire.
\end{proof}
Notons que cette preuve repose sur le fait que tout élément de l'ensemble de définition de la fonction arc sinus peut être écrit sous la forme \( \sin(x)\) pour un certain \( x\).

Si \( x_0\in\mathopen[ -1 , 1 \mathclose]\) est donné, calculer \( \arcsin(x_0)\) revient à trouver un angle \( \theta_0\) dans \( \mathopen[ -\frac{ \pi }{2} , \frac{ \pi }{2} \mathclose]\) pour lequel \( \sin(\theta_0)=x_0\). Un tel angle sera forcément unique.

\begin{remark}
  La définition de arc sinus découle du choix de l'intervalle $I$, qui est une convention. Il aurait été possible de faire un choix différent : pourriez vous trouver la réciproque de la fonction sinus sur l'intervalle $[\pi/2, 3\pi/2]$ ? Le mieux est de l'écrire comme une translatée de arc sinus, en utilisant le fait que sinus est une fonction périodique. 
\end{remark}

\begin{example}
    Pour calculer \( \arcsin(1)\), il faut chercher un angle entre \( -\frac{ \pi }{2}\) et \( \frac{ \pi }{ 2 }\) ayant \( 1\) pour sinus : résoudre \( \sin(\theta)=1\). La solution est \( \theta=\frac{ \pi }{2}\) et nous avons donc \( \arcsin(1)=\frac{ \pi }{2}\).
\end{example}

À l'aide des valeurs remarquables de la fonction sinus nous obtenons le tableau suivant de valeurs remarquables pour l'arc sinus.
\begin{equation*}
    \begin{array}[]{|c|c|c|c|c|c|}
        \hline
        x&0&\frac{ 1 }{2}&\frac{ \sqrt{2} }{2}&\frac{ \sqrt{3} }{2}&1\\
          \hline
          \arcsin(x)&0&\frac{ \pi }{ 6 }&\frac{ \pi }{ 4 }&\frac{ \pi }{ 3 }&\frac{ \pi }{ 2 }\\ 
          \hline 
           \end{array}
\end{equation*}
Les autres valeurs remarquables peuvent être déduites du fait que l'arc sinus est une fonction impaire.

En ce qui concerne la dérivabilité de la fonction arc sinus, en application de la proposition \ref{PropMRBooXnnDLq} elle est dérivable en tout \( y=\sin(x)\) tel que \( \sin'(x)\neq 0\), c'est à dire tel que \( \cos(x)\neq 0\). Or \( \cos(x)=0\) pour \( x=\pm\frac{ \pi }{2}\), ce qui correspond à \( y=\sin(\pm\frac{ \pi }{2})=\pm 1\). La fonction arc sinus est donc dérivable sur \( \mathopen] -1 , 1 \mathclose[\). Nous avons donc la propriété suivante pour la dérivabilité.

\begin{proposition}
    La fonction arc sinus est continue sur \( \mathopen[ -1 , 1 \mathclose]\) et dérivable sur \( \mathopen] -1 , 1 \mathclose[\). Pour tout \( y\in\mathopen] -1 , 1 \mathclose[\), la dérivée est donnée par la formule \eqref{EqWWAooBRFNsv}, qui dans ce cas s'écrit
        \begin{equation}
            \arcsin'(y)=\frac{1}{ \cos\big( \arcsin(y) \big) }=\frac{1}{ \sqrt{1-y^2} }.
        \end{equation}
\end{proposition}
La dernière égalité viens du fait que si $x=\arcsin(y)$ alors $y = \sin(x)$ et $\cos(x)= \sqrt{1-\sin^2(x)} = \sqrt{1-y^2}$. 

Pour comprendre la dernière égalité, remarquer que dans le dessin suivant, \( \theta=\arcsin(y)\), donc $y = \sin(\theta)$, et \( x=\cos(\theta)\).
\begin{center}
    \input{auto/pictures_tex/Fig_BIFooDsvVHb.pstricks}
\end{center}

Notons enfin que le graphe de la fonction arc sinus est donné à la figure \ref{LabelFigFGRooDhFkch}. % From file FGRooDhFkch
\newcommand{\CaptionFigFGRooDhFkch}{Le graphe de la fonction \( x\mapsto \arcsin(x)\)}
\input{auto/pictures_tex/Fig_FGRooDhFkch.pstricks}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{La fonction arc cosinus}
%---------------------------------------------------------------------------------------------------------------------------

Nous voulons étudier la fonction
\begin{equation}
    \begin{aligned}
        \cos\colon \eR&\to \mathopen[ -1 , 1 \mathclose] \\
        x&\mapsto \cos(x) 
    \end{aligned}
\end{equation}
et son éventuelle réciproque. Encore une fois il n'est pas possible d'en prendre la réciproque globale parce que ce n'est pas une bijection. Nous choisissons de considérer l'intervalle \( \mathopen[ 0 , \pi \mathclose]\) sur lequel la fonction cosinus est continue et strictement monotone décroissante.

Nous avons alors le résultat suivant :

\begin{proposition}
    La fonction
    \begin{equation}
        \begin{aligned}
            \cos\colon \mathopen[ 0 , \pi \mathclose]&\to \mathopen[ -1 , 1 \mathclose] \\
            x&\mapsto \cos(x) 
        \end{aligned}
    \end{equation}
    est une bijection continue strictement décroissante. Sa bijection réciproque, nommée \defe{arc cosinus}{arc cosinus}
    \begin{equation}
        \begin{aligned}
            \arccos\colon \mathopen[ -1 , 1 \mathclose]&\to \mathopen[ 0 , \pi \mathclose] \\
            x&\mapsto \arccos(x) 
        \end{aligned}
    \end{equation}
est continue, strictement décroissante et dérivable. Pour tout \( y\in\mathopen] -1 , 1 \mathclose[\), sa dérivée est donnée par
    \begin{equation}
        \arccos'(y)=\frac{1}{ -\sin\big( \arccos(y) \big) }=\frac{ -1 }{ \sqrt{1-y^2} }.
    \end{equation}
\end{proposition}

\begin{remark}
    Certes la fonction cosinus est paire (vue sur \( \eR\)), mais la fonction arc cosinus ne l'est pas car elle est une bijection entre \(\mathopen[ -1 , 1 \mathclose]\) et \(\mathopen[ 0 , \pi \mathclose]\).
\end{remark}

Pour \( y_0\in\mathopen[ -1 , 1 \mathclose]\), trouver la valeur de \( \arccos(y_0)\) revient à résoudre l'équation \( \cos(x_0)=y_0\). Cela nous permet de construire une tableau de valeurs :
\begin{equation*}
    \begin{array}[]{|c|c|c|c|c|c|c|c|c|c|}
        \hline
        x&-1&-\frac{ \sqrt{3} }{2}&-\frac{ \sqrt{2} }{2}&-\frac{ 1 }{2}&0&\frac{ 1 }{2}&\frac{ \sqrt{2} }{2}&\frac{ \sqrt{3} }{2}&1\\
          \hline
          \arccos(x)&\pi&\frac{ 5\pi }{ 6 }&\frac{ 3 }{ 4 }\pi&\frac{ 2 }{ 3 }\pi&\frac{ 1 }{2}\pi&\frac{ \pi }{ 3 }&\frac{1}{ 4 }\pi&\frac{1}{ 6 }\pi&0\\
          \hline 
           \end{array}
\end{equation*}

\begin{example}
    Cherchons \( \arccos(\frac{ 1 }{2})\). Il faut trouver un angle \( \theta\in\mathopen[ 0 , \pi \mathclose]\) tel que \( \cos(\theta)=\frac{ 1 }{2}\). La solution est \( \theta=\frac{ \pi }{ 3 }\). Donc \( \arccos(\frac{ 1 }{2})=\frac{ \pi }{ 3 }\).

    Il n'est cependant pas immédiat d'en déduire la valeur de \( \arccos(-\frac{ 1 }{2})\). En effet \( \theta=\arccos(-\frac{ 1 }{2})\) si et seulement si \( \cos(\theta)=-\frac{ 1 }{2}\) avec \( \theta\in\mathopen[ 0 , \pi \mathclose]\). La solution est \( \theta=\frac{ 2\pi }{ 3 }\).
\end{example}

En ce qui concerne la représentation graphique, il suffit de tracer la fonction cosinus entre \( 0\) et \( \pi\) puis de prendre le symétrique par rapport à la droite \( y=x\).

\begin{center}
    \input{auto/pictures_tex/Fig_GMIooJvcCXg.pstricks}
\end{center}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{La fonction arc tangente}
%---------------------------------------------------------------------------------------------------------------------------

La fonction tangente est donnée par la formule
\begin{equation}
    \tan(x)=\frac{ \sin(x) }{ \cos(x) }
\end{equation}
et n'est pas définie sur les points de la forme \( x=\frac{ \pi }{2}+k\pi\), \( k\in \eZ\). Afin de définir une bijection réciproque nous considérons l'intervalle \( \mathopen] -\frac{ \pi }{2} , \frac{ \pi }{2} \mathclose[\) (qui est ouvert, contrairement aux intervalles choisis pour arc cosinus et arc sinus). Le résultat est le suivant.

\begin{theorem}     \label{THOooUSVGooOAnCvC}
    La fonction
    \begin{equation}
        \begin{aligned}
        \tan\colon \left] -\frac{ \pi }{2} , \frac{ \pi }{2} \right[&\to \eR \\
            x&\mapsto \tan(x) 
        \end{aligned}
    \end{equation}
    est une bijection strictement croissante.

    La bijection réciproque 
    \begin{equation}
        \begin{aligned}
        \arctan\colon \eR&\to \left] -\frac{ \pi }{2} , \frac{ \pi }{2} \right[ \\
            x&\mapsto \arctan(x) 
        \end{aligned}
    \end{equation}
    nommée \defe{arc tangente}{arc tangente} est
    \begin{enumerate}
        \item
            impaire et strictement croissante sur \( \eR\).
        \item       \label{ITEMooMNHLooOVhIIb}
            dérivable sur \( \eR\) de dérivée
            \begin{equation}
                \arctan'(x)=\frac{1}{ 1+\tan^2\big( \arctan(x) \big) }=\frac{1}{ 1+x^2 }.
            \end{equation}
    \end{enumerate}
\end{theorem}
Note : la dernière ligne n'a rien de mystérieux : \( \tan\big( \arctan(x) \big)=x\) et donc \( \tan^2\big( \arctan(x) \big)=x^2\).    

En ce qui concerne la dérivabilité nous savons que
\begin{equation}
    \tan'(x)=1+\tan^2(x) ,
\end{equation}
qui ne s'annule pour aucune valeur de \( x\); c'est pour cela que \( \arctan\) est dérivable sur tout \( \eR\).

Le nombre \( \arctan(x_0)\) se calcule en cherchant l'angle \( \theta\in\mathopen[ -\frac{ \pi }{2} , \frac{ \pi }{2} \mathclose]\) dont la tangente vaut \( x_0\). Nous obtenons le tableau de valeurs suivant :
\begin{equation*}
    \begin{array}[]{|c|c|c|c|c|}
        \hline
        x&0&\frac{1}{ \sqrt{3} }&1&\sqrt{3}\\
        \hline
        \arctan(x)&0&\frac{ \pi }{ 6 }&\frac{ \pi }{ 4 }&\frac{ \pi }{ 3 }\\
        \hline
    \end{array}
\end{equation*}

En ce qui concerne la représentation graphique de la fonction \( x\mapsto\arctan(x)\), elle s'obtient «en retournant» la partie entre \( -\frac{ \pi }{2}\) et \( \frac{ \pi }{ 2 }\) du graphique de la fonction tangente (voir les rappels \ref{secHTVooJuBtam}).
\begin{center}
   \input{auto/pictures_tex/Fig_UQZooGFLNEq.pstricks}
\end{center}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Forme polaire ou trigonométrique des nombres complexes}
%---------------------------------------------------------------------------------------------------------------------------

Dans le plan de Gauss, le module d'un complexe $z$ représente la distance entre $0$ et $z$. On appelle \Defn{argument} de $z$ (noté $\arg z$) l'angle (déterminé à $2\pi$ près) entre le demi-axe des réels positifs et la demi-droite qui part de $0$ et passe par $z$. Le module et l'argument d'un complexe permettent de déterminer univoquement ce complexe puisqu'on a la formule
\[z = a + bi = \module z \left( \cos(\arg(z)) + i \sin(\arg(z)) \right)\]

L'argument de $z$ se détermine via les formules 
\[\frac a {\module z} = \cos(\arg(z)) \quad \frac b {\module z} = \sin(\arg(z))\]
ou encore par la formule
\[
\frac b a = \tan(\arg(z)) \quad \text{en vérifiant le quadrant.}
\]
La vérification du quadrant vient de ce que la tangente ne détermine l'angle qu'à $\pi$ près.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Vitesses de $x^{\alpha}$, de l'exponentielle et du logarithme}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{lemma}   \label{LemSYHKooUiSMFJ}
    Pour tout \( \alpha>0\), il existe \( N\) tel que \( \ln(n)\leq n^{\alpha}\) pour tout \( n\geq N\).
\end{lemma}

\begin{proof}
En effet, nous avons
\begin{equation}
    \lim_{x\to\infty} \frac{ x^{\alpha} }{ \ln(x) }=\lim_{x\to\infty} \frac{ \alpha x^{\alpha-1} }{ 1/x }=\lim_{x\to\infty} \alpha x^{\alpha}=\infty
\end{equation}
quand $\alpha>0$. 
\end{proof}
Cela tient également lorsque nous considérons $\ln(x)^p$ au lieu de $\ln(x)$. De cela, nous disons que le logarithme croit moins vite que n'importe quel polynôme. 

\begin{lemma}
    L'exponentielle croit plus vite que tout polynôme, et plus vite que que logarithme :
    \begin{equation}        \label{EqExpDecrtPlusVite}
        \lim_{t\to\infty} e^{-t}(\ln t)^{n}t^{\alpha}=0
    \end{equation}
    pour tout $n$ et pour tout $\alpha$.
\end{lemma}

\begin{lemma}       \label{LemVKDKooEftNzG}
    Nous avons aussi la limite utile suivante 
    \begin{equation}
        \lim_{n\to \infty} n^{\alpha}a^n
    \end{equation}
    pour tout \( \alpha>0\) et \( a<1\).
\end{lemma}

\begin{proof}
    En passant à l'exponentielle, pour chaque \( n\) nous avons
    \begin{equation}        \label{EqLKLQooLIlWgm}
        n^{\alpha}a^n= e^{\alpha\ln(n)+n\ln(a)}.
    \end{equation}
    Ce qui est dans l'exponentielle est
    \begin{equation}
        \alpha\ln(n)+n\ln(a)=n\big(\alpha \frac{ \ln(n) }{ n }+\ln(a) \big).
    \end{equation}
    Dans la parenthèse, \( \ln(a)<0\) et \( \frac{ \ln(n) }{ n }\to 0\). Donc ce qui est dans l'exponentielle \eqref{EqLKLQooLIlWgm} tend vers \( -\infty\) et au final l'expression demandée tend vers zéro.
\end{proof}

\begin{proposition} \label{PropBQGBooHxNrrf}
    Pour tout polynôme \( P\) et pour tout \( a>0\) la fonction \( f(x)=P(x) e^{-ax}\) est intégrable\footnote{Définition \ref{DefTCXooAstMYl}.} sur \( \mathopen[ 0 , \infty [\).
\end{proposition}

\begin{proof}
    Nous avons \( f(x)=P(x) e^{-ax/2} e^{-ax/2}\), et par la vitesse comparée des exponentielles et polynômes, pour un certain \( M>0\) nous pouvons affirmer que \( P(x) e^{-ax/2}<1\) sur \( \mathopen[ M , 0 [\). Dès lors
        \begin{equation}
            | f(x) |< e^{-ax/2},
        \end{equation}
        qui est intégrable.
\end{proof}


%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Dénombrement des solutions d'une équation diophantienne}
%---------------------------------------------------------------------------------------------------------------------------

\begin{theorem}[\cite{fJhCTE,NHXUsTa}] \label{ThoDIDNooUrFFei}
    Soient des entiers naturels premiers dans leur ensemble\footnote{Définition \ref{DefZHRXooNeWIcB}.} \( \alpha_1,\ldots, \alpha_p\) et l'équation
    \begin{equation}
        \alpha_1n_1+\cdots +\alpha_pn_p=n
    \end{equation}
    pour les naturels \( n_i\) où \( n\) est un naturel donné. Nous notons \( S_n\) le nombre de solutions de cette équation. Alors :
    \begin{enumerate}
        \item
            Il existe un algorithme (en temps fini) pour calculer \( S_n\) en fonction des \( \alpha_i\) et de \( n\).
        \item
            Nous avons le comportement asymptotique
            \begin{equation}
                S_n\sim\frac{1}{ \alpha_1\ldots\alpha_p }\frac{ n^{p-1} }{ (p-1)! }.
            \end{equation}
    \end{enumerate}
\end{theorem}

\begin{proof}
    Pour \( | z |<1\) dans \( \eC\), utilisant le lemme \ref{LemPQFDooGUPBvF}, nous écrivons le développement
    \begin{equation}
        F(z)=\prod_{i=1}^p\frac{1}{ 1-z^{\alpha_i} }=\prod_{i=1}^p\sum_{n\geq 0}z^{n\alpha_i}.
    \end{equation}
    Nous allons maintenant à la pêche au terme de degré \( k\) dans ce produit de sommes en utilisant \( p\) fois le produit de Cauchy de la formule \eqref{EqFPGGooDQlXGe}. Nous avons
    \begin{equation}
        F(z)=\sum_{k\geq 0}\left( \sum_{n_1\alpha_1+\cdots +n_p\alpha_p=n}1 \right)z^k=\sum_{k\geq 0}S_kz^k.
    \end{equation}
    
    La technique pour déterminer la valeur de \( S_n\) est alors de développer \( F(z)\) en série de façon un peu explicite et d'identifier le coefficient de \( z^n\) parce que nous venons de voir que ce coefficient est \( S_n\). Nous commençons par une décomposition en éléments simples, expliquée autour de l'équation \eqref{EqDWYBooJIMBAt} :
    \begin{equation}
        \frac{1}{ 1-z^{\alpha_i} }=\sum_{\alpha\in U_{\alpha_i}}\frac{ A_{\omega,i} }{ \omega-z }.
    \end{equation}
    où \( U_{\alpha_i}\) est le groupe des racines \( \alpha_i\)\ieme de l'unité décrit en \ref{SecGJOLooWdMYVl}. La raison de ce développement est que, comme mentionné dans le lemme \ref{LemKYGBooAwpOHD}, \( \prod_{\omega\in\gU_{\alpha_i}}(z-\omega)=z^{\alpha_1}-1\). Lorsque nous effectuons la somme, le dénominateur commun est donc bien\footnote{Pour le signe, c'est ajustable avec le signe de \( A_{\omega,i}\).} \( 1-z^{\alpha_i}\).
    En récrivant le produit :
    \begin{equation}
        F(z)=\prod_{i=1}^{p}\frac{1}{ 1-z^{\alpha_i} }=\prod_{i=1}^p\sum_{\omega\in U_{\alpha_i}}\frac{ A_{\omega,i} }{ \omega-z }
    \end{equation}
    Les coefficients \( A_{\omega,i}\) sont calculables explicitement, en temps fini.

    Vu que \( 1\) est dans tous les \( \gU_{\alpha_i}\), le produit fait intervenir au dénominateur des puissances de \( (1-z)\) jusqu'à la puissance \( p\). Les autres racines de l'unité appartiennent au maximum à \( p-1\) des groupes \( \gU_{\alpha_i}\) parce que les nombres \( \alpha_i\) sont premiers dans leur ensemble, voir la proposition \ref{PropFDDHooEyYxBC}.

    La fonction \( F\) peut alors s'écrire sous la forme
    \begin{equation}    \label{EqLISXooSlwIWD}
        F(z)=\frac{ A }{ (1-z)^p }+G(z)
    \end{equation}
    où \( G(z)\) est une somme de termes de la forme
    \begin{equation}
        \frac{ a_{i,1} }{ 1-\omega_i }+\cdots +\frac{ a_{i,p} }{ (1-\omega_i)^{p-1} }
    \end{equation}
    où les \( \omega_i\) sont les racines \( \alpha_i\)\ieme de l'unité et \( a_{k,r}\) sont des nombres complexes. Trouvons \( A\). D'abord grâce au lemme \ref{LemISPooHIKJBU}\ref{ItemLTBooAcyMtNii} nous avons
    \begin{equation}
        F(z)(1-z)^p=\prod_{l=1}^p\frac{ 1-z }{ 1-z^{\alpha_i} }=\prod_{i=1}^p\frac{ 1 }{ 1+z+\cdots +z^{\alpha_i-1} },
    \end{equation}
    et donc 
    \begin{equation}
        \lim_{z\to 1}F(z)(1-z)^p=\prod_{i=1}^p\frac{1}{ \alpha_i }.
    \end{equation}
    Mais vu ce que contient \( G(z)\), nous avons aussi \( \lim_{z\to 1}F(z)=A\). Nous avons donc déjà déterminé \( A=\frac{1}{  \alpha_1\ldots\alpha_p }\).

    Pour la suite nous avons besoin des développements du lemme \ref{LemPQFDooGUPBvF}. Nous utiliserons en particulier celle-ci :
    \begin{equation}
        \frac{1}{ (\omega-z)^k }=\frac{1}{ (k-1)! }\sum_{s=0}^{\infty}\omega^{-s-1-k}\frac{ (s+k-1)! }{ s! }z^s.
    \end{equation}
    En particulier le module du coefficient de \( z^n\) là dedans est : \(  \frac{(n+k-1)! }{ n!(k-1)! } \). Dans la partie \( G\) de la décomposition \eqref{EqLISXooSlwIWD}, \( k\) est majoré par \( p-2\) et la dépendance en \( n\) est donc au maximum du type
    \begin{equation}
        \frac{ (n+p-2)! }{ n!(p-2)! }\sim  \frac{ n^{n+p-2} }{ n^n(p-2)! }=\frac{ n^{p-2} }{ (p-2)! }.
    \end{equation}
    Dans le premier terme par contre, il y a des termes jusqu'à \( k=p\). Le terme dominant est alors en \( \frac{ n^{p-1} }{ (p-1)! }\) et son coefficient est \( A\) qui est déjà calculé. Au final le terme dominant du coefficient de \( z^n\) dans \( F(z)\) est
    \begin{equation}
        S_n\sim \frac{ A }{ (p-1)! }n^{p-1}=\frac{1}{ \alpha_1\ldots \alpha_p }\frac{ n^{p-1} }{ (p-1)! }.
    \end{equation}
\end{proof}

\begin{example}
    Pour \( p=1\), l'équation est \( \alpha x=n\), qui possède au maximum une solution, quel que soit \( n\). Et de plus pour avoir une solution il faut et suffit que \( \alpha\) divise \( n\), c'est à dire que \( n\) soit un multiple de \( \alpha\). Il n'y a que un nombre sur \( \alpha\) à être multiple de \( \alpha\). D'où le comportement en \( \frac{1}{ \alpha }\).

    Pour \( p=2\), c'est l'équation \eqref{EqTOVSooJbxlIq} déjà étudiée. Il y a une famille à un paramètre de solutions dont seulement un certain nombre sont positives. A priori, le nombre de solutions positives croît linéairement en \( n\).
\end{example}
