% This is part of Mes notes de mathématique
% Copyright (c) 2011-2017
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Exponentielle et logarithme}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

La méthode adoptée ici est la suivante :
\begin{itemize}
    \item L'exponentielle est définie par la série.
    \item Nous démontrons qu'elle vérifie l'équation différentielle \( y'=y\), \( y(0)=1\).
    \item Nous démontrons l'unicité de la solution à cette équation différentielle.
    \item Nous démontrons qu'elle est égale à \( x\mapsto y(1)^x\). Cela est une définition du nombre \( e=\) comme valant \( y(1)\).
    \item Nous définissons le logarithme comme l'application réciproque de l'exponentielle (définition \ref{DEFooELGOooGiZQjt}).
\end{itemize}

\begin{theorem}[Existence de l'exponentielle] \label{ThoKRYAooAcnTut}
    La série entière
    \begin{equation}    \label{EqEIGZooKWSvPS}
        y(x)=\sum_{k=0}^{\infty}\frac{ x^k }{ k! }
    \end{equation}
    définit une fonction dérivable solution de
    \begin{subequations}
        \begin{numcases}{}
            y'=y\\
            y(0)=1.
        \end{numcases}
    \end{subequations}
\end{theorem}
\index{exponentielle!existence}

\begin{proof}
    La formule de Hadamard (théorème \ref{ThoSerPuissRap}) donne le rayon de convergence de la série \eqref{EqEIGZooKWSvPS} par
    \begin{equation}
        \frac{1}{ R }=\lim_{k\to \infty} \frac{ \frac{1}{ (k+1)! } }{ \frac{1}{ k! } }=\lim_{k\to \infty} \frac{1}{ k+1 }=0.
    \end{equation}
    Donc nous avons un rayon de convergence infini. La fonction \( y\) est définie sur \( \eR\) et la proposition \ref{ProptzOIuG} nous dit que \( y\) est dérivable. Nous pouvons aussi dériver terme à terme :
    \begin{equation}
            y'(x)=\sum_{k=0}^{\infty}\frac{ kx^{k-1} }{ k! }=\sum_{k=1}^{\infty}\frac{ kx^{k-1} }{ k! }=\sum_{k=1}^{\infty}\frac{ x^{k-1} }{ (k-1)! }=\sum_{k=0}^{\infty}\frac{ x^k }{ k! }=y(x).
    \end{equation}
    Notez le petit jeu d'indice de départ de \( k\). Dans un premier temps, nous remarquons que \( k=0\) donne un terme nul et nous le supprimons, et dans un second temps nous effectuons la simplification des factorielles (qui ne fonctionne pas avec \( k=0\)).
\end{proof}

Pour la suite nous notons \( y\) une solution de l'équation \( y'=y\), \( y(0)=1\), et nous allons en donner des propriétés indépendamment de l'existence, donnée par le théorème \ref{ThoKRYAooAcnTut}.

\begin{proposition} \label{PropTLECooEiLbPP}
    Quelques propriétés de \( y\) (si elle existe) :
    \begin{enumerate}
        \item
            Pour tout \( x\in \eR\) nous avons \( y(x)y(-x)=1\).
        \item
            \( y(x)>0\) pour tout \( x\).
        \item
            \( y\) est strictement croissante.
    \end{enumerate}
\end{proposition}

\begin{proof}
    Nous posons \( \varphi(x)=y(x)y(-x)\) et nous dérivons :
    \begin{equation}
        \varphi'(x)=y'(x)y(-x)-y(x)y'(-x)=0.
    \end{equation}
    Donc \( \varphi\) est constante\footnote{Proposition \ref{PropGFkZMwD}.}. Vu que \( \varphi(0)=1\) nous avons automatiquement \( y(x)y(-x)=1\) pour tout \( x\).

Les deux autres allégations sont simples : si \( y(x_0)<0\) alors il existe \( t\in\mathopen] x_0 , 1 \mathclose[\) tel que \( y(t)=0\), ce qui est impossible parce que \( y(t)y(-t)=1\). La stricte croissance de \( y\) s'ensuit.
\end{proof}

\begin{proposition}[Unicité de l'exponentielle] \label{PropDJQSooYIwwhy}
    Si elle existe, la solution au problème 
    \begin{subequations}
        \begin{numcases}{}
            y'=y\\
            y(0)=1
        \end{numcases}
    \end{subequations}
    est unique.
\end{proposition}
\index{exponentielle!unicité}

\begin{proof}
    Soient \( y\) et \( g\) deux solutions et considérions la fonction \( h(x)=g(x)y(-x)\). Un calcul immédiat donne
    \begin{equation}
        h'(x)=0
    \end{equation}
    et donc \( h\) est constante. Vu que \( h(0)=1\) nous avons \( g(x)y(-x)=1\) pour tout \( x\), c'est à dire
    \begin{equation}
        g(x)=\frac{1}{ y(-x) }=y(x).
    \end{equation}
\end{proof}

\begin{proposition}     \label{PROPooGGUIooExVHPM}
    Quelques formules pour tout \( a,b\in \eR\) et \( n\in \eZ\) :
    \begin{enumerate}
        \item       \label{ITEMooMPSUooWQpVQJ}
            \( y(a+b)=y(a)y(b)\)
        \item
            \( y(na)=y(a)^n\)
        \item
            \( y\left( \frac{ a }{ n } \right)=\sqrt[n]{y(a)}\).
    \end{enumerate}
\end{proposition}

\begin{proof}
    Nous posons \( h(x)=y(a+b-x)y(x)\) et nous avons encore \( h'(x)=0\) dont nous déduisons que $h$ est constante. De plus
    \begin{equation}
        h(0)=y(a+b)y(0)=y(a+b)
    \end{equation}
    et
    \begin{equation}
        h(b)=y(a)y(b).
    \end{equation}
    Vu que \( h\) est constante, ces deux expressions sont égales : \( y(a+b)=y(a)y(b)\).

    Forts de cette relation, une récurrence donne \( y(na)=y(a)^n\) pour tout \( n\in \eN\). De plus
    \begin{equation}
        y(a)=y\left( \frac{ a }{ n }\times n \right)=y\left( \frac{ a }{ n } \right)^n,
    \end{equation}
    ce qui donne \( y(a)=y(a/n)^n\) ou encore \( y(a/n)=\sqrt[n]{y(a)}\).

    Enfin pour les négatifs, si \( n\in \eN\),
    \begin{equation}
        y(-na)=\frac{1}{ y(na) }=\frac{1}{ y(a)^n }=y(a)^{-n}.
    \end{equation}
    Et de la même façon,
    \begin{equation}
        y\left( -\frac{ a }{ n } \right)=\frac{1}{ y\left( \frac{ a }{ n } \right) }=\sqrt[n]{\frac{1}{ y(a) }}=\sqrt[-n]{y(a)}.
    \end{equation}
\end{proof}

\begin{proposition} \label{PropCELWooLBSYmS}
    Pour tout \( x\in \eR\), nous avons
    \begin{equation}
        y(x)=y(1)^x.
    \end{equation}
\end{proposition}

\begin{proof}
    Si \( q\in \eQ\) alors \( q=a/b\) et
    \begin{equation}
        y(q)=y\left( \frac{ a }{ b } \right)=y\left( a\times \frac{1}{ b } \right)=y\left( \frac{1}{ b } \right)^a=\big( \sqrt[b]{y(1)} \big)^a=y(1)^{a/b}=y(1)^{q}.
    \end{equation}

    Par ailleurs si \( a\in \eR\), alors la fonction \( x\mapsto a^x\) est continue. Les fonctions \( y\) et \( x\mapsto y(1)^x\) sont deux fonctions continues égales sur \( \eQ\). Elles sont donc égales par la proposition \ref{PropCJGIooZNpnGF}.
\end{proof}
Nous notons \( y(1)=e\), le \defe{nombre de Néper}{nombre!de Néper}, de telle sorte que
\begin{equation}
    y(x)=e^x.
\end{equation}

Une conséquence est que 
\begin{subequations}    \label{EqLOIUooHxnEDn}
    \begin{align}
        \lim_{x\to -\infty}  e^{x}=0\\
        \lim_{x\to +\infty}  e^{x}=+\infty,
    \end{align}
\end{subequations}
et en particulier, 
\begin{equation}
    \begin{aligned}
    \exp\colon \eR&\to \mathopen] 0 , \infty \mathclose[ \\
        x&\mapsto  e^{x} 
    \end{aligned}
\end{equation}
est une bijection.

Nous donnons maintenant quelque approximations numériques de \( e\), particulièrement inefficaces.

\begin{lemma}
    Nous avons
    \begin{equation}
        2<e<3.
    \end{equation}
\end{lemma}

\begin{proof}
    Nous savons que \( y(0)=1\) et \( y'(0)=1\). La fonction \( y\) est strictement croissante (et donc sa dérivée aussi). Nous avons donc \( y'(x)>1\) pour tout \( x\in\mathopen] 0 , 1 \mathclose]\), et donc
    \begin{equation}
        y(1)>1+1\times 1=2.
    \end{equation}
    Sachant que \( 2>y'(x)\) pour tout \( x\in \mathopen] 0 , 1 \mathclose[\) nous pouvons refaire le coup de l'approximation affine, cette fois en majorant :
        \begin{equation}
            y(1)<1+2\times 1=3.
        \end{equation}
\end{proof}

De la même façon nous savons que
\begin{equation}
    y(\frac{1}{ n })>1+\frac{1}{ n }
\end{equation}
parce que \( y'\) est minoré par \( 1\) sur \( \mathopen] 0 , \frac{1}{ n } \mathclose[\). Avec cela nous avons aussi la majoration
\begin{equation}
    y(\frac{1}{ n })<1+\frac{1}{ n }\times \left( 1+\frac{1}{ n } \right)=1+\frac{1}{ n }+\frac{1}{ n^2 }.
\end{equation}
Et enfin nous pouvons donner l'encadrement, valable pour tout \( n\) :
\begin{equation}
    \left( 1+\frac{1}{ n } \right)^n<y(1)<\left( 1+\frac{1}{ n }+\frac{1}{ n^2 } \right)^n.
\end{equation}
Pour \( n=10\) nous trouvons
\begin{equation}
    2.50<e<2.83.
\end{equation}

Bien que ce soit à mon avis humainement pas possible à faire à la main nous avons, pour \( n=100\) :
\begin{equation}
    2.70<e<2.7317
\end{equation}
Cela reste un encadrement très modeste.

Une méthode plus efficace consiste à calculer directement le développement de définition
\begin{equation}
    e=\exp(1)=\sum_{k=0}^{\infty}\frac{1}{ n! }.
\end{equation}
\lstinputlisting{tex/sage/sageSnip013.sage}

\begin{probleme}
    Comment trouver, avec cette méthode, un \emph{encadrement pour \( e\) ?}
\end{probleme}
    
Ce petit programme, avec \( 5\) termes donne \( e\simeq 65/24\simeq 2.708\). Avouez que c'est déjà bien mieux.

\begin{theorem}[Définition de l'exponentielle]  \label{ThoRWOZooYJOGgR}
    Les choses que nous savons sur l'exponentielle :
    \begin{enumerate}
        \item
            Il y a unicité de la solution à l'équation différentielle
            \begin{subequations}    \label{subeqBKJNooJQtbBD}
        \begin{numcases}{}
            y'=y\\
            y(0)=1.
        \end{numcases}
    \end{subequations}
    \item
        L'équation différentielle \eqref{subeqBKJNooJQtbBD} possède une solution donnée par la série entière\nomenclature[Y]{\( \exp\)}{exponentielle}
        \begin{equation}    \label{EqUARSooKXnQxu}
        \exp(x)=\sum_{k=0}^{\infty}\frac{ x^k }{ k! }
    \end{equation}
\item
    Cette solution est une bijection \( y\colon \eR\to \mathopen] 0 , \infty \mathclose[\).
    \item   \label{ItemYTLTooSnfhOu}
        La fonction \( y\) ainsi définie est de classe \(  C^{\infty}\).
\item
    Elle est également donnée par la formule
    \begin{equation}
        \exp(x)=e^x
    \end{equation}
    où \( e\) est définit par \( e=\exp(1)\).
\item
    Elle vérifie
    \begin{equation}        \label{EQooVFXUooBfwjJY}
        e^{a+b}= e^{a} e^{b}
    \end{equation}
    \end{enumerate}
\end{theorem}
Nous nommons \defe{exponentielle}{exponentielle} cette fonction.

\begin{proof}
    \begin{enumerate}
        \item
            C'est la proposition \ref{PropDJQSooYIwwhy}.
        \item 
            C'est le théorème \ref{ThoKRYAooAcnTut}.
        \item
            Le rayon de convergence de la série \eqref{EqUARSooKXnQxu} est infini (théorème \ref{ThoKRYAooAcnTut}); elle est donc définie sur \( \eR\). Le fait que ce soit une bijection est dû au fait qu'elle est strictement croissante (proposition \ref{PropTLECooEiLbPP}) ainsi qu'aux limite \eqref{EqLOIUooHxnEDn}.
        \item
            Vu que \( y=y'\), \( y\) est dérivable. Mais comme \( y'\) est alors égale à une fonction dérivable, \( y'\) est dérivable. En dérivant l'égalité \( y'=y\) nous obtenons \( y''=y'\) et le jeu continue.
        \item
            C'est la proposition \ref{PropCELWooLBSYmS}.
        \item
            C'est la proposition \ref{PROPooGGUIooExVHPM}\ref{ITEMooMPSUooWQpVQJ}.
    \end{enumerate}
\end{proof}

\begin{example}[Un endomorphisme sans polynôme annulateur\cite{RombaldiO}]     \label{ExooLRHCooMYLQTU}
    l'exponentielle permet de donner un exemple d'un endomorphisme n'ayant pas de polynôme annulateur\footnote{Voir la définition \ref{DefooOHUXooNkPWaB} et ce qui suit.} : l'endomorphisme de dérivation
    \begin{equation}
        \begin{aligned}
            D\colon C^{\infty}(\eR,\eR)&\to  C^{\infty}(\eR,\eR) \\
            f&\mapsto f' 
        \end{aligned}
    \end{equation}
    n'a pas de polynôme annulateur. En effet supposons que \( P=\sum_{k=0}^{p}a_kX^k\) en soit un, et considérons les fonction \( f_{\lambda}\colon t\mapsto  e^{\lambda t}\). Nous avons
    \begin{equation}
            0=P(D)f_{\lambda}
            =\sum_ka_kD^k(f_{\lambda})
            =\sum_ka_k\lambda^kf_{\lambda}
            =P(\lambda)f_{\lambda}.
    \end{equation}
    Par conséquent \( \lambda\) est une racine de \( P\) pour tout \( \lambda\in \eR\). Cela implique que \( P=0\).
    
    D'ailleurs si on y pense bien, cet exemple n'est qu'un habillage de l'exemple \ref{ExooDTUJooIMqSKn}.
\end{example}


\begin{propositionDef}    \label{DEFooELGOooGiZQjt}
            L'application \(\exp\colon \eR\to \mathopen] 0 , \infty \mathclose[\) est une bijection.  L'application réciproque
            \begin{equation}
                \ln\colon \mathopen] 0 , \infty \mathclose[\to \eR
            \end{equation}
            est le \defe{logarithme}{logarithme!sur les réels positifs}.
\end{propositionDef}

\begin{proof}
Le fonction exponentielle est dérivable, toujours strictement positive, donc strictement croissante. Les limites en \( \pm \infty\) sont \( 0\) et \( +\infty\). Le théorème des valeurs intermédiaires \ref{ThoValInter} nous dit que c'est une bijection. En effet, l'injectivité est la stricte croissance. En ce qui concerne la surjection, soit \( y\in \mathopen] 0 , \infty \mathclose[\). Vu que la limite en \( -\infty\) est zéro, il existe \( A\in \eR\) tel que \( \exp(x)<y\) pour tout \( x<A\), et de la même façon, il existe \( B\in \eR\) tel que \( \exp(x)>y\) pour tout \( x>B\). Si \( a<A\) et \( b>B\) alors \( \exp(a)<y\) et \( \exp(b)>y\), donc \( y\) est dans l'image de \( \mathopen[ a , b \mathclose]\) par l'exponentielle.
\end{proof}

\begin{proposition}
    Quelque propriétés du logarithme.
    \begin{enumerate}
        \item
            Le logarithme est une application croissante et dérivable.
        \item
            Le logarithme est la primitive de \( x\mapsto\frac{1}{ x }\) qui s'annule en \( x=1\).
    \end{enumerate}
\end{proposition}

Supprimer un des deux labels :
ThoEOMRooZPUfJg
ThoEXXNooCLwgQg

\begin{example}[Exponentielle et logarithme]    \label{ExZLMooMzYqfK}
    Nous savons que la fonction
    \begin{equation}
        \begin{aligned}
        \exp\colon \eR&\to \mathopen] 0 , \infty \mathclose[ \\
            x&\mapsto e^x 
        \end{aligned}
    \end{equation}
    est croissante et dérivable. Elle est donc bijective, d'inverse continue et dérivable par le théorème \ref{ThoKBRooQKXThd} et la proposition \ref{PropMRBooXnnDLq}. Nous nommons \defe{logarithme}{logarithme} la fonction inverse de l'exponentielle :
    \begin{equation}
    \ln\colon \mathopen] 0 , \infty \mathclose[\to \eR.
    \end{equation}
    La proposition \ref{PropMRBooXnnDLq} nous enseigne que la fonction logarithme est croissante et que sa dérivée peut être calculée\footnote{Nous savons que \( \exp'(x)=\exp(x)\) : la dérivée de l'exponentielle est l'exponentielle elle-même.} : si \( y= e^{x}\) alors
    \begin{equation}
        \ln'(y)=\frac{1}{ \exp'(x) }=\frac{1}{ y }.
    \end{equation}
    Nous retrouvons ainsi la formule très connue comme quoi la dérivée du logarithme est l'inverse\footnote{Ou encore que le logarithme est une primitive de la fonction inverse.}.
\end{example}


\begin{proof}
    L'existence d'une primitive est justement le sujet de ce lemme\footnote{C'est l'avantage de notre approche, qui construit la primitive sans devoir invoquer le théorème \ref{ThoEOMRooZPUfJg} pour en assurer l'existence.}. En tant qu'application réciproque nous avons pour tout \( x\in \eR\) :
    \begin{equation}
        \ln\big( \exp(x) \big)=x,
    \end{equation}
    que nous pouvons dériver en utilisant le théorème de dérivation des fonctions composées :
    \begin{equation}
        \ln'\big( \exp(x) \big)\exp'(x)=1.
    \end{equation}
    Mais \( \exp'(x)=x\), donc
    \begin{equation}
        \ln'(y)=\frac{1}{ y }
    \end{equation}
    pour tout \( y\) dans l'image de \( \exp\), c'est à dire pour tout \( y\) dans l'ensemble de définition de \( \ln\).

    Par ailleurs, \( \exp(0)=1\) donc
    \begin{equation}
        \ln(1)=\ln\big( \exp(0) \big)=0.
    \end{equation}

    En ce qui concerne l'unicité d'une primitive s'annulant en \( x=1\), c'est le corollaire \ref{CorZeroCst}.
\end{proof}

\begin{lemma}
Si \( u\colon \eR\to \mathopen] 0 , \infty \mathclose[\) est dérivable alors \( \ln(u)'=\dfrac{ u' }{ u }\).
\end{lemma}

\begin{proof}
    Cela est une conséquence du théorème de dérivation des fonctions composées : si \( g(x)=\ln(u(x))\) alors
    \begin{equation}
        g'(x)=\ln'\big( u(x) \big)u'(x)=\frac{1}{ u(x) }u'(x).
    \end{equation}
\end{proof}

\begin{lemma}   \label{LemPEYJooEZlueU}
Si \( a,b\in\mathopen] 0 , \infty \mathclose[\) alors
    \begin{equation}
        \ln(ab)=\ln(a)+\ln(b)
    \end{equation}
    et
    \begin{equation}    \label{EqOOZGooOWkGlA}
        \ln\left( \frac{1}{ b } \right)=-\ln(b).
    \end{equation}
\end{lemma}

\begin{proof}
    Nous posons \( f(x)=\ln(ax)\) qui est une fonction dérivable. Alors \( f'(x)=\frac{ a }{ ax }=\frac{1}{ x }\). Cette fonction \( f\) est donc une primitive de \( \frac{1}{ x }\) et il existe une constante \( K\) telle que
    \begin{equation}
        f(x)=\ln(x)+K.
    \end{equation}
    Vu que \( \ln(1)=0\) nous avons \( K=f(1)= \ln(a)\). Donc
    \begin{equation}
        \ln(ax)=\ln(x)+\ln(a).
    \end{equation}

    En ce qui concerne la seconde formule à démontrer, nous avons
    \begin{equation}
        \ln(1)=\ln\left( \frac{1}{ b }b \right)=\ln\left( \frac{1}{ b } \right)+\ln(b).
    \end{equation}
    Étant donné que $\ln(1)=0$ nous en déduisons la formule \eqref{EqOOZGooOWkGlA}.
\end{proof}

\begin{example}
    Montrons que la fonction\footnote{Pour la définition du logarithme, c'est la définition \ref{DEFooELGOooGiZQjt}.}
    \begin{equation}
        \begin{aligned}
            f\colon \eR_+\setminus\{ 0,1 \}&\to \eR \\
            x&\mapsto \frac{ \ln(x) }{ x-1 } 
        \end{aligned}
    \end{equation}
    admet un prolongement \( C^{\infty}\) sur \( \eR_+\setminus\{ 0 \}\).

    Nous allons étudier la fonction
    \begin{equation}
        f(x)=\frac{ \ln(1+x) }{ x }
    \end{equation}
    autour de \( x=0\). Le logarithme ne pose pas de problèmes à développer dans un voisinage :
    \begin{subequations}
        \begin{align}
            f(x)&=\frac{1}{ x }\sum_{n=1}^{\infty}\frac{ (-1)^{n+1} }{ n }x^n\\
            &=\sum_{n=1}^{\infty}\frac{ (-1)^{n+1} }{ n }x^{n-1}\\
            &=\sum_{n=0}^{\infty}\frac{ (-1)^k }{ k+1 }x^k.
        \end{align}
    \end{subequations}
    Cette série a un rayon de convergence égal à \( 1\), et donc définit sans problèmes une fonction \( C^{\infty}\) dans un voisinage de \( x=0\). Notons que par convention \( x^0=1\) même si \( x=0\).
\end{example}

\begin{example}     \label{EXooKNTPooKiRExX}
    Montrons que pour tout \( x\in\mathopen] -1 , 1 \mathclose[\) nous avons
    \begin{equation}        \label{EqweEZnV}
        -\ln(1-x)=\sum_{n=1}^{\infty}\frac{ x^n }{ n }.
    \end{equation}
    Nous calculerons ensuite la valeur de la série
    \begin{equation}    \label{EqKUQmOZ}
        \sum_{n=1}^{\infty}\frac{ (-1)^n }{ n }.
    \end{equation}

    La série \eqref{EqKUQmOZ} serait \( f(-1)=-\ln(2)\) où \( f\) est la série de fonctions \eqref{EqweEZnV}. Nous utilisons le théorème de convergence radiale d'Abel (théorème \ref{ThoLUXVjs}) pour justifier cette réponse :
    \begin{equation}
        \sum_n\frac{ (-1)^n }{ n }
    \end{equation}
    converge.
\end{example}

\begin{example}[Primitive du logarithme]\label{primln}
    La primitive de la fonction logarithme définie en \label{DEFooELGOooGiZQjt} nous offre un bon moment d'intégration par partie.

    Trouver la primitive de la fonction \( x\mapsto \ln(x)\). Pour calculer
    \begin{equation}
        \int\ln(x)dx
    \end{equation}
    nous écrivons \( \ln(x)=1\times \ln(x)\) et nous posons \( u'=1\) et \( v=\ln(x)\), c'est à dire
    \begin{equation}
        \begin{aligned}[]
            u'&=1&v=\ln(x)\\
            u&=x&v'=\frac{1}{ x }.
        \end{aligned}
    \end{equation}
    La formule d'intégration par parties \eqref{EQooKISBooQvGMQT} donne donc 
    \begin{equation}
        \int \ln(x)=x\ln(x)-\int x\times \frac{1}{ x }=x\ln(x)-\int 1=x\ln(x)-x+C, \qquad C\in\eR.
    \end{equation}
    Il est facile de vérifier par un petit calcul que
    \begin{equation}
        \big( x\ln(x)-x \big)'=\ln(x).
    \end{equation}
\end{example}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Trigonométrie}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Définitions, périodicité et quelque valeurs remarquables}
%---------------------------------------------------------------------------------------------------------------------------

\begin{propositionDef}[Défintion du cosinus]        \label{PROPooZXPVooBjONka}
    La série
    \begin{equation}
        \cos(x)=\sum_{n=0}^{\infty}\frac{ (-1)^n }{ (2n)! }x^{2n}
    \end{equation}
    définit une fonction \( \cos\colon \eR\to \eR\) de classe \(  C^{\infty}\). Nous l'appelons \defe{cosinus}{cosinus}

    La série
    \begin{equation}        \label{EQooCMRFooCTtpge}
        \sin(x)=\sum_{n=0}^{\infty}\frac{ (-1)^n }{ (2n+1)! }x^{2n+1}
    \end{equation}
    définit une fonction \( \sin\colon \eR\to \eR\) de classe \(  C^{\infty}\). Nous l'appelons \defe{sinus}{sinus}
\end{propositionDef}

\begin{proof}
    La série entière définissant \( \cos(x)\) a pour coefficients
    \begin{equation}
        a_n=\begin{cases}
            0    &   \text{si } n\text{ est impair}\\
            \frac{ (-1)^{n/2} }{ n! }    &   \text{si } n\text{ est pair}.
        \end{cases}
    \end{equation}
    Nous pouvons la majorer par la série entière donnée par les coefficients
    \begin{equation}
        b_n=\begin{cases}
            1/n!    &   \text{si } n\text{ est impair}\\
            \frac{ (-1)^{n/2} }{ n! }    &   \text{si } n\text{ est pair}.
        \end{cases}
    \end{equation}
    Quelle que soit la parité de \( k\) nous avons toujours
    \begin{equation}
        | \frac{ b_{k+1} }{ b_k } |=\frac{1}{ k+1 },
    \end{equation}
    de telle sorte que la formule d'Hadamard \eqref{EqAlphaSerPuissAtern} nous donne \( R=\infty\) pour la série \( \sum_{k=0}^{\infty}b_kx^k\). A fortiori\footnote{Remarque \ref{REMooYOTEooKvxHSf}.} le rayon de convergence pour la série du cosinus est infini.

    L'assertion concernant le sinus se démontre de même.

    En ce qui concerne le fait que les fonctions \( \sin\) et \( \cos\) sont de classe \(  C^{\infty}\) sur \( \eR\), il faut invoquer le corollaire \ref{CorCBYHooQhgara}.
\end{proof}

\begin{lemma}
    En ce qui concerne la dérivation, nous avons
    \begin{subequations}
        \begin{align}
            \sin'&=\cos\\
            \cos'&=-\sin.
        \end{align}
    \end{subequations}
\end{lemma}

\begin{proof}
    Il s'agit de se permettre de dériver terme à terme (proposition \ref{ProptzOIuG}) les séries qui définissent le sinus et le cosinus.
\end{proof}

\begin{lemma}       \label{LEMooAEFPooGSgOkF}
    Les fonctions sinus et cosinus vérifient
    \begin{equation}
        \cos^2(x)+\sin^2(x)=1
    \end{equation}
    pour tout \( x\in \eR\).
\end{lemma}

\begin{proof}
    Posons \( f(x)=\sin^2(x)+\cos^2(x)\) et dérivons :
    \begin{equation}
        f'(x)=2\sin(x)\cos(x)+2\cos(x)(-)\sin(x)=0.
    \end{equation}
    La fonction \( f\) est donc constante par le corollaire \ref{CORooEOERooYprteX}. Nous avons donc pour tout \( x\) :
    \begin{equation}
        f(x)=f(0)=\sin^2(0)+\cos^2(0)=1.
    \end{equation}
    Le dernier calcul s'obtient en substituant directement \( x\) par zéro dans les séries : \( \sin(0)=0\) et \( \cos(0)=1\).
\end{proof}

\begin{lemma}
    Nous avons la formule
    \begin{equation}        \label{EQooRVPJooTMwNTU}
        e^{ix}=\cos(x)+i\sin(x)
    \end{equation}
    pour tout \( x\in \eR\).
\end{lemma}

\begin{proof}
    Il faut partir de la définition de l'exponentielle \eqref{EqEIGZooKWSvPS}, et remarquer que \( i^k\) vaut \( 1\), \( i\), \( -1\), \( -i\). Donc un terme sur deux est imaginaire pur et parmi ceux-là, un sur deux est positif. À bien y regarder, les termes imaginaires purs forment la série du sinus et ceux réels la série du cosinus.
\end{proof}

\begin{lemma}
    Nous avons les formules d'addition d'angles
    \begin{subequations}        \label{SUBEQSooFSSMooHcYwRc}
        \begin{align}
            \cos(a+b)=\cos(a)\cos(b)-\sin(a)\sin(b)\\
            \sin(a+b)=\cos(a)\sin(b)+\sin(a)\cos(b).
        \end{align}
    \end{subequations}
    pour tout \( a\), \( b\) réels.
\end{lemma}

\begin{proof}
    Nous utilisons la formule d'addition dans l'exponentielle, proposition \eqref{EQooVFXUooBfwjJY} et la formule \eqref{EQooRVPJooTMwNTU} avant de séparer les parties réelles et imaginaires :
    \begin{equation}
        e^{i(a+b)}= e^{ia} e^{ib}=\cos(a)\cos(b)-\sin(a)\sin(b)+i\big( \cos(a)\sin(b)+\sin(a)\cos(b) \big).
    \end{equation}
    Cela est également égal à
    \begin{equation}
        \cos(a+b)+i\sin(a+b).
    \end{equation}
    En identifiant les parties réelle et imaginaires, nous obtenons les formules annoncées.
\end{proof}

\begin{lemma}       \label{LEMooPQWWooMdPWUT}
    Un sous-groupe de \( (\eR,+)\) est soit dense dans \( \eR\) soit de la forme \( p\eZ\) pour un certain réel \( p\neq 0\).
\end{lemma}

\begin{proof}
    Soit \( A\), un sous groupe de \( (\eR,+)\) qui ne soit pas dense. Soit un intervalle \( \mathopen] a , b \mathclose[\) qui n'intersecte pas \( A\) (si vous voulez frimer, vous noterez ici que nous utilisons le fait que les intervalles ouverts forment une base de la topologie de \( \eR\)). Si \( d=| b-a |\), l'ensemble \( A\) ne contient pas deux éléments séparés par strictement moins de \( d\). Soit \( p\), le plus petit élément strictement positif de \( A\); nous avons \( p\geq d\) (parce que \( 0\in A\) de toutes façons).

        Vu que \( A\) est un groupe nous avons \( p\eZ\subset A\).

        Pour l'inclusion inverse, si \( x\in A\) est hors de \( p\eZ\), il existe un \( y\in p\eZ\) avec \( | x-y |<p\). Et donc le nombre \( | x-y |\) est dans \( A\) tout en étant plus petit que \( p\). Contradiction.
\end{proof}

\begin{proposition}[\cite{ooUMDHooHrJpfV}]      \label{PROPooFRVCooKSgYUM}
    La fonction \( \cos\) est périodique et le nombre \( T>0\) est une période si et seulement si \( \cos(T)=1\) et \( \sin(T)=0\).
\end{proposition}

\begin{proof}
    Plusieurs étapes.
    \begin{subproof}
        \item[La fonction cosinus n'est pas toujours positive]
    Supposons d'abord que \( \cos(x)>0\) pour tout \( x\in \eR\). Dans ce cas, la fonction \( \sin\) est strictement croissante. Mais les deux fonctions sont bornées par \( 1\) du fait de la formule \( \cos^2(x)+\sin^2(x)=1\). La fonction \( \sin\) étant croissante et bornée, elle est convergente vers un réel par la proposition \ref{PropMTmBYeU} :
    \begin{equation}
        \lim_{x\to \infty} \sin(x)=\ell
    \end{equation}
    pour un certain \( \ell>0\). Avec ça nous avons aussi (pour cause de dérivée) \( \lim_{x\to \infty} \sin'(x)=0\), c'est à dire \( \lim_{x\to \infty} \cos(x)=0\). Mais vu que \( \cos^2(x)+\sin^2(x)=1\) nous avons \( \lim_{x\to \infty} \sin(x)=1\). Mézalor \( \lim_{x\to \infty} \cos'(x)=-1\), ce qui donne que la fonction \( \cos\) n'est pas bornée. Cela est impossible. Nous en déduisons que \( \cos(x)\) n'est pas toujours positive.

\item[Il existe \( T>0\) tel que \( \cos(T)=1\) et \( \sin(T)=0\)]

    Par ce que nous venons de faire, il existe \( r>0\) tel que \( \cos(r)=0\). Pour cette valeur, nous avons aussi obligatoirement \( \sin(r)=\pm 1\). Nous avons aussi, en utilisant les formules \eqref{SUBEQSooFSSMooHcYwRc},
    \begin{subequations}
        \begin{align}
            \cos(2r)=\cos^2(r)-\sin^2(r)=-1\\
            \sin(2r)=2\cos(r)\sin(r)=0.
        \end{align}
    \end{subequations}
    et par conséquent
    \begin{subequations}
        \begin{align}
            \cos(4r)=\cos^2(2r)-\sin^2(2r)=1\\
            \sin(4r)=2\cos(2r)\sin(2r)=0.
        \end{align}
    \end{subequations}
    Donc \( T=4r\) fonctionne.

\item[Si \( T\) est une période]
    Nous entrons dans le vif de la preuve. Soit un \( T>0\) tel que \( \cos(x+T)=\cos(x)\) pour tout \( x\in \eR\). Avec la formule d'addition d'angle\footnote{Rien ne nous empêche de donner ce nom à ces formules, mais seriez vous capable de définir précisément le mot «angle» ?} dans le cosinus nous cherchons un \( T\) tel que
    \begin{equation}
        \cos(x+T)=\cos(x)\cos(T)-\sin(x)\sin(T)=\cos(x)
    \end{equation}
    et donc tel que
    \begin{equation}        \label{EQooELSAooLNtBnm}
        \cos(x)\big( \cos(T)-1 \big)=\sin(x)\sin(T).
    \end{equation}
    Nous dérivons cette équation :
    \begin{equation}        \label{EQooCECFooLpxXaw}
        -\sin(x)\big( \cos(T)-1 \big)=\cos(x)\sin(T).
    \end{equation}
    Nous multiplions chacune des deux équations \eqref{EQooELSAooLNtBnm} et \eqref{EQooCECFooLpxXaw} par \( \sin(x)\) et \( \cos(x)\) pour obtenir les quatre relations suivantes :
    \begin{subequations}
        \begin{align}
            \cos^2(x)\big( \cos(T)-1 \big)-\sin(x)\cos(x)\sin(T)=0   \label{SUBEQooLGQXooIrLMLW}\\
            -\sin(x)\cos(x)\big( \cos(T)-1 \big)-\cos^2(x)\sin(T)=0     \label{SUBEQooCHTDooKwvyZF}\\
            \sin(x)\cos(x)\big( \cos(T)-1 \big)-\sin^2(x)\sin(T)=0 \label{SUBEQooEWPTooTLCUMf}\\
            \sin^2(x)\big( \cos(T)-1 \big)-\sin(x)\cos(x)\sin(T)=0  \label{SUBEQooGBXTooCFekGJ}
        \end{align}
    \end{subequations}
    En faisant \eqref{SUBEQooLGQXooIrLMLW} moins \eqref{SUBEQooGBXTooCFekGJ} nous trouvons \( \cos(T)=1\). Et en sommant \eqref{SUBEQooCHTDooKwvyZF} avec \eqref{SUBEQooEWPTooTLCUMf} nous avons \( -\sin(T)=0\).

\item[Si \( T>0\) est tel que \( \sin(T)=0\) et \( \cos(T)=1\)]

    Alors la formule d'addition d'angle donne tout de suite
    \begin{equation}
        \cos(x+T)=\cos(x).
    \end{equation}

    \end{subproof}

    À de niveau nous croyons avoir prouvé que \( \cos\) était périodique et que la période est donnée par
    \begin{equation}
        \min\{ T>0\tq \sin(T)=0,\cos(T)=1 \}.
    \end{equation}
    Or rien n'est moins sûr parce qu'il pourrait arriver que ce minimum n'existe pas, c'est à dire que l'infimum soit zéro. Autrement dit, il peut arriver que l'ensemble des périodes soit dense. Plus précisément, soit \( P\subset \eR\) l'ensemble des périodes de \( \cos\). C'est un sous-groupe de \( (\eR,+)\) et le lemme \ref{LEMooPQWWooMdPWUT} nous dit que \( P\) est soit dense dans \( \eR\) soit de la forme \( p\eZ\) pour un \( p>0\).

    Si \( P\) est dense, soit \( t\in \eR\) et une suite \( (t_n)\) dans \( P\) telle que \( t_n\to t\). Pour tout \( x\) et tout \( n\) nous avons
    \begin{equation}
        \cos(x+t_n)=\cos(x),
    \end{equation}
    Vu que la fonction cosinus est continue, nous pouvons passer à la limite et écrire \( \cos(x+t)=\cos(x)\). Cela étant valable pour tout \( x\) et pour tout \( t\), la fonction cosinus est constante. Or nous savons que ce n'est pas le cas, donc \( P\) n'est pas dense. Donc cosinus est périodique.
\end{proof}

\begin{definition}[Le nombre \( \pi\)]
    Le nombre \( \pi>0\) est donné par
    \begin{equation}
        2\pi=\min\{ T>0\tq \cos(x+T)=\cos(x)\,\forall x \}.
    \end{equation}
\end{definition}
Par ce qui a été dit dans la démonstration nous avons aussi
\begin{equation}
    2\pi=\min\{ T>0\tq \sin(T)=0,\cos(T)=1 \}.
\end{equation}
Notons que tout ceci ne nous donne pas la plus petite indication d'ordre de grandeur de la valeur de \( \pi\). Cela peut encore être \( 0.1\) autant que \( 500\).

\begin{proposition}[\cite{ooUMDHooHrJpfV}]      \label{PROPooMWMDooJYIlis}
    Des propriétés à la chaîne à propos des sinus, cosinus et de leurs périodes.
    \begin{enumerate}
        \item
            Le nombre \( 2\pi\) est le plus petit tel que
            \begin{subequations}
                \begin{numcases}{}
                    \cos(2\pi)=1\\
                    \sin(2\pi)=0.
                \end{numcases}
            \end{subequations}
        \item
            Le nombre \( 2\pi\) est également la période de la fonction \( \sin\).
        \item
            Nous avons \( \cos(\pi)=- 1\) et \( \sin(\pi)=0\).
        \item
            Pour tout \( a\in \eR\) nous avons
            \begin{subequations}
                \begin{align}
                    \cos(a+\pi)&=-\cos(\pi)\\
                    \sin(a+\pi)&=-\sin(\pi).
                \end{align}
            \end{subequations}
        \item
            Le nombre \( \pi\) est le plus petit \( T>0\) tel que \( \cos(T)=-1\) et \( \sin(T)=0\).
        \item
            Nous avons
            \begin{subequations}
                \begin{numcases}{}
                    \cos(\pi/2)=0\\
                    \sin(\pi/2)=1.
                \end{numcases}
            \end{subequations}
        \item
            Nous avons les formules
            \begin{subequations}        \label{EQSooRJZGooCFVqbZ}
                \begin{numcases}{}
                    \cos(x+\pi/2)=-\sin(x)\\
                    \sin(x+\pi/2)=\cos(x)
                \end{numcases}
            \end{subequations}
            pour tout \( x\in \eR\).
        \item
            Le nombre \( \pi/2\) est le plus petit \( T\) vérifiant \( \sin(T)=1\), \( \cos(T)=0\).
        \item
            Nous avons les valeurs
            \begin{subequations}
                \begin{numcases}{}
                    \cos(\frac{ 3\pi }{ 2 })=0\\
                    \sin(\frac{ 3\pi }{ 2 })=-1.
                \end{numcases}
            \end{subequations}
        \item       \label{ITEMooQKPKooEPeHER}
            Le nombre \( \pi/2\) est le plus petit \( T>0\) tel que \( \cos(T)=0\).
    \end{enumerate}
\end{proposition}

\begin{proof}
    C'est parti.
    \begin{enumerate}
        \item
            Le fond de la proposition \ref{PROPooFRVCooKSgYUM} est que toutes les périodes \( T>0\) vérifient \( \cos(T)=1\) et \( \sin(T)=0\). La définition de \( \pi\) est que c'est la plus petite période.
        \item
            En utilisant le fait que l'une est la dérivée de l'autre, si \( T\) est une période de \( \cos\) nous avons
            \begin{subequations}
                \begin{align}
                    \sin(x+T)&=-\cos'(x+T)\\
                    &=-\lim_{\epsilon\to 0}\frac{ \cos(x+T+\epsilon)-\cos(x+T) }{\epsilon  }\\
                    &=-\lim_{\epsilon\to 0}\frac{ \cos(x+\epsilon)-\cos(x) }{ \epsilon }\\
                    &=-\cos'(x)\\
                    &=\sin(x).
                \end{align}
            \end{subequations}
            Nous déduisons que toute période de \( \cos\) est une période de \( \sin\). De la même façon, nous pouvons prouver le contraire : toute période de \( \sin\) est une période de \( \cos\).
        \item
            D'un côté nous avons
            \begin{equation}
                \cos(2\pi)=\cos^2(\pi)-\sin^2(\pi)=1
            \end{equation}
            parce que \( \cos(2\pi)=\cos(0)=1\). Vu que \( \cos(\pi)\) et \( \sin(\pi)\) sont bornés par \( -1\) et \( 1\), nous devons avoir \( \sin(\pi)=0\) et \( \cos(\pi)=\pm 1\).

            Mais d'un autre côté, le nombre \( 2\pi\) est le plus petit \( T\) vérifiant \( \cos(T)=1\), \( \sin(T)=0\). Donc avoir \( \cos(\pi)=1\) n'est pas possible. Nous concluons
            \begin{subequations}
                \begin{numcases}{}
                    \cos(\pi)=-1\\
                    \sin(\pi)=0.
                \end{numcases}
            \end{subequations}
        \item
            Il s'agit d'utiliser les formules d'addition d'angles pour calculer \( \cos(a+\pi)\) et \( \sin(a+\pi)\) en tenant compte du fait que \( \cos(\pi)=-1\) et \( \sin(\pi)=0\).
        \item
        Soit \( a\in\mathopen] 0 , \pi \mathclose[\) tel que \( \cos(a)=-1\) et \( \sin(a)=0\). Alors nous avons
            \begin{subequations}
                \begin{align}
                    \cos(a+\pi)=-\cos(\pi)=1\\
                    \sin(a+\pi)=-\sin(\pi)=0,
                \end{align}
            \end{subequations}
        ce qui donnerait \( a+\pi\in\mathopen] \pi , 2\pi \mathclose[\) dont le cosinus est \( 1\) et le sinus est zéro. Mais nous savons déjà que \( 2\pi\) est le minimum pour cette propriété.
        \item
            Nous avons
            \begin{equation}
                -1=\cos(\pi)=\cos^2(\pi/2)-\sin^2(\pi/2),
            \end{equation}
            donc \( \cos(\pi/2)=0\) et \( \sin^2(\pi/2)=1\), ce qui donne \( \sin(\pi/2)=\pm 1\).

        Nous devons départager le \( \pm\). Pour cela nous savons que \( \sin'(0)=\cos(0)=1\), donc il existe \( \epsilon>\epsilon\) tel que pour tout \( x\in\mathopen] 0 , \epsilon \mathclose[\) nous avons \( 0<\cos(x)<1\) et \( 0\sin(x)<1\). Nous choisissons \( \epsilon\) plus petit que \( \pi/2\) .  
            
        Supposons que \( \sin(\pi/2)=-1\). Le théorème des valeurs intermédiaires \ref{ThoValInter} dit qu'il existe \( x_0\in\mathopen] \epsilon , \pi/2 \mathclose[\) tel que \( \sin(x_0)=0\). Pour cette valeur de \( x_0\) nous devons aussi avoir \( \cos(x_0)=\pm 1\). Mais vu que \( 2\pi\) est minium pour avoir \( \cos=1\) et \( \sin=0\) nous devons avoir \( \cos(x_0)=-1\). Alors nous avons aussi
            \begin{subequations}
                \begin{align}
                    \cos(x_0+\pi)=\cos(x_0)\cos(\pi)-\sin(x_0)\sin(\pi)=-\cos(x_0)=1\\
                    \sin(x_0+\pi)=\cos(x_0)\sin(\pi)+\sin(x_0)\cos(\pi)=\sin(x_0)=0.
                \end{align}
            \end{subequations}
            Encore une fois par minimalité de \( 2\pi\), cela ne va pas. Conclusion : \( \sin(\pi/2)=1\).
        \item
            Il s'agit encore d'utiliser les formules d'addition d'angle en tenant compte du fait que \( \cos(\pi/2)=0\) et \( \sin(\pi/2)=1\).
        \item
        Supposons \( x_0\in\mathopen] 0 , \pi/2 \mathclose[\) tel que \( \sin(x_0)=1\) et \( \cos(x_0)=0\). En utilisant les formules \eqref{EQSooRJZGooCFVqbZ} nous avons
            \begin{subequations}
                \begin{align}
                    \cos(x_0+\pi/2)=-1\\
                    \sin(x_0+\pi/2)=0,
                \end{align}
            \end{subequations}
            avec \( x_0+\pi/2<\pi\). Cela contredirait la minimalité de \( \pi\).
        \item
            Il s'agit d'utiliser les formules \eqref{EQSooRJZGooCFVqbZ} :
            \begin{subequations}
                \begin{align}
                    \cos(\frac{ 3\pi }{ 2 })=\cos(\pi+\pi/2)=-\sin(\pi)=0\\
                    \sin(\frac{ 3\pi }{ 2 })=\sin(\pi+\pi/2)=\cos(\pi)=-1.
                \end{align}
            \end{subequations}
        \item
            Si \( \cos(x_0)=0\) alors \( \sin(x_0)=-1\) (parce que \( \sin(x_0)=1\) est déjà exclu). Alors \( \cos(x_0+\pi/2)=1\) et \( \sin(x_0+\pi/2)=0\), ce qui est également impossible.
    \end{enumerate}
\end{proof}
Tout cela nous permet d'écrire le tableau de variations de sinus et cosinus.

\begin{proposition}     \label{PROPooKSGXooOqGyZj}
    L'application
    \begin{equation}
        \begin{aligned}
            \gamma\colon \mathopen[ 0 , 2\pi \mathclose[&\to S^1\subset \eR^2 \\
            t&\mapsto \big( \cos(t),\sin(t) \big) 
        \end{aligned}
    \end{equation}
    est une bijection continue.
\end{proposition}

\begin{proof}
    La continuité découle de la continuité des composantes. Le fait que l'image de \( \gamma\) soit dans \( S^1\) découle immédiatement du fait que \( \sin^2+\cos^2=1\).

    Pour la bijection, il faut injectif et surjectif.
    \begin{subproof}
        \item[Injectif]
            Soient \( x_1<x_2\) tels que \( \sin(x_1)=\sin(x_2)\) et \( \cos(x_1)=\cos(x_2)\). Supposons pour fixer les idées que \( \sin(x_1)>0\) et \( \cos(x_1)>0\) : si ce n'est pas le cas, il faut traiter séparément les \( 4\) possibilités de combinaisons de signes.

            Nous avons obligatoirement \( x_1,x_2\in\mathopen[ 0 , \frac{ \pi }{ 2 } \mathclose[\). Vu que \( \sin(x_1)=\sin(x_2)\), il existe par le théorème de Rolle \ref{ThoRolle} un élément \( c\in \mathopen] x_1 , x_2 \mathclose[\) tel que \( \sin'(c)=0\), c'est à dire \( \cos(c)=0\). Cela contredirait la proposition \ref{PROPooMWMDooJYIlis}\ref{ITEMooQKPKooEPeHER} à moins que \( x_1=x_2\).

            \item[Surjectif]

                Soient \( x,y\) tels que \( x^2+y^2=1\). Supposons pour varier les plaisirs que \( x<0\) et \( y>0\). Vu que la fonction \( \cos\) va de \( 0\) à \( -1\) lorsque \( x\) va de \( \pi/2\) à \( \pi\), le théorème des valeurs intermédiaires donne \( t\in\mathopen[ \pi/2 , \pi \mathclose]\) tel que \( \cos(t)=x\). Pour cette valeur de \( x\) nous avons
                \begin{equation}
                    \cos^2(x)+\sin^2(x)=1,
                \end{equation}
                et donc \( \sin^2(x)=y^2\), ce qui donne \( \sin(x)=\pm y\). Mais pour \( x\in \mathopen[ \pi/2 , \pi \mathclose]\) nous avons \( \sin(t)>0\). Par conséquent \( \sin(t)=y\).
    \end{subproof}
\end{proof}

\begin{lemma}       \label{LEMooIGNPooPEctJy}
    Nous avons les valeurs remarquables
    \begin{equation}
        \sin(\frac{ \pi }{ 4 })=\cos(\frac{ \pi }{ 4 })=\frac{ \sqrt{ 2 } }{2}.
    \end{equation}
\end{lemma}
Je crois que vous devriez pouvoir faire la preuve tout seul. Si ça ne va pas, contactez-moi.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Exemples}
%---------------------------------------------------------------------------------------------------------------------------

Nous mettons ici quelque exemples concernant les fonctions trigonométriques, qui n'ont pas pu être mis dans les chapitres le plus adapté, parce que ces derniers sont plus haut dans la table des matière.

\begin{example}[Taylor]     \label{EXooXLYJooKVqhTE}
	Le développement du cosinus est donné par
	\begin{equation}
		\cos(x)=1-\frac{ x^2 }{ 2 }+\frac{ x^4 }{ 4! }-\frac{ x^6 }{ 6! }\cdots
	\end{equation}
	Nous avons donc l'existence d'une fonction $h_1\in o(x^2)$ telle que $\cos(x)=1-\frac{ x^2 }{ 2 }+h_1(x)$. Il existe aussi une autre fonction $h_2\in o(x^4)$ telle que $\cos(x)=1-\frac{ x^2 }{ 2 }+\frac{ x^4 }{ 4! }+h_2(x)$.
\end{example}

\begin{example}[Limite et prolongement par continuité] \label{ExQWHooGddTLE}
    La fonction 
    \begin{equation}
        f(x)=\frac{ \cos(x)-1 }{ x }
    \end{equation}
    n'est pas définie en \( x=0\), mais en la limite
    \begin{equation}
        \lim_{x\to 0} \frac{ \cos(x)-1 }{ x }
    \end{equation}
    nous reconnaissons la limite définissant la dérivée du cosinus en \( 0\), c'est à dire que
    \begin{equation}
        \lim_{x\to 0} \frac{ \cos(x)-1 }{ x }=\sin(0)=0.
    \end{equation}
    Nous avons donc le prolongement par continuité
    \begin{equation}
        \tilde f(x)=\begin{cases}
            \frac{ \cos(x)-1 }{ x }    &   \text{si } x\neq 0\\
            0    &    \text{sinon}.
        \end{cases}
    \end{equation}

    Encore une fois, le graphe de la fonction \(\tilde f\) ne présente aucune particularité autour de \( x=0\).
    \begin{center}
        \input{auto/pictures_tex/Fig_RPNooQXxpZZ.pstricks}
    \end{center}
\end{example}

\begin{example}[Un calcul heuristique de limite]        \label{EXooINLRooPzRWEA}
    Soit à calculer la limite suivante :
    \begin{equation}
        \lim_{x\to 0} \frac{  e^{-2\cos(x)+2}\sin(x) }{ \sqrt{ e^{2\cos(x)+2}}-1 }.
    \end{equation}
    La stratégie que nous allons suivre pour calculer cette limite est de développer certaines parties de l'expression en série de Taylor, afin de simplifier l'expression. La première chose à faire est de remplacer $ e^{y(x)}$ par $1+y(x)$ lorsque $y(x)\to 0$. La limite devient
    \begin{equation}
        \lim_{x\to 0} \frac{ \big( -2\cos(x)+3 \big)\sin(x) }{ \sqrt{-2\cos(x)+2} }.
    \end{equation}
    Nous allons maintenant remplacer $\cos(x)$ par $1$ au numérateur et par $1-x^2/2$ au dénominateur. Pourquoi ? Parce que le cosinus du dénominateur est dans une racine, donc nous nous attendons à ce que le terme de degré deux du cosinus donne un degré un en dehors de la racine, alors que du degré un est exactement ce que nous avons au numérateur : le développement du sinus commence par $x$.

    Nous calculons donc
    \begin{equation}
        \begin{aligned}[]
            \lim_{x\to 0} \frac{ \sin(x) }{ \sqrt{-2\left( 1-\frac{ x^2 }{ 2 } \right)+2} }=\lim_{x\to 0} \frac{ \sin(x) }{ x }=1.
        \end{aligned}
    \end{equation}
    Tout ceci n'est évidement pas très rigoureux, mais en principe vous avez tous les éléments en main pour justifier les étapes.
\end{example}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Exemples : intégration par partie}
%---------------------------------------------------------------------------------------------------------------------------

Les fonctions trigonométries offrent de nombreux moment d'intégration par partie.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Très modeste approximation de \( \pi\)}
%---------------------------------------------------------------------------------------------------------------------------
\label{SUBSECooPQVKooAOyxOe}

Nous sommes en droit de vouloir une valeur approchée de \( \pi\). 
\begin{lemma}       \label{LEMooJWSGooExmtDA}
    Nous avons l'approximation numérique
    \begin{equation}
        2\sqrt{ 2 }<\pi<4.
    \end{equation}
\end{lemma}

\begin{proof}
    Grace au lemme \ref{LEMooIGNPooPEctJy} nous savons que la fonction \( \sin\) passe de \( 0\) à \( \sqrt{ 2 }/2\) sur un intervalle de taille \( \pi/4\) avec une dérivé majorée par \( 1\). Par conséquent
    \begin{equation}
        \frac{ \pi }{ 4 }>\frac{ \sqrt{ 2 } }{2}
    \end{equation}
    et donc\footnote{Sérieusement, êtes vous capables de trouver une approximation de \( \sqrt{ 2 }\) en ne vous basant que sur des choses vues jusqu'ici ?}
    \begin{equation}
        \pi>2\sqrt{ 2 }\simeq 2.82
    \end{equation}
    De plus la fonction \( \sin\) passe de \( 0\) à \( \sqrt{ 2 }/2\) sur un intervalle de taille \( \pi/4\) avec une dérivée majorée par \( \sqrt{ 2 }/2\), donc
    \begin{equation}
        \frac{ \pi }{ 4 }<\frac{ \sqrt{ 2 }/2 }{ \sqrt{ 2 }/2 },
    \end{equation}
    ce qui donne
    \begin{equation}
        \pi<4.
    \end{equation}
\end{proof}

Pour avoir une meilleur approximation de \( \pi\), nous pouvons remarquer que \( \pi\in\mathopen] 2.82 , 4 \mathclose[\), et que cet intervalle est suffisamment petit pour ne pas recouvrir l'intervalle correspondant pour \( 2\pi\). L'équation \( \cos(x)=-1\) possède donc une unique solution dans cet intervalle (et cette solution est \( \pi\)). Nous pouvons donc faire une dichotomie pour trouver la valeur de \( \pi\), pourvu que nous ayons une façon d'évaluer des valeurs de \( \cos(x)\) de façon pas trop ridicule.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Cercle trigonométrique}
%---------------------------------------------------------------------------------------------------------------------------

Le \href{http://fr.wikiversity.org/wiki/Trigonométrie/Cosinus_et_sinus_dans_le_cercle_trigonométrique}{cercle trigonométrique} est le cercle de rayon $1$ représenté à la figure \ref{LabelFigCercleTrigono}. Sa longueur est $2\pi$.
\newcommand{\CaptionFigCercleTrigono}{Le cercle trigonométrique.}
\input{auto/pictures_tex/Fig_CercleTrigono.pstricks}

Nous verrons plus tard que la longueur de l'arc de cercle intercepté par un angle $\theta$ est égal à $\theta$. Les radians sont donc l'unité d'angle les plus adaptés au calcul de longueurs sur le cercle. 

%TODO : remettre ce lien après le fork
%Voir exercice \ref{exoGeomAnal-0034}.


%---------------------------------------------------------------------------------------------------------------------------
\subsection{Les fonctions tangente et arc tangente}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}
    La fonction \defe{tangente}{tangente} est :
    \begin{equation}
        \tan(x)=\frac{ \sin(x) }{ \cos(x) }
    \end{equation}
    où \( \sin\) et \( \cos\) sont de la définition \ref{PROPooZXPVooBjONka}.
\end{definition}
La fonction tangente n'est pas définie sur les points de la forme \( x=\frac{ \pi }{2}+k\pi\), \( k\in \eZ\). Une interprétation géométrique, qui justifie le nom, est donnée sur la figure \ref{LabelFigTgCercleTrigono}.
\newcommand{\CaptionFigTgCercleTrigono}{Interprétation géométrique de la fonction tangente. La tangente de l'angle $\theta$ est positive (et un peu plus grande que $1$) tandis que celle de la tangente de l'angle $\varphi$ est négative.}
\input{auto/pictures_tex/Fig_TgCercleTrigono.pstricks}

\begin{proposition}
    La fonction
    \begin{equation}
        \begin{aligned}
        \tan\colon \mathopen] -\frac{ \pi }{ 2 } , \frac{ \pi }{2} \mathclose[&\to \eR \\
            x&\mapsto \tan(x) 
        \end{aligned}
    \end{equation}
    est une bijection.
\end{proposition}

\begin{proof}
    Le cosinus ne s'annulant pas sur l'intervalle donné, la fonction est bien définie. Nous avons
    \begin{equation}
        \lim_{x\to \pi/2^-} \tan(x)=+\infty
    \end{equation}
    parce que la limite du sinus est \( 1\) est celle du cosinus est zéro par les valeurs positives. Le même raisonnement donne la limite en \( -\pi/2\) qui vaut \( -\infty\). Le théorème des valeurs intermédiaires\footnote{Théorème \ref{ThoValInter}.} dit que la fonction tangente est alors surjective sur \( \eR\).

    Par ailleurs en utilisant les règles de calcul comme la dérivation du quotient \ref{PROPooOUZOooEcYKxn}\ref{ITEMooMUNQooLiKffz} nous trouvons
    \begin{equation}
        \tan'(x)=\tan^2(x)+1,
    \end{equation}
    ce qui nous donne une dérivée partout strictement positive, et donc une fonction strictement croissante et donc injective.
\end{proof}

Le graphe de la fonction tangente est sur la figure \ref{LabelFigPVJooJDyNAg}. % From file PVJooJDyNAg
\newcommand{\CaptionFigPVJooJDyNAg}{Le graphe de la fonction tangente.}
\input{auto/pictures_tex/Fig_PVJooJDyNAg.pstricks}

En ce qui concerne la bijection réciproque nous avons le théorème suivant.
\begin{theorem}     \label{THOooUSVGooOAnCvC}
    La fonction
    \begin{equation}
        \begin{aligned}
        \arctan\colon \eR&\to \left] -\frac{ \pi }{2} , \frac{ \pi }{2} \right[ \\
            x&\mapsto \arctan(x) 
        \end{aligned}
    \end{equation}
    nommée \defe{arc tangente}{arc tangente} est
    \begin{enumerate}
        \item
            impaire et strictement croissante sur \( \eR\).
        \item       \label{ITEMooMNHLooOVhIIb}
            dérivable sur \( \eR\) de dérivée
            \begin{equation}
                \arctan'(x)=\frac{1}{ 1+x^2 }.
            \end{equation}
    \end{enumerate}
\end{theorem}

\begin{proof}
    La fonction sinus étant impaire (visible sur son développement de définition \eqref{EQooCMRFooCTtpge}), et la fonction cosinus étant paire, la fonction tangente est impaire et sa réciproque l'est tout autant.

    La fonction arc tangente est également dérivable (donc continue) par la proposition \ref{PropMRBooXnnDLq} parce que la fonction tangente l'est. Notons qu'ici nous nous sommes restreint à \( \mathopen] -\pi/2 , \pi/2 \mathclose[\). Sinon, le résultat est faux.

    La formule proposée pour la dérivée provient également de la proposition \ref{PropMRBooXnnDLq} et de la dérivée de la tangente :
\end{proof}

\begin{lemma}       \label{LEMooJKIUooEMMOrs}
    Nous avons la valeur remarquable
    \begin{equation}
        \arctan(1/\sqrt{ 3 })=\frac{ \pi }{ 6 }.
    \end{equation}
\end{lemma}

Le nombre \( \arctan(x_0)\) se calcule en cherchant l'angle \( \theta\in\mathopen[ -\frac{ \pi }{2} , \frac{ \pi }{2} \mathclose]\) dont la tangente vaut \( x_0\). Nous obtenons le tableau de valeurs suivant :
\begin{equation*}
    \begin{array}[]{|c|c|c|c|c|}
        \hline
        x&0&\frac{1}{ \sqrt{3} }&1&\sqrt{3}\\
        \hline
        \arctan(x)&0&\frac{ \pi }{ 6 }&\frac{ \pi }{ 4 }&\frac{ \pi }{ 3 }\\
        \hline
    \end{array}
\end{equation*}

En ce qui concerne la représentation graphique de la fonction \( x\mapsto\arctan(x)\), elle s'obtient «en retournant» la partie entre \( -\frac{ \pi }{2}\) et \( \frac{ \pi }{ 2 }\) du graphique de la fonction tangente :
\begin{center}
   \input{auto/pictures_tex/Fig_UQZooGFLNEq.pstricks}
\end{center}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{La fonction arc sinus}
%---------------------------------------------------------------------------------------------------------------------------

Nous voulons étudier la fonction
\begin{equation}
    \begin{aligned}
        \sin\colon \eR&\to \mathopen[ -1 , 1 \mathclose] \\
        x&\mapsto \sin(x) 
    \end{aligned}
\end{equation}
et sa réciproque éventuelle.

La fonction sinus est continue sur \( \eR\) mais n'est pas bijective : elle prend une infinité de fois chaque valeur de \( J=\mathopen[ -1 , 1 \mathclose]\). Pour définir une bijection réciproque de la fonction sinus en utilisant le théorème \ref{ThoKBRooQKXThd}, nous devons donc choisir un intervalle à partir duquel la fonction sinus est monotone. Nous choisissons l'intervalle
\begin{equation}
    I=\mathopen[ -\frac{ \pi }{ 2 } , \frac{ \pi }{2} \mathclose].
\end{equation}
La fonction
\begin{equation}
    \begin{aligned}
        \sin\colon \mathopen[ -\frac{ \pi }{2} , \frac{ \pi }{2} \mathclose]&\to \mathopen[ -1 , 1 \mathclose] \\
        x&\mapsto \sin(x) 
    \end{aligned}
\end{equation}
est une bijection croissante et continue. Nous avons donc le résultat suivant.
\begin{theorem}[Définition et propriétés de arc sinus]
    Nous nommons \defe{arc sinus}{arc sinus} la bijection inverse de la fonction \( \sin\colon I\to J\). La fonction
    \begin{equation}
        \begin{aligned}
            \arcsin\colon \mathopen[ -1 , 1 \mathclose]&\to \mathopen[ -\frac{ \pi }{2} , \frac{ \pi }{2} \mathclose] \\
            x&\mapsto \arcsin(x) 
        \end{aligned}
    \end{equation}
    ainsi définie est
    \begin{enumerate}
        \item
            continue et strictement croissante;
        \item
            impaire : pour tout \( x\in\mathopen[ -1 , 1 \mathclose]\) nous avons \( \arcsin(-x)=-\arcsin(x)\).
    \end{enumerate}
\end{theorem}

\begin{proof}
    Nous prouvons le fait que \( \arcsin\) est impaire. Un élément de l'ensemble de définition de \( \arcsin\) est de la forme \( y=\sin(x)\) avec \( x\in\mathopen[ -\pi/2 , \pi/2 \mathclose]\). La relation \eqref{EqHQRooNmLYbF} s'écrit dans notre cas
    \begin{equation}    \label{EqVUWooUwVxVp}
        x=\arcsin\big( \sin(x) \big).
    \end{equation}
    Nous écrivons d'une part cette équation avec \( -x\) au lieu de \( x\) :
    \begin{equation}    \label{EqRLYooIwOvSz}
        -x=\arcsin\big( \sin(-x) \big)=\arcsin\big( -\sin(x) \big)=\arcsin(-y);
    \end{equation}
    et d'autre part nous multiplions \eqref{EqVUWooUwVxVp} par \( -1\) :
    \begin{equation}    \label{EqTGIooDeRYyT}
        -x=-\arcsin\big( \sin(x) \big)=-\arcsin(y).
    \end{equation}
    En égalisant les valeurs \eqref{EqRLYooIwOvSz} et \eqref{EqTGIooDeRYyT} nous trouvons
    \begin{equation}
        \arcsin(-y)=-\arcsin(y),
    \end{equation}
    ce qui signifie que \( \arcsin\) est une fonction impaire.
\end{proof}
Notons que cette preuve repose sur le fait que tout élément de l'ensemble de définition de la fonction arc sinus peut être écrit sous la forme \( \sin(x)\) pour un certain \( x\).

Si \( x_0\in\mathopen[ -1 , 1 \mathclose]\) est donné, calculer \( \arcsin(x_0)\) revient à trouver un angle \( \theta_0\) dans \( \mathopen[ -\frac{ \pi }{2} , \frac{ \pi }{2} \mathclose]\) pour lequel \( \sin(\theta_0)=x_0\). Un tel angle sera forcément unique.

\begin{remark}
  La définition de arc sinus découle du choix de l'intervalle $I$, qui est une convention. Il aurait été possible de faire un choix différent : pourriez vous trouver la réciproque de la fonction sinus sur l'intervalle $[\pi/2, 3\pi/2]$ ? Le mieux est de l'écrire comme une translatée de arc sinus, en utilisant le fait que sinus est une fonction périodique. 
\end{remark}

\begin{example}
    Pour calculer \( \arcsin(1)\), il faut chercher un angle entre \( -\frac{ \pi }{2}\) et \( \frac{ \pi }{ 2 }\) ayant \( 1\) pour sinus : résoudre \( \sin(\theta)=1\). La solution est \( \theta=\frac{ \pi }{2}\) et nous avons donc \( \arcsin(1)=\frac{ \pi }{2}\).
\end{example}

À l'aide des valeurs remarquables de la fonction sinus nous obtenons le tableau suivant de valeurs remarquables pour l'arc sinus.
\begin{equation*}
    \begin{array}[]{|c|c|c|c|c|c|}
        \hline
        x&0&\frac{ 1 }{2}&\frac{ \sqrt{2} }{2}&\frac{ \sqrt{3} }{2}&1\\
          \hline
          \arcsin(x)&0&\frac{ \pi }{ 6 }&\frac{ \pi }{ 4 }&\frac{ \pi }{ 3 }&\frac{ \pi }{ 2 }\\ 
          \hline 
           \end{array}
\end{equation*}
Les autres valeurs remarquables peuvent être déduites du fait que l'arc sinus est une fonction impaire.

En ce qui concerne la dérivabilité de la fonction arc sinus, en application de la proposition \ref{PropMRBooXnnDLq} elle est dérivable en tout \( y=\sin(x)\) tel que \( \sin'(x)\neq 0\), c'est à dire tel que \( \cos(x)\neq 0\). Or \( \cos(x)=0\) pour \( x=\pm\frac{ \pi }{2}\), ce qui correspond à \( y=\sin(\pm\frac{ \pi }{2})=\pm 1\). La fonction arc sinus est donc dérivable sur \( \mathopen] -1 , 1 \mathclose[\). Nous avons donc la propriété suivante pour la dérivabilité.

\begin{proposition}
    La fonction arc sinus est continue sur \( \mathopen[ -1 , 1 \mathclose]\) et dérivable sur \( \mathopen] -1 , 1 \mathclose[\). Pour tout \( y\in\mathopen] -1 , 1 \mathclose[\), la dérivée est donnée par la formule \eqref{EqWWAooBRFNsv}, qui dans ce cas s'écrit
        \begin{equation}
            \arcsin'(y)=\frac{1}{ \cos\big( \arcsin(y) \big) }=\frac{1}{ \sqrt{1-y^2} }.
        \end{equation}
\end{proposition}
La dernière égalité viens du fait que si $x=\arcsin(y)$ alors $y = \sin(x)$ et $\cos(x)= \sqrt{1-\sin^2(x)} = \sqrt{1-y^2}$. 

Pour comprendre la dernière égalité, remarquer que dans le dessin suivant, \( \theta=\arcsin(y)\), donc $y = \sin(\theta)$, et \( x=\cos(\theta)\).
\begin{center}
    \input{auto/pictures_tex/Fig_BIFooDsvVHb.pstricks}
\end{center}

Notons enfin que le graphe de la fonction arc sinus est donné à la figure \ref{LabelFigFGRooDhFkch}. % From file FGRooDhFkch
\newcommand{\CaptionFigFGRooDhFkch}{Le graphe de la fonction \( x\mapsto \arcsin(x)\)}
\input{auto/pictures_tex/Fig_FGRooDhFkch.pstricks}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{La fonction arc cosinus}
%---------------------------------------------------------------------------------------------------------------------------

Nous voulons étudier la fonction
\begin{equation}
    \begin{aligned}
        \cos\colon \eR&\to \mathopen[ -1 , 1 \mathclose] \\
        x&\mapsto \cos(x) 
    \end{aligned}
\end{equation}
et son éventuelle réciproque. Encore une fois il n'est pas possible d'en prendre la réciproque globale parce que ce n'est pas une bijection. Nous choisissons de considérer l'intervalle \( \mathopen[ 0 , \pi \mathclose]\) sur lequel la fonction cosinus est continue et strictement monotone décroissante.

Nous avons alors le résultat suivant :

\begin{proposition}
    La fonction
    \begin{equation}
        \begin{aligned}
            \cos\colon \mathopen[ 0 , \pi \mathclose]&\to \mathopen[ -1 , 1 \mathclose] \\
            x&\mapsto \cos(x) 
        \end{aligned}
    \end{equation}
    est une bijection continue strictement décroissante. Sa bijection réciproque, nommée \defe{arc cosinus}{arc cosinus}
    \begin{equation}
        \begin{aligned}
            \arccos\colon \mathopen[ -1 , 1 \mathclose]&\to \mathopen[ 0 , \pi \mathclose] \\
            x&\mapsto \arccos(x) 
        \end{aligned}
    \end{equation}
est continue, strictement décroissante et dérivable. Pour tout \( y\in\mathopen] -1 , 1 \mathclose[\), sa dérivée est donnée par
    \begin{equation}
        \arccos'(y)=\frac{1}{ -\sin\big( \arccos(y) \big) }=\frac{ -1 }{ \sqrt{1-y^2} }.
    \end{equation}
\end{proposition}

\begin{remark}
    Certes la fonction cosinus est paire (vue sur \( \eR\)), mais la fonction arc cosinus ne l'est pas car elle est une bijection entre \(\mathopen[ -1 , 1 \mathclose]\) et \(\mathopen[ 0 , \pi \mathclose]\).
\end{remark}

Pour \( y_0\in\mathopen[ -1 , 1 \mathclose]\), trouver la valeur de \( \arccos(y_0)\) revient à résoudre l'équation \( \cos(x_0)=y_0\). Cela nous permet de construire une tableau de valeurs :
\begin{equation*}
    \begin{array}[]{|c|c|c|c|c|c|c|c|c|c|}
        \hline
        x&-1&-\frac{ \sqrt{3} }{2}&-\frac{ \sqrt{2} }{2}&-\frac{ 1 }{2}&0&\frac{ 1 }{2}&\frac{ \sqrt{2} }{2}&\frac{ \sqrt{3} }{2}&1\\
          \hline
          \arccos(x)&\pi&\frac{ 5\pi }{ 6 }&\frac{ 3 }{ 4 }\pi&\frac{ 2 }{ 3 }\pi&\frac{ 1 }{2}\pi&\frac{ \pi }{ 3 }&\frac{1}{ 4 }\pi&\frac{1}{ 6 }\pi&0\\
          \hline 
           \end{array}
\end{equation*}

\begin{example}
    Cherchons \( \arccos(\frac{ 1 }{2})\). Il faut trouver un angle \( \theta\in\mathopen[ 0 , \pi \mathclose]\) tel que \( \cos(\theta)=\frac{ 1 }{2}\). La solution est \( \theta=\frac{ \pi }{ 3 }\). Donc \( \arccos(\frac{ 1 }{2})=\frac{ \pi }{ 3 }\).

    Il n'est cependant pas immédiat d'en déduire la valeur de \( \arccos(-\frac{ 1 }{2})\). En effet \( \theta=\arccos(-\frac{ 1 }{2})\) si et seulement si \( \cos(\theta)=-\frac{ 1 }{2}\) avec \( \theta\in\mathopen[ 0 , \pi \mathclose]\). La solution est \( \theta=\frac{ 2\pi }{ 3 }\).
\end{example}

En ce qui concerne la représentation graphique, il suffit de tracer la fonction cosinus entre \( 0\) et \( \pi\) puis de prendre le symétrique par rapport à la droite \( y=x\).

\begin{center}
    \input{auto/pictures_tex/Fig_GMIooJvcCXg.pstricks}
\end{center}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Les coordonnées polaires}
%---------------------------------------------------------------------------------------------------------------------------

On a vu qu'un point $M$ dans $\eR^2$ peut être représenté par ses abscisses $x$ et ses ordonnées $y$. Nous pouvons également déterminer le même point $M$ en donnant un angle et une distance comme montré sur la figure \ref{LabelFigJWINooSfKCeA}.
\newcommand{\CaptionFigJWINooSfKCeA}{Un point en coordonnées polaires est donné par sa distance à l'origine et par l'angle qu'il faut avec l'horizontale.}
\input{auto/pictures_tex/Fig_JWINooSfKCeA.pstricks}


Le même point $M$ peut être décrit indifféremment avec les coordonnées $(x,y)$ ou bien avec $(r,\theta)$.

\begin{remark}
	L'angle $\theta$ d'un point n'étant a priori défini qu'à un multiple de $2\pi$ près, nous convenons de toujours choisir un angle $0\leq\theta<2\pi$. Par ailleurs l'angle $\theta$ n'est pas défini si $(x,y)=(0,0)$.

	La coordonnée $r$ est toujours positive.
\end{remark}

En utilisant la trigonométrie, il est facile de trouver le changement de variable qui donne $(x,y)$ en fonction de $(r,\theta)$:
\begin{subequations}		\label{EqrthetaxyPoal}
	\begin{numcases}{}
		x=r\cos(\theta)\\
		y=r\sin(\theta).
	\end{numcases}
\end{subequations}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Transformation inverse : théorie}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Voyons la question inverse : comment retrouver $r$ et $\theta$ si on connait $x$ et $y$ ? Tout d'abord,
\begin{equation}
	r=\sqrt{x^2+y^2}
\end{equation}
parce que la coordonnée $r$ est la distance entre l'origine et $(x,y)$. Comment trouver l'angle ? Nous supposons $(x,y)\neq (0,0)$. Si $x=0$, alors le point est sur l'axe vertical et nous avons
\begin{equation}
	\theta=\begin{cases}
		\pi/2	&	\text{si }y>0\\
		3\pi/2	&	 \text{si }y<0
	\end{cases}
\end{equation}
Notez que si $y<0$, conformément à notre convention $\theta\geq 0$, nous avons noté $\frac{ 3\pi }{2}$ et non $-\frac{ \pi }{ 2 }$.

Supposons maintenant le cas général avec $x\neq 0$. Les équations \eqref{EqrthetaxyPoal} montrent que
\begin{equation}
	\tan(\theta)=\frac{ y }{ x }.
\end{equation}
Nous avons donc
\begin{equation}
	\theta=\tan^{-1}\left( \frac{ y }{ x } \right).
\end{equation}
La fonction inverse de la fonction tangente est celle définie plus haut.

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Transformation inverse : pratique}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Le code suivant utilise \href{http://www.sagemath.org}{Sage}.

\lstinputlisting{tex/frido/calculAngle.py}

Son exécution retourne :
\begin{verbatim}
(sqrt(2), 1/4*pi)
(sqrt(5), pi - arctan(1/2))
(6, 1/6*pi)
\end{verbatim}
Notez que ce sont des valeurs \emph{exactes}. Ce ne sont pas des approximations, Sage travaille de façon symbolique.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Rappels de trigonométrie}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\label{secHTVooJuBtam}

Voici un tableau qui rappelle les valeurs à retenir pour les fonctions sinus, cosinus et tangente.\label{PGooIMQFooTnBdIl}
\begin{equation*}
    \begin{array}[]{|c|c|c|c|}
      \hline
      x&\sin(x)&\cos(x)&\tan(x)\\
      \hline
      0&0&1&0\\
      \hline
      \pi/6&1/2&\sqrt{3}/2&\sqrt{3}/3\\
      \hline
      \pi/6&1/2&\sqrt{3}/2&\sqrt{3}/3\\
      \hline
      \pi/4&\sqrt{2}/2&\sqrt{2}/2&1\\
      \hline
      \pi/3&\sqrt{3}/2&1/2&\sqrt{3}\\
      \hline
      \pi/2&1&0&\text{N.D.}\\
      \hline
    \end{array}
\end{equation*}
où «N.D.»  signifie «non défini».

Rappelons le graphe de la fonction sinus :
\begin{center}
   \input{auto/pictures_tex/Fig_TWHooJjXEtS.pstricks}
\end{center}
celui de la fonction cosinus :
\begin{center}
   \input{auto/pictures_tex/Fig_JJAooWpimYW.pstricks}
\end{center}


    \begin{lemma}
      Pour toute valeur de $x\in \eR$ on a $|\sin(x)|\leq |x|$. 
    \end{lemma}

    \begin{proof}
        Nous séparons des cas en fonction des valeurs.
    \begin{itemize}
    \item Si $0\leq x\leq \pi/2$ alors le sinus de $x$ est la longueur du cathète verticale du triangle rectangle de sommets $O = (0,0)$, $A = (\cos(x), \sin(x))$ et $B = (\cos(x), 0)$. Le triangle de sommets $A$, $B$ et $C = (1, 0)$ est aussi rectangle et nous savons que chacun des cathètes ne peut pas \^etre plus long que l'hypoténuse. Donc $\sin(x)$ est inférieur à la longueur du segment $AC$. À son tour le segment $AC$ ne peut pas \^etre plus long que l'arc de cercle $\wideparen{A0C}$, car le chemin le plus court entre deux points du plan est toujours donné par un morceau de droite. La longueur de l'arc du cercle $\frown{AC}$ est \emph{par définition} la mesure en radiants de l'angle $\widehat{AOC}$, qui est $x$ et on a l'inégalité $\sin(x)\leq x$. 
    \item Si $-\pi/2\leq x\leq 0$ le m\^eme raisonnement que au point précédent permet de conclure que $\sin(x)\leq |x|$.
    \item Nous savons par ailleurs que la fonction sinus prend ses valeurs dans l'intervalle $[-1,1]$ et donc pour tout $x$ tel que $|x|\geq \pi/2 \equiv 1,57\ldots$ on a forcement $|\sin(x)|\leq |x|$.  
    \end{itemize}
    \end{proof}

\begin{proposition}
    Nous avons la limite
    \begin{equation}\label{sinsurx}
      \lim_{x\to 0} \frac{\sin(x)}{x} = 1.
    \end{equation}
\end{proposition}

\begin{proof}
    On commence par observer que la fonction $g(x)=\frac{\sin(x)}{x}$ est un rapport entre deux fonction impaires et est donc une fonction paire. Nous pouvons alors nous réduire à considérer le cas où $x$ est positif. La première étape de cette preuve nous dit que $g(x)\leq 1$ pour tout $x\in\eR^{+,*}$. 

    Nous voulons étudier le comportement de $g$ dans un voisinage de $0$. Nous pouvons alors supposer que $x$ soit inférieur à $\pi/2$. Soit $D = (1, \tan (x))$. On voit très bien dans le dessin que l'aire du triangle de sommets $O$, $D$ et $C$ est supérieure à l'aire du secteur circulaire de sommets $O$, $A$ et $C$. Ces deux aires peuvent \^etre calculées très facilement et nous obtenons
    \begin{equation*}
      \frac{\sin(x)}{2\cos(x)} \geq \frac{x}{2}.
    \end{equation*}
    À partir de cette dernière inégalité nous pouvons écrire 
    \begin{equation*}
      1\geq \frac{\sin(x)}{x}\geq \cos(x).
    \end{equation*}
    En prenant la limite lorsque $x$ tend vers $0$ dans les trois membres de l'inégalité la règle de l'étau nous permet d'obtenir la limite remarquable  \eqref{sinsurx}. 
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Forme polaire ou trigonométrique des nombres complexes}
%---------------------------------------------------------------------------------------------------------------------------

Dans le plan de Gauss, le module d'un complexe $z$ représente la distance entre $0$ et $z$. On appelle \Defn{argument} de $z$ (noté $\arg z$) l'angle (déterminé à $2\pi$ près) entre le demi-axe des réels positifs et la demi-droite qui part de $0$ et passe par $z$. Le module et l'argument d'un complexe permettent de déterminer univoquement ce complexe puisqu'on a la formule
\[z = a + bi = \module z \left( \cos(\arg(z)) + i \sin(\arg(z)) \right)\]

L'argument de $z$ se détermine via les formules 
\[\frac a {\module z} = \cos(\arg(z)) \quad \frac b {\module z} = \sin(\arg(z))\]
ou encore par la formule
\[
\frac b a = \tan(\arg(z)) \quad \text{en vérifiant le quadrant.}
\]
La vérification du quadrant vient de ce que la tangente ne détermine l'angle qu'à $\pi$ près.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Angle entre deux vecteurs}
%---------------------------------------------------------------------------------------------------------------------------

Si $a$ et $b$ sont des réels, l'inégalité $| a |\leq b$ peut se développer en une double inégalité
\begin{equation}
	-b\leq a\leq b.
\end{equation}
L'inégalité de Cauchy-Schwarz devient alors
\begin{equation}
	-\| X \|\| Y \|\leq X\cdot Y\leq\| X \|\| Y \|.
\end{equation}
Si $X\neq 0$ et $Y\neq 0$, nous avons alors
\begin{equation}
	-1\leq\frac{ X\cdot Y }{ \| X \|\| Y \| }\leq 1.
\end{equation}
Il existe donc un angle $\theta\in\mathopen[ 0 , \pi \mathclose]$ tel que
\begin{equation}		\label{eqDefAngleVect}
	\cos(\theta)=\frac{ X\cdot Y }{ \| X \|\| Y \| }.
\end{equation}

\begin{definition}      \label{DEFooSVDZooPWHwFQ}
L'angle ainsi défini est l'\defe{angle}{angle!entre vecteurs} entre $X$ et $Y$. La définition \eqref{eqDefAngleVect} est souvent utilisée sous la forme
\begin{equation}		\label{eqPropCosThet}
	X\cdot Y=\| X \|\| Y \|\cos(\theta).
\end{equation}
\index{cosinus!angle entre deux vecteurs}
\end{definition}

Notez que les angles sont toujours des angles plus petits ou égaux à \unit{180}{\degree}.

La longueur de la projection du point $P$ sur la droite horizontale va naturellement être égale à $\cos(\theta)$. En effet, si nous notons $X$ un vecteur horizontal de norme $1$, cette projection est donné par $P\cdot X$. Mais en reprenant l'équation \eqref{eqPropCosThet}, nous voyons que
\begin{equation}
	P\cdot X=\| P \|\| X \|\cos(\theta),
\end{equation}
tandis qu'ici nous avons $\| P \|=\| X \|=1$.

Nous appelons $\sin(\theta)$ la longueur de la projection sur l'axe vertical.

Quelques dessins nous convainquent que 
\begin{equation}
	\begin{aligned}[]
		\sin(\theta+2\pi)&=\sin(\theta)&\cos(\theta+2\pi)&=\sin(\theta),\\
		\sin(\theta+\frac{ \pi }{2})&=\cos(\theta)&\cos(\theta+\frac{ \pi }{2})&=-\sin(\theta),\\
		\sin(\pi-\theta)&=\sin(\theta)&\cos(\pi-\theta)&=-\cos(\theta).
	\end{aligned}
\end{equation}
Le théorème de Pythagore nous montre aussi l'importante relation
\begin{equation}
	\sin^2(\theta)+\cos^2(\theta)=1.
\end{equation}

Quelques valeurs remarquables pour les sinus et cosinus :
\begin{equation}
	\begin{aligned}[]
		\sin 0&=0,&\sin\frac{ \pi }{ 6 }&=\frac{ 1 }{2},&\sin\frac{ \pi }{ 4 }&=\frac{ \sqrt{2} }{2},&\sin\frac{ \pi }{ 3 }&=\frac{ \sqrt{3} }{2},&\sin\frac{ \pi }{2}&=1,&\sin\pi&=0\\
		\cos 0&=1,&\cos\frac{ \pi }{ 6 }&=\frac{ \sqrt{3} }{2},&\cos\frac{ \pi }{ 4 }&=\frac{ \sqrt{2} }{2},&\cos\frac{ \pi }{ 3 }&=\frac{ 1 }{2},&\cos\frac{ \pi }{2}&=0,&\cos\pi&=-1
	\end{aligned}
\end{equation}

Nous pouvons prouver simplement que $\sin(\unit{30}{\degree})=\frac{ 1 }{2}$ et $\cos(\unit{30}{\degree})=\frac{ \sqrt{3} }{2}$ en s'inspirant de la figure \ref{LabelFigGVDJooYzMxLW}. % From file GVDJooYzMxLW
\newcommand{\CaptionFigGVDJooYzMxLW}{Un triangle équilatéral de côté $1$.}
\input{auto/pictures_tex/Fig_GVDJooYzMxLW.pstricks}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Vitesses de $x^{\alpha}$, de l'exponentielle et du logarithme}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{lemma}   \label{LemSYHKooUiSMFJ}
    Pour tout \( \alpha>0\), il existe \( N\) tel que \( \ln(n)\leq n^{\alpha}\) pour tout \( n\geq N\).
\end{lemma}

\begin{proof}
En effet, nous avons
\begin{equation}
    \lim_{x\to\infty} \frac{ x^{\alpha} }{ \ln(x) }=\lim_{x\to\infty} \frac{ \alpha x^{\alpha-1} }{ 1/x }=\lim_{x\to\infty} \alpha x^{\alpha}=\infty
\end{equation}
quand $\alpha>0$. 
\end{proof}
Cela tient également lorsque nous considérons $\ln(x)^p$ au lieu de $\ln(x)$. De cela, nous disons que le logarithme croit moins vite que n'importe quel polynôme. 

\begin{lemma}
    L'exponentielle croit plus vite que tout polynôme, et plus vite que que logarithme :
    \begin{equation}        \label{EqExpDecrtPlusVite}
        \lim_{t\to\infty} e^{-t}(\ln t)^{n}t^{\alpha}=0
    \end{equation}
    pour tout $n$ et pour tout $\alpha$.
\end{lemma}

\begin{lemma}       \label{LemVKDKooEftNzG}
    Nous avons aussi la limite utile suivante 
    \begin{equation}
        \lim_{n\to \infty} n^{\alpha}a^n
    \end{equation}
    pour tout \( \alpha>0\) et \( a<1\).
\end{lemma}

\begin{proof}
    En passant à l'exponentielle, pour chaque \( n\) nous avons
    \begin{equation}        \label{EqLKLQooLIlWgm}
        n^{\alpha}a^n= e^{\alpha\ln(n)+n\ln(a)}.
    \end{equation}
    Ce qui est dans l'exponentielle est
    \begin{equation}
        \alpha\ln(n)+n\ln(a)=n\big(\alpha \frac{ \ln(n) }{ n }+\ln(a) \big).
    \end{equation}
    Dans la parenthèse, \( \ln(a)<0\) et \( \frac{ \ln(n) }{ n }\to 0\). Donc ce qui est dans l'exponentielle \eqref{EqLKLQooLIlWgm} tend vers \( -\infty\) et au final l'expression demandée tend vers zéro.
\end{proof}

\begin{proposition} \label{PropBQGBooHxNrrf}
    Pour tout polynôme \( P\) et pour tout \( a>0\) la fonction \( f(x)=P(x) e^{-ax}\) est intégrable\footnote{Définition \ref{DefTCXooAstMYl}.} sur \( \mathopen[ 0 , \infty [\).
\end{proposition}

\begin{proof}
    Nous avons \( f(x)=P(x) e^{-ax/2} e^{-ax/2}\), et par la vitesse comparée des exponentielles et polynômes, pour un certain \( M>0\) nous pouvons affirmer que \( P(x) e^{-ax/2}<1\) sur \( \mathopen[ M , 0 [\). Dès lors
        \begin{equation}
            | f(x) |< e^{-ax/2},
        \end{equation}
        qui est intégrable.
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Trigonométrie hyperbolique}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{definition}
    Les fonction \defe{sinus hyperbolique}{sinus!hyperbolique} et \defe{cosinus hyperbolique}{cosinus!hyperbolique} sont les fonctions définies sur $\eR$ par les formules suivantes :
    \begin{subequations}
        \begin{align}
            \cosh(x)&=\frac{  e^{x}+ e^{-x} }{2}\\
            \sinh(x)&=\frac{  e^{x}- e^{-x} }{2}
        \end{align}
    \end{subequations}
\end{definition}

Leurs principales propriétés sont :
\begin{enumerate}
    \item
        \( \cosh^2(x)-\sinh^2(x)=1\)
    \item
        \( \cosh'(x)=\sinh(x)\) 
    \item
        \( \sinh'(x)=\cosh\).
\end{enumerate}

Les représentations graphiques sont ceci :
\begin{center}
   \input{auto/pictures_tex/Fig_UNVooMsXxHa.pstricks}
\end{center}

La \defe{tangente hyperbolique}{tangente hyperbolique} est donnée par le quotient
\begin{equation}
    \tanh(x)=\frac{ \sinh(x) }{ \cosh(x) }.
\end{equation}

%Les fonction réciproques de $\sinh$, $\cosh$ et $\tanh$ sont traitées dans les exercices.



%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Dénombrement des solutions d'une équation diophantienne}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{theorem}[\cite{fJhCTE,NHXUsTa}] \label{ThoDIDNooUrFFei}
    Soient des entiers naturels premiers dans leur ensemble\footnote{Définition \ref{DefZHRXooNeWIcB}.} \( \alpha_1,\ldots, \alpha_p\) et l'équation
    \begin{equation}
        \alpha_1n_1+\cdots +\alpha_pn_p=n
    \end{equation}
    pour les naturels \( n_i\) où \( n\) est un naturel donné. Nous notons \( S_n\) le nombre de solutions de cette équation. Alors :
    \begin{enumerate}
        \item
            Il existe un algorithme (en temps fini) pour calculer \( S_n\) en fonction des \( \alpha_i\) et de \( n\).
        \item
            Nous avons le comportement asymptotique
            \begin{equation}
                S_n\sim\frac{1}{ \alpha_1\ldots\alpha_p }\frac{ n^{p-1} }{ (p-1)! }.
            \end{equation}
    \end{enumerate}
\end{theorem}

\begin{proof}
    Pour \( | z |<1\) dans \( \eC\), utilisant le lemme \ref{LemPQFDooGUPBvF}, nous écrivons le développement
    \begin{equation}
        F(z)=\prod_{i=1}^p\frac{1}{ 1-z^{\alpha_i} }=\prod_{i=1}^p\sum_{n\geq 0}z^{n\alpha_i}.
    \end{equation}
    Nous allons maintenant à la pêche au terme de degré \( k\) dans ce produit de sommes en utilisant \( p\) fois le produit de Cauchy de la formule \eqref{EqFPGGooDQlXGe}. Nous avons
    \begin{equation}
        F(z)=\sum_{k\geq 0}\left( \sum_{n_1\alpha_1+\cdots +n_p\alpha_p=n}1 \right)z^k=\sum_{k\geq 0}S_kz^k.
    \end{equation}
    
    La technique pour déterminer la valeur de \( S_n\) est alors de développer \( F(z)\) en série de façon un peu explicite et d'identifier le coefficient de \( z^n\) parce que nous venons de voir que ce coefficient est \( S_n\). Nous commençons par une décomposition en éléments simples, expliquée autour de l'équation \eqref{EqDWYBooJIMBAt} :
    \begin{equation}
        \frac{1}{ 1-z^{\alpha_i} }=\sum_{\alpha\in U_{\alpha_i}}\frac{ A_{\omega,i} }{ \omega-z }.
    \end{equation}
    où \( U_{\alpha_i}\) est le groupe des racines \( \alpha_i\)\ieme de l'unité décrit en \ref{SecGJOLooWdMYVl}. La raison de ce développement est que, comme mentionné dans le lemme \ref{LemKYGBooAwpOHD}, \( \prod_{\omega\in\gU_{\alpha_i}}(z-\omega)=z^{\alpha_1}-1\). Lorsque nous effectuons la somme, le dénominateur commun est donc bien\footnote{Pour le signe, c'est ajustable avec le signe de \( A_{\omega,i}\).} \( 1-z^{\alpha_i}\).
    En récrivant le produit :
    \begin{equation}
        F(z)=\prod_{i=1}^{p}\frac{1}{ 1-z^{\alpha_i} }=\prod_{i=1}^p\sum_{\omega\in U_{\alpha_i}}\frac{ A_{\omega,i} }{ \omega-z }
    \end{equation}
    Les coefficients \( A_{\omega,i}\) sont calculables explicitement, en temps fini.

    Vu que \( 1\) est dans tous les \( \gU_{\alpha_i}\), le produit fait intervenir au dénominateur des puissances de \( (1-z)\) jusqu'à la puissance \( p\). Les autres racines de l'unité appartiennent au maximum à \( p-1\) des groupes \( \gU_{\alpha_i}\) parce que les nombres \( \alpha_i\) sont premiers dans leur ensemble, voir la proposition \ref{PropFDDHooEyYxBC}.

    La fonction \( F\) peut alors s'écrire sous la forme
    \begin{equation}    \label{EqLISXooSlwIWD}
        F(z)=\frac{ A }{ (1-z)^p }+G(z)
    \end{equation}
    où \( G(z)\) est une somme de termes de la forme
    \begin{equation}
        \frac{ a_{i,1} }{ 1-\omega_i }+\cdots +\frac{ a_{i,p} }{ (1-\omega_i)^{p-1} }
    \end{equation}
    où les \( \omega_i\) sont les racines \( \alpha_i\)\ieme de l'unité et \( a_{k,r}\) sont des nombres complexes. Trouvons \( A\). D'abord grâce au lemme \ref{LemISPooHIKJBU}\ref{ItemLTBooAcyMtNii} nous avons
    \begin{equation}
        F(z)(1-z)^p=\prod_{l=1}^p\frac{ 1-z }{ 1-z^{\alpha_i} }=\prod_{i=1}^p\frac{ 1 }{ 1+z+\cdots +z^{\alpha_i-1} },
    \end{equation}
    et donc 
    \begin{equation}
        \lim_{z\to 1}F(z)(1-z)^p=\prod_{i=1}^p\frac{1}{ \alpha_i }.
    \end{equation}
    Mais vu ce que contient \( G(z)\), nous avons aussi \( \lim_{z\to 1}F(z)=A\). Nous avons donc déjà déterminé \( A=\frac{1}{  \alpha_1\ldots\alpha_p }\).

    Pour la suite nous avons besoin des développements du lemme \ref{LemPQFDooGUPBvF}. Nous utiliserons en particulier celle-ci :
    \begin{equation}
        \frac{1}{ (\omega-z)^k }=\frac{1}{ (k-1)! }\sum_{s=0}^{\infty}\omega^{-s-1-k}\frac{ (s+k-1)! }{ s! }z^s.
    \end{equation}
    En particulier le module du coefficient de \( z^n\) là dedans est : \(  \frac{(n+k-1)! }{ n!(k-1)! } \). Dans la partie \( G\) de la décomposition \eqref{EqLISXooSlwIWD}, \( k\) est majoré par \( p-2\) et la dépendance en \( n\) est donc au maximum du type
    \begin{equation}
        \frac{ (n+p-2)! }{ n!(p-2)! }\sim  \frac{ n^{n+p-2} }{ n^n(p-2)! }=\frac{ n^{p-2} }{ (p-2)! }.
    \end{equation}
    Dans le premier terme par contre, il y a des termes jusqu'à \( k=p\). Le terme dominant est alors en \( \frac{ n^{p-1} }{ (p-1)! }\) et son coefficient est \( A\) qui est déjà calculé. Au final le terme dominant du coefficient de \( z^n\) dans \( F(z)\) est
    \begin{equation}
        S_n\sim \frac{ A }{ (p-1)! }n^{p-1}=\frac{1}{ \alpha_1\ldots \alpha_p }\frac{ n^{p-1} }{ (p-1)! }.
    \end{equation}
\end{proof}

\begin{example}
    Pour \( p=1\), l'équation est \( \alpha x=n\), qui possède au maximum une solution, quel que soit \( n\). Et de plus pour avoir une solution il faut et suffit que \( \alpha\) divise \( n\), c'est à dire que \( n\) soit un multiple de \( \alpha\). Il n'y a que un nombre sur \( \alpha\) à être multiple de \( \alpha\). D'où le comportement en \( \frac{1}{ \alpha }\).

    Pour \( p=2\), c'est l'équation \eqref{EqTOVSooJbxlIq} déjà étudiée. Il y a une famille à un paramètre de solutions dont seulement un certain nombre sont positives. A priori, le nombre de solutions positives croît linéairement en \( n\).
\end{example}
