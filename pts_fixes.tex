% This is part of Mes notes de mathématique
% Copyright (c) 2011-2013
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Convolution}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Le théorème qui permet de définir le produit de convolution est la suivant.

\begin{theorem}[\cite{MesIntProbb}]
    Soient \( f,g\in L^1(\eR^n)\). 
    \begin{enumerate}
        \item
            Pour presque tout \( x\in \eR^n\), la fonction
            \begin{equation}
                y\mapsto g(x-y)f(y)
            \end{equation}
            est dans \( L^1(\eR^n)\), et nous définissons le \defe{produit de convolution}{produit!de convolution} de \( f\) et \( g\) par
            \begin{equation}
                (f*g)(x)=\int_{\eR^n} f(y)g(x-y)dy.
            \end{equation}
        \item
            \( f*g\in L^1(\eR^n)\).
        \item
            \( \| f*g \|_1\leq \| f \|_1\| g \|_1\).
    \end{enumerate}
\end{theorem}

L'ensemble \( L^1(\eR^n)\) devient alors une algèbre de Banach.

\begin{lemma}
    Le produit de convolution est commutatif : \( f*g=g*f\).
\end{lemma}

\begin{proof}
    Le théorème de Fubini (théorème \ref{ThoFubinioYLtPI}) permet d'écrire
    \begin{equation}
        (f*g)(x)=\int_{\eR^n}f(y)g(x-y)dy=\int_{-\infty}^{\infty}dy_1\ldots \int_{-\infty}^{\infty}dy_nf(y)g(x-y).
    \end{equation}
    En effectuant le changement de variable \( z_i=x_i-y_i\) dans chacune des intégrales nous obtenons
    \begin{equation}
        (f*g)(x)=\int_{\eR^n}g(z)f(x-z)dz=(g*f)(x).
    \end{equation}
\end{proof}

\begin{proposition}[\cite{CXCQJIt}] \label{PropHNbdMQe}
    Si \( f\in L^1(\eR)\) et si \( g\) est dérivable avec \( g'\in L^{\infty}\), alors \( f*g\) est dérivable et \( (f*g)'=f*g'\).
\end{proposition}

\begin{proof}
    La fonction qu'il faut intégrer pour obtenir \( f*g\) est $f(t)g(x-t)$, dont la dérivée par rapport à \( x\) est \( f(t)g'(x-t)\). La norme de cette dernière est majorée (uniformément en \( x\)) par \( G(t)=| f(t) | \| g' \|_{\infty}\). La fonction \( f\) étant dans \( L^1(\eR)\), la fonction \( G\) est intégrable et le théorème de dérivation sous l'intégrale (théorème \ref{ThoMWpRKYp}) nous dit que \( f*g\) est dérivable et
    \begin{equation}
        (f*g)'(x)=\frac{ d }{ dx }\int_{\eR}f(t)g(x-t)dt=\int_{\eR}f(t)g'(x-t)dt=(f*g')(x).
    \end{equation}
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Théorème du point fixe de Picard}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{definition}
    Une application \( f\colon (X,\| . \|_X)\to (Y,\| . \|_Y)\) entre deux espaces métriques est une \defe{contraction}{contraction} si elle est \( k\)-\defe{Lipschitz}{Lipschitz} pour un certain \( 0\leq k<1\), c'est à dire si pour tout \( x,y\in X\) nous avons
    \begin{equation}
        \| f(x)-f(y) \|_Y\leq k\| x-y \|_{X}.
    \end{equation}
\end{definition}


\begin{theorem}[Picard \cite{ClemKetl,NourdinAnal}\footnote{Il me semble qu'à la page 100 de \cite{NourdinAnal}, l'hypothèse H1 qui est prouvée ne prouve pas Hn dans le cas \( n=1\). Merci de m'écrire si vous pouvez confirmer ou infirmer. La preuve donnée ici ne contient pas cette «erreur».}.]     \label{ThoEPVkCL}\index{théorème!Picard}
    Soit \( X\) un espace métrique complet et \( f\colon X\to X\) une application contractante, de constante de Lipschitz \( k\). Alors \( f\) admet un unique point fixe, nommé \( \xi\). Ce dernier est donné par la limite de la suite définie par récurrence 
    \begin{subequations}
        \begin{numcases}{}
            x_0\in X\\
            x_{n+1}=f(x_n).
        \end{numcases}
    \end{subequations}
    De plus nous pouvons majorer l'erreur par
    \begin{equation}    \label{EqKErdim}
        \| x_n-x \|\leq \frac{ k^n }{ 1-k }\| x_n-x_{n-1} \|\leq \frac{ k^n }{ 1-k }\| x_1-x_0 \|.
    \end{equation}

    Soit \( r>0\), \( a\in X\) tels que la fonction \( f\) laisse la boule \( K=\overline{ B(a,r) }\) invariante (c'est à dire que \( f\) se restreint à \( f\colon K\to K\)). Nous considérons les suites \( (u_n)\) et \( (v_n)\) définies par
    \begin{subequations}
        \begin{numcases}{}
            u_0=v_0\in K\\
            u_{n+1}=f(v_n), v_{n+1}\in B(u_n,\epsilon).
        \end{numcases}
    \end{subequations}
    Alors le point fixe \( \xi\) de \( f\) est dans \( K\) et la suite \( (v_n)\) satisfait l'estimation
    \begin{equation}
        \| v_n-\xi \|\leq \frac{ k^n }{ 1-k }\| u_1-u_0 \|+\frac{ \epsilon }{ 1-k }.
    \end{equation}
\end{theorem}

La première inégalité \eqref{EqKErdim} donne une estimation de l'erreur calculable en cours de processus; la seconde donne une estimation de l'erreur calculable avant de commencer.

\begin{proof}
    
    Nous commençons par l'unicité du point fixe. Si \( a\) et \( b\) sont des points fixes, alors \( f(a)=a\) et \( f(b)=b\). Par conséquent
    \begin{equation}
        \| f(a)-f(b) \|=\| a-b \|,
    \end{equation}
    ce qui contredit le fait que \( f\) soit une contraction.

    En ce qui concerne l'existence, notons que si la suite des \( x_n\) converge dans \( X\), alors la limite est un point fixe. En effet en prenant la limite des deux côtés de l'équation \( x_{n+1}=f(x_n)\), nous obtenons \( \xi=f(\xi)\), c'est à dire que \( \xi\) est un point fixe de \( f\). Notons que nous avons utilisé ici la continuité de \( f\), laquelle est une conséquence du fait qu'elle soit Lipschitz. Nous allons donc porter nos efforts à prouver que la suite est de Cauchy (et donc convergente parce que \( X\) est complet). Nous commençons par prouver que \( \| x_{n+1}-x_n \|\leq k^n\| x_0-x_1 \|\). En effet pour tout \( n\) nous avons
    \begin{equation}
        \| x_{n+1}-x_n \|=\| f(x_n)-f(x_{n-1}) \|\leq k\| x_n-x_{n-1} \|.
    \end{equation}
    La relation cherchée s'obtient alors par récurrence. Soient \( q>p\). En utilisant une somme télescopique,
    \begin{subequations}
        \begin{align}
            \| x_q-x_p \|&\leq \sum_{l=p}^{q-1}\| x_{l+1}-x_l \|\\
            &\leq\left( \sum_{l=p}^{q-1}k^l \right)\| x_1-x_0 \|\\
            &\leq\left(\sum_{l=p}^{\infty}k^l\right)\| x_1-x_0 \|.
        \end{align}
    \end{subequations}
    Étant donné que \( k<1\), la parenthèse est la queue d'une série qui converge, et donc tend vers zéro lorsque \( p\) tend vers l'infini.

    En ce qui concerne les inégalités \eqref{EqKErdim}, nous refaisons une somme télescopique :
    \begin{subequations}
        \begin{align}
            \| x_{n+p}-x_n \|&\leq \| x_{n+p}-x_{n+p-1} \|+\ldots +\| x_{n+1}-x_n \|\\
            &\leq k^p\| x_n-x_{n-1} \|+k^{p-1}\| x_n-x_{n-1} \|+\ldots +k\| x_n-x_{n-1} \|\\
            &=k(1+\ldots +k^{p-1})\| x_n-x_{n-1}\|  \\
            &\leq \frac{ k }{ 1-k }\| x_n-x_{n-1} \|.
        \end{align}
    \end{subequations}
    En prenant la limite \( p\to \infty\) nous trouvons
    \begin{equation}        \label{EqlUMVGW}
        \| \xi-x_n \|\leq \frac{ k }{ 1-k }\| x_n-x_{n-1} \|\leq \frac{ k }{ 1-k }\| x_1-x_0 \|.
    \end{equation}

    Nous passons maintenant à la seconde partie du théorème en supposant que \( f\) se restreigne en une fonction \( f\colon K\to K\). D'abord \( K\) est encore un espace métrique complet, donc la première partie du théorème s'y applique et \( f\) y a un unique point fixe.
    
    Nous allons montrer la relation par récurrence. Tout d'abord pour \( n=1\) nous avons
    \begin{equation}
        \| v_1-\xi \|\leq\| v_1-u_1 \|+\| u_1-\xi \|\leq \epsilon+\frac{ k }{ 1-k }\| u_1-u_0 \|
    \end{equation}
    où nous avons utilisé l'estimation \eqref{EqlUMVGW}, qui reste valable en remplaçant \( x_1\) par \( u_1\)\footnote{Elle n'est cependant pas spécialement valable si on remplace \( x_n\) par \( u_n\).}. Nous pouvons maintenant faire la récurrence :
    \begin{subequations}
        \begin{align}
            \| v_{n+1}-\xi \|&\leq \| v_{n+1}-u_{n+1} \|+\| u_{n+1}-\xi \|\\
            &\leq \epsilon+k\| v_n-\xi \|\\
            &\leq \epsilon+k\left( \frac{ k^n }{ 1-k }\| u_1-u_0 \|+\frac{ \epsilon }{ 1-k } \right)\\
            &=\frac{ \epsilon }{ 1-k }+\frac{ k^{n+1} }{ 1-k }\| u_1-u_0 \|.
        \end{align}
    \end{subequations}
\end{proof}

\begin{remark}
    Ce théorème comporte deux parties d'intérêts différents. La première partie est un théorème de point fixe usuel, qui sera utilisé pour prouver l'existence de certaines équations différentielles.

    La seconde partie est intéressante d'un point de vie numérique. En effet, ce qu'elle nous enseigne est que si à chaque pas de calcul de la récurrence \( x_{n+1}=f(x_n)\) nous commettons une erreur d'ordre de grandeur \( \epsilon\), alors le procédé (la suite \( (v_n)\)) ne converge plus spécialement vers le point fixe, mais tend vers le point fixe avec une erreur majorée par \( \epsilon/(k-1)\).
\end{remark}

\begin{remark}
Au final l'erreur minimale qu'on peut atteindre est de l'ordre de \( \epsilon\). Évidemment si on commet une faute de calcul de l'ordre de \( \epsilon\) à chaque pas, on ne peut pas espérer mieux.
\end{remark}

\begin{remark}  \label{remIOHUJm}
    Si \( f\) elle-même n'est pas contractante, mais si \( f^p\) est contractante pour un certain \( p\in \eN\) alors la conclusion du théorème de Picard reste valide et \( f\) a le même unique point fixe que \( f^p\). En effet nommons \( x\) le point fixe de \( f\) : \( f^p(x)=x\). Nous avons alors
    \begin{equation}
        f^p\big( f(x) \big)=f\big( f^p(x) \big)=f(x),
    \end{equation}
    ce qui prouve que \( f(x)\) est un point fixe de \( f^p\). Par unicité nous avons alors \( f(x)=x\), c'est à dire que \( x\) est également un point fixe de \( f\).

    Cette remarque est le sujet d'une partie de l'exercice \ref{exoTP20090002}
\end{remark}

Si la fonction n'est pas Lipschitz mais presque, nous avons une variante.
\begin{proposition}
    Soit \( E\) un ensemble compact\footnote{Notez cette hypothèse plus forte} et si \( f\colon E\to E\) est une fonction telle que
    \begin{equation}        \label{EqLJRVvN}
        \| f(x)-f(y) \|< \| x-y \|
    \end{equation}
    pour tout \( x\neq y\) dans \( E\) alors \( f\) possède un unique point fixe.
\end{proposition}

\begin{proof}
    La suite \( x_{n+1}=f(x_n)\) possède une sous suite convergente. La limite de cette sous suite est un point fixe de \( f\) parce que \( f\) est continue. L'unicité est due à l'aspect strict de l'inégalité \eqref{EqLJRVvN}.
\end{proof}

\begin{proposition}[\cite{ZCKMFRg}] \label{PropGZoqknC}
    Soit \( \varphi\colon U\subset \eR^m\to \eR^m\) une \( \lambda\)-contraction. Alors l'application \( f\colon x\mapsto x+\varphi(x)\) est un homéomorphisme sur un ouvert de \( \eR^m\). De plus l'inverse est Lipschitz de constante plus petite ou égale à \( (1-\lambda)^{-1}\).
\end{proposition}
%TODO : une preuve.
Cette proposition utilise le théorème de point fixe de Picard \ref{ThoEPVkCL},
et sera utilisée pour démontrer le théorème d'inversion locale \ref{ThoXWpzqCn}.
% note que garder deux lignes ici est important pour vérifier les références vers le futur : la seconde ligne peut être ignorée, pas la seconde.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Théorème de Cauchy-Lipschitz}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}
    Une fonction 
    \begin{equation}
        \begin{aligned}
            f\colon \eR^n\times R^m&\to \eR^p \\
            (t,y)&\mapsto f(t,y) 
        \end{aligned}
    \end{equation}
    est \defe{localement Lipschitz}{Lipschitz!localement} en \( y\) au point \( (t_0,y_0)\) si il existe des voisinages \( V\) de \( t_0\) et \( W\) de \( y_0\) et un nombre \( k>0\) tels que pour tout \( (t,y)\in V\times W\) on ait
    \begin{equation}
        \big\| f(t_0,y_0)-f(t,y) \big\|\leq k\| y-y_0 \|.
    \end{equation}
    La fonction est localement Lipschitz sur un ouvert \( U\) de \( \eR^n\times \eR^m\) si elle est localement Lipschitz en chaque point de \( U\).
\end{definition}

\begin{lemma}       \label{LemdLKKnd}
    Soient \( A\) et \( B\) deux espaces compact. L'ensemble des fonctions continues de \( A\) vers \( B\) muni de la norme uniforme est complet.
\end{lemma}

\begin{proof}
    Soit \( (f_k)\) une suite de Cauchy de fonctions dans \( C(A,B)\). Pour chaque \( x\in A \) nous avons
    \begin{equation}
        \| f_k(x)-f_l(x) \|_B\leq \| f_k-f_l \|_{\infty},
    \end{equation}
    de telle sorte que la suite \( (f_k(x))\) est de Cauchy dans \( B\) et converge donc vers un élément de \( B\). La suite de Cauchy \( (f_k)\) converge donc vers une fonction \( f\colon A\to B\). Nous devons encore voir que cette fonction est continue; ce sera l'uniformité de la norme qui donnera la continuité. En effet soit \( x_n\to x\) une suite dans \( A\) convergent vers \( x\in A\). Pour chaque \( k\in \eN\) nous avons
    \begin{equation}
        \| f(x_n)-f(x) \|\leq \| f(x_n)-f_k(x_n) \|  +\| f_k(x_n)-f_k(x) \|+\| f_k(x)-f(x) \|.
    \end{equation}
    En prenant \( k\) et \( n\) assez grands, cette expression peut être rendue aussi petite que l'on veut. La suite \( f(x_n)\) est donc convergente vers \( f(x)\) et la fonction \( f\) est continue.
\end{proof}

\begin{theorem}[Cauchy-Lipschitz\cite{SandrineCL}]\index{théorème!Cauchy-Lipschitz}\label{ThokUUlgU}
    Nous considérons l'équation différentielle
    \begin{subequations}        \label{XtiXON}
        \begin{numcases}{}
            y'=f(t,y)\\
            y(t_0)=y_0
        \end{numcases}
    \end{subequations}
    avec \( f\colon U\to \eR^n\) où \( U\) est un ouvert de \( \eR\times \eR^n\). Nous supposons que \( f\) est continue sur \( U\) et localement Lipschitz\footnote{Nous ne supposons pas que \( f\) soit une contraction.} par rapport à \( y\). Alors le système \eqref{XtiXON} admet une unique solution maximale. Cette solution est \( C^1\). 
\end{theorem}

\begin{remark}
    L'écriture «\( y'=f(t,y)\)» est un abus de notation pour demander que pour chaque \( t\) nous ayons \( y'(t)=f\big(t,y(t)\big)\).
\end{remark}

\begin{proof}
    Si \( y\) est une solution de l'équation différentielle considérée, elle vérifie
    \begin{equation}        \label{EqPGLwcL}
        y(t)=y_0+\int_{t_0}^tf\big( u,y(u) \big)du.
    \end{equation}
    Ceci nous incite à considérer l'opérateur \( \Phi\colon \mF\to \mF\) défini par
    \begin{equation}
        \Phi(y)(t)=y_0+\int_{t_0}^tf\big( u,y(u) \big)du.
    \end{equation}
    Précisons l'espace fonctionnel \( \mF\) adéquat. Soient \( V\) et \( W\) les voisinages de \( t_0\) et \( y_0\) sur lesquels \( f\) est localement Lipschitz. Nous considérons les quantités suivantes :
    \begin{enumerate}
        \item
            \( M=\sup_{V\times W}f\) ;
        \item
            \( r>0\) tel que \( \overline{ B(y_0,r) }\subset V\)
        \item
            \( T>0\) tel que \( \overline{ B(t_0,T) }\subset W\) et \( T<r/M\).
    \end{enumerate}
    Nous considérons alors \( \mF\), l'ensemble des fonctions continues \( \overline{ B(t_0,T) }\to \overline{ B(y_0,r) }\) muni de la norme uniforme. Par le lemme \ref{LemdLKKnd} l'espace \( \mF\) est complet.

    Le fait que \( \Phi(y)\) soit continue lorsque \( y\) est continue est une propriété de l'intégration et du fait que \( f\) soit continue en ses deux variables. Prouvons que \( \Phi(y)(t)\in\overline{ B(y_0,r) }\). Pour cela, notons que
    \begin{equation}
        | \Phi(y)(t)-y_0 |\leq \int_{t_0}^t |f\big( u,y(u) \big)|du\leq | t-t_0 |\| f \|_{\infty}.
    \end{equation}
    Étant donné que \( t\in\overline{ B(t_0,T) }\) nous avons \( | t-t_0 |\leq r/M\) et donc \( | \Phi(y)(t)-y_0 |\leq r\).

    L'équation \eqref{EqPGLwcL} signifie que \( y\) est un point fixe de \( \Phi\). L'espace \( \mF\) étant complet le théorème de point fixe de Picard (théorème \ref{ThoEPVkCL}) s'applique. Nous allons montrer qu'il existe un \( p\in\eN\) tel que \( \Phi^p\) soit contractante. Par conséquent \( \Phi^p\) aura un unique point fixe qui sera également unique point fixe de \( \Phi\) par la remarque \ref{remIOHUJm}.
    
    Prouvons donc que \( \Phi^p\) est contractante pour un certain \( p\). Pour cela nous commençons par montrer la formule suivante par récurrence :
    \begin{equation}        \label{EqRAdKxT}
        \big\| \Phi^p(x)(t)-\Phi^p(y)(t) \big\|\leq \frac{ k^p| t-t_0 |^p }{ p! }\| x-y \|_{\infty}
    \end{equation}
    pour tout \( x,y\in\mF\), et pour tout \( t\in\overline{ B(t_0,T) }\). Pour \( p=0\) la formule \eqref{EqRAdKxT} est vérifiée parce que \( \| x-y \|_{\infty}\) est le supremum de \( \| x(t)-y(t) \|\) pour \( t\in\overline{ B(t_0,T) }\). Supposons que la formule soit vraie pour \( p\) et calculons pour \( p+1\). Pour tout \( t\in\overline{ B(t_0,T) }\) nous avons
    \begin{subequations}
        \begin{align}
            \big\| \Phi^{p+1}(x)(t)-\Phi^{p+1}(y)(t) \big\|&\leq \left| \int_{t_0}^t\big\| f\big( u,\Phi^p(x)(u) \big)-f\big( u,\Phi^p(y)(u) \big) \big\|du \right| \\
            &\leq \left| \int_{t_0}^tk\| \Phi^p(x)(u)-\Phi^p(y)(u) \|du \right|    \label{subIKYixF}\\
            &\leq \left| \int_{t_0}^tk\frac{ k^p| t-t_0 | }{ p! }\| x-y \|_{\infty} \right| \label{subxkNjiV} \\
            &=\frac{ k^{p+1}| t-t_0 |^{p+1} }{ (p+1)! }\| x-y \|_{\infty}.
        \end{align}
    \end{subequations}
    Justifications :
    \begin{itemize}
        \item \eqref{subIKYixF} parce que \( f\) est Lipschitz.
        \item \eqref{subxkNjiV} par hypothèse de récurrence.
    \end{itemize}
    La formule \eqref{EqRAdKxT} est maintenant établie. Nous pouvons maintenant montrer que \( \Phi^p\) est une contraction pour un certain \( p\). Pour tout \( t\in \overline{ B(t_0,T) }\) nous avons
    \begin{subequations}
        \begin{align}
        \big\| \Phi^p(x)-\Phi^p(y) \big\|_{\infty}&\leq \| \Phi^p(x)(t)-\Phi^p(y)(t) \|\\
        &\leq \frac{ k^p }{ t! }| t-t_0 |^p\| x-y \|_{\infty}\\
        &\leq \frac{ k^pT^p }{ p! }\| x-y \|_{\infty}
        \end{align}
    \end{subequations}
    où nous avons utilisé le fait que \( | t-t_0 |^p<T^p\). Le membre de droite tend vers zéro lorsque \( p\to\infty\) parce que \( k<1\) et \( T^p/p!\to 0\). Nous concluons donc que \( \Phi^p\) est une contraction pour un certain \( p\).

    L'unique point fixe de \( \Phi\) est alors l'unique solution continue de l'équation différentielle \eqref{XtiXON}. Par ailleurs l'équation elle-même \( y'=f(t,y)\) demande implicitement que \( y\) soit dérivable et donc continue. Nous concluons que l'unique point fixe de \( \Phi\) est l'unique solution de l'équation différentielle donnée. Cette dernière est automatiquement \( C^1\) parce que si \( y\) est continue alors \( u\mapsto f(u,y(u))\) est continue, c'est à dire que \( y'\) est continue.


    Nous passons maintenant à la partie «prolongement maximum» du théorème. Soient \( x_1\) et \( x_2\) deux solutions maximales du problème \eqref{XtiXON} sur des intervalles \( I_1\) et \( I_2\) respectivement. Les intervalles \( I_1\) et \( I_2\) contiennent \( \overline{ B(t_0,r) }\) sur lequel \( x_1=x_2\) par unicité.
    
    
    Nous allons maintenant montrer que pour tout \( t\geq t_0\) pour lequel \( x_1\) ou \( x_2\) est défini, \( x_1(t)\) et \( x_2(t)\) sont définis et sont égaux. Le raisonnement sur \( t\leq t_0\) est similaire.
    
    Supposons que l'ensemble des \( t\geq t_0\) tels que \( x_1=x_2\) soit ouvert à droite, c'est à dire soit de la forme \( \mathopen[ t_0 ,b [\). Dans ce cas, soit \( x_1\) soit \( x_2\) (soit les deux) cesse d'exister en \( b\). En effet si nous avions les fonctions \( x_i\) sur \(\mathopen[ t_0 , b+\epsilon [\) alors l'équation \( x_1=x_2\) définirait un fermé dans \( \mathopen[ t_0 , b+\epsilon [\). Supposons pour fixer les idées que \( x_1\) cesse d'exister : le domaine de \( x_1\) (parmi les \( t\geq 0\)) est \( \mathopen[ t_0 , b [\) et sur ce domaine nous avons \( x_1=x_2\). Dans ce cas \( x_1\) pourrait être prolongé en \( x_2\) au-delà de \( b\). Si \( x_1\) et \( x_2\) s'arrêtent d'exister en même temps en \( b\), alors nous avons bien \( x_1=x_2\).

    Nous devons donc traiter le cas où \( x_1=x_2\) sur \( \mathopen[ t_0 , b \mathclose]\) alors que \( x_1\) et \( x_2\) existent sur \( \mathopen[ t_0 , b+\epsilon [\) pour un certain \( \epsilon\).

    Nous pouvons appliquer le théorème d'existence locale au problème
    \begin{subequations}
        \begin{numcases}{}
            y'=f(t,y)\\
            y(b)=x_1(b).
        \end{numcases}
    \end{subequations}
    Il existe un voisinage de \( b\) sur lequel la solution est unique. Sur ce voisinage nous devons donc avoir \( x_1=x_2\), ce qui contredit le fait que \( x_1\neq x_2\) en dehors de \( \mathopen[ t_0 , b \mathclose]\).
\end{proof}


%---------------------------------------------------------------------------------------------------------------------------
\subsection{Équation de Fredholm}
%---------------------------------------------------------------------------------------------------------------------------

\begin{theorem}[Équation de Fredholm]\index{Fredholm!équation}\index{équation!Fredholm}     \label{ThoagJPZJ}
    Soit \( K\colon \mathopen[ a , b \mathclose]\times \mathopen[ a , b \mathclose]\to \eR\) et \( \varphi\colon \mathopen[ a , b \mathclose]\to \eR\), deux fonctions continues. Alors si \( \lambda\) est suffisamment petit, l'équation
    \begin{equation}
        f(x)=\lambda\int_a^bK(x,y)f(y)dy+\varphi(x)
    \end{equation}
    admet une unique solution qui sera de plus continue sur \( \mathopen[ a , b \mathclose]\).
\end{theorem}

\begin{proof}
    Nous considérons l'ensemble \( \mF\) des fonctions continues \( \mathopen[ a , b \mathclose]\to\mathopen[ a , b \mathclose]\) muni de la norme uniforme. Le lemme \ref{LemdLKKnd} implique que \( \mF\) est complet. Nous considérons l'application \( \Phi\colon \mF\to \mF\) donnée par
    \begin{equation}
        \Phi(f)(x)=\lambda\int_a^bK(x,y)f(y)dy+\varphi(x). 
    \end{equation}
    Nous montrons que \( \Phi^p\) est une application contractante pour un certain \( p\). Pour tout \( x\in \mathopen[ a , b \mathclose]\) nous avons
    \begin{subequations}
        \begin{align}
            \| \Phi(f)-\Phi(g) \|_{\infty}&\leq \| \Phi(f)(x)-\Phi(g)(x) \|\\
            &=| \lambda |\Big\| \int_a^bK(x,y)\big( f(y)-g(y) \big)dy  \Big\|\\
            &\leq | \lambda |\| K \|_{\infty}| b-a |\| f-g \|_{\infty}
        \end{align}
    \end{subequations}
    Si \( \lambda\) est assez petit, et si \( p\) est assez grand, l'application \( \Phi^p\) est donc une contraction. Elle possède donc un unique point fixe par le théorème de Picard \ref{ThoEPVkCL}.
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
					\section{Théorème d'inversion locale de la fonction implicite}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Mise en situation}
%---------------------------------------------------------------------------------------------------------------------------

Dans un certain nombre de situation, il n'est pas possible de trouver des solutions explicites aux équations qui apparaissent. Néanmoins, l'existence «théorique» d'une telle solution est souvent déjà suffisante. C'est l'objet du théorème de la fonction implicite.

Prenons par exemple la fonction sur $\eR^2$ donnée par 
\begin{equation}
	F(x,y)=x^2+y^2-1.
\end{equation}
Nous pouvons bien entendu regarder l'ensemble des points donnés par $F(x,y)=0$. C'est le cercle dessiné à la figure \ref{LabelFigCercleImplicite}.
\newcommand{\CaptionFigCercleImplicite}{Un cercle pour montrer l'intérêt de la fonction implicite. Si on donne \( x\), nous ne pouvons pas savoir si nous parlons de \( P\) ou de \( P'\).}
\input{Fig_CercleImplicite.pstricks}

%\ref{LabelFigCercleImplicite}.
%\newcommand{\CaptionFigCercleImplicite}{Un cercle pour montrer l'intérêt de la fonction implicite.}
%\input{Fig_CercleImplicite.pstricks}

Nous ne pouvons pas donner le cercle sous la forme $y=y(x)$ à cause du $\pm$ qui arrive quand on prend la racine carrée. Mais si on se donne le point $P$, nous pouvons dire que \emph{autour de $P$}, le cercle est la fonction
\begin{equation}
	y(x)=\sqrt{1-x^2}.
\end{equation}
Tandis que autour du point $P'$, le cercle est la fonction
\begin{equation}
	y(x)=-\sqrt{1-x^2}.
\end{equation}
Autour de ces deux point, donc, le cercle est donné par une fonction. Il n'est par contre pas possible de donner le cercle autour du point $Q$ sous la forme d'une fonction.

Ce que nous voulons faire, en général, est de voir si l'ensemble des points tels que
\begin{equation}
	F(x_1,\ldots,x_n,y)=0
\end{equation}
peut être donné par une fonction $y=y(x_1,\ldots,x_n)$. En d'autre termes, est-ce qu'il existe une fonction $y(x_1,\ldots,x_n)$ telle que
\begin{equation}
	F\big( x_1,\ldots,x_n,y(x_1,\ldots,x_n)\big)=0.
\end{equation}



\subsection{Définitions et rappels}
Soit
\begin{equation}
    \begin{aligned}
        F\colon D\subset \eR^n\times \eR^m&\to \eR^m \\
        (x,y)&\mapsto \big( F_1(x,y),\ldots, F_m(x,y) \big) 
    \end{aligned}
\end{equation}
avec $x = (x_1,\ldots, x_n)$ et $y = (y_1,\ldots,y_m)$.

Pour chaque $x$ fixé, on s'intéresse aux solutions du système de $m$
 équations $F(x,y) = 0$ pour les inconnues $y$ ; en particulier, on
 voudrait pouvoir écrire $y = \varphi(x)$ vérifiant $F(x,\varphi(x)) = 0$.

Pour $(x,y) \in \interieur D$, la matrice
\begin{equation}
    \frac{ \partial (F_1,\ldots, F_m) }{ \partial (y_1,\ldots, y_m) }=
\begin{pmatrix}
\pder {F_1}{y_1}(x,y)& \ldots& \pder {F_1}{y_m}(x,y)\\
\vdots& \ddots & \vdots\\
\pder {F_m}{y_1}(x,y)& \ldots& \pder {F_m}{y_m}(x,y)\\
\end{pmatrix}
\end{equation}
est la \defe{matrice jacobienne}{jacobienne!matrice} de $F$ par rapport à $y$ au point
$(x,y)$; son déterminant est appelé le \defe{jacobien}{jacobien} de $F$ par
rapport à $y$.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Théorème d'inversion locale}
%---------------------------------------------------------------------------------------------------------------------------

Le théorème suivant est une conséquence du théorème de point fixe de Picard \ref{ThoEPVkCL}.
\begin{theorem}[Inversion locale\cite{ZCKMFRg}] \label{ThoXWpzqCn}
    Soit \( f\in C^k(\eR^n,\eR^n)\) et \( x_0\in \eR^n\). Si \( df_{x_0}\) est inversible, alors il existe un voisinage ouvert \( U\) de \( x_0\) et \( V\) de \( f(x_0)\) tels que \( f\colon U\to V\) soit un \( C^k\)-difféomorphisme. (c'est à dire que \( f^{-1}\) est également de classe \( C^k\))
\end{theorem}
\index{application!différentiable}
\index{théorème!inversion locale}

\begin{proof}
    Nous commençons par simplifier un peu le problème. Pour cela, nous considérons la translation \( T\colon x\mapsto x+x_0 \) qui est  un difféomorphisme. De la même manière nous considérons aussi l'application linéaire
    \begin{equation}
        \begin{aligned}
            L\colon \eR^n&\to \eR^n \\
            x&\mapsto (df_{x_0}^{-1})x
        \end{aligned}
    \end{equation}
    qui est également un difféomorphisme par hypothèse d'inversibilité. Quitte à travailler avec la fonction \( k=L\circ f\circ T\), nous pouvons supposer que \( x_0=0\) et que \( df_{x_0}=\mtu\).

    Nous posons \( g=f-\mtu\), c'est à dire \( g(x)=f(x)-x\), qui a la propriété \( dg_0=0\). Étant donné que \( g\) est de classe \( C^1\) et que \( dg_x\) est une matrice contenant les dérivées de \( g\), l'application
    \begin{equation}
        \begin{aligned}
            dg\colon \eR^n&\to \GL(n,\eR) \\
            x&\mapsto dg_x 
        \end{aligned}
    \end{equation}
    est continue. En conséquence de quoi nous avons un voisinage \( U'\) de \( 0 \) pour lequel
    \begin{equation}    \label{EqSGTOfvx}
        \sup_{x\in U'}\| dg_x \|<\frac{ 1 }{2}.
    \end{equation}
    Maintenant le théorème de la moyenne \ref{val_medio_2} nous indique que pour tout \( x,x'\in U'\) nous avons\footnote{Ici nous supposons avoir choisi \( U'\) convexe afin que tous les \( a\in \mathopen[ x , x' \mathclose]\) soient bien dans \( U'\) et donc soumis à l'inéquation \eqref{EqSGTOfvx}, ce qui est toujours possible, il suffit de prendre une boule.}
    \begin{equation}
        \| g(x')-g(x) \|\leq \sup_{a\in\mathopen[ x , x' \mathclose]}\| dg_a \| \cdot \| x-x' \|\leq \frac{ 1 }{2}\| x-x' \|,
    \end{equation}
    ce qui prouve que \( g\) est une contraction au moins sur l'ouvert \( U'\). Nous allons aussi donner une idée de la façon dont \( f\) fonctionne : si \( x_1,x_2\in U'\) alors
    \begin{subequations}
        \begin{align}
            \| x_1-x_2 \|&=\| g(x_1)-f(x_1)-g(x_2)+f(x_2) \| \\
            &\leq \| g(x_1)-g(x_2) \|+\| f(x_1)-f(x_2) \|\\
            &\leq \frac{ 1 }{2}\| x_1-x_2 \|+\| f(x_1)-f(x_2) \|,
        \end{align}
    \end{subequations}
    ce qui montre que
    \begin{equation}
        \| x_1-x_2 \|\leq 2\| f(x_1)-f(x_2) \|.
    \end{equation}
    Maintenant que nous savons que \( g\) est contractante de constante \( \frac{ 1 }{2}\) et que \( f=g+\mtu\) nous pouvons utiliser la proposition \ref{PropGZoqknC} pour conclure que \( f\) est un homéomorphisme sur un ouvert \( U\) (partie de \( U'\)) de \( \eR^n\) et \( f^{-1}\) a une constante de Lipschitz plus petite ou égale à \( (1-\frac{ 1 }{2})^{-1}=2\).

    Nous allons maintenant prouver que \( f^{-1}\) est différentiable et que sa différentielle est donnée par \( df^{-1}_{f(x)}=(df_x)^{-1}\).

    Soient \( a,b\in U\) et \( u=b-a\). Étant donné que \( f\) est différentiable en \( a\), il existe une fonction \( \alpha\in o(\| u \|)\) telle que
    \begin{equation}
        f(b)-f(a)-df_a(u)=\alpha(u).
    \end{equation}
    En notant \( y_a=f(a)\) et \( y_b=f(b)\) et en appliquant \( (df_a)^{-1}\) à cette dernière équation,
    \begin{equation}
        (df_a)^{-1}(y_b-y_a)-u=(df_a)^{-1} \big( \alpha(u) \big).
    \end{equation}
    Vu que \( df_a\) est bornée (et son inverse aussi), le membre de droite est encore une fonction \( \beta\) ayant la propriété \( \lim_{u\to 0}\beta(u)/\| u \|=0\); en réordonnant les termes,
    \begin{equation}
        b-a=(df_a)^{-1}(y_b-y_a)+\beta(u)
    \end{equation}
    et donc
    \begin{equation}
        f^{-1}(y_b)-f^{-1}(y_a)-(df_a)^{-1}(y_b-y_a)=\beta(u),
    \end{equation}
    ce qui prouve que \( f^{-1}\) est différentiable et que \( (df^{-1})_{y_a}=(df_a)^{-1}\).

    La différentielle \( df^{-1}\) est donc obtenue par la chaine
    \begin{equation}
    \xymatrix{%
        df^{-1}\colon f(U) \ar[r]^-{f^{-1}}     &   U'\ar[r]^-{df}&\GL(n,\eR)\ar[r]^-{\Inv}&\GL(n,\eR)
       }
    \end{equation}
    où l'application \( \Inv\colon \GL\to \GL\) est l'application \( X\mapsto X^{-1}\); c'est évidemment une application \(  C^{\infty}\). D'autre part, par hypothèse \( df\) est une application de classe \( C^{k-1}\)\quext{Ici il me semble que dans \cite{ZCKMFRg} il est fautivement noté \( C^k\).} et donc au minimum \( C^0\) parce que \( k\geq 1\). Enfin, l'application \( f^{-1}\colon f(U)\to U\) est continue (parce que la proposition \ref{PropGZoqknC} précise que \( f\) est un homéomorphisme). Donc toute la chaine est continue et \( df^{-1}\) est continue. Cela entraine immédiatement que \( f^{-1}\) est \( C^1\) et donc que toute la chaine est \( C^1\).

    Par récurrence nous obtenons la chaine
    \begin{equation}
    \xymatrix{%
        df^{-1}\colon f(U) \ar[r]^-{f^{-1}}_-{C^{k-1}}     &   U'\ar[r]^-{df}_-{C^{k-1}}&\GL(n,\eR)\ar[r]^-{\Inv}_-{ C^{\infty}}&\GL(n,\eR)
       }
    \end{equation}
    qui prouve que \( df^{-1}\) est \( C^{k-1} \) et donc que \( f^{-1}\) est \( C^k\). La récurrence s'arrête ici parce que \( df\) n'est pas mieux que \( C^{k-1}\).
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Théorème de la fonction implicite}
%---------------------------------------------------------------------------------------------------------------------------

\begin{theorem}[théorème de la fonction implicite] \index{théorème!fonction implicite} \label{ThoAcaWho}
    Soit une fonction \( F\colon \eR^n\times \eR^m\to \eR^m\) de classe \( C^k\) et \( (\alpha,\beta)\in \eR^n\times \eR^m\) tels que
    \begin{enumerate}
        \item
            \( f(\alpha,\beta)=0\),
        \item
            $\det\frac{ \partial (F_1,\ldots, F_m) }{ \partial (y_1,\ldots, y_m) }\neq 0$.
    \end{enumerate}
    Alors il existe un voisinage ouvert \( V\) de \( \alpha\) dans \( \eR^n\), un voisinage ouvert \( W\) de \( \beta\) dans \( \eR^m\) et une application \( \varphi\colon V\to W\) de classe \( C^k\)  telle que pour \( (x,y)\in V\times W\) on ait
    \begin{equation}
        F(x,y)=0
    \end{equation}
    si et seulement si \( y=\varphi(x)\).
\end{theorem}
	
Le théorème de la fonction implicite a pour objet de donner l'existence de la fonction $\varphi$. Maintenant nous pouvons dire beaucoup de choses sur les dérivées de $\varphi$ en considérant la fonction
\begin{equation}
	x\mapsto F\big( x,\varphi(x) \big).
\end{equation}
Par définition de $\varphi$, cette fonction est toujours nulle. En particulier, nous pouvons dériver l'équation
\begin{equation}
	F\big( x,\varphi(x) \big)=0,
\end{equation}
et nous trouvons plein de choses.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Exemple}
%---------------------------------------------------------------------------------------------------------------------------

Prenons par exemple la fonction
\begin{equation}
	F\big( (x,y),z \big)=ze^z-x-y,
\end{equation}
et demandons nous ce que nous pouvons dire sur la fonction $z(x,y)$ telle que
\begin{equation}
	F\big( x,y,z(x,y) \big)=0,
\end{equation}
c'est à dire telle que
\begin{equation}		\label{EqDefZImplExemple}
	z(x,y) e^{z(x,y)}-x-y=0.
\end{equation}
pour tout $x$ et $y\in\eR$. Nous pouvons facilement trouver $z(0,0)$ parce que
\begin{equation}
	z(0,0) e^{z(0,0)}=0,
\end{equation}
donc $z(0,0)=0$.

Nous pouvons dire des choses sur les dérivées de $z(x,y)$. Voyons par exemple $(\partial_xz)(x,y)$. Pour trouver cette dérivée, nous dérivons la relation \eqref{EqDefZImplExemple} par rapport à $x$. Ce que nous trouvons est
\begin{equation}
	(\partial_xz)e^z+ze^z(\partial_xz)-1=0.
\end{equation}
Cette équation peut être résolue par rapport à $\partial_xz$~:
\begin{equation}
	\frac{ \partial z }{ \partial x }(x,y)=\frac{1}{ e^z(1+z) }.
\end{equation}
Remarquez que cette équation ne donne pas tout à fait la dérivée de $z$ en fonction de $x$ et $y$, parce que $z$ apparaît dans l'expression, alors que $z$ est justement la fonction inconnue. En général, c'est la vie, nous ne pouvons pas faire mieux.

Dans certains cas, on peut aller plus loin. Par exemple, nous pouvons calculer cette dérivée au point $(x,y)=(0,0)$ parce que $z(0,0)$ est connu :
\begin{equation}
	\frac{ \partial z }{ \partial x }(0,0)=1.
\end{equation}
Cela est pratique pour calculer, par exemple, le développement en Taylor de $z$ autour de $(0,0)$.


\begin{example}
    Est-ce que l'équation \( e^{y}+xy=0\) définit au moins localement une fonction \( y(x)\) ? Nous considérons la fonction
    \begin{equation}
        f(x,y)=\begin{pmatrix}
            x    \\ 
            e^{y}+xy    
        \end{pmatrix}
    \end{equation}
    La différentielle de cette application est
    \begin{subequations}
        \begin{align}
            df_{(0,0)}(u)&=\frac{ d }{ dt }\Big[ f(tu_1,tu_2) \Big]_{t=0}\\
            &=\frac{ d }{ dt }\begin{pmatrix}
                tu_1    \\ 
                e^{tu_2}+t^2u_1u_2    
            \end{pmatrix}_{t=0}\\
            &=\begin{pmatrix}
                u_1    \\ 
                u_2    
            \end{pmatrix}.
        \end{align}
    \end{subequations}
    L'application \( f\) définit donc un difféomorphisme local autour des points \( (x_0,y_0)\) et \( f(x_0,y_0)\). Soit \( (u,0)\) un point dans le voisinage de \( f(x_0,y_0)\). Alors il existe un unique \( (x,y)\) tel que
    \begin{equation}
        f(x,y)=\begin{pmatrix}
               x \\ 
            e^y+xy    
        \end{pmatrix}=
        \begin{pmatrix}
            u    \\ 
                0
        \end{pmatrix}.
    \end{equation}
    Nous avons automatiquement \( x=u\) et \( e^y+xy=0\). Notons toutefois que pour que ce procédé donne effectivement une fonction implicite \( y(x)\) nous devons avoir des points de la forme \( (u,0)\) dans le voisinage de \( f(x_0,y_0)\).
\end{example}


 \section{Les nombres complexes}
 \subsection{Définitions de base}
 Un nombre complexe s'écrit sous la forme $z = a + b i$, où $a$ et $b$
 sont des nombres réels appelés (et notés) respectivement partie réelle
 ($a = \Re(z)$) et partie imaginaire ($b = \Im(z)$) de $z$. L'ensemble
 des nombres de cette forme s'appelle l'ensemble des nombres complexes
 ; cet ensemble porte une structure de corps et est noté $\eC$. Le
 nombre complexe $i = 0 + 1 i$ est un nombre imaginaire qui a la
 particularité que $i^2 = -1$.

 Deux nombres complexes $a + bi$ et $c + di$ sont égaux si et seulement
 si $a = c$ et $b = d$, c'est-à-dire leurs parties réelles sont égales,
 et leurs parties imaginaires sont égales.

 Un nombre complexe étant représenté par deux nombres, on peut le
 représenter dans un plan appelé « plan de Gauss ». La plupart des
 opérations sur les nombres complexes ont leur interprétation
 géométrique dans ce plan.

 Pour $z = a + bi$ un nombre complexe, on note $\bar z = a - bi$ le
 \Defn{complexe conjugué} de $z$. Dans le plan de Gauss, il s'agit du
 symétrique de $z$ par rapport à la droite réelle (généralement
 dessinée horizontalement).

 On définit le module du complexe $z$ par $\module z = \sqrt{z\bar z} =
 \sqrt{a^2 + b^2}$. Dans le plan de Gauss, il s'agit de la distance
 entre $0$ et $z$.

 \begin{proposition}
Pour tout $z = a+bi$ et $z^\prime$ nombres complexes, on a
   \begin{enumerate}
   \item $z \bar z = a^2 + b^2$;
   \item $\bar{\bar{z}} = z$;
   \item $\module z = \module {\bar z}$;
   \item $\module{zz^\prime} = \module z \module{z^\prime}$;
   \item $\module{z+z^\prime} \leq \module z + \module{z^\prime}$.
   \end{enumerate}
 \end{proposition}

 \subsection{Forme polaire ou trigonométrique}
 Dans le plan de Gauss, le module d'un complexe $z$ représente la
 distance entre $0$ et $z$. On appelle \Defn{argument} de $z$ (noté
 $\arg z$) l'angle (déterminé à $2\pi$ près) entre le demi-axe des
 réels positifs et la demi-droite qui part de $0$ et passe par $z$. Le
 module et l'argument d'un complexe permettent de déterminer
 univoquement ce complexe puisqu'on a la formule
 \[z = a + bi = \module z \left( \cos(\arg(z)) + i \sin(\arg(z))
 \right)\]

 L'argument de $z$ se détermine via les formules
 \[\frac a {\module z} = \cos(\arg(z)) \quad \frac b {\module z} =
 \sin(\arg(z))\] ou encore par la formule
 \[\frac b a = \tan(\arg(z)) \quad \text{en vérifiant le
   quadrant.}\]%
 La vérification du quadrant vient de ce que la tangente ne détermine
 l'angle qu'à $\pi$ près.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
                    \section{Maximisation sans contraintes}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
                    \subsection{Maximisation à une variable}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}
Soit $f\colon A\subset \eR\to \eR$ et $a\in A$. Le point $a$ est un \defe{maximum local}{maximum!local} de $f$ si il existe un voisinage $\mU$ de $a$ tel que $f(a)\geq f(x)$ pour tout $x\in\mU\cap A$. Le point $a$ est un \defe{maximum global}{maximum!global} si $f(a)\geq g(x)$ pour tout $x\in A$.
\end{definition}

La proposition basique à utiliser lors de la recherche d'extrema est la suivante :
\begin{proposition}
Soit $f\colon A\subset\eR\to \eR$ et $a\in\Int(A)$. Supposons que $f$ est dérivable en $a$. Si $a$ est un \href{http://fr.wikipedia.org/wiki/Extremum}{extremum} local, alors $f'(a)=0$.
\end{proposition}

La réciproque n'est pas vraie, comme le montre l'exemple de la fonction $x\mapsto x^3$ en $x=0$ : sa dérivée est nulle et pourtant $x=0$ n'est ni un maximum ni un minimum local. 

Cette proposition ne sert donc qu'à sélectionner des \emph{candidats} extremum. Afin de savoir si ces candidats sont des extrema, il y a la proposition suivante.
\begin{proposition}
Soit $f\colon I\subset \eR\to \eR$, une fonction de classe $C^k$ au voisinage d'un point $a\in\Int I$. Supposons que
\begin{equation}
    f'(a)=f''(a)=\ldots=f^{(k-1)}(a)=0,
\end{equation}
et que
\begin{equation}
    f^{(k)}(a)\neq 0.
\end{equation}
Dans ce cas,
\begin{enumerate}

\item
Si $k$ est pair, alors $a$ est un point d'extremum local de $f$, c'est un minimum si $f^{(k)}(a)>0$, et un maximum si $f^{(k)}(a)<0$,
\item
Si $k$ est impair, alors $a$ n'est pas un extremum local de $f$.

\end{enumerate}
\end{proposition}

Note : jusqu'à présent nous n'avons rien dit des extrema \emph{globaux} de $f$. Il n'y a pas grand chose à en dire. Si un point d'extremum global est situé dans l'intérieur du domaine de $f$, alors il sera extremum local (a fortiori). Ou alors, le maximum global peut être sur le bord du domaine. C'est ce qui arrive à des fonctions strictement croissantes sur un domaine compact.

Une seule certitude : si une fonction est continue sur un compact, elle possède une minimum et un maximum global.

%---------------------------------------------------------------------------------------------------------------------------
                    \subsection{Quelque mots à propos de matrices}
%---------------------------------------------------------------------------------------------------------------------------

Les notions qui suivent seront vues au cours de géométrie lorsqu'il sera temps. 

Si $g$ est une application bilinéaire sur $\eR^2$, nous disons qu'elle est
\begin{enumerate}

\item
\defe{définie positive}{application!définie positive} si $g(u,u)\geq 0$ pour tout $u\in\eR^2$ et $g(u,u)=0$ si et seulement si $u=0$.

\item
\defe{semi-définie positive}{application!semi-définie positive} si $g(u,u)\geq 0$ pour tout $u\in\eR^2$. 

\end{enumerate}

Une matrice $M$ est définie positive si $v^tMv>0$ pour tout $v\neq 0$, en particulier si $v$ est un vecteur propre de valeur propre $\lambda$ (c'est à dire si $Mv=\lambda v$), alors $\lambda v^tv>0$, et donc $\lambda>0$. Donc $M$ sera définie positive si toutes ses valeurs propres sont positives.

\begin{proposition}     \label{PropcnJyXZ}
    Soit $M$, une matrice $2\times 2$ symétrique\footnote{la matrice $d^2f(a)$ est toujours symétrique quand $f$ est de classe $C^2$.}. Nous avons
    \begin{enumerate}
        \item
        $\det M>0$ et $\tr(M)>0$ implique $M$ définie positive,
        \item
        $\det M>0$ et $\tr(M)<0$ implique $M$ définie négative,
    \item   \label{ItemluuFPN}
        $\det M<0$ implique ni semi définie positive, ni définie négative 
        \item
        $\det M=0$ implique $M$ semi-définie positive ou semi-définie négative.
    \end{enumerate}
\end{proposition}


 
%---------------------------------------------------------------------------------------------------------------------------
                    \subsection{Les théorèmes}
%---------------------------------------------------------------------------------------------------------------------------

Un point $a$ à l'intérieur du domaine d'une fonction $f\colon A\subset\eR^n\to \eR$ est un \defe{point critique}{critique!point} de $f$ lorsque $df(a)=0$. Ces points sont analogues aux points où la dérivée d'une fonction sur $\eR$ s'annule. Les points critiques de $f$ sont dons les candidats à être des points d'extremum.

Pour rappel, dans le cas d'une fonction à deux variables, $d^2f(a)$ est la matrice (et donc l'application linéaire)
\begin{equation}
    d^2f(a)=\begin{pmatrix}
    \frac{ d^2f  }{ dx^2 }(a)   &   \frac{ d^2f  }{ dx\,dy }(a) \\ 
    \frac{ d^2f  }{ dy\,dx }(a)     &   \frac{ d^2f  }{ dy^2 }(a)
\end{pmatrix}.
\end{equation}
Dans le cas d'une fonction $C^2$, cette matrice est symétrique.

\begin{proposition}     \label{PropoExtreRn}
    Soit $f\colon A\subset\eR^n\to \eR$ une fonction de classe $C^2$ au voisinage de $a\in\Int(A)$.
    \begin{enumerate}
        \item
            Si $a$ est un point critique de $f$, et si $d^2f(a)$ est \href{http://fr.wikipedia.org/wiki/Matrice_définie_positive}{définie positive}, alors $a$ est un minimum local strict de $f$,
        \item\label{ItemPropoExtreRn}
            Si $a$ est un minimum local, alors $a$ est un point critique et $d^2f(a)$ est définie positive.
    \end{enumerate}
\end{proposition}
\index{fonction!différentiable}
\index{extrema}
La seconde partie de l'énoncé est tout à fait comparable au fait bien connu que, pour une fonction $f\colon \eR\to \eR$, si le point $a$ est minimum local, alors $f'(a)=0$ et $f''(a)>0$.

La méthode pour chercher les extrema de $f$ est donc de suivre le points suivants :
\begin{enumerate}
    \item
        Trouver les candidats extrema en résolvant $\nabla f=(0,0)$,
    \item
        écrire $d^2f(a)$ pour chacun des candidats
    \item
        calculer les valeurs propres de $d^2f(a)$, déterminer si la matrice est définie positive ou négative,
    \item
        conclure.
\end{enumerate}

Une conséquence du point \ref{ItemluuFPN} de la proposition \ref{PropcnJyXZ} est que si \( \det M<0\), alors le point \( a\) n'est pas  un extrema dans le cas où $M=d^2f(a)$ par le point \ref{ItemPropoExtreRn} de la proposition \ref{PropoExtreRn}.

\begin{example}
    Soit la fonction \( f(x,y)=x^4+y^4-4xy\). C'est une fonction différentiable sans problèmes. D'abord sa différentielle est
    \begin{equation}
        df=|big(4x^3-4y;4y^3-4x),
    \end{equation}
    et la matrice des dérivées secondes est
    \begin{equation}
        M=d^2f(x,y)=\begin{pmatrix}
            12x^2    &   -4    \\ 
            -4    &   12y^2    
        \end{pmatrix}.
    \end{equation}
    Nous avons \( fd=0\) pour les trois points \( (0,0)\), \( (1,1)\) et \( -1,-1\).

    Pour le point \( (0,0)\) nous avons
    \begin{equation}
        M=\begin{pmatrix}
            0    &   -4    \\ 
            -4    &   0    
        \end{pmatrix},
    \end{equation}
    dont les valeurs propres sont \( 4\) et \( -4\). Elle n'est donc semi-définie ou définie rien du tout. Donc \( (0,0)\) n'est pas un extremum local.

    Au contraire pour les points \( (1,1)\) et \( (-1,-1)\) nous avons
    \begin{equation}
        M=\begin{pmatrix}
            12    &   -4    \\ 
            -4    &   12    
        \end{pmatrix},
    \end{equation}
    dont les valeurs propres sont \( 16\) et \( 8\). La matrice \( d^2f\) y est donc définie positive. Ces deux points sont donc extrema locaux.
\end{example}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Extrema liés}
%---------------------------------------------------------------------------------------------------------------------------

Soit $f$, une fonction sur $\eR^n$, et $M\subset \eR^n$ une variété de dimension $m$. Nous voulons savoir quelle sont les plus grandes et plus petites valeurs atteintes par $f$ sur $M$.

Pour ce faire, nous avons un théorème qui permet de trouver des extrema \emph{locaux} de $f$ sur la variété. Pour rappel, $a\in M$ est une \defe{extrema local de $f$ relativement}{extrema!local!relatif} à l'ensemble $M$ si il existe une boule $B(a,\epsilon)$ telle que $f(a)\leq f(x)$ pour tout $x\in B(a,\epsilon)\cap M$.

\begin{theorem}[Extrema lié \cite{ytMOpe}] \label{ThoRGJosS}
	Soit \( A\), un ouvert de \( \eR^n\) et
	\begin{enumerate}
		\item
			une fonction (celle à minimiser) $f\in C^1(A,\eR)$,
		\item 
			des fonctions (les contraintes) $G_1,\ldots,G_r\in C^1(A,\eR)$,
		\item
			$M=\{ x\in A\tq G_i(x)=0\,\forall i\}$,
		\item
			un extrema local $a\in M$ de $f$ relativement à $M$.
	\end{enumerate}
	Supposons que les gradients $\nabla G_1(a)$, \ldots,$\nabla G_r(a)$ soient linéairement indépendants. Alors $a=(x_1,\ldots,x_n)$ est une solution de \( \nabla L(a)=0\) où
	\begin{equation}
		L(x_1,\ldots,x_n,\lambda_1,\ldots,\lambda_r)=f(x_1,\ldots,x_n)+\sum_{i=1}^r\lambda_iG_i(x_1,\ldots,x_n).
	\end{equation}
    Autrement dit, si \( a\) est un extrema lié, alors \( \nabla f(a)\) est une combinaisons des \( \nabla G_i(a)\), ou encore il existe des \( \lambda_i\) tels que
    \begin{equation}    \label{EqRDsSXyZ}
        df(a)=\sum_i\lambda_idG_i(a).
    \end{equation}
\end{theorem}
\index{théorème!inversion locale!utilisation}
\index{extrema!lié}
\index{théorème!extrema!lié}
\index{application!différentiable!extrema lié}
\index{variété}
\index{rang!différentielle}
\index{forme!linéaire!différentielle}
La fonction $L$ est le \defe{lagrangien}{lagrangien} du problème et les variables \( \lambda_i\) sont les \defe{multiplicateurs de Lagrange}{multiplicateur!de Lagrange}.

\begin{proof}
    Si \( r=n\) alors les vecteurs linéairement indépendantes \( \nabla G_i(a) \) forment une base de \( \eR^n\) et donc évidemment les \( \lambda_i\) existent. Nous supposons donc maintenant que \( r<n\). Nous notons \( (z_i)_{i=1\ldots n}\) les coordonnées sur \( \eR^n\).
    
    La matrice
    \begin{equation}
        \begin{pmatrix}
            \frac{ \partial G_1 }{ \partial z_1 }(a)    &   \cdots    &   \frac{ \partial G_1 }{ \partial z_n }(a)    \\
            \vdots    &   \ddots    &   \vdots    \\
            \frac{ \partial G_r }{ \partial z_1 }(a)    &   \cdots    &   \frac{ \partial G_r }{ \partial z_n }(a)
        \end{pmatrix}
    \end{equation}
    est de rang \( r\) parce que les lignes sont par hypothèses linéairement indépendantes. Nous nommons \( (y_i)_{i=1,\ldots, r}\) un choix de \( r\) parmi les \( (z_i)\) tels que
    \begin{equation}
        \det\begin{pmatrix}
            \frac{ \partial G_1 }{ \partial y_1 }    &   \ldots    &   \frac{ \partial G_1 }{ \partial y_r }    \\
            \vdots    &   \ddots    &   \vdots    \\
            \frac{ \partial G_r }{ \partial y_1 }    &   \ldots    &   \frac{ \partial G_r }{ \partial y_r }
        \end{pmatrix}\neq 0.
    \end{equation}
    Nous identifions \( \eR^n\) à \( \eR^s\times \eR^r\) dans lequel \( \eR^r\) est la partie générée par les \( (y_i)_{i=1,\ldots, r}\). Nous nommons \( (x_j)_{j=1,\ldots, s}\) les coordonnées sur \( \eR^s\). Autrement dit, les coordonnées sur \( \eR^n\) sont \( x_1,\ldots, x_s,y_1,\ldots, y_r\). Dans ces coordonnées, nous nommons \( a=(\alpha,\beta)\) avec \( \alpha\in \eR^s\) et \( \beta\in \eR^r\).

    Si nous notons \( G=(G_1,\ldots, G_r)\), le théorème de la fonction implicite (théorème \ref{ThoAcaWho})  nous dit qu'il existe un voisinage \( U'\) de \( \alpha\in \eR^n\), un voisinage \( V'\) de \( \beta\in \eR^r\) et une fonction \( \varphi\colon U'\to V'\) de classe \( C^1\) telle que si \( (x,y)\in U'\times V'\), alors
    \begin{equation}
        g(x,y)=0
    \end{equation}
    si et seulement si \( y=\varphi(x)\). Nous posons maintenant
    \begin{subequations}
        \begin{align}
            \psi(x)&=(x,\varphi(x))\\
            h(x)&=f\big( \psi(x) \big).
        \end{align}
    \end{subequations}
    Nous avons \( \psi(\alpha)=a\) et \( \psi(x)\in M\) pour tout \( x\in U'\). La fonction \( h\) a donc un extrema local en \( \alpha\) et donc les dérivées partielles de \( h\) y sont nulles. Cela signifie que
    \begin{equation}
        0=\frac{ \partial h }{ \partial x_i }(\alpha)=\sum_{j=1}^n\frac{ \partial f }{ \partial x_j }\frac{ \partial x_j }{ \partial x_i }+\sum_{k=1}^r\frac{ \partial f }{ \partial y_k }\frac{ \partial \varphi_k }{ \partial x_i },
    \end{equation}
    c'est à dire
    \begin{equation}
        \frac{ \partial f }{ \partial x_i }(\alpha)+\sum_{k=1}^r\frac{ \partial f }{ \partial y_k }(a)\frac{ \partial \varphi_k }{ \partial x_i }(\alpha)=0
    \end{equation}
    pour tout \( i=1,\ldots, s\). D'autre part pour tout $k$, la fonction \( l_k(x)=G_k\big( x,\varphi(x) \big)\) est constante et vaut zéro; ses dérivées partielles sont donc nulles :
    \begin{equation}
        \frac{ \partial l }{ \partial x_i }(\alpha)=\frac{ \partial G_k }{ \partial x_i }(\alpha)+\sum_{k=1}^r\frac{ \partial G_k }{ \partial y_k }(a)\frac{ \partial \varphi_k }{ \partial x_i }(\alpha)=0
    \end{equation}
    pour tout \( i=1,\ldots, s\) et \( k=1,\ldots, r\).
    
    Les \( s\) premières colonnes de la matrice
    \begin{equation}
        \begin{pmatrix}
            \frac{ \partial f }{ \partial x_1 }   &   \cdots    &   \frac{ \partial f }{ \partial x_s }    &   \frac{ \partial f }{ \partial y_1 }    &   \cdots    &   \frac{ \partial f }{ \partial y_r }\\  
            \frac{ \partial G_1 }{ \partial x_1 }    &   \cdots    &   \frac{ \partial G_1 }{ \partial x_s }    &   \frac{ \partial G_1 }{ \partial y_1 }    &   \cdots    &   \frac{ \partial G_1 }{ \partial y_r }\\
            \vdots    &   \vdots    &   \vdots    &   \vdots    &   \vdots    &   \vdots\\
            \frac{ \partial G_r }{ \partial x_1 }    &   \cdots    &   \frac{ \partial G_r }{ \partial x_s }    &   \frac{ \partial G_r }{ \partial y_1 }    &  \cdots   & \frac{ \partial G_r }{ \partial y_r }  
        \end{pmatrix}
    \end{equation}
    s'expriment en terme des \( r\) dernières. La matrice est donc au maximum de rang \( r\). Notons que la première ligne est \( \nabla f\) et les \( r\) suivantes sont les \( \nabla G_i\). Vu que ces lignes sont des vecteurs liés, il existe \( \mu_0,\ldots, \mu_r\) tels que
    \begin{equation}
        \mu_0\nabla f+\sum_{i=1}^r\mu_i\nabla G_i=0.
    \end{equation}
    Par hypothèse les \( \nabla G_i\) sont linéairement indépendants, ce qui nous dit que \( \mu_0\neq 0\). Donc nous avons ce qu'il nous faut :
    \begin{equation}
        \nabla f(a)=\sum_i\frac{ \mu_i }{ \mu_0 } \nabla G_i(a).
    \end{equation}

    Notons qu'au vu de l'expression \eqref{EqRDsSXyZ}, le fait que les formes \( \{ dG_i(a) \}_{1\leq i\leq r}\) forment une partie libre dans \( (\eR^n)^*\) implique que les \( \lambda_i\) sont uniques.
\end{proof}

La proposition suivante est la même que \ref{ThoRGJosS}.
\begin{proposition} \label{PropfPPUxh}
    Soit \( U\), un ouvert de \( \eR^n\) et des fonctions de classe \( C^1\) \( f,g_1,\ldots, g_r\colon U\to \eR\). Nous considérons
    \begin{equation}
        \Gamma=\{ x\in U\tq g_1(x)=\ldots=g_r(x)=0 \}.
    \end{equation}
    Soit \( a\) un extrémum de \( f|_{\Gamma}\). Supposons que les formes \( dg_1,\ldots, dg_r\) soient linéairement indépendantes en \( a\). Alors il existe \( \lambda_1,\ldots, \lambda_r\) dans \( \eR\) tel que
    \begin{equation}
        df_a=\sum_{i=1}^r\lambda_i(dg_i)_a.
    \end{equation}
\end{proposition}

En pratique les candidats extrema locaux sont tous les points où les gradients ne sont pas linéairement indépendants, plus tous les points donnés par l'équation $\nabla L=0$. Parmi ces candidats, il faut trouver lesquels sont maxima ou minima, locaux ou globaux.

L'existence d'extrema locaux se prouve généralement en invoquant de la compacité, et en invoquant le lemme suivant qui permet de réduire le problème à un compact.

\begin{lemma}		\label{LemmeMinSCimpliqueS}
	Soit $S$, un ensemble dans $\eR^n$ et $C$, un ouvert de $\eR^n$. Si $a\in\Int S$ est un minimum local relatif à $S\cap C$, alors il est un minimum local par rapport à $S$.
\end{lemma}

\begin{proof}
	Nous avons que $\forall x\in B(a,\epsilon_1)\cap S\cap C$, $f(x)\geq f(x)$. Mais étant donné que $C$ est ouvert, et que $a\in C$, il existe un $\epsilon_2$ tel que $B(a,\epsilon_2)\subset C$. En prenant $\epsilon=\min\{ \epsilon_1,\epsilon_2 \}$, nous trouvons que $f(x)\geq f(a)$ pour tout $x\in B(a,\epsilon)\cap(S\cap C)=B(a,\epsilon)\cap S$.
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Formes quadratiques, signature, et lemme de Morse}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Soit \( (E,\| . \|_E)\) un espace vectoriel réel normé de dimension finie \( n\). L'ensemble des formes quadratiques réelles sur \( E\) est vu comme l'ensemble des matrices symétriques \( S_n(\eR)\); il sera noté \( Q(E)\) et le sous-ensemble des formes quadratiques non dégénérées est \( S_n(\eR)\cap\GL(n,\eR)\) qui sera noté \( \Omega(E)\). Nous rappelons que la correspondance est donnée de la façon suivante. Si \( A\in S_n(\eR)\), la forme quadratique associée est \( q_A\) donnée par \( q_A(x)=x^tAx\).

Sur \( Q(E)\) nous mettons la norme
\begin{equation}
    N(q)=\sup_{\| x \|_E=1}| q(x) |,
\end{equation}
qui du point de vue de \( S_n(\eR)\) est
\begin{equation}    \label{EqDOgBNAg}
    N(A)=\sup_{\| x \|_E=1}| x^tAx |.
\end{equation}
Notons que à droite, c'est la valeur absolue usuelle sur \( \eR\).

Nous savons par le théorème de Sylvester (théorème \ref{ThoQFVsBCk}) que dans \( \eM(n,\eR)\), toute matrice symétrique de signature \( (p,q)\) est semblable à la matrice
\begin{equation}
    \mtu_{p,q}=\begin{pmatrix}
        \mtu_p    &       &       \\
        &   \mtu_{p}    &       \\
        &       &   0_{n-p-q}
    \end{pmatrix}.
\end{equation}
Donc deux matrices de \( S_n\) sont semblables si et seulement si elles ont la même signature (même si elles ne sont pas de rang maximum, cela soit dit au passage). Si nous notons \( S_n^{p,q}(\eR)\) l'ensemble des matrices réelles symétriques de signature \( (p,q)\), alors
\begin{equation}
    S_n^{p,q}(\eR)=\{ P^tAP\tq P\in \GL(n,\eR) \}
\end{equation}
où \( A\) est une quelconque ce ces matrices.

Nous voudrions en savoir plus sur ces ensembles. En particulier nous aimerions savoir si la signature est une notion «stable» au sens où ces ensembles seraient ouverts dans \( S_n\). Pour cela nous considérons l'action de \( \GL(n,\eR)\) sur \( S_n\) définie par
\begin{equation}
    \begin{aligned}
        \alpha\colon \GL(n,\eR)\times S_n(\eR)&\to S_n(\eR) \\
        (P,A)&\mapsto P^tAP 
    \end{aligned}
\end{equation}
faite exprès pour que les orbites de cette action soient les ensembles \( S_n^{p,q}(\eR)\).

La proposition suivante montre que lorsque \( p+q=n\), c'est à dire lorsqu'on parle de matrices de rang maximum, les ensembles \( S_n^{p,q}(\eR)\) sont ouverts, c'est à dire que la signature d'une forme quadratique est une propriété «stable» par petite variations des éléments de matrice. Notons tout de suite que si le rang n'est pas maximum, le théorème de Sylvester dit qu'elle est semblable à une matrice diagonale avec des zéros sur la diagonale; en modifiant un peu ces zéros, on peut modifier évidemment la signature.
\begin{proposition}[\cite{KXjFWKA}] \label{PropNPbnsMd}
    Soit \( (E,\| . \|_{E})\) un espace vectoriel normé de dimension finie. Alors
    \begin{enumerate}
        \item
            les formes quadratiques non dégénérées forment un ouvert dans l'ensemble des formes quadratiques,
        \item
            les ensembles \( S_n^{p,q}(\eR)\) avec \( p+q=n\) sont ouverts dans \( S_n(\eR)\),
        \item   \label{ItemGOhRIiViii}
            les composantes connexes de \( \Omega(E)\) sont les \( S_n^{p,q}(\eR)\) avec \( p+q=n\),
        \item   \label{ItemGOhRIiViv}
            les \( S_n^{p,q}(\eR)\) non dégénérés sont connexes par arc.
    \end{enumerate}
\end{proposition}
\index{connexité!signature d'une forme quadratique}
\index{matrice!symétrique!réelle}
\index{forme!quadratique}

\begin{proof}
    Cette preuve est donnée du point de vue des matrices. La différence entre le point \ref{ItemGOhRIiViii} et \ref{ItemGOhRIiViv} est que dans le premier nous prouvons la connexité de \( S_n^{p,q}(\eR)\) à partir de la connexité de \( \GL^+(n,\eR)\), tandis que dans le second nous prouvons la connexité par arc de \( S_n^{p,q}(\eR)\) à partir de la connexité par arc de \( \GL^+(n,\eR)\). Bien entendu le second implique le premier.
    \begin{enumerate}
        \item
            Il s'agit simplement de remarquer que \( Q(E)=S_n(\eR)\), que \( \Omega(E)=S_n(\eR)\cap\GL(n,\eR)\) et que le déterminant est une fonction continue sur \( \eM(n,\eR)\).
        \item
            Soit \( A_0\in S_n^{p,q}(\eR)\). Le théorème de Sylvester \ref{ThoQFVsBCk} nous donne une matrice inversible \( P\) telle que \( P^tA_0P=\mtu_{p,q}\). Nous allons montrer qu'il existe un voisinage \( \mU\) de \( \mtu_{p,q}\) contenu dans \( S_n^{p,q}(\eR)\). À partir de là, l'ensemble \( (P^{-1})^t\mU P^{-1}\) sera un voisinage de \( A_0\) contenu dans \( S_n^{p,q}(\eR)\).

            Nous considérons les espaces vectoriels
            \begin{subequations}
                \begin{align}
                    F&=\Span\{ e_1,\ldots, e_p \}\\
                    G&=\Span\{ e_{p+1},\ldots, e_n \}
                \end{align}
            \end{subequations}
            La norme euclidienne \( \| . \|_p\) sur \( F\) est équivalente à la norme \( | . |_E\) par le théorème \ref{ThoNormesEquiv}. Donc il existe une constante \( k_1>0\) telle que pour tout \( x\in F\),
            \begin{equation}    \label{EqMViCjJJ}
                \| x \|_p\geq k_1\| x \|_E.
            \end{equation}
            De la même façon sur \( G\), il existe une constante \( k_2>0\) telle que
            \begin{equation}    \label{EqSFwOcDw}
                \| x \|_q\geq k_2\| x \|_E.
            \end{equation}
            Si nous posons \( k=\min\{ k_1^2,k_2^2 \}\), alors nous avons
            \begin{subequations}
                \begin{align}
                    \forall x\in F,\quad &\| x \|_p^2\geq k_1^2\| x \|_E^2\geq k\| x \|_E^2\\
                    \forall x\in G,\quad &\| x \|_q^2\geq k_2^2\| x \|_E^2\geq k\| x \|_E^2.
                \end{align}
            \end{subequations}
            
            Soit une matrice \( A\in S_n(\eR)\) telle que \( N(A-\mtu_{p,q})<k\), c'est à dire que \( A\) est dans un voisinage de \( \mtu_{p,q}\) pour la norme sur \( S_n(\eR)\) donné par \eqref{EqDOgBNAg}. Si \( x\) est non nul dans \( E\), nous avons
            \begin{equation}
                \big| x^t(A-\mtu_{p,q})x \big|\leq N(\mtu_{p,q}-A)\| x \|^2\leq k\| x \|^2.
            \end{equation}
            En déballant la valeur absolue, cela signifie que
            \begin{equation}
                -k\| x \|_E^2\leq x^t(A-\mtu_{p,q})x\leq k\| x \|^2.
            \end{equation}
            Si \( x\in F\), alors la première inéquation et \eqref{EqMViCjJJ} donnent
            \begin{equation}
                x^tAx\geq \| x \|_p^2-k\| x \|_E^2>0
            \end{equation}
            Si \( x\in G\), alors la seconde inéquation et \eqref{EqSFwOcDw} donnent
            \begin{equation}
                x^tAx\leq  k\| x \|_E^2-\| x \|_q^2<0.
            \end{equation}
            
            Nous avons donc montré que \( x\mapsto x^tAx\) est positive sur \( F\) et négative sur \( G\), ce qui prouve que \( A\) est bien de signature \( (p,q)\) et appartient donc à \( S_n^{p,q}(\eR)\). Autrement dit nous avons
            \begin{equation}
                B(\mtu_{p,q},k)\subset S_n^{p,q}(\eR).
            \end{equation}

        \item
            Cette partie de la preuve provient essentiellement de \cite{VKqpMYL}, et fonctionne pour tous les \( S_n^{p,q}(\eR)\), même pour ceux qui ne sont pas de rang maximum. 
            
            Soit \( A\in S_n^{p,q}(\eR)\). Nous savons que \( \GL(n,\eR)\) a deux composantes connexes (proposition \ref{PropYGBEECo}). Vu que l'application 
            \begin{equation}
                \begin{aligned}
                    \alpha\colon \GL(n,\eR)&\to S_n \\
                    P&\mapsto P^tAP 
                \end{aligned}
            \end{equation}
            est continue, l'image d'un connexe de \( \GL(n,\eR)\) par \( \alpha\) est connexe (proposition \ref{PropGWMVzqb}). En particulier, \( \alpha\big( \GL^{\pm}(n,\eR) \big)\) sont deux connexes et nous savons que \( S_n^{p,q}(\eR)\) a au plus ces deux composantes connexes. 

            Notre but est maintenant de trouver une intersection entre \( \alpha\big( \GL^+(n,\eR) \big)\) et \( \alpha\big( \GL^-(n,\eR) \big)\)\quext{À ce point, il me semble que \cite{VKqpMYL} fait erreur parce que la matrice \( -\mtu_n\) est de déterminant \( 1\) lorsque \( n\) est pair. L'argument donné ici provient de \cite{KXjFWKA}}. Soit par le théorème de Sylvester, soit par le théorème de diagonalisation des matrices symétriques réelles \ref{ThoeTMXla}, il existe une matrice \( P\in \GL(n,\eR)\) diagonalisant \( A\). En suivant la remarque \ref{RemGKDZfxu}, et en notant \( Q\) la matrice obtenue à partir de \( P\) en changeant le signe de sa première ligne, nous avons
            \begin{equation}
                \alpha(Q)=Q^tAQ=P^tAP=\alpha(P).
            \end{equation}
            Or si \( P\in \GL^+(n,\eR)\), alors \( Q\in \GL^-(n,\eR)\) et inversement. Donc nous avons trouvé une intersection entre \( \alpha\big( \GL^+(n,\eR) \big)\) et \( \alpha\big( \GL^-(n,\eR) \big)\).

        \item

            Soient \( A\) et \( B\) dans \( S_n^{p,q}(\eR)\cap\GL(n,\eR)\). Par le théorème de Sylvester, il existe \( P\) et \( Q\) dans \( \GL(n,\eR)\) telles que \( A=P^t\mtu_{p,q}P\) et \( B=Q^t\mtu_{p,q}Q\). Par la remarque \ref{RemGKDZfxu} nous pouvons choisir \( P\) et \( Q\) dans \( \GL^+(n,\eR)\). Ce dernier groupe étant connexe par arc, il existe un chemin
            \begin{equation}
                    \gamma\colon \mathopen[ 0 , 1 \mathclose]\to \GL^+(n,\eR) 
            \end{equation}
            tel que \( \gamma(0)=P\) et \( \gamma(1)=Q\). Alors le chemin
            \begin{equation}
                s\mapsto \gamma(s)^t\mtu_{p,q}\gamma(s)
            \end{equation}
            est un chemin continu dans \( S_n^{p,q}(\eR)\) joignant \( A\) à \( B\).
    \end{enumerate}
\end{proof}
% TODO : prouver la connexité par arc de GL^+(n,\eR) et mettre une référence ici.

Nous savons déjà de la proposition \ref{PropNPbnsMd} que les ensembles \( S_n^{p,q}(\eR)\) (pas spécialement de rang maximum) sont ouverts dans \( S_n(\eR)\). Le lemme suivant nous donne une précision à ce sujet, dans le cas des matrices de rang maximum, en disant que la matrice qui donne la similitude entre \( A_0\) et \( A\) est localement un \( C^1\)-difféomorphisme de \( A\).
\begin{lemma}   \label{LemWLCvLXe}
    Soit \( A_0\in \Omega(\eR^n)= S_n\cap\GL(n,\eR)\), une matrice symétrique inversible. Alors il existe un voisinage \( V\) de \( A_0\) dans \( S_n\) et une application \( \phi\colon V\to \GL(n,\eR)\) qui
    \begin{enumerate}
        \item
            est de classe \( C^1\),
        \item
            est telle que pour tout \( A\in V\), \( \varphi(A)^t A_0\phi(A)=A\).
    \end{enumerate}
\end{lemma}
\index{groupe!\( \GL(n,\eR)\)}
\index{forme!quadratique}
\index{matrice!symétrique}
\index{matrice!semblables}

\begin{proof}
    Nous considérons l'application
    \begin{equation}
        \begin{aligned}
            \varphi\colon \eM(n,\eR)&\to S_n \\
            M&\mapsto M^tA_0M. 
        \end{aligned}
    \end{equation}
    Étant donné que les composantes de \( \varphi(M)\) sont des polynômes en les entrées de \( M\), cette application est de classe \( C^1\) -- et même plus. Soit maintenant \( H\in \eM(n,\eR)\) et calculons \( d\varphi_{\mtu}(H)\) par la formule \eqref{EqOWQSoMA} :
    \begin{subequations}
        \begin{align}
            d\varphi_{\mtu}(H)&=\Dsdd{ \varphi(\mtu+tH) }{t}{0}\\
            &=\Dsdd{ (\mtu+tH^t)A_0(\mtu+tH) }{t}{0}\\
            &=\Dsdd{ A_0+tA_0H+tH^tA_0+t^2H^tA_0H }{t}{0}\\
            &=A_0H+H^tA_0.
        \end{align}
    \end{subequations}
    Donc
    \begin{equation}
        d\varphi_{\mtu}(H)=(A_0H)+(A_0H)^t.
    \end{equation}
    Par conséquent 
    \begin{equation}
        \ker(d\varphi_{\mtu})=\{ H\in \eM(n,\eR)\tq A_0H\text{ est antisymétrique} \},
    \end{equation}
    et si nous posons
    \begin{equation}
        F=\{ H\in \eM(n,\eR)\tq A_0H\text{ est symétrique} \}
    \end{equation}
    nous avons
    \begin{equation}
        \eM(n,\eR)=F\oplus\ker(d\varphi_{\mtu})
    \end{equation}
    parce que toute matrice peur être décomposée de façon unique en partir symétrique et antisymétrique. De plus l'application
    \begin{equation}    \label{EqGTBusDm}
        \begin{aligned}
            f\colon F&\to S_n \\
            H&\mapsto A_0H 
        \end{aligned}
    \end{equation}
    est une bijection linéaire. D'abord \( A_0H=0\) implique \( H=0\) parce que \( A_0\) est inversible, et ensuite si \( X\in S_n\), alors \( X=A_0A_0^{-1}X\), ce qui prouve que \( X\) est l'image par \( f\) de \( A_0^{-1}X\) et donc que \( f\) est surjective.

    Maintenant nous considérons la restriction \( \psi=\varphi_{|_F}\), \( \psi\colon F\to S_n\). Remarquons que \( \mtu\in F\) parce que \( A_0\in S_n\). L'application \( d\psi_{\mtu}\) est une bijection. En effet d'abord
    \begin{equation}
        d(\varphi_{|_F})_{\mtu}=(d\varphi_{\mtu})_{|_F},
    \end{equation}
    ce qui prouve que
    \begin{equation}
        \ker(d\psi_{\mtu})=\ker(d\varphi_{\mtu})\cap F=\{ 0 \},
    \end{equation}
    ce qui prouve que \( d\psi_{\mtu}\) est injective. Pour montrer que \( d\psi_{\mtu}\) est surjective, il suffit de mentionner le fait que \( \dim F=\dim S_n\) du fait que l'application \eqref{EqGTBusDm} est une bijection linéaire.

    Nous pouvons utiliser le théorème d'inversion locale (théorème \ref{ThoXWpzqCn}) et conclure qu'il existe un voisinage ouvert \( U\) de \( \mtu\) dans \( F\) tel que \( \psi\) soit un difféomorphisme \( C^1\) entre \( U\) et \( V=\psi(U)\). Vu que \( \GL(n,\eR)\) est ouvert dans \( \eM(n,\eR)\), nous pouvons prendre \( U\cap \GL(n,\eR)\) et donc supposer que \( U\subset \GL(n,\eR)\).

    Pour tout \( A\in V\), il existe une unique \( M\in U\) telle que \( \psi(M)=A\), c'est à dire telle que \( A=M^tA_0M\). Cette matrice \( M\) est \( \psi^{-1}(A)\) et est une matrice inversible. Bref, nous posons
    \begin{equation}
        \begin{aligned}
            \phi\colon V&\to \GL(n,\eR) \\
            A&\mapsto \psi^{-1}(A), 
        \end{aligned}
    \end{equation}
    et ce \( \phi\) est de classe \( C^1\) sur \( V\) parce que c'est ce que dit le théorème d'inversion locale. Cette application répond à la question parce que \( V\) est un voisinage de \( \varphi(\mtu)=A_0\) et pour tout \( A\in V\) nous avons
    \begin{equation}
        \phi(A)^tA_0\phi(A)=\varphi^{-1}(A)^tA_0\varphi^{-1}(A)=A.
    \end{equation}
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Lemme de Morse}
%---------------------------------------------------------------------------------------------------------------------------

\begin{lemma}[Lemme de Morse]     \label{LemNQAmCLo}
    Soit \( f\in C^3(\mU,\eR)\) où \( \mU\) est un ouvert de \( \eR^n\) contenant \( 0\). Nous supposons que \( df_0=0\) et que \( d^2f_0\) est non dégénérée\footnote{En tant qu'application bilinéaire.} et de signature \( (p,n-p)\). Alors il existe un \( C^1\)-difféomorphisme \( \varphi\) entre deux voisinages de \( 0\) dans \( \eR^n\) tel que
    \begin{enumerate}
        \item
            \( \varphi(0)=0\),
        \item
            si \( \varphi(x)=u\) alors
            \begin{equation}
                f(x)-f(0)=u_1^2+\ldots +u_p^2-u_{p+1}^2-\ldots-u_n^2.
            \end{equation}
    \end{enumerate}
    Une autre façon de dire est qu'il existe un \( C^1\)-difféomorphisme local \( \psi\) tel que
    \begin{equation}
        (f\circ\psi)(x)-f(0)=x_1^2+\ldots +x_p^2-x_{p+1}^2-\ldots-x_n^2.
    \end{equation}
\end{lemma}
\index{lemme!de Morse}
\index{développement!Taylor}
\index{application!différentiable}
\index{forme!quadratique}
\index{théorème!inversion locale}
\index{action de groupe!sur des matrices}
\index{extremum}

\begin{proof}
    Nous allons noter \( Hf\) la matrice Hessienne de \( f\), c'est à dire \( Hf_a=d^2f_a\in\aL^{(2)}(\eR^n,\eR)\). Écrivons la formule de Taylor avec reste intégral (proposition \ref{PropAXaSClx} avec \( p=0\) et \( m=2\)) :
    \begin{equation}
        f(x)-f(0)=\underbrace{df_0(x)}_{=0}+\int_0^1(1-t)\underbrace{d^2f_{tx}(x,x)}_{x^t(Hf)_{tx}x=\langle Hf_{tx}x, x\rangle }dt=x^tQ(x)x
    \end{equation}
    avec
    \begin{equation}
        Q(x)=\int_0^1(1-t)(Hf)_{tx}dt
    \end{equation}
    qui est une intégrale dans \( \aL^{(2)}(\eR^n,\eR)\). Nous prouvons à présent que \( Q\) est de classe \( C^1\) en utilisant le résultat de différentiabilité sous l'intégrale \ref{PropAOZkDsh}. Pour cela nous passons aux composantes (de la matrice) et nous considérons
    \begin{equation}
        \begin{aligned}
            h_{kl}\colon U\times\mathopen[ 0 , 1 \mathclose]&\to \eR \\
            h_{kl}(x,t)&=(1-t)\frac{ \partial^2f  }{ \partial x_k\partial x_l }(tx).
        \end{aligned}
    \end{equation}
    Étant donné que \( f\) est de classe \( C^3\), la dérivée de \( h_{kl}\) par rapport à \( x_i\) ne pose pas de problèmes :
    \begin{equation}
        \frac{ \partial h_{kl} }{ \partial x_i }=t(t-1)\frac{ \partial^3f  }{ \partial x_i\partial x_k\partial x_l }(tx),
    \end{equation}
    qui est encore continue à la fois en \( t\) et en \( x\). La proposition \ref{PropAOZkDsh} nous montre à présent que
    \begin{equation}
        Q_{kl}(x)=\int_0^1(1-t)h_{kl}(tx)dt
    \end{equation}
    est une fonction \( C^1\). Étant donné que les composantes de \( Q\) sont \( C^1\), la fonction \( Q\) est également \( C^1\).

    Nous avons \( Q(0)=\frac{ 1 }{2}(Hf)_0\in S_n\cap \GL(n,\eR)\), d'abord parce que \( f\) est \( C^2\) (et donc la matrice hessienne est symétrique), ensuite par hypothèse \( d^2f_0\) est non dégénérée.
    %TODO : prouver que la matrice hessienne est symétrique lorsque f est C^2 (ou vérifier que c'est déjà fait), et référentier ici.

    À partir de là, le lemme \ref{LemWLCvLXe} donne un voisinage \( V\) de \( Q(0)\) dans \( S_n\) et une application \( \phi\) de classe \( C^1\)
    \begin{equation}
            \phi\colon V\to \GL(n,\eR) \\
    \end{equation}
    telle que pour tout \( A\in V\),
    \begin{equation}
        \phi(A)^tQ(0)\phi(A)=A.
    \end{equation}
    Si on pose \( M=\phi\circ Q\), et si \( x\) est dans un voisinage de zéro, \( Q\) étant continue nous avons \( Q(x)\in V\) et donc
    \begin{equation}
        Q(x)=M(x)^tQ(0)M(x).
    \end{equation}
    Notons que l'application \( \eM\colon \eR\to \GL(n,\eR)\) est de classe \( C^1\) parce que \( Q\) et \( \phi\) le sont.

    Nous avons
    \begin{equation}
        f(x)-f(0)=x^tQ(x)x=x^tM(x)^tQ(0)M(x)x=y(x)^tQ(0)y(x)
    \end{equation}
    où \( y(x)=M(x)x=(\phi\circ Q)(x)x\) est encore une fonction de classe \( C^1\) parce que la multiplication est une application \(  C^{\infty}\).

    D'un autre côté le théorème de Sylvester \ref{ThoQFVsBCk} nous donne une matrice inversible \( P\) telle que
    \begin{equation}
        Q(0)=P^t\begin{pmatrix}
            \mtu_p    &       \\ 
            &   -\mtu_{n-p}    
        \end{pmatrix}P.
    \end{equation}
    Et nous posons enfin \( u=\varphi(x)=Py(x)\) qui est toujours de classe \( C^1\) et qui donne
    \begin{subequations}
        \begin{align}
            f(x)-f(0)&=y^tQ(0)y\\
            &=y^tP^t\begin{pmatrix}
                \mtu    &       \\ 
                    &   -\mtu    
            \end{pmatrix}Py\\
            &=u^t\begin{pmatrix}
                \mtu    &       \\ 
                    &   -\mtu    
            \end{pmatrix}u\\
            &=u_1^2+\ldots +u_p^2-u_{p+1}^2-\ldots -u_n^2.
        \end{align}
    \end{subequations}
    
    Nous devons maintenant montrer que, quitte à réduire son domaine à un ouvert plus petit, \( \varphi\) est un \( C^1\)-difféomorphisme. Dans la chaine qui donne \( \varphi\), seule l'application 
    \begin{equation}
        \begin{aligned}
            g\colon U\subset \eR^n&\to \eR^n \\
            x&\mapsto M(x)x 
        \end{aligned}
    \end{equation}
    est sujette à caution. Nous allons appliquer le théorème d'inversion locale. Nous savons que \( g\) est de classe \( C^1\) et donc différentiable; calculons la différentielle en utilisant la formule \eqref{EqOWQSoMA} :
    \begin{equation}
        dg_0(x)=\Dsdd{ g(tx) }{t}{0}=\Dsdd{ tM(tx)x }{t}{0}=M(0)x.
    \end{equation}
    Note que nous avons utilisé la règle de Leibnitz pour la dérivée d'un produit, mais le second terme s'est annulé. Donc \( dg_0=M(0)\in \GL(n,\eR)\) et \( g\) est localement un \( C^1\)-difféomorphisme.

    Il suffit de restreindre \( \varphi\) au domaine sur lequel \( g\) est un \( C^1\)-difféomorphisme pour que \( \varphi\) devienne lui-même un \( C^1\)-difféomorphisme.

\end{proof}

\begin{definition}
    Un point \( a\) est un \defe{point critique}{point critique!définition} de la fonction différentiable \( f\) si \( df_a=0\).
\end{definition}

\begin{corollary}[\cite{XPautfO}]
    Les points critiques non dégénérés d'une fonction \( C^3\) sont isolés.
\end{corollary}

\begin{proof}
    Soit \( a\) un point critique non dégénéré. Par le lemme de Morse \ref{LemNQAmCLo}, il existe un \( C^1\)-difféomorphisme \( \psi\) et un entier \( p\) tel que
    \begin{equation}
        (f\circ \psi)(x)=x_1^2+\ldots +x_p^2-x_{p+1}^2-\ldots -x_n^2+f(a)
    \end{equation}
    sur un voisinage \( \mU\) de \( a\). Vue la formule générale \( df_x(u)=\nabla f(x)\cdot u\), si \( x\) est un point critique de \( f\), alors \( \nabla f(x)=0\). Dans notre cas, les points critiques de \( f\circ \psi\) dans \( \mU\) doivent vérifier \( x_i=0\) pour tout \( i\), et donc \( x=a\).

    Nous devons nous assurer que la fonction \( f\) elle-même n'a pas de points critiques dans \( \mU\). Pour cela nous utilisons la formule générale de dérivation de fonction composée :
    \begin{equation}
        \nabla(f\circ\psi)(x)=\sum_k \frac{ \partial f }{ \partial y_k }\big( g(x) \big)\nabla g_k(x).
    \end{equation}
    Si \( \psi(x)\) est une point critique de \( f\), alors le membre de droite est le vecteur nul parce que tous les \( \partial_kf\big( \psi(x) \big)\) sont nuls. Par conséquent le membre de gauche est également nul, et \( x\) est un point critique de \( f\circ\psi\). Or nous venons de voir que \( f\circ\psi\) n'a pas de points critiques dans \( \mU\).

    Donc \( f\) n'a pas de points critiques dans un voisinage d'un point critique non dégénéré.
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Variétés}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\subsection{Introduction}
Soit $f : S^2 \to \eR$ une fonction définie sur la sphère usuelle
$S^2 \subset \eR^3$. Une question naturelle est d'estimer la
régularité de $f$ ; est-elle continue, dérivable, différentiable ? Il
n'existe pas de dérivée directionnelle étant donné que le quotient
différentiel
\begin{equation*}
  \frac{f(x + \epsilon u_1 ,y + \epsilon u_2) - f(x,y)}{\epsilon}
\end{equation*}
n'a pas de sens pour un point $(x + \epsilon u_1 ,y + \epsilon u_2)$
qui n'est pas --sauf valeurs particulières-- dans la surface. Pour la
même raison il n'est pas possible de parler de différentiabilité de
cette manière. Comment faire, sans devoir étendre le domaine de
définition de $f$ à un voisinage de la sphère ? Une solution possible
est de parler de la notion de variété.

Une variété est un objet qui ressemble, vu de près, à $\eR^m$ pour un
certain $m$. En d'autres termes, on imagine une variété comme un
recollement de morceaux de $\eR^m$ vivant dans un espace plus grand
$\eR^n$. Ces morceaux sont appelés des ouverts de carte, et
l'application qui exprime la ressemblance à $\eR^m$ est l'application
de carte.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Définition et propriétés}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}
  Soit $\emptyset \neq M \subset \eR^n$, $1 \leq m < n$ et $k \geq
  1$. $M$ est une \Defn{variété de classe $C^k$ de dimension $m$} si
  pour tout $a \in \var M$, il existe un voisinage ouvert $U$ de $a$
  dans $\eR^n$, et un ouvert $V$ de $\eR^m$ tel que $U \cap \var M$
  soit le graphe d'une fonction $f : V \subset \eR^m \to \eR^{n-m}$
  de classe $C^1$, c'est-à-dire qu'il existe un réagencement des
  coordonnées $(x_{i_1}, \ldots, x_{i_m}, x_{i_{m+1}}, \ldots,
  x_{i_n})$ avec
  \begin{equation*}
    M \cap U = \left\{ (x_1, \ldots, x_n) \in \eR^n \tq
%      \begin{array}{l} % deux conditions
      (x_{i_1}, \ldots, x_{i_m}) \in V \quad \left\{\begin{array}{c!{=}l} % 1: equations
        x_{i_{m+1}} & f_1(x_{i_1}, \ldots, x_{i_m})\\
        \vdots & \vdots \\
        x_{i_n} & f_{n-m}(x_{i_1}, \ldots, x_{i_m})
      \end{array}\right.
%    \end{array}
    \right\}
  \end{equation*}
  où $V$ est un voisinage ouvert de $(a_{i_1}, \ldots, a_{i_m}) \in \eR^m$.
\end{definition}

La littérature regorge de théorèmes qui proposent des conditions équivalentes à la définition d'une variété. Celle que nous allons le plus utiliser est la suivante% , de la page 268.
\begin{proposition}
	Soit $M\subset\eR^n$ et $1\leq m\leq n-1$. L'ensemble $M$ est une variété si et seulement si $\forall a\in M$, il existe un voisinage ouvert $\mU$ de $a$ dans $\eR^n$ et une application $F\colon W\subset\eR^m\to \eR^n$ où $W$ est un ouvert tels que
	\begin{enumerate}
		\item
			$F$ est un homéomorphisme de $W$ vers $M\cap\mU$,
		\item
			$F\in C^1(W,\eR^n)$,
		\item
			Le rang de $dF(w)\in L(\eR^m,\eR^n)$ est de rang maximum (c'est à dire $m$) en tout point $w\in W$.
	\end{enumerate}
\end{proposition}
Pour rappel, si $T\colon \eR^m\to \eR^n$ est une application linéaire, son \defe{rang}{rang} est la dimension de son image. On peut prouver que si $A$ est la matrice d'une application linéaire, alors le rang de cette application linéaire est égal à la taille de la plus grande matrice carré de déterminant non nul contenue dans $A$.

La condition de rang maximum sert à éviter le genre de cas de la figure \ref{LabelFigExempleNonRang} qui représente l'image de l'ouvert $\mathopen] -1 , 1 \mathclose[$ par l'application $F(t)=(t^2,t^3)$.
\newcommand{\CaptionFigExempleNonRang}{Quelque chose qui n'est pas de rang maximum et qui n'est pas une variété.}
\input{Fig_ExempleNonRang.pstricks}
%\ref{LabelFigExempleNonRang} 
%\newcommand{\CaptionFigExempleNonRang}{Quelque chose qui n'est pas de rang maximum et qui n'est pas une variété.}
%\input{Fig_ExempleNonRang.pstricks}
La différentielle a pour matrice
\begin{equation}
	dF(t)=(2t,3t^2).
\end{equation}
Le rang maximum est $1$, mais en $t=0$, la matrice vaut $(0,0)$ et son rang est zéro. Pour toute autre valeur de $t$, c'est bon.

Une autre caractérisation des variétés est donnée par la proposition suivante %(proposition 3, page 274).
\begin{proposition}		\label{PropCarVarZerFonc}
	Soit $M\in \eR^n$ et $1\leq m\leq n-1$. L'ensemble $M$ est une variété si et seulement si $\forall a\in M$, il existe un voisinage ouvert $\mU$ de $a$ dans $\eR^n$ tel et une application $G\in C^1(\mU,\eR^{n-m})$ tel que
	\begin{enumerate}

		\item
			le rang de $dG(a)\in L(\eR^n,\eR^{n-m})$ soit maximum (c'est à dire $n-m$) en tout $a\in M$,
		\item
			$M\cap\mU=\{ x\in\mU\tq G(x)=0 \}$.

	\end{enumerate}
\end{proposition}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Espace tangent}
%---------------------------------------------------------------------------------------------------------------------------

Soit $M$, une variété dans $\eR^n$, et considérons un chemin $\gamma\colon I\to \eR^n$ tel que $\gamma(t)\in M$ pour tout $t\in I$ et tel que $\gamma(0)=a$ et que $\gamma$ est dérivable en $0$. La \defe{tangente}{tangente à un chemin} au chemin $\gamma$ au point $a\in M$ est la droite
\begin{equation}
	s\mapsto a+s\gamma'(0).
\end{equation}
L'\defe{espace tangent}{espace!tangent} de $M$ au point $a$ est l'ensemble décrit par toutes les tangentes en $a$ pour tous les chemins $\gamma$ possibles.

\begin{proposition}			\label{PropDimEspTanVarConst}
	Une variété de dimension $m$ dans $\eR^n$ a un espace tangent de dimension $m$ en chacun de ses points.
\end{proposition}

