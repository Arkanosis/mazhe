% This is part of Mes notes de mathématique
% Copyright (c) 2011-2014
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
					\section{Théorème d'inversion locale de la fonction implicite}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Mise en situation}
%---------------------------------------------------------------------------------------------------------------------------

Dans un certain nombre de situation, il n'est pas possible de trouver des solutions explicites aux équations qui apparaissent. Néanmoins, l'existence «théorique» d'une telle solution est souvent déjà suffisante. C'est l'objet du théorème de la fonction implicite.

Prenons par exemple la fonction sur $\eR^2$ donnée par 
\begin{equation}
	F(x,y)=x^2+y^2-1.
\end{equation}
Nous pouvons bien entendu regarder l'ensemble des points donnés par $F(x,y)=0$. C'est le cercle dessiné à la figure \ref{LabelFigCercleImplicite}.
\newcommand{\CaptionFigCercleImplicite}{Un cercle pour montrer l'intérêt de la fonction implicite. Si on donne \( x\), nous ne pouvons pas savoir si nous parlons de \( P\) ou de \( P'\).}
\input{Fig_CercleImplicite.pstricks}

%\ref{LabelFigCercleImplicite}.
%\newcommand{\CaptionFigCercleImplicite}{Un cercle pour montrer l'intérêt de la fonction implicite.}
%\input{Fig_CercleImplicite.pstricks}

Nous ne pouvons pas donner le cercle sous la forme $y=y(x)$ à cause du $\pm$ qui arrive quand on prend la racine carrée. Mais si on se donne le point $P$, nous pouvons dire que \emph{autour de $P$}, le cercle est la fonction
\begin{equation}
	y(x)=\sqrt{1-x^2}.
\end{equation}
Tandis que autour du point $P'$, le cercle est la fonction
\begin{equation}
	y(x)=-\sqrt{1-x^2}.
\end{equation}
Autour de ces deux point, donc, le cercle est donné par une fonction. Il n'est par contre pas possible de donner le cercle autour du point $Q$ sous la forme d'une fonction.

Ce que nous voulons faire, en général, est de voir si l'ensemble des points tels que
\begin{equation}
	F(x_1,\ldots,x_n,y)=0
\end{equation}
peut être donné par une fonction $y=y(x_1,\ldots,x_n)$. En d'autre termes, est-ce qu'il existe une fonction $y(x_1,\ldots,x_n)$ telle que
\begin{equation}
	F\big( x_1,\ldots,x_n,y(x_1,\ldots,x_n)\big)=0.
\end{equation}

Plus généralement, soit une fonction
\begin{equation}
    \begin{aligned}
        F\colon D\subset \eR^n\times \eR^m&\to \eR^m \\
        (x,y)&\mapsto \big( F_1(x,y),\ldots, F_m(x,y) \big) 
    \end{aligned}
\end{equation}
avec $x = (x_1,\ldots, x_n)$ et $y = (y_1,\ldots,y_m)$. Pour chaque $x$ fixé, on s'intéresse aux solutions du système de $m$ équations $F(x,y) = 0$ pour les inconnues $y$ ; en particulier, on voudrait pouvoir écrire $y = \varphi(x)$ vérifiant $F(x,\varphi(x)) = 0$.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Théorème d'inversion locale}
%---------------------------------------------------------------------------------------------------------------------------

\begin{lemma}[\cite{ZCKMFRg}] \label{LemGZoqknC}
    Soit \( E\) un espace de Banach (métrique complet) et \( \mO\) un ouvert de \( E\). Nous considérons une \( \lambda\)-contraction \( \varphi\colon \mO\to E\). Alors l'application
    \begin{equation}
    f\colon x\mapsto x+\varphi(x)
    \end{equation}
    est un homéomorphisme entre \( \mO\) et un ouvert de \( E\). De plus \( f^{-1}\) est Lipschitz de constante plus petite ou égale à \( (1-\lambda)^{-1}\).
\end{lemma}
Cette proposition utilise le théorème de point fixe de Picard \ref{ThoEPVkCL},
et sera utilisée pour démontrer le théorème d'inversion locale \ref{ThoXWpzqCn}.
% note que garder deux lignes ici est important pour vérifier les références vers le futur : la seconde ligne peut être ignorée, pas la seconde.

\begin{proof}
        Soient \( x_1,x_2\in\mO\). Nous posons \( y_1=f(x_1)\) et \( y_2=f(x_2)\). En vertu de l'inégalité de la proposition \ref{PropNmNNm} nous avons
        \begin{subequations}    \label{subEqEBJsBfz}
            \begin{align}
            \big\| f(x_2)-f(x_1) \big\|&=\big\| x_2+\varphi(x_2)-x_1-\varphi(x_1) \big\|\\
        &\geq \Big|        \| x_2-x_1 \|-\big\| \varphi(x_2)-\varphi(x_1) \big\|  \Big|\\
    &\geq   (1-\lambda)\| x_2-x_1 \|.
            \end{align}
        \end{subequations}
        À la dernière ligne les valeurs absolues sont enlevées parce que nous savons que ce qui est à l'intérieur est positif. Cela nous dit d'abord que \( f\) est injective parce que \( f(x_2)=f(x_1)\) implique \( x_2=x_1\). Donc \( f\) est inversible sur son image. Nous posons \( A=f(\mO)\) et nous devons prouver que que \( f^{-1}\colon A\to \mO\) est continue, Lipschitz de constante majorée par \( (1-\lambda)^{-1}\) et que \( A\) est ouvert.

    Les inéquations \eqref{subEqEBJsBfz} nous disent que
    \begin{equation}
    \big\| f^{-1}(y_1)-f^{-1}(y_2) \big\|\leq \frac{ \| y_1-y_2 \| }{ 1-\lambda },
    \end{equation}
    c'est à dire que
    \begin{equation}
        f^{-1}\big( B(y,r) \big)\subset B\big( f^{-1}(y),\frac{ r }{ 1-\lambda } \big),
    \end{equation}
    ce qui signifie que \( f^{-1}\) est Lipschitz de constante souhaitée et donc continue.

    Il reste à prouver que \( f(\mO)\) est ouvert. Pour cela nous prenons \( y_0=f(x_0)\) dans \( f(\mO)\) est nous prouvons qu'il existe \( \epsilon\) tel que \( B(y_0,\epsilon)\) soit dans \( f(\mO)\). Il faut donc que pour tout \( y\in B(y_0,\epsilon)\), l'équation \( f(x)=y\) ait une solution. Nous considérons l'application
    \begin{equation}
        L_y\colon x\mapsto y-\varphi(x).
    \end{equation}
    Ce que nous cherchons est un point fixe de \( L_y\) parce que si \( L_y(x)=x\) alors \( y=x+\varphi(x)=f(x)\). Vu que
    \begin{equation}
        \big\| L_y(x)-L_y(x') \big\|=\big\| \varphi(x)-\varphi(x') \big\|\leq\lambda\| x-x' \|,
    \end{equation}
    l'application \( L_y\) est une contraction de constante \( \lambda\). Par ailleurs \( x_0\) est un point fixe de \( L_{y_0}\), donc en vertu de la caractérisation \eqref{EqDZvtUbn} des fonctions Lipschitziennes, 
    \begin{equation}
        L_{y_0}\big( \overline{ B(x_0,\delta) } \big)\subset \overline{ B\big( L_{y_0}(x_0),\lambda\delta \big) }=\overline{ B(x_0,\lambda\delta) }.
    \end{equation}
    Vu que pour tout \( y\) et \( x\) nous avons \( L_y(x)=L_{y_0}(x)+y-y_0\),
    \begin{equation}
    L_y\big( \overline{ B(x_0,\delta) } \big)=L_{y_0}\big( \overline{ B(x_0,\delta) } \big)+(y-y_0)\subset \overline{ B(x_0,\lambda\delta) }+(y-y_0)\subset \overline{ B(x_0),\lambda\delta+\| y-y_0 \| }.
    \end{equation}
    Si \( \epsilon<(1-\lambda)\delta\) alors \( \lambda\delta+\| y-y_0 \|<\delta\). Un tel choix de \( \epsilon>0\) est possible parce que \( \lambda<1\). Pour une telle valeur de \( \epsilon\) nous avons
    \begin{equation}
        L_y\big( \overline{ B(x_0,\delta) } \big)\subset \overline{ B(x_0,\delta) }.
    \end{equation}
    Par conséquent \( L_y\) est une contraction sur l'espace métrique complet \( \overline{ B(x_0,\delta) }\), ce qui signifie que \( L_y\) y possède un point fixe par le théorème de Picard \ref{ThoEPVkCL}.
\end{proof}

Le théorème d'inversion locale s'énonce de la façon suivante dans \( \eR^n\) :
\begin{theorem} % Ne pas mettre de label ici parce qu'il faut référencer l'autre, celui dans Banach.
    Soit \( f\in C^k(\eR^n,\eR^n)\) et \( x_0\in \eR^n\). Si \( df_{x_0}\) est inversible, alors il existe un voisinage ouvert \( U\) de \( x_0\) et \( V\) de \( f(x_0)\) tels que \( f\colon U\to V\) soit un \( C^k\)-difféomorphisme. (c'est à dire que \( f^{-1}\) est également de classe \( C^k\))
\end{theorem}
Nous allons le démontrer dans le cas un peu plus général (mais pas plus cher\footnote{Sauf la justification de la régulatité de l'application \( A\mapsto A^{-1}\)}) des espaces de Banach en tant que conséquence du théorème de point fixe de Picard \ref{ThoEPVkCL}.
\begin{theorem}[Inversion locale\cite{ZCKMFRg,OWTzoEK}] \label{ThoXWpzqCn}
    Soit une fonction \( f\in C^p(E,F)\) avec \( p\geq 1\) entre deux espaces de Banach. Soit \( x_0\in E\) tel que \( df_{x_0}\) soit une bijection bicontinue. Alors il existe un voisinage ouvert \( V\) de \( x_0\) et \( W\) de \( f(x_0)\) tels que
    \begin{enumerate}
        \item
        \( f\colon V\to W\) soit une bijection,
    \item
        \( f^{-1}\colon W\to V\) soit de classe \( C^p\).
    \end{enumerate}
\end{theorem}
\index{application!différentiable}
\index{théorème!inversion locale}

\begin{proof}
    Nous commençons par simplifier un peu le problème. Pour cela, nous considérons la translation \( T\colon x\mapsto x+x_0 \) et l'application linéaire
    \begin{equation}
        \begin{aligned}
            L\colon \eR^n&\to \eR^n \\
            x&\mapsto (df_{x_0})^{-1}x
        \end{aligned}
    \end{equation}
    qui sont tout deux des difféomorphismes (\( L\) en est un par hypothèse d'inversibilité). Quitte à travailler avec la fonction \( k=L\circ f\circ T\), nous pouvons supposer que \( x_0=0\) et que \( df_{x_0}=\mtu\). Pour comprendre cela il faut utiliser deux fois la formule de différentielle de fonction composée de la proposition \ref{EqDiffCompose} :
    \begin{equation}
        dk_0(u)=dL_{(f\circ T)(0)}\Big( df_{T(0)}dT_0(u) \Big).
    \end{equation}
    Vu que \( L\) est linéaire, sa différentielle est elle-même, c'est à dire \( dL_{(f\circ T)(0)}=(df_{x_0})^{-1}\), et par ailleurs \( dT_0=\mtu\), donc
    \begin{equation}
        dk_0(u)=(df_{x_0})^{-1}\Big( df_{x_0}(u) \Big)=u,
    \end{equation}
    ce qui signifie bien que \( dk_0=\mtu\). Pour tout cela nous avons utilisé en plein le fait que \( df_{x_0}\) était inversible.

Nous posons \( g=f-\mtu\), c'est à dire \( g(x)=f(x)-x\), qui a la propriété \( dg_0=0\). Étant donné que \( g\) est de classe \( C^1\), l'application\footnote{Ici \( \GL(F)\) est l'ensemble des applications linéaires, inversibles et continues de \( F\) dans lui-même. Ce ne sont pas spécialement des matrices parce que nous n'avons pas d'hypothèses sur la dimension de \( F\), finie ou non.}
    \begin{equation}
        \begin{aligned}
            dg\colon E&\to \GL(F) \\
            x&\mapsto dg_x 
        \end{aligned}
    \end{equation}
    est continue. En conséquence de quoi nous avons un voisinage \( U'\) de \( 0 \) pour lequel
    \begin{equation}    \label{EqSGTOfvx}
        \sup_{x\in U'}\| dg_x \|<\frac{ 1 }{2}.
    \end{equation}
    Maintenant le théorème des accroissements finis \ref{ThoNAKKght} (\ref{val_medio_2} pour la dimension finie) nous indique que pour tout \( x,x'\in U'\) nous avons\footnote{Ici nous supposons avoir choisi \( U'\) convexe afin que tous les \( a\in \mathopen[ x , x' \mathclose]\) soient bien dans \( U'\) et donc soumis à l'inéquation \eqref{EqSGTOfvx}, ce qui est toujours possible, il suffit de prendre une boule.}
    \begin{equation}
        \| g(x')-g(x) \|\leq \sup_{a\in\mathopen[ x , x' \mathclose]}\| dg_a \| \cdot \| x-x' \|\leq \frac{ 1 }{2}\| x-x' \|,
    \end{equation}
    ce qui prouve que \( g\) est une contraction au moins sur l'ouvert \( U'\). Nous allons aussi donner une idée de la façon dont \( f\) fonctionne : si \( x_1,x_2\in U'\) alors
    \begin{subequations}
        \begin{align}
            \| x_1-x_2 \|&=\| g(x_1)-f(x_1)-g(x_2)+f(x_2) \| \\
            &\leq \| g(x_1)-g(x_2) \|+\| f(x_1)-f(x_2) \|\\
            &\leq \frac{ 1 }{2}\| x_1-x_2 \|+\| f(x_1)-f(x_2) \|,
        \end{align}
    \end{subequations}
    ce qui montre que
    \begin{equation}
        \| x_1-x_2 \|\leq 2\| f(x_1)-f(x_2) \|.
    \end{equation}
    Maintenant que nous savons que \( g\) est contractante de constante \( \frac{ 1 }{2}\) et que \( f=g+\mtu\) nous pouvons utiliser la proposition \ref{LemGZoqknC} pour conclure que \( f\) est un homéomorphisme sur un ouvert \( U\) (partie de \( U'\)) de \( E\) et \( f^{-1}\) a une constante de Lipschitz plus petite ou égale à \( (1-\frac{ 1 }{2})^{-1}=2\).

    Nous allons maintenant prouver que \( f^{-1}\) est différentiable et que sa différentielle est donnée par \( (df^{-1})_{f(x)}=(df_x)^{-1}\).

    Soient \( a,b\in U\) et \( u=b-a\). Étant donné que \( f\) est différentiable en \( a\), il existe une fonction \( \alpha\in o(\| u \|)\) telle que
    \begin{equation}
        f(b)-f(a)-df_a(u)=\alpha(u).
    \end{equation}
    En notant \( y_a=f(a)\) et \( y_b=f(b)\) et en appliquant \( (df_a)^{-1}\) à cette dernière équation,
    \begin{equation}
        (df_a)^{-1}(y_b-y_a)-u=(df_a)^{-1} \big( \alpha(u) \big).
    \end{equation}
    Vu que \( df_a\) est bornée (et son inverse aussi), le membre de droite est encore une fonction \( \beta\) ayant la propriété \( \lim_{u\to 0}\beta(u)/\| u \|=0\); en réordonnant les termes,
    \begin{equation}
        b-a=(df_a)^{-1}(y_b-y_a)+\beta(u)
    \end{equation}
    et donc
    \begin{equation}
        f^{-1}(y_b)-f^{-1}(y_a)-(df_a)^{-1}(y_b-y_a)=\beta(u),
    \end{equation}
    ce qui prouve que \( f^{-1}\) est différentiable et que \( (df^{-1})_{y_a}=(df_a)^{-1}\).

    La différentielle \( df^{-1}\) est donc obtenue par la chaine
    \begin{equation}
    \xymatrix{%
        df^{-1}\colon f(U) \ar[r]^-{f^{-1}}     &   U'\ar[r]^-{df}&\GL(F)\ar[r]^-{\Inv}&\GL(F)
       }
    \end{equation}
    où l'application \( \Inv\colon \GL(F)\to \GL(F)\) est l'application \( X\mapsto X^{-1}\) qui est de classe \(  C^{\infty}\) par le théorème \ref{ThoCINVBTJ}. D'autre part, par hypothèse \( df\) est une application de classe \( C^{k-1}\)\quext{Ici il me semble que dans \cite{ZCKMFRg} il est fautivement noté \( C^k\).} et donc au minimum \( C^0\) parce que \( k\geq 1\). Enfin, l'application \( f^{-1}\colon f(U)\to U\) est continue (parce que la proposition \ref{LemGZoqknC} précise que \( f\) est un homéomorphisme). Donc toute la chaine est continue et \( df^{-1}\) est continue. Cela entraine immédiatement que \( f^{-1}\) est \( C^1\) et donc que toute la chaine est \( C^1\).

    Par récurrence nous obtenons la chaine
    \begin{equation}
    \xymatrix{%
        df^{-1}\colon f(U) \ar[r]^-{f^{-1}}_-{C^{k-1}}     &   U'\ar[r]^-{df}_-{C^{k-1}}&\GL(F)\ar[r]^-{\Inv}_-{ C^{\infty}}&\GL(F)
       }
    \end{equation}
    qui prouve que \( df^{-1}\) est \( C^{k-1} \) et donc que \( f^{-1}\) est \( C^k\). La récurrence s'arrête ici parce que \( df\) n'est pas mieux que \( C^{k-1}\).
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Théorème de la fonction implicite}
%---------------------------------------------------------------------------------------------------------------------------


Nous énonçons et le démontrons le théorème de la fonction implicite dans le cas d'espaces de Banach.
\begin{theorem}[Théorème de la fonction implicite dans Banach\cite{SNPdukn}] \label{ThoAcaWho}
    Soient \( E\), \( F\) et \( G\) des espaces de Banach et des ouverts \( U\subset E\), \( V\subset F\). Nous considérons une fonction \( f\colon U\times V\to G\) de classe \( C^r\) telle que\footnote{La notation \( d_y\) est la différentielle partielle de la définition \ref{VJM_CtSKT}.}
    \begin{equation}
        d_yf_{(x_0,y_0)}\colon F\to G
    \end{equation}
    soit un isomorphisme pour un certain \( (x_0,y_0)\in U\times V\).

    Alors nous avons des voisinages \( U_0\) de \( x_0\) dans \( E\) et \( W_0\) de \( f(x_0,y_0)\) dans \( G\) et une fonction de classe \( C^r\) 
    \begin{equation}
        g\colon U_0\times W_0\to V
    \end{equation}
    telle que 
    \begin{equation}
        f\big( x,g(x,w) \big)=w
    \end{equation}
    pour tout \( (x,w)\in U_0\times W_0\).
    
    Cette fonction \( g\) est unique au sens suivant : il existe un voisinage \( V_0 \) de \( y_0\) tel que si \( (x,y)\in U_0\times V_0\) et \( w\in W_0\) satisfont à \( f(x,y)=w\) alors \( y=g(x,w)\). Autrement dit, la fonction \( g\colon U_0\times W_0\to V_0\) est unique.
\end{theorem}
\index{théorème!fonction implicite dans Banach}

\begin{proof}
    Nous commençons par considérer la fonction
    \begin{equation}
        \begin{aligned}
            \Phi\colon U\times V&\to E\times G \\
            (x,y)&\mapsto \big( x,f(x,y) \big)
        \end{aligned}
    \end{equation}
    et sa différentielle 
    \begin{subequations}
        \begin{align}
            d\Phi_{(x_0,y_0)}(u,v)&=\Dsdd{ \big( x_0+tu,f(x_0+tu,y_0+tv) \big) }{t}{0}\\
            &=\left( \Dsdd{ x_0+tu }{t}{0},\Dsdd{ f(x_0+tu,y_0+tv) }{t}{0} \right)\\
            &=\left( u,df_{(x_0,y_0)}(u,v) \right).
        \end{align}
    \end{subequations}
    Nous utilisons alors la proposition \ref{PropLDN_nHWDF} pour conclure que
    \begin{equation}
        d\Phi_{(x_0,y_0)}(u,v)=\big( u,(d_1f)_{(x_0,y_0)}(u)+(d_2f)_{(x_0,y_0)}(v) \big),
    \end{equation}
    mais comme par hypothèse \( (d_2f)_{(x_0,y_0)}\colon F\to G\) est un isomorphisme, l'application \( d\Phi_{(x_0,y_0)}\colon E\times F\to E\times G\) est également un isomorphisme. Par conséquent le théorème d'inversion locale \ref{ThoXWpzqCn} nous indique qu'il existe un voisinage \( \mO\) de \( (x_0,y_0)\) et \( \mP\) de \( \Phi(x_0,y_0)\) tels que \( \Phi\colon \mO\to \mP\) soit une bijection et \( \Phi^{-1}\colon \mP\to \mO\) soit de classe \( C^r\). Vu que \( \mP\) est un voisinage de
    \begin{equation}
        \Phi(x_0,y_0)=\big( x_0,f(x_0,y_0) \big),
    \end{equation}
    nous pouvons par \ref{PropDXR_KbaLC} le choisir un peu plus petit de telle sorte à avoir \( \mP=U_0\times W_0\) où \( U_0\) est un voisinage de \( x_0\) et \( W_0\) un voisinage de \( f(x_0,y_0)\). Dans ce cas nous devons obligatoirement aussi restreindre \( \mO\) à \( U_0\times V_0\) pour un certain voisinage \( V_0\) de \( y_0\). L'application \( \Phi^{-1}\) a obligatoirement la forme
    \begin{equation}    \label{EqMHT_QrHRn}
        \begin{aligned}
            \Phi^{-1}\colon U_0\times W_0&\to U_0\times V_0 \\
            (x,w)&\mapsto \big( x,g(x,w) \big) 
        \end{aligned}
    \end{equation}
    pour une certaine fonction \( g\colon U_0\times W_0\to V\). Cette fonction \( g\) est la fonction cherchée parce qu'en appliquant \( \Phi\) à \eqref{EqMHT_QrHRn}, 
    \begin{equation}
        (x,w)=\Phi\big( x,g(x,w) \big)=\Big( x,f\big( x,g(x,w) \big) \Big),
    \end{equation}
    qui nous dit que pour tout \( x\in U_0\) et tout \( w\in W_0\) nous avons
    \begin{equation}
        f\big( x,g(x,w) \big)=w.
    \end{equation}

    Si vous avez bien suivi le sens de l'équation \eqref{EqMHT_QrHRn} alors vous avez compris l'unicité. Sinon, considérez \( (x,y)\in U_0\times V_0\) et \( w\in W_0\) tels que \( f(x,y)=w\). Alors \( \big( x,f(x,y) \big)=(x,w)\) et 
    \begin{equation}
        \Phi(x,y)=(x,w).
    \end{equation}
    Mais vu que \( \Phi\colon U_0\times V_0\to U_0\times W_0\) est une bijection, cette relation définit de façon univoque l'élément \( (x,y)\) de \( U_0\times V_0\), qui ne sera autre que \( g(x,w)\).
\end{proof}

Le théorème de la fonction implicite s'énonce de la façon suivante pour des espaces de dimension finie.
% Attention : avant de citer ce théorème, voir si il est suffisant. Ici \varphi a une variable; dans l'autre énoncé il en a deux.
\begin{theorem}[Théorème de la fonction implicite en dimension finie]   \label{ThoRYN_jvZrZ}
    Soit une fonction \( F\colon \eR^n\times \eR^m\to \eR^m\) de classe \( C^k\) et \( (\alpha,\beta)\in \eR^n\times \eR^m\) tels que
    \begin{enumerate}
        \item
            \( F(\alpha,\beta)=0\),
        \item
            \( \frac{ \partial (F_1,\ldots, F_m) }{ \partial (y_1,\ldots, y_m) }\neq 0\), c'est à dire que \( (d_yF)_{(\alpha,\beta)} \) est inversible.
    \end{enumerate}
    Alors il existe un voisinage ouvert \( V\) de \( \alpha\) dans \( \eR^n\), un voisinage ouvert \( W\) de \( \beta\) dans \( \eR^m\) et une application \( \varphi\colon V\to W\) de classe \( C^k\)  telle que pour tout \( x\in V\) on ait
    \begin{equation}
        F\big( x,\varphi(x) \big)=0.
    \end{equation}
    De plus si \( (x,y)\in V\times W\) satisfait à \( F(x,y)=0\), alors \( y=\varphi(x)\).
\end{theorem}
\index{théorème!fonction implicite dans \( \eR^n\)}

\begin{remark}\label{RemPYA_pkTEx}
    Notons que cet énoncé est tourné un peu différemment en ce qui concerne le nombre de variables dont dépend la fonction implicite : comparez
    \begin{subequations}
        \begin{align}
            f\big( x,g(x,w) \big)=w\\
            F\big( x,\varphi(x) \big)=0.
        \end{align}
    \end{subequations}
    Le deuxième est un cas particulier du premier en posant 
    \begin{equation}
        F(x,y)=f(x,y)-f(x_0,y_0)
    \end{equation}
    et donc en considérant \( w\) comme valant la constante \( f(x_0,y_0)\); dans ce cas la fonction \( g\) ne dépend plus que de la variable \( x\).

\end{remark}

\begin{example}
    La remarque \ref{RemPYA_pkTEx} signifie entre autres que le théorème \ref{ThoAcaWho} est plus fort que \ref{ThoRYN_jvZrZ} parce que le premier permet de choisir la valeur d'arrivée. Parlons de l'exemple classique du cercle et de la fonction \( f(x,y)=x^2+y^2\). Nous savons que
    \begin{equation}
        f(\alpha,\beta)=1.
    \end{equation}
    Alors le théorème \ref{ThoAcaWho} nous donne une fonction \( g\) telle que
    \begin{equation}
        f(x,g(x,r))=r
    \end{equation}
    tant que \( x\) est proche de \( \alpha\), que \( r\) est proche de \( 1\) et que \( g\) donne des valeurs proches de \( \beta\).

    L'énoncé \ref{ThoRYN_jvZrZ} nous oblige à travailler avec la fonction \( F(x,y)=x^2+y^2-1\), de telle sorte que
    \begin{equation}
        F(\alpha,\beta)=0,
    \end{equation}
    et que nous ayons une fonction \( \varphi\) telle que
    \begin{equation}
        F(x,\varphi(x))=0.
    \end{equation}
    La fonction \( \varphi\) ne permet donc que de trouver des points sur le cercle de rayon \( 1\).
\end{example}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Exemple}
%---------------------------------------------------------------------------------------------------------------------------
	
Le théorème de la fonction implicite a pour objet de donner l'existence de la fonction $\varphi$. Maintenant nous pouvons dire beaucoup de choses sur les dérivées de $\varphi$ en considérant la fonction
\begin{equation}
	x\mapsto F\big( x,\varphi(x) \big).
\end{equation}
Par définition de $\varphi$, cette fonction est toujours nulle. En particulier, nous pouvons dériver l'équation
\begin{equation}
	F\big( x,\varphi(x) \big)=0,
\end{equation}
et nous trouvons plein de choses.


Prenons par exemple la fonction
\begin{equation}
	F\big( (x,y),z \big)=ze^z-x-y,
\end{equation}
et demandons nous ce que nous pouvons dire sur la fonction $z(x,y)$ telle que
\begin{equation}
	F\big( x,y,z(x,y) \big)=0,
\end{equation}
c'est à dire telle que
\begin{equation}		\label{EqDefZImplExemple}
	z(x,y) e^{z(x,y)}-x-y=0.
\end{equation}
pour tout $x$ et $y\in\eR$. Nous pouvons facilement trouver $z(0,0)$ parce que
\begin{equation}
	z(0,0) e^{z(0,0)}=0,
\end{equation}
donc $z(0,0)=0$.

Nous pouvons dire des choses sur les dérivées de $z(x,y)$. Voyons par exemple $(\partial_xz)(x,y)$. Pour trouver cette dérivée, nous dérivons la relation \eqref{EqDefZImplExemple} par rapport à $x$. Ce que nous trouvons est
\begin{equation}
	(\partial_xz)e^z+ze^z(\partial_xz)-1=0.
\end{equation}
Cette équation peut être résolue par rapport à $\partial_xz$~:
\begin{equation}
	\frac{ \partial z }{ \partial x }(x,y)=\frac{1}{ e^z(1+z) }.
\end{equation}
Remarquez que cette équation ne donne pas tout à fait la dérivée de $z$ en fonction de $x$ et $y$, parce que $z$ apparaît dans l'expression, alors que $z$ est justement la fonction inconnue. En général, c'est la vie, nous ne pouvons pas faire mieux.

Dans certains cas, on peut aller plus loin. Par exemple, nous pouvons calculer cette dérivée au point $(x,y)=(0,0)$ parce que $z(0,0)$ est connu :
\begin{equation}
	\frac{ \partial z }{ \partial x }(0,0)=1.
\end{equation}
Cela est pratique pour calculer, par exemple, le développement en Taylor de $z$ autour de $(0,0)$.

\begin{example}
    Est-ce que l'équation \( e^{y}+xy=0\) définit au moins localement une fonction \( y(x)\) ? Nous considérons la fonction
    \begin{equation}
        f(x,y)=\begin{pmatrix}
            x    \\ 
            e^{y}+xy    
        \end{pmatrix}
    \end{equation}
    La différentielle de cette application est
    \begin{equation}
            df_{(0,0)}(u)=\frac{ d }{ dt }\Big[ f(tu_1,tu_2) \Big]_{t=0}
            =\frac{ d }{ dt }\begin{pmatrix}
                tu_1    \\ 
                e^{tu_2}+t^2u_1u_2    
            \end{pmatrix}_{t=0}
            =\begin{pmatrix}
                u_1    \\ 
                u_2    
            \end{pmatrix}.
    \end{equation}
    L'application \( f\) définit donc un difféomorphisme local autour des points \( (x_0,y_0)\) et \( f(x_0,y_0)\). Soit \( (u,0)\) un point dans le voisinage de \( f(x_0,y_0)\). Alors il existe un unique \( (x,y)\) tel que
    \begin{equation}
        f(x,y)=\begin{pmatrix}
               x \\ 
            e^y+xy    
        \end{pmatrix}=
        \begin{pmatrix}
            u    \\ 
                0
        \end{pmatrix}.
    \end{equation}
    Nous avons automatiquement \( x=u\) et \( e^y+xy=0\). Notons toutefois que pour que ce procédé donne effectivement une fonction implicite \( y(x)\) nous devons avoir des points de la forme \( (u,0)\) dans le voisinage de \( f(x_0,y_0)\).
\end{example}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Théorème de Von Neumann}
%---------------------------------------------------------------------------------------------------------------------------

\begin{lemma}[\cite{KXjFWKA}]
    Soit \( G\), un sous groupe fermé de \( \GL(n,\eR)\) et 
    \begin{equation}
        \mL_G=\{ m\in \eM(n,\eR)\tq  e^{tm}\in G\,\forall t\in\eR \}.
    \end{equation}
    Alors \( \mL_G\) est un sous-espace vectoriel de \( \eM(n,\eR)\).
\end{lemma}

\begin{proof}
    Si \( m\in\mL_G\), alors \( \lambda m\in\mL_G\) par construction. Le point délicat à prouver est le fait que si \( a,b\in \mL_G\), alors \( a+b\in\mL_G\). Soit \( a\in \eM(n,\eR)\); nous savons qu'il existe une fonction \( \alpha_a\colon \eR\to \eM\) telle que
    \begin{equation}
        e^{ta}=\mtu+ta+\alpha_a(t)
    \end{equation}
    et 
    \begin{equation}
        \lim_{t\to 0} \frac{ \alpha(t) }{ t }=0.
    \end{equation}
    Si \( a\) et \( b\) sont dans \( \mL_G\), alors \(  e^{ta} e^{tb}\in G\), mais il n'est pas vrai en général que cela soit égal à \(  e^{t(a+b)}\). Pour tout \( k\in \eN\) nous avons
    \begin{equation}
        e^{a/k} e^{b/k}=\left( \mtu+\frac{ a }{ k }+\alpha_a(\frac{1}{ k }) \right)\left( \mtu+\frac{ b }{ k }+\alpha_b(\frac{1}{ k }) \right)=\mtu+\frac{ a+b }{2}+\beta\left( \frac{1}{ k } \right)
    \end{equation}
   où \( \beta\colon \eR\to \eM\) est encore une fonction vérifiant \( \beta(t)/t\to 0\). Si \( k\) est assez grand, nous avons
   \begin{equation}
       \left\| \frac{ a+b }{ k }+\beta(\frac{1}{ k })  \right\|<1,
   \end{equation}
   et nous pouvons profiter du lemme \ref{LemQZIQxaB} pour écrire alors
   \begin{equation}
       \left(  e^{a/k} e^{b/k} \right)^k= e^{k\ln\big(\mtu+\frac{ a+b }{ k }+\beta(\frac{1}{ k })\big)}.
   \end{equation}
   Ce qui se trouve dans l'exponentielle est
   \begin{equation}
       k\left[ \frac{ a+b }{ k }+\alpha( \frac{1}{ k })+\sigma\left( \frac{ a+b }{ k }+\alpha(\frac{1}{ k }) \right) \right].
   \end{equation}
   Les diverses propriétés vues montrent que le tout tend vers \( a+b\) lorsque \( k\to \infty\). Par conséquent
   \begin{equation}
       \lim_{k\to \infty} \left(  e^{a/k} e^{b/k} \right)^k= e^{a+b}.
   \end{equation}
   Ce que nous avons prouvé est que pour tout \( t\), \(  e^{t(a+b)}\) est une limite d'éléments dans \( G\) et est donc dans \( G\) parce que ce dernier est fermé.
\end{proof}

Vu que \( \mL_G\) est un sous-espace vectoriel de \( \eM(n,\eR)\), nous pouvons considérer un supplémentaire \( M\).

\begin{lemma}   \label{LemHOsbREC}
    Il n'existe pas se suites \( (m_k)\) dans \( M\setminus\{ 0 \}\) convergeant vers zéro et telle que \(  e^{m_k}\in G\) pour tout \( k\).
\end{lemma}

\begin{proof}
    Supposons que nous ayons \( m_k\to 0\) dans \( M\setminus\{ 0 \}\) avec \(  e^{m_k}\in G\). Nous considérons les éléments \( \epsilon_k=\frac{ m_k }{ \| m_k \| }\) qui sont sur la sphère unité de \(\GL(n,\eR)\). Quitte à prendre une sous-suite, nous pouvons supposer que cette suite converge, et vu que \( M\) est fermé, ce sera vers \( \epsilon\in M\) avec \( \| \epsilon \|=1\). Pour tout \( t\in \eR\) nous avons
    \begin{equation}
        e^{t\epsilon}=\lim_{k\to \infty}  e^{t\epsilon_k}.
    \end{equation}
    En vertu de la décomposition d'un réel en partie entière et décimale, pour tout \( k\) nous avons \( \lambda_k\in \eZ\) et \( | \mu_k |\leq \frac{ 1 }{2}\) tel que \( t/\| m_k \|=\lambda_k+\mu_k\). Avec ça,
    \begin{equation}
        e^{t\epsilon}=\lim_{k\to \infty}\exp\Big( \frac{ t }{ m_k }m_k \Big)=\lim_{k\to \infty}  e^{\lambda_km_k} e^{\mu_km_k}.
    \end{equation}
    Pour tout \( k\) nous avons \(  e^{\lambda_km_k}\in G\). De plus \( | \mu_k |\) étant borné et \( m_k\) tendant vers zéro nous avons \(  e^{\mu_km_k}\to 1\). Au final
    \begin{equation}
        e^{t\epsilon}=\lim_{k\to \infty}  e^{t\epsilon_k}\in G
    \end{equation}
    Cela signifie que \( \epsilon\in\mL_G\), ce qui est impossible parce que nous avions déjà dit que \( \epsilon\in M\setminus\{ 0 \}\).
\end{proof}

\begin{lemma}   \label{LemGGTtxdF}
    L'application
    \begin{equation}
        \begin{aligned}
            f\colon \mL_G\times M&\to \GL(n,\eR) \\
            l,m&\mapsto  e^{l} e^{m} 
        \end{aligned}
    \end{equation}
    est un difféomorphisme local entre un voisinage de \( (0,0)\) dans \( \eM(n,\eR)\) et un voisinage de \( \mtu\) dans \( \exp\big( \eM(n,\eR) \big)\).
\end{lemma}
Notons que nous ne disons rien de \(  e^{\eM(n,\eR)}\). Nous n'allons pas nous embarquer à discuter si ce serait tout \( \GL(n,\eR)\)\footnote{Vu les dimensions y'a tout de même peu de chance.} ou bien si ça contiendrait ne fut-ce que \( G\).

\begin{proof}
    Le fait que \( f\) prenne ses valeurs dans \( \GL(n,\eR)\) est simplement dû au fait que les exponentielles sont toujours inversibles. Nous considérons ensuite la différentielle : si \( u\in \mL_G\) et \( v\in M\) nous avons
    \begin{equation}
        df_{(0,0)}(u,v)=\Dsdd{ f\big( t(u,v) \big) }{t}{0}=\Dsdd{  e^{tu} e^{tv} }{t}{0}=u+v.
    \end{equation}
    L'application \( df_0\) est donc une bijection entre \( \mL_G\times M\) et \( \eM(n,\eR)\). Le théorème d'inversion locale \ref{ThoXWpzqCn} nous assure alors que \( f\) est une bijection entre un voisinage de \( (0,0)\) dans \( \mL_G\times M\) et son image. Mais vu que \( df_0\) est une bijection avec \( \eM(n,\eR)\), l'image en question contient un ouvert autour de \( \mtu\) dans \( \exp\big( \eM(n,\eR) \big)\).
\end{proof}

\begin{theorem}[Von Neumann\cite{KXjFWKA,ISpsBzT,GpAlgLie_Faraut,Lie_groups}]       \label{ThoOBriEoe}
    Tout sous-groupe fermé de \( \GL(n,\eR)\) est une sous-variété de \( \GL(n,\eR)\).
\end{theorem}
\index{théorème!Von Neumann}
\index{exponentielle!de matrice!utilisation}

\begin{proof}
    Soit \( G\) un tel groupe; nous devons prouver que c'est localement difféomorphe à un ouvert de \( \eR^n\). Et si on est pervers, on ne va pas faire localement difféomorphe à un ouvert de \( \eR^n\), mais à un ouvert d'un espace vectoriel de dimension finie. Nous allons être pervers.

    Étant donné que pour tout \( g\in G\), l'application 
    \begin{equation}
        \begin{aligned}
            L_g\colon G&\to G \\
            h&\mapsto gh 
        \end{aligned}
    \end{equation}
    est de classe \(  C^{\infty}\) et d'inverse \(  C^{\infty}\), il suffit de prouver le résultat pour un voisinage de \( \mtu\).

    Supposons d'abord que \( \mL_G=\{ 0 \}\). Alors \( 0\) est un point isolé de \( \ln(G)\); en effet si ce n'était pas le cas nous aurions un élément \( m_k\) de \( \ln(G)\) dans chaque boule \( B(0,r_k)\). Nous aurions alors \( m_k=\ln(a_k)\) avec \( a_k\in G\) et donc
    \begin{equation}
        e^{m_k}=a_k\in G.
    \end{equation}
    De plus \( m_k\) appartient forcément à \( M\) parce que \( \mL_G\) est réduit à zéro. Cela nous donnerait une suite \( m_k\to 0\) dans \( M\) dont l'exponentielle reste dans \( G\). Or cela est interdit par le lemme \ref{LemHOsbREC}. Donc \( 0\) est un point isolé de \( \ln(G)\). L'application \(\ln\) étant continue\footnote{Par le lemme \ref{LemQZIQxaB}.}, nous en déduisons que \( \mtu\) est isolé dans \( G\). Par le difféomorphisme \( L_g\), tous les points de \( G\) sont isolés; ce groupe est donc discret et par voie de conséquence une variété.

    Nous supposons maintenant que \( \mL_G\neq\{ 0 \}\). Nous savons par la proposition \ref{PropXFfOiOb} que 
    \begin{equation}
        \exp\colon \eM(n,\eR)\to \eM(n,\eR)
    \end{equation}
    est une application \(  C^{\infty}\) vérifiant \( d\exp_0=\id\). Nous pouvons donc utiliser le théorème d'inversion locale \ref{ThoXWpzqCn} qui nous offre donc l'existence d'un voisinage \( U\) de \( 0\) dans \( \eM(n,\eR)\) tel que \( W=\exp(U)\) soit un ouvert de \( \GL(n,\eR)\) et que \( \exp\colon U\to W\) soit un difféomorphisme de classe \(  C^{\infty}\).

    Montrons que quitte à restreindre \( U\) (et donc \( W\) qui reste par définition l'image de \( U\) par \( \exp\)), nous pouvons avoir \( \exp\big( U\cap\mL_G \big)=W\cap G\). D'abord \( \exp(\mL_G)\subset G\) par construction. Nous avons donc \( \exp\big( U\cap\mL_G \big)\subset W\cap G\). Pour trouver une restriction de \( U\) pour laquelle nous avons l'égalité, nous supposons que pour tout ouvert \( \mO\) dans \( U\), 
    \begin{equation}
        \exp\colon \mO\cap\mL_G\to \exp(\mO)\cap G
    \end{equation}
    ne soit pas surjective. Cela donnerait un élément de \( \mO\cap\complement\mL_G\) dont l'image par \( \exp\) n'est pas dans \( G\). Nous construisons ainsi une suite en considérant une boule \( B(0,\frac{1}{ k })\) inclue à \( U\) et \( x_k\in B(0,\frac{1}{ k })\cap\complement\mL_G\) vérifiant \(  e^{x_k}\in G\). Vu le choix des boules nous avons évidemment \( x_k\to 0\).

    L'élément \(  e^{x_k}\) est dans \(  e^{\eM(n,\eR)}\) et le difféomorphisme du lemme \ref{LemGGTtxdF}\quext{Il me semble que l'utilisation de ce lemme manque à l'avant-dernière ligne de la preuve chez \cite{KXjFWKA}.} nous donne \( (l_k,m_k)\in \mL_G\times M\) tel que \(  e^{l_k} e^{m_k}= e^{x_k}\). À ce point nous considérons \( k\) suffisamment grand pour que \(  e^{x_k}\) soit dans la partie de l'image de \( f\) sur lequel nous avons le difféomorphisme. Plus prosaïquement, nous posons
    \begin{equation}
        (l_k,m_k)=f^{-1}( e^{x_k})
    \end{equation}
    et nous profitons de la continuité pour permuter la limite avec \( f^{-1}\) :
    \begin{equation}
        \lim_{k\to \infty} (l_k,m_k)=f^{-1}\big( \lim_{k\to \infty}  e^{x_k} \big)=f^{-1}(\mtu)=(0,0).
    \end{equation}
    En particulier \( m_k\to 0\) alors que \(  e^{m_k}= e^{x_k} e^{-l_k}\in G\). La suite \( m_k\) viole le lemme \ref{LemHOsbREC}. Nous pouvons donc restreindre \( U\) de telle façon à avoir
    \begin{equation}
        \exp\big( U\cap\mL_G \big)=W\cap G.
    \end{equation}
    Nous avons donc un ouvert de \( \mL_G\) (l'ouvert \( U\cap\mL_G\)) qui est difféomorphe avec l'ouvert \( W\cap G\) de \( G\). Donc \( G\) est une variété et accepte \( \mL_G\) comme carte locale.

\end{proof}

\begin{remark}
    En termes savants, nous avons surtout montré que si \( G\) est un groupe de Lie d'algèbre de Lie \( \lG\), alors l'exponentielle donne un difféomorphisme local entre \( \lG\) et \( G\).
\end{remark}

 \section{Les nombres complexes}
 \subsection{Définitions de base}
 Un nombre complexe s'écrit sous la forme $z = a + b i$, où $a$ et $b$
 sont des nombres réels appelés (et notés) respectivement partie réelle
 ($a = \Re(z)$) et partie imaginaire ($b = \Im(z)$) de $z$. L'ensemble
 des nombres de cette forme s'appelle l'ensemble des nombres complexes
 ; cet ensemble porte une structure de corps et est noté $\eC$. Le
 nombre complexe $i = 0 + 1 i$ est un nombre imaginaire qui a la
 particularité que $i^2 = -1$.

 Deux nombres complexes $a + bi$ et $c + di$ sont égaux si et seulement
 si $a = c$ et $b = d$, c'est-à-dire leurs parties réelles sont égales,
 et leurs parties imaginaires sont égales.

 Un nombre complexe étant représenté par deux nombres, on peut le
 représenter dans un plan appelé « plan de Gauss ». La plupart des
 opérations sur les nombres complexes ont leur interprétation
 géométrique dans ce plan.

 Pour $z = a + bi$ un nombre complexe, on note $\bar z = a - bi$ le
 \Defn{complexe conjugué} de $z$. Dans le plan de Gauss, il s'agit du
 symétrique de $z$ par rapport à la droite réelle (généralement
 dessinée horizontalement).

 On définit le module du complexe $z$ par $\module z = \sqrt{z\bar z} =
 \sqrt{a^2 + b^2}$. Dans le plan de Gauss, il s'agit de la distance
 entre $0$ et $z$.

 \begin{proposition}
Pour tout $z = a+bi$ et $z^\prime$ nombres complexes, on a
   \begin{enumerate}
   \item $z \bar z = a^2 + b^2$;
   \item $\bar{\bar{z}} = z$;
   \item $\module z = \module {\bar z}$;
   \item $\module{zz^\prime} = \module z \module{z^\prime}$;
   \item $\module{z+z^\prime} \leq \module z + \module{z^\prime}$.
   \end{enumerate}
 \end{proposition}

 \subsection{Forme polaire ou trigonométrique}
 Dans le plan de Gauss, le module d'un complexe $z$ représente la
 distance entre $0$ et $z$. On appelle \Defn{argument} de $z$ (noté
 $\arg z$) l'angle (déterminé à $2\pi$ près) entre le demi-axe des
 réels positifs et la demi-droite qui part de $0$ et passe par $z$. Le
 module et l'argument d'un complexe permettent de déterminer
 univoquement ce complexe puisqu'on a la formule
 \[z = a + bi = \module z \left( \cos(\arg(z)) + i \sin(\arg(z))
 \right)\]

 L'argument de $z$ se détermine via les formules
 \[\frac a {\module z} = \cos(\arg(z)) \quad \frac b {\module z} =
 \sin(\arg(z))\] ou encore par la formule
 \[\frac b a = \tan(\arg(z)) \quad \text{en vérifiant le
   quadrant.}\]%
 La vérification du quadrant vient de ce que la tangente ne détermine
 l'angle qu'à $\pi$ près.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
                    \section{Maximisation sans contraintes}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
                    \subsection{Maximisation à une variable}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}
Soit $f\colon A\subset \eR\to \eR$ et $a\in A$. Le point $a$ est un \defe{maximum local}{maximum!local} de $f$ si il existe un voisinage $\mU$ de $a$ tel que $f(a)\geq f(x)$ pour tout $x\in\mU\cap A$. Le point $a$ est un \defe{maximum global}{maximum!global} si $f(a)\geq g(x)$ pour tout $x\in A$.
\end{definition}

La proposition basique à utiliser lors de la recherche d'extrema est la suivante :
\begin{proposition}
Soit $f\colon A\subset\eR\to \eR$ et $a\in\Int(A)$. Supposons que $f$ est dérivable en $a$. Si $a$ est un \href{http://fr.wikipedia.org/wiki/Extremum}{extremum} local, alors $f'(a)=0$.
\end{proposition}

La réciproque n'est pas vraie, comme le montre l'exemple de la fonction $x\mapsto x^3$ en $x=0$ : sa dérivée est nulle et pourtant $x=0$ n'est ni un maximum ni un minimum local. 

Cette proposition ne sert donc qu'à sélectionner des \emph{candidats} extremum. Afin de savoir si ces candidats sont des extrema, il y a la proposition suivante.
\begin{proposition}
Soit $f\colon I\subset \eR\to \eR$, une fonction de classe $C^k$ au voisinage d'un point $a\in\Int I$. Supposons que
\begin{equation}
    f'(a)=f''(a)=\ldots=f^{(k-1)}(a)=0,
\end{equation}
et que
\begin{equation}
    f^{(k)}(a)\neq 0.
\end{equation}
Dans ce cas,
\begin{enumerate}

\item
Si $k$ est pair, alors $a$ est un point d'extremum local de $f$, c'est un minimum si $f^{(k)}(a)>0$, et un maximum si $f^{(k)}(a)<0$,
\item
Si $k$ est impair, alors $a$ n'est pas un extremum local de $f$.

\end{enumerate}
\end{proposition}

Note : jusqu'à présent nous n'avons rien dit des extrema \emph{globaux} de $f$. Il n'y a pas grand chose à en dire. Si un point d'extremum global est situé dans l'intérieur du domaine de $f$, alors il sera extremum local (a fortiori). Ou alors, le maximum global peut être sur le bord du domaine. C'est ce qui arrive à des fonctions strictement croissantes sur un domaine compact.

Une seule certitude : si une fonction est continue sur un compact, elle possède une minimum et un maximum global.
 
%---------------------------------------------------------------------------------------------------------------------------
                    \subsection{Les théorèmes}
%---------------------------------------------------------------------------------------------------------------------------

Un point $a$ à l'intérieur du domaine d'une fonction $f\colon A\subset\eR^n\to \eR$ est un \defe{point critique}{critique!point} de $f$ lorsque $df(a)=0$. Ces points sont analogues aux points où la dérivée d'une fonction sur $\eR$ s'annule. Les points critiques de $f$ sont dons les candidats à être des points d'extremum.

Pour rappel, dans le cas d'une fonction à deux variables, $d^2f(a)$ est la matrice (et donc l'application linéaire)
\begin{equation}
    d^2f(a)=\begin{pmatrix}
    \frac{ d^2f  }{ dx^2 }(a)   &   \frac{ d^2f  }{ dx\,dy }(a) \\ 
    \frac{ d^2f  }{ dy\,dx }(a)     &   \frac{ d^2f  }{ dy^2 }(a)
\end{pmatrix}.
\end{equation}
Dans le cas d'une fonction $C^2$, cette matrice est symétrique.

\begin{proposition}     \label{PropoExtreRn}
    Soit $f\colon A\subset\eR^n\to \eR$ une fonction de classe $C^2$ au voisinage de $a\in\Int(A)$.
    \begin{enumerate}
        \item
            Si $a$ est un point critique de $f$, et si $d^2f(a)$ est \href{http://fr.wikipedia.org/wiki/Matrice_définie_positive}{définie positive}, alors $a$ est un minimum local strict de $f$,
        \item\label{ItemPropoExtreRn}
            Si $a$ est un minimum local, alors $a$ est un point critique et $d^2f(a)$ est définie positive.
    \end{enumerate}
\end{proposition}
\index{fonction!différentiable}
\index{extrema}
La seconde partie de l'énoncé est tout à fait comparable au fait bien connu que, pour une fonction $f\colon \eR\to \eR$, si le point $a$ est minimum local, alors $f'(a)=0$ et $f''(a)>0$.

La méthode pour chercher les extrema de $f$ est donc de suivre le points suivants :
\begin{enumerate}
    \item
        Trouver les candidats extrema en résolvant $\nabla f=(0,0)$,
    \item
        écrire $d^2f(a)$ pour chacun des candidats
    \item
        calculer les valeurs propres de $d^2f(a)$, déterminer si la matrice est définie positive ou négative,
    \item
        conclure.
\end{enumerate}

Une conséquence du point \ref{ItemluuFPN} de la proposition \ref{PropcnJyXZ}\footnote{La matrice $d^2f(a)$ est toujours symétrique quand $f$ est de classe $C^2$.} est que si \( \det M<0\), alors le point \( a\) n'est pas  un extrema dans le cas où $M=d^2f(a)$ par le point \ref{ItemPropoExtreRn} de la proposition \ref{PropoExtreRn}.

\begin{example}
    Soit la fonction \( f(x,y)=x^4+y^4-4xy\). C'est une fonction différentiable sans problèmes. D'abord sa différentielle est
    \begin{equation}
        df=|big(4x^3-4y;4y^3-4x),
    \end{equation}
    et la matrice des dérivées secondes est
    \begin{equation}
        M=d^2f(x,y)=\begin{pmatrix}
            12x^2    &   -4    \\ 
            -4    &   12y^2    
        \end{pmatrix}.
    \end{equation}
    Nous avons \( fd=0\) pour les trois points \( (0,0)\), \( (1,1)\) et \( -1,-1\).

    Pour le point \( (0,0)\) nous avons
    \begin{equation}
        M=\begin{pmatrix}
            0    &   -4    \\ 
            -4    &   0    
        \end{pmatrix},
    \end{equation}
    dont les valeurs propres sont \( 4\) et \( -4\). Elle n'est donc semi-définie ou définie rien du tout. Donc \( (0,0)\) n'est pas un extremum local.

    Au contraire pour les points \( (1,1)\) et \( (-1,-1)\) nous avons
    \begin{equation}
        M=\begin{pmatrix}
            12    &   -4    \\ 
            -4    &   12    
        \end{pmatrix},
    \end{equation}
    dont les valeurs propres sont \( 16\) et \( 8\). La matrice \( d^2f\) y est donc définie positive. Ces deux points sont donc extrema locaux.
\end{example}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Extrema liés}
%---------------------------------------------------------------------------------------------------------------------------

Soit $f$, une fonction sur $\eR^n$, et $M\subset \eR^n$ une variété de dimension $m$. Nous voulons savoir quelle sont les plus grandes et plus petites valeurs atteintes par $f$ sur $M$.

Pour ce faire, nous avons un théorème qui permet de trouver des extrema \emph{locaux} de $f$ sur la variété. Pour rappel, $a\in M$ est une \defe{extrema local de $f$ relativement}{extrema!local!relatif} à l'ensemble $M$ si il existe une boule $B(a,\epsilon)$ telle que $f(a)\leq f(x)$ pour tout $x\in B(a,\epsilon)\cap M$.

\begin{theorem}[Extrema lié \cite{ytMOpe}] \label{ThoRGJosS}
	Soit \( A\), un ouvert de \( \eR^n\) et
	\begin{enumerate}
		\item
			une fonction (celle à minimiser) $f\in C^1(A,\eR)$,
		\item 
			des fonctions (les contraintes) $G_1,\ldots,G_r\in C^1(A,\eR)$,
		\item
			$M=\{ x\in A\tq G_i(x)=0\,\forall i\}$,
		\item
			un extrema local $a\in M$ de $f$ relativement à $M$.
	\end{enumerate}
	Supposons que les gradients $\nabla G_1(a)$, \ldots,$\nabla G_r(a)$ soient linéairement indépendants. Alors $a=(x_1,\ldots,x_n)$ est une solution de \( \nabla L(a)=0\) où
	\begin{equation}
		L(x_1,\ldots,x_n,\lambda_1,\ldots,\lambda_r)=f(x_1,\ldots,x_n)+\sum_{i=1}^r\lambda_iG_i(x_1,\ldots,x_n).
	\end{equation}
    Autrement dit, si \( a\) est un extrema lié, alors \( \nabla f(a)\) est une combinaisons des \( \nabla G_i(a)\), ou encore il existe des \( \lambda_i\) tels que
    \begin{equation}    \label{EqRDsSXyZ}
        df(a)=\sum_i\lambda_idG_i(a).
    \end{equation}
\end{theorem}
\index{théorème!inversion locale!utilisation}
\index{extrema!lié}
\index{théorème!extrema!lié}
\index{application!différentiable!extrema lié}
\index{variété}
\index{rang!différentielle}
\index{forme!linéaire!différentielle}
La fonction $L$ est le \defe{lagrangien}{lagrangien} du problème et les variables \( \lambda_i\) sont les \defe{multiplicateurs de Lagrange}{multiplicateur!de Lagrange}\index{Lagrange!multiplicateur}.

\begin{proof}
    Si \( r=n\) alors les vecteurs linéairement indépendantes \( \nabla G_i(a) \) forment une base de \( \eR^n\) et donc évidemment les \( \lambda_i\) existent. Nous supposons donc maintenant que \( r<n\). Nous notons \( (z_i)_{i=1\ldots n}\) les coordonnées sur \( \eR^n\).
    
    La matrice
    \begin{equation}
        \begin{pmatrix}
            \frac{ \partial G_1 }{ \partial z_1 }(a)    &   \cdots    &   \frac{ \partial G_1 }{ \partial z_n }(a)    \\
            \vdots    &   \ddots    &   \vdots    \\
            \frac{ \partial G_r }{ \partial z_1 }(a)    &   \cdots    &   \frac{ \partial G_r }{ \partial z_n }(a)
        \end{pmatrix}
    \end{equation}
    est de rang \( r\) parce que les lignes sont par hypothèses linéairement indépendantes. Nous nommons \( (y_i)_{i=1,\ldots, r}\) un choix de \( r\) parmi les \( (z_i)\) tels que
    \begin{equation}
        \det\begin{pmatrix}
            \frac{ \partial G_1 }{ \partial y_1 }    &   \ldots    &   \frac{ \partial G_1 }{ \partial y_r }    \\
            \vdots    &   \ddots    &   \vdots    \\
            \frac{ \partial G_r }{ \partial y_1 }    &   \ldots    &   \frac{ \partial G_r }{ \partial y_r }
        \end{pmatrix}\neq 0.
    \end{equation}
    Nous identifions \( \eR^n\) à \( \eR^s\times \eR^r\) dans lequel \( \eR^r\) est la partie générée par les \( (y_i)_{i=1,\ldots, r}\). Nous nommons \( (x_j)_{j=1,\ldots, s}\) les coordonnées sur \( \eR^s\). Autrement dit, les coordonnées sur \( \eR^n\) sont \( x_1,\ldots, x_s,y_1,\ldots, y_r\). Dans ces coordonnées, nous nommons \( a=(\alpha,\beta)\) avec \( \alpha\in \eR^s\) et \( \beta\in \eR^r\).

    Si nous notons \( G=(G_1,\ldots, G_r)\), le théorème de la fonction implicite (théorème \ref{ThoAcaWho})  nous dit qu'il existe un voisinage \( U'\) de \( \alpha\in \eR^n\), un voisinage \( V'\) de \( \beta\in \eR^r\) et une fonction \( \varphi\colon U'\to V'\) de classe \( C^1\) telle que si \( (x,y)\in U'\times V'\), alors
    \begin{equation}
        g(x,y)=0
    \end{equation}
    si et seulement si \( y=\varphi(x)\). Nous posons maintenant
    \begin{subequations}
        \begin{align}
            \psi(x)&=(x,\varphi(x))\\
            h(x)&=f\big( \psi(x) \big).
        \end{align}
    \end{subequations}
    Nous avons \( \psi(\alpha)=a\) et \( \psi(x)\in M\) pour tout \( x\in U'\). La fonction \( h\) a donc un extrema local en \( \alpha\) et donc les dérivées partielles de \( h\) y sont nulles. Cela signifie que
    \begin{equation}
        0=\frac{ \partial h }{ \partial x_i }(\alpha)=\sum_{j=1}^n\frac{ \partial f }{ \partial x_j }\frac{ \partial x_j }{ \partial x_i }+\sum_{k=1}^r\frac{ \partial f }{ \partial y_k }\frac{ \partial \varphi_k }{ \partial x_i },
    \end{equation}
    c'est à dire
    \begin{equation}
        \frac{ \partial f }{ \partial x_i }(\alpha)+\sum_{k=1}^r\frac{ \partial f }{ \partial y_k }(a)\frac{ \partial \varphi_k }{ \partial x_i }(\alpha)=0
    \end{equation}
    pour tout \( i=1,\ldots, s\). D'autre part pour tout $k$, la fonction \( l_k(x)=G_k\big( x,\varphi(x) \big)\) est constante et vaut zéro; ses dérivées partielles sont donc nulles :
    \begin{equation}
        \frac{ \partial l }{ \partial x_i }(\alpha)=\frac{ \partial G_k }{ \partial x_i }(\alpha)+\sum_{k=1}^r\frac{ \partial G_k }{ \partial y_k }(a)\frac{ \partial \varphi_k }{ \partial x_i }(\alpha)=0
    \end{equation}
    pour tout \( i=1,\ldots, s\) et \( k=1,\ldots, r\).
    
    Les \( s\) premières colonnes de la matrice
    \begin{equation}
        \begin{pmatrix}
            \frac{ \partial f }{ \partial x_1 }   &   \cdots    &   \frac{ \partial f }{ \partial x_s }    &   \frac{ \partial f }{ \partial y_1 }    &   \cdots    &   \frac{ \partial f }{ \partial y_r }\\  
            \frac{ \partial G_1 }{ \partial x_1 }    &   \cdots    &   \frac{ \partial G_1 }{ \partial x_s }    &   \frac{ \partial G_1 }{ \partial y_1 }    &   \cdots    &   \frac{ \partial G_1 }{ \partial y_r }\\
            \vdots    &   \vdots    &   \vdots    &   \vdots    &   \vdots    &   \vdots\\
            \frac{ \partial G_r }{ \partial x_1 }    &   \cdots    &   \frac{ \partial G_r }{ \partial x_s }    &   \frac{ \partial G_r }{ \partial y_1 }    &  \cdots   & \frac{ \partial G_r }{ \partial y_r }  
        \end{pmatrix}
    \end{equation}
    s'expriment en terme des \( r\) dernières. La matrice est donc au maximum de rang \( r\). Notons que la première ligne est \( \nabla f\) et les \( r\) suivantes sont les \( \nabla G_i\). Vu que ces lignes sont des vecteurs liés, il existe \( \mu_0,\ldots, \mu_r\) tels que
    \begin{equation}
        \mu_0\nabla f+\sum_{i=1}^r\mu_i\nabla G_i=0.
    \end{equation}
    Par hypothèse les \( \nabla G_i\) sont linéairement indépendants, ce qui nous dit que \( \mu_0\neq 0\). Donc nous avons ce qu'il nous faut :
    \begin{equation}
        \nabla f(a)=\sum_i\frac{ \mu_i }{ \mu_0 } \nabla G_i(a).
    \end{equation}

    Notons qu'au vu de l'expression \eqref{EqRDsSXyZ}, le fait que les formes \( \{ dG_i(a) \}_{1\leq i\leq r}\) forment une partie libre dans \( (\eR^n)^*\) implique que les \( \lambda_i\) sont uniques.
\end{proof}

La proposition suivante est la même que \ref{ThoRGJosS}.
\begin{proposition} \label{PropfPPUxh}
    Soit \( U\), un ouvert de \( \eR^n\) et des fonctions de classe \( C^1\) \( f,g_1,\ldots, g_r\colon U\to \eR\). Nous considérons
    \begin{equation}
        \Gamma=\{ x\in U\tq g_1(x)=\ldots=g_r(x)=0 \}.
    \end{equation}
    Soit \( a\) un extrémum de \( f|_{\Gamma}\). Supposons que les formes \( dg_1,\ldots, dg_r\) soient linéairement indépendantes en \( a\). Alors il existe \( \lambda_1,\ldots, \lambda_r\) dans \( \eR\) tel que
    \begin{equation}
        df_a=\sum_{i=1}^r\lambda_i(dg_i)_a.
    \end{equation}
\end{proposition}

En pratique les candidats extrema locaux sont tous les points où les gradients ne sont pas linéairement indépendants, plus tous les points donnés par l'équation $\nabla L=0$. Parmi ces candidats, il faut trouver lesquels sont maxima ou minima, locaux ou globaux.

L'existence d'extrema locaux se prouve généralement en invoquant de la compacité, et en invoquant le lemme suivant qui permet de réduire le problème à un compact.

\begin{lemma}		\label{LemmeMinSCimpliqueS}
	Soit $S$, un ensemble dans $\eR^n$ et $C$, un ouvert de $\eR^n$. Si $a\in\Int S$ est un minimum local relatif à $S\cap C$, alors il est un minimum local par rapport à $S$.
\end{lemma}

\begin{proof}
	Nous avons que $\forall x\in B(a,\epsilon_1)\cap S\cap C$, $f(x)\geq f(x)$. Mais étant donné que $C$ est ouvert, et que $a\in C$, il existe un $\epsilon_2$ tel que $B(a,\epsilon_2)\subset C$. En prenant $\epsilon=\min\{ \epsilon_1,\epsilon_2 \}$, nous trouvons que $f(x)\geq f(a)$ pour tout $x\in B(a,\epsilon)\cap(S\cap C)=B(a,\epsilon)\cap S$.
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Formes quadratiques, signature, et lemme de Morse}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Soit \( (E,\| . \|_E)\) un espace vectoriel réel normé de dimension finie \( n\). L'ensemble des formes quadratiques réelles sur \( E\) est vu comme l'ensemble des matrices symétriques \( S_n(\eR)\); il sera noté \( Q(E)\) et le sous-ensemble des formes quadratiques non dégénérées est \( S_n(\eR)\cap\GL(n,\eR)\) qui sera noté \( \Omega(E)\). Nous rappelons que la correspondance est donnée de la façon suivante. Si \( A\in S_n(\eR)\), la forme quadratique associée est \( q_A\) donnée par \( q_A(x)=x^tAx\).

Sur \( Q(E)\) nous mettons la norme
\begin{equation}
    N(q)=\sup_{\| x \|_E=1}| q(x) |,
\end{equation}
qui du point de vue de \( S_n(\eR)\) est
\begin{equation}    \label{EqDOgBNAg}
    N(A)=\sup_{\| x \|_E=1}| x^tAx |.
\end{equation}
Notons que à droite, c'est la valeur absolue usuelle sur \( \eR\).

Nous savons par le théorème de Sylvester (théorème \ref{ThoQFVsBCk}) que dans \( \eM(n,\eR)\), toute matrice symétrique de signature \( (p,q)\) est semblable à la matrice
\begin{equation}
    \mtu_{p,q}=\begin{pmatrix}
        \mtu_p    &       &       \\
        &   \mtu_{p}    &       \\
        &       &   0_{n-p-q}
    \end{pmatrix}.
\end{equation}
Donc deux matrices de \( S_n\) sont semblables si et seulement si elles ont la même signature (même si elles ne sont pas de rang maximum, cela soit dit au passage). Si nous notons \( S_n^{p,q}(\eR)\) l'ensemble des matrices réelles symétriques de signature \( (p,q)\), alors
\begin{equation}
    S_n^{p,q}(\eR)=\{ P^tAP\tq P\in \GL(n,\eR) \}
\end{equation}
où \( A\) est une quelconque ce ces matrices.

Nous voudrions en savoir plus sur ces ensembles. En particulier nous aimerions savoir si la signature est une notion «stable» au sens où ces ensembles seraient ouverts dans \( S_n\). Pour cela nous considérons l'action de \( \GL(n,\eR)\) sur \( S_n\) définie par
\begin{equation}
    \begin{aligned}
        \alpha\colon \GL(n,\eR)\times S_n(\eR)&\to S_n(\eR) \\
        (P,A)&\mapsto P^tAP 
    \end{aligned}
\end{equation}
faite exprès pour que les orbites de cette action soient les ensembles \( S_n^{p,q}(\eR)\).

La proposition suivante montre que lorsque \( p+q=n\), c'est à dire lorsqu'on parle de matrices de rang maximum, les ensembles \( S_n^{p,q}(\eR)\) sont ouverts, c'est à dire que la signature d'une forme quadratique est une propriété «stable» par petite variations des éléments de matrice. Notons tout de suite que si le rang n'est pas maximum, le théorème de Sylvester dit qu'elle est semblable à une matrice diagonale avec des zéros sur la diagonale; en modifiant un peu ces zéros, on peut modifier évidemment la signature.
\begin{proposition}[\cite{KXjFWKA}] \label{PropNPbnsMd}
    Soit \( (E,\| . \|_{E})\) un espace vectoriel normé de dimension finie. Alors
    \begin{enumerate}
        \item
            les formes quadratiques non dégénérées forment un ouvert dans l'ensemble des formes quadratiques,
        \item
            les ensembles \( S_n^{p,q}(\eR)\) avec \( p+q=n\) sont ouverts dans \( S_n(\eR)\),
        \item   \label{ItemGOhRIiViii}
            les composantes connexes de \( \Omega(E)\) sont les \( S_n^{p,q}(\eR)\) avec \( p+q=n\),
        \item   \label{ItemGOhRIiViv}
            les \( S_n^{p,q}(\eR)\) non dégénérés sont connexes par arc.
    \end{enumerate}
\end{proposition}
\index{connexité!signature d'une forme quadratique}
\index{matrice!symétrique!réelle}
\index{forme!quadratique}

\begin{proof}
    Cette preuve est donnée du point de vue des matrices. La différence entre le point \ref{ItemGOhRIiViii} et \ref{ItemGOhRIiViv} est que dans le premier nous prouvons la connexité de \( S_n^{p,q}(\eR)\) à partir de la connexité de \( \GL^+(n,\eR)\), tandis que dans le second nous prouvons la connexité par arc de \( S_n^{p,q}(\eR)\) à partir de la connexité par arc de \( \GL^+(n,\eR)\). Bien entendu le second implique le premier.
    \begin{enumerate}
        \item
            Il s'agit simplement de remarquer que \( Q(E)=S_n(\eR)\), que \( \Omega(E)=S_n(\eR)\cap\GL(n,\eR)\) et que le déterminant est une fonction continue sur \( \eM(n,\eR)\).
        \item
            Soit \( A_0\in S_n^{p,q}(\eR)\). Le théorème de Sylvester \ref{ThoQFVsBCk} nous donne une matrice inversible \( P\) telle que \( P^tA_0P=\mtu_{p,q}\). Nous allons montrer qu'il existe un voisinage \( \mU\) de \( \mtu_{p,q}\) contenu dans \( S_n^{p,q}(\eR)\). À partir de là, l'ensemble \( (P^{-1})^t\mU P^{-1}\) sera un voisinage de \( A_0\) contenu dans \( S_n^{p,q}(\eR)\).

            Nous considérons les espaces vectoriels
            \begin{subequations}
                \begin{align}
                    F&=\Span\{ e_1,\ldots, e_p \}\\
                    G&=\Span\{ e_{p+1},\ldots, e_n \}
                \end{align}
            \end{subequations}
            La norme euclidienne \( \| . \|_p\) sur \( F\) est équivalente à la norme \( | . |_E\) par le théorème \ref{ThoNormesEquiv}. Donc il existe une constante \( k_1>0\) telle que pour tout \( x\in F\),
            \begin{equation}    \label{EqMViCjJJ}
                \| x \|_p\geq k_1\| x \|_E.
            \end{equation}
            De la même façon sur \( G\), il existe une constante \( k_2>0\) telle que
            \begin{equation}    \label{EqSFwOcDw}
                \| x \|_q\geq k_2\| x \|_E.
            \end{equation}
            Si nous posons \( k=\min\{ k_1^2,k_2^2 \}\), alors nous avons
            \begin{subequations}
                \begin{align}
                    \forall x\in F,\quad &\| x \|_p^2\geq k_1^2\| x \|_E^2\geq k\| x \|_E^2\\
                    \forall x\in G,\quad &\| x \|_q^2\geq k_2^2\| x \|_E^2\geq k\| x \|_E^2.
                \end{align}
            \end{subequations}
            
            Soit une matrice \( A\in S_n(\eR)\) telle que \( N(A-\mtu_{p,q})<k\), c'est à dire que \( A\) est dans un voisinage de \( \mtu_{p,q}\) pour la norme sur \( S_n(\eR)\) donné par \eqref{EqDOgBNAg}. Si \( x\) est non nul dans \( E\), nous avons
            \begin{equation}
                \big| x^t(A-\mtu_{p,q})x \big|\leq N(\mtu_{p,q}-A)\| x \|^2\leq k\| x \|^2.
            \end{equation}
            En déballant la valeur absolue, cela signifie que
            \begin{equation}
                -k\| x \|_E^2\leq x^t(A-\mtu_{p,q})x\leq k\| x \|^2.
            \end{equation}
            Si \( x\in F\), alors la première inéquation et \eqref{EqMViCjJJ} donnent
            \begin{equation}
                x^tAx\geq \| x \|_p^2-k\| x \|_E^2>0
            \end{equation}
            Si \( x\in G\), alors la seconde inéquation et \eqref{EqSFwOcDw} donnent
            \begin{equation}
                x^tAx\leq  k\| x \|_E^2-\| x \|_q^2<0.
            \end{equation}
            
            Nous avons donc montré que \( x\mapsto x^tAx\) est positive sur \( F\) et négative sur \( G\), ce qui prouve que \( A\) est bien de signature \( (p,q)\) et appartient donc à \( S_n^{p,q}(\eR)\). Autrement dit nous avons
            \begin{equation}
                B(\mtu_{p,q},k)\subset S_n^{p,q}(\eR).
            \end{equation}

        \item
            Cette partie de la preuve provient essentiellement de \cite{VKqpMYL}, et fonctionne pour tous les \( S_n^{p,q}(\eR)\), même pour ceux qui ne sont pas de rang maximum. 
            
            Soit \( A\in S_n^{p,q}(\eR)\). Nous savons que \( \GL(n,\eR)\) a deux composantes connexes (proposition \ref{PropYGBEECo}). Vu que l'application 
            \begin{equation}
                \begin{aligned}
                    \alpha\colon \GL(n,\eR)&\to S_n \\
                    P&\mapsto P^tAP 
                \end{aligned}
            \end{equation}
            est continue, l'image d'un connexe de \( \GL(n,\eR)\) par \( \alpha\) est connexe (proposition \ref{PropGWMVzqb}). En particulier, \( \alpha\big( \GL^{\pm}(n,\eR) \big)\) sont deux connexes et nous savons que \( S_n^{p,q}(\eR)\) a au plus ces deux composantes connexes. 

            Notre but est maintenant de trouver une intersection entre \( \alpha\big( \GL^+(n,\eR) \big)\) et \( \alpha\big( \GL^-(n,\eR) \big)\)\quext{À ce point, il me semble que \cite{VKqpMYL} fait erreur parce que la matrice \( -\mtu_n\) est de déterminant \( 1\) lorsque \( n\) est pair. L'argument donné ici provient de \cite{KXjFWKA}}. Soit par le théorème de Sylvester, soit par le théorème de diagonalisation des matrices symétriques réelles \ref{ThoeTMXla}, il existe une matrice \( P\in \GL(n,\eR)\) diagonalisant \( A\). En suivant la remarque \ref{RemGKDZfxu}, et en notant \( Q\) la matrice obtenue à partir de \( P\) en changeant le signe de sa première ligne, nous avons
            \begin{equation}
                \alpha(Q)=Q^tAQ=P^tAP=\alpha(P).
            \end{equation}
            Or si \( P\in \GL^+(n,\eR)\), alors \( Q\in \GL^-(n,\eR)\) et inversement. Donc nous avons trouvé une intersection entre \( \alpha\big( \GL^+(n,\eR) \big)\) et \( \alpha\big( \GL^-(n,\eR) \big)\).

        \item

            Soient \( A\) et \( B\) dans \( S_n^{p,q}(\eR)\cap\GL(n,\eR)\). Par le théorème de Sylvester, il existe \( P\) et \( Q\) dans \( \GL(n,\eR)\) telles que \( A=P^t\mtu_{p,q}P\) et \( B=Q^t\mtu_{p,q}Q\). Par la remarque \ref{RemGKDZfxu} nous pouvons choisir \( P\) et \( Q\) dans \( \GL^+(n,\eR)\). Ce dernier groupe étant connexe par arc, il existe un chemin
            \begin{equation}
                    \gamma\colon \mathopen[ 0 , 1 \mathclose]\to \GL^+(n,\eR) 
            \end{equation}
            tel que \( \gamma(0)=P\) et \( \gamma(1)=Q\). Alors le chemin
            \begin{equation}
                s\mapsto \gamma(s)^t\mtu_{p,q}\gamma(s)
            \end{equation}
            est un chemin continu dans \( S_n^{p,q}(\eR)\) joignant \( A\) à \( B\).
    \end{enumerate}
\end{proof}
% TODO : prouver la connexité par arc de GL^+(n,\eR) et mettre une référence ici.

Nous savons déjà de la proposition \ref{PropNPbnsMd} que les ensembles \( S_n^{p,q}(\eR)\) (pas spécialement de rang maximum) sont ouverts dans \( S_n(\eR)\). Le lemme suivant nous donne une précision à ce sujet, dans le cas des matrices de rang maximum, en disant que la matrice qui donne la similitude entre \( A_0\) et \( A\) est localement un \( C^1\)-difféomorphisme de \( A\).
\begin{lemma}   \label{LemWLCvLXe}
    Soit \( A_0\in \Omega(\eR^n)= S_n\cap\GL(n,\eR)\), une matrice symétrique inversible. Alors il existe un voisinage \( V\) de \( A_0\) dans \( S_n\) et une application \( \phi\colon V\to \GL(n,\eR)\) qui
    \begin{enumerate}
        \item
            est de classe \( C^1\),
        \item
            est telle que pour tout \( A\in V\), \( \varphi(A)^t A_0\phi(A)=A\).
    \end{enumerate}
\end{lemma}
\index{groupe!\( \GL(n,\eR)\)}
\index{forme!quadratique}
\index{matrice!symétrique}
\index{matrice!semblables}

\begin{proof}
    Nous considérons l'application
    \begin{equation}
        \begin{aligned}
            \varphi\colon \eM(n,\eR)&\to S_n \\
            M&\mapsto M^tA_0M. 
        \end{aligned}
    \end{equation}
    Étant donné que les composantes de \( \varphi(M)\) sont des polynômes en les entrées de \( M\), cette application est de classe \( C^1\) -- et même plus. Soit maintenant \( H\in \eM(n,\eR)\) et calculons \( d\varphi_{\mtu}(H)\) par la formule \eqref{EqOWQSoMA} :
    \begin{subequations}
        \begin{align}
            d\varphi_{\mtu}(H)&=\Dsdd{ \varphi(\mtu+tH) }{t}{0}\\
            &=\Dsdd{ (\mtu+tH^t)A_0(\mtu+tH) }{t}{0}\\
            &=\Dsdd{ A_0+tA_0H+tH^tA_0+t^2H^tA_0H }{t}{0}\\
            &=A_0H+H^tA_0.
        \end{align}
    \end{subequations}
    Donc
    \begin{equation}
        d\varphi_{\mtu}(H)=(A_0H)+(A_0H)^t.
    \end{equation}
    Par conséquent 
    \begin{equation}
        \ker(d\varphi_{\mtu})=\{ H\in \eM(n,\eR)\tq A_0H\text{ est antisymétrique} \},
    \end{equation}
    et si nous posons
    \begin{equation}
        F=\{ H\in \eM(n,\eR)\tq A_0H\text{ est symétrique} \}
    \end{equation}
    nous avons
    \begin{equation}
        \eM(n,\eR)=F\oplus\ker(d\varphi_{\mtu})
    \end{equation}
    parce que toute matrice peur être décomposée de façon unique en partir symétrique et antisymétrique. De plus l'application
    \begin{equation}    \label{EqGTBusDm}
        \begin{aligned}
            f\colon F&\to S_n \\
            H&\mapsto A_0H 
        \end{aligned}
    \end{equation}
    est une bijection linéaire. D'abord \( A_0H=0\) implique \( H=0\) parce que \( A_0\) est inversible, et ensuite si \( X\in S_n\), alors \( X=A_0A_0^{-1}X\), ce qui prouve que \( X\) est l'image par \( f\) de \( A_0^{-1}X\) et donc que \( f\) est surjective.

    Maintenant nous considérons la restriction \( \psi=\varphi_{|_F}\), \( \psi\colon F\to S_n\). Remarquons que \( \mtu\in F\) parce que \( A_0\in S_n\). L'application \( d\psi_{\mtu}\) est une bijection. En effet d'abord
    \begin{equation}
        d(\varphi_{|_F})_{\mtu}=(d\varphi_{\mtu})_{|_F},
    \end{equation}
    ce qui prouve que
    \begin{equation}
        \ker(d\psi_{\mtu})=\ker(d\varphi_{\mtu})\cap F=\{ 0 \},
    \end{equation}
    ce qui prouve que \( d\psi_{\mtu}\) est injective. Pour montrer que \( d\psi_{\mtu}\) est surjective, il suffit de mentionner le fait que \( \dim F=\dim S_n\) du fait que l'application \eqref{EqGTBusDm} est une bijection linéaire.

    Nous pouvons utiliser le théorème d'inversion locale (théorème \ref{ThoXWpzqCn}) et conclure qu'il existe un voisinage ouvert \( U\) de \( \mtu\) dans \( F\) tel que \( \psi\) soit un difféomorphisme \( C^1\) entre \( U\) et \( V=\psi(U)\). Vu que \( \GL(n,\eR)\) est ouvert dans \( \eM(n,\eR)\), nous pouvons prendre \( U\cap \GL(n,\eR)\) et donc supposer que \( U\subset \GL(n,\eR)\).

    Pour tout \( A\in V\), il existe une unique \( M\in U\) telle que \( \psi(M)=A\), c'est à dire telle que \( A=M^tA_0M\). Cette matrice \( M\) est \( \psi^{-1}(A)\) et est une matrice inversible. Bref, nous posons
    \begin{equation}
        \begin{aligned}
            \phi\colon V&\to \GL(n,\eR) \\
            A&\mapsto \psi^{-1}(A), 
        \end{aligned}
    \end{equation}
    et ce \( \phi\) est de classe \( C^1\) sur \( V\) parce que c'est ce que dit le théorème d'inversion locale. Cette application répond à la question parce que \( V\) est un voisinage de \( \varphi(\mtu)=A_0\) et pour tout \( A\in V\) nous avons
    \begin{equation}
        \phi(A)^tA_0\phi(A)=\varphi^{-1}(A)^tA_0\varphi^{-1}(A)=A.
    \end{equation}
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Lemme de Morse}
%---------------------------------------------------------------------------------------------------------------------------

\begin{lemma}[Lemme de Morse]     \label{LemNQAmCLo}
    Soit \( f\in C^3(\mU,\eR)\) où \( \mU\) est un ouvert de \( \eR^n\) contenant \( 0\). Nous supposons que \( df_0=0\) et que \( d^2f_0\) est non dégénérée\footnote{En tant qu'application bilinéaire.} et de signature \( (p,n-p)\). Alors il existe un \( C^1\)-difféomorphisme \( \varphi\) entre deux voisinages de \( 0\) dans \( \eR^n\) tel que
    \begin{enumerate}
        \item
            \( \varphi(0)=0\),
        \item
            si \( \varphi(x)=u\) alors
            \begin{equation}
                f(x)-f(0)=u_1^2+\ldots +u_p^2-u_{p+1}^2-\ldots-u_n^2.
            \end{equation}
    \end{enumerate}
    Une autre façon de dire est qu'il existe un \( C^1\)-difféomorphisme local \( \psi\) tel que
    \begin{equation}
        (f\circ\psi)(x)-f(0)=x_1^2+\ldots +x_p^2-x_{p+1}^2-\ldots-x_n^2.
    \end{equation}
\end{lemma}
\index{lemme!de Morse}
\index{développement!Taylor}
\index{application!différentiable}
\index{forme!quadratique}
\index{théorème!inversion locale!utilisation}
\index{action de groupe!sur des matrices}
\index{extremum}

\begin{proof}
    Nous allons noter \( Hf\) la matrice Hessienne de \( f\), c'est à dire \( Hf_a=d^2f_a\in\aL^{(2)}(\eR^n,\eR)\). Écrivons la formule de Taylor avec reste intégral (proposition \ref{PropAXaSClx} avec \( p=0\) et \( m=2\)) :
    \begin{equation}
        f(x)-f(0)=\underbrace{df_0(x)}_{=0}+\int_0^1(1-t)\underbrace{d^2f_{tx}(x,x)}_{x^t(Hf)_{tx}x=\langle Hf_{tx}x, x\rangle }dt=x^tQ(x)x
    \end{equation}
    avec
    \begin{equation}
        Q(x)=\int_0^1(1-t)(Hf)_{tx}dt
    \end{equation}
    qui est une intégrale dans \( \aL^{(2)}(\eR^n,\eR)\). Nous prouvons à présent que \( Q\) est de classe \( C^1\) en utilisant le résultat de différentiabilité sous l'intégrale \ref{PropAOZkDsh}. Pour cela nous passons aux composantes (de la matrice) et nous considérons
    \begin{equation}
        \begin{aligned}
            h_{kl}\colon U\times\mathopen[ 0 , 1 \mathclose]&\to \eR \\
            h_{kl}(x,t)&=(1-t)\frac{ \partial^2f  }{ \partial x_k\partial x_l }(tx).
        \end{aligned}
    \end{equation}
    Étant donné que \( f\) est de classe \( C^3\), la dérivée de \( h_{kl}\) par rapport à \( x_i\) ne pose pas de problèmes :
    \begin{equation}
        \frac{ \partial h_{kl} }{ \partial x_i }=t(t-1)\frac{ \partial^3f  }{ \partial x_i\partial x_k\partial x_l }(tx),
    \end{equation}
    qui est encore continue à la fois en \( t\) et en \( x\). La proposition \ref{PropAOZkDsh} nous montre à présent que
    \begin{equation}
        Q_{kl}(x)=\int_0^1(1-t)h_{kl}(tx)dt
    \end{equation}
    est une fonction \( C^1\). Étant donné que les composantes de \( Q\) sont \( C^1\), la fonction \( Q\) est également \( C^1\).

    Nous avons \( Q(0)=\frac{ 1 }{2}(Hf)_0\in S_n\cap \GL(n,\eR)\), d'abord parce que \( f\) est \( C^2\) (et donc la matrice hessienne est symétrique), ensuite par hypothèse \( d^2f_0\) est non dégénérée.
    %TODO : prouver que la matrice hessienne est symétrique lorsque f est C^2 (ou vérifier que c'est déjà fait), et référentier ici.

    À partir de là, le lemme \ref{LemWLCvLXe} donne un voisinage \( V\) de \( Q(0)\) dans \( S_n\) et une application \( \phi\) de classe \( C^1\)
    \begin{equation}
            \phi\colon V\to \GL(n,\eR) \\
    \end{equation}
    telle que pour tout \( A\in V\),
    \begin{equation}
        \phi(A)^tQ(0)\phi(A)=A.
    \end{equation}
    Si on pose \( M=\phi\circ Q\), et si \( x\) est dans un voisinage de zéro, \( Q\) étant continue nous avons \( Q(x)\in V\) et donc
    \begin{equation}
        Q(x)=M(x)^tQ(0)M(x).
    \end{equation}
    Notons que l'application \( \eM\colon \eR\to \GL(n,\eR)\) est de classe \( C^1\) parce que \( Q\) et \( \phi\) le sont.

    Nous avons
    \begin{equation}
        f(x)-f(0)=x^tQ(x)x=x^tM(x)^tQ(0)M(x)x=y(x)^tQ(0)y(x)
    \end{equation}
    où \( y(x)=M(x)x=(\phi\circ Q)(x)x\) est encore une fonction de classe \( C^1\) parce que la multiplication est une application \(  C^{\infty}\).

    D'un autre côté le théorème de Sylvester \ref{ThoQFVsBCk} nous donne une matrice inversible \( P\) telle que
    \begin{equation}
        Q(0)=P^t\begin{pmatrix}
            \mtu_p    &       \\ 
            &   -\mtu_{n-p}    
        \end{pmatrix}P.
    \end{equation}
    Et nous posons enfin \( u=\varphi(x)=Py(x)\) qui est toujours de classe \( C^1\) et qui donne
    \begin{subequations}
        \begin{align}
            f(x)-f(0)&=y^tQ(0)y\\
            &=y^tP^t\begin{pmatrix}
                \mtu    &       \\ 
                    &   -\mtu    
            \end{pmatrix}Py\\
            &=u^t\begin{pmatrix}
                \mtu    &       \\ 
                    &   -\mtu    
            \end{pmatrix}u\\
            &=u_1^2+\ldots +u_p^2-u_{p+1}^2-\ldots -u_n^2.
        \end{align}
    \end{subequations}
    
    Nous devons maintenant montrer que, quitte à réduire son domaine à un ouvert plus petit, \( \varphi\) est un \( C^1\)-difféomorphisme. Dans la chaine qui donne \( \varphi\), seule l'application 
    \begin{equation}
        \begin{aligned}
            g\colon U\subset \eR^n&\to \eR^n \\
            x&\mapsto M(x)x 
        \end{aligned}
    \end{equation}
    est sujette à caution. Nous allons appliquer le théorème d'inversion locale. Nous savons que \( g\) est de classe \( C^1\) et donc différentiable; calculons la différentielle en utilisant la formule \eqref{EqOWQSoMA} :
    \begin{equation}
        dg_0(x)=\Dsdd{ g(tx) }{t}{0}=\Dsdd{ tM(tx)x }{t}{0}=M(0)x.
    \end{equation}
    Note que nous avons utilisé la règle de Leibnitz pour la dérivée d'un produit, mais le second terme s'est annulé. Donc \( dg_0=M(0)\in \GL(n,\eR)\) et \( g\) est localement un \( C^1\)-difféomorphisme.

    Il suffit de restreindre \( \varphi\) au domaine sur lequel \( g\) est un \( C^1\)-difféomorphisme pour que \( \varphi\) devienne lui-même un \( C^1\)-difféomorphisme.

\end{proof}

\begin{definition}
    Un point \( a\) est un \defe{point critique}{point critique!définition} de la fonction différentiable \( f\) si \( df_a=0\).
\end{definition}

\begin{corollary}[\cite{XPautfO}]
    Les points critiques non dégénérés d'une fonction \( C^3\) sont isolés.
\end{corollary}

\begin{proof}
    Soit \( a\) un point critique non dégénéré. Par le lemme de Morse \ref{LemNQAmCLo}, il existe un \( C^1\)-difféomorphisme \( \psi\) et un entier \( p\) tel que
    \begin{equation}
        (f\circ \psi)(x)=x_1^2+\ldots +x_p^2-x_{p+1}^2-\ldots -x_n^2+f(a)
    \end{equation}
    sur un voisinage \( \mU\) de \( a\). Vue la formule générale \( df_x(u)=\nabla f(x)\cdot u\), si \( x\) est un point critique de \( f\), alors \( \nabla f(x)=0\). Dans notre cas, les points critiques de \( f\circ \psi\) dans \( \mU\) doivent vérifier \( x_i=0\) pour tout \( i\), et donc \( x=a\).

    Nous devons nous assurer que la fonction \( f\) elle-même n'a pas de points critiques dans \( \mU\). Pour cela nous utilisons la formule générale de dérivation de fonction composée :
    \begin{equation}
        \nabla(f\circ\psi)(x)=\sum_k \frac{ \partial f }{ \partial y_k }\big( g(x) \big)\nabla g_k(x).
    \end{equation}
    Si \( \psi(x)\) est une point critique de \( f\), alors le membre de droite est le vecteur nul parce que tous les \( \partial_kf\big( \psi(x) \big)\) sont nuls. Par conséquent le membre de gauche est également nul, et \( x\) est un point critique de \( f\circ\psi\). Or nous venons de voir que \( f\circ\psi\) n'a pas de points critiques dans \( \mU\).

    Donc \( f\) n'a pas de points critiques dans un voisinage d'un point critique non dégénéré.
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Variétés}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\subsection{Introduction}
Soit $f : S^2 \to \eR$ une fonction définie sur la sphère usuelle
$S^2 \subset \eR^3$. Une question naturelle est d'estimer la
régularité de $f$ ; est-elle continue, dérivable, différentiable ? Il
n'existe pas de dérivée directionnelle étant donné que le quotient
différentiel
\begin{equation*}
  \frac{f(x + \epsilon u_1 ,y + \epsilon u_2) - f(x,y)}{\epsilon}
\end{equation*}
n'a pas de sens pour un point $(x + \epsilon u_1 ,y + \epsilon u_2)$
qui n'est pas --sauf valeurs particulières-- dans la surface. Pour la
même raison il n'est pas possible de parler de différentiabilité de
cette manière. Comment faire, sans devoir étendre le domaine de
définition de $f$ à un voisinage de la sphère ? Une solution possible
est de parler de la notion de variété.

Une variété est un objet qui ressemble, vu de près, à $\eR^m$ pour un
certain $m$. En d'autres termes, on imagine une variété comme un
recollement de morceaux de $\eR^m$ vivant dans un espace plus grand
$\eR^n$. Ces morceaux sont appelés des ouverts de carte, et
l'application qui exprime la ressemblance à $\eR^m$ est l'application
de carte.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Définition et propriétés}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}
  Soit $\emptyset \neq M \subset \eR^n$, $1 \leq m < n$ et $k \geq
  1$. $M$ est une \Defn{variété de classe $C^k$ de dimension $m$} si
  pour tout $a \in  M$, il existe un voisinage ouvert $U$ de $a$
  dans $\eR^n$, et un ouvert $V$ de $\eR^m$ tel que $U \cap M$
  soit le graphe d'une fonction $f : V \subset \eR^m \to \eR^{n-m}$
  de classe $C^1$, c'est-à-dire qu'il existe un réagencement des
  coordonnées $(x_{i_1}, \ldots, x_{i_m}, x_{i_{m+1}}, \ldots,
  x_{i_n})$ avec
  \begin{equation*}
    M \cap U = \left\{ (x_1, \ldots, x_n) \in \eR^n \tq
%      \begin{array}{l} % deux conditions
      (x_{i_1}, \ldots, x_{i_m}) \in V \quad \left\{\begin{array}{c!{=}l} % 1: equations
        x_{i_{m+1}} & f_1(x_{i_1}, \ldots, x_{i_m})\\
        \vdots & \vdots \\
        x_{i_n} & f_{n-m}(x_{i_1}, \ldots, x_{i_m})
      \end{array}\right.
%    \end{array}
    \right\}
  \end{equation*}
  où $V$ est un voisinage ouvert de $(a_{i_1}, \ldots, a_{i_m}) \in \eR^m$.
\end{definition}

La littérature regorge de théorèmes qui proposent des conditions équivalentes à la définition d'une variété. Celle que nous allons le plus utiliser est la suivante% , de la page 268.
\begin{proposition}
	Soit $M\subset\eR^n$ et $1\leq m\leq n-1$. L'ensemble $M$ est une variété si et seulement si $\forall a\in M$, il existe un voisinage ouvert $\mU$ de $a$ dans $\eR^n$ et une application $F\colon W\subset\eR^m\to \eR^n$ où $W$ est un ouvert tels que
	\begin{enumerate}
		\item
			$F$ est un homéomorphisme de $W$ vers $M\cap\mU$,
		\item
			$F\in C^1(W,\eR^n)$,
		\item
			Le rang de $dF(w)\in L(\eR^m,\eR^n)$ est de rang maximum (c'est à dire $m$) en tout point $w\in W$.
	\end{enumerate}
\end{proposition}
Pour rappel, si $T\colon \eR^m\to \eR^n$ est une application linéaire, son \defe{rang}{rang} est la dimension de son image. On peut prouver que si $A$ est la matrice d'une application linéaire, alors le rang de cette application linéaire est égal à la taille de la plus grande matrice carré de déterminant non nul contenue dans $A$.

La condition de rang maximum sert à éviter le genre de cas de la figure \ref{LabelFigExempleNonRang} qui représente l'image de l'ouvert $\mathopen] -1 , 1 \mathclose[$ par l'application $F(t)=(t^2,t^3)$.
\newcommand{\CaptionFigExempleNonRang}{Quelque chose qui n'est pas de rang maximum et qui n'est pas une variété.}
\input{Fig_ExempleNonRang.pstricks}
%\ref{LabelFigExempleNonRang} 
%\newcommand{\CaptionFigExempleNonRang}{Quelque chose qui n'est pas de rang maximum et qui n'est pas une variété.}
%\input{Fig_ExempleNonRang.pstricks}
La différentielle a pour matrice
\begin{equation}
	dF(t)=(2t,3t^2).
\end{equation}
Le rang maximum est $1$, mais en $t=0$, la matrice vaut $(0,0)$ et son rang est zéro. Pour toute autre valeur de $t$, c'est bon.

Une autre caractérisation des variétés est donnée par la proposition suivante %(proposition 3, page 274).
\begin{proposition}		\label{PropCarVarZerFonc}
	Soit $M\in \eR^n$ et $1\leq m\leq n-1$. L'ensemble $M$ est une variété si et seulement si $\forall a\in M$, il existe un voisinage ouvert $\mU$ de $a$ dans $\eR^n$ tel et une application $G\in C^1(\mU,\eR^{n-m})$ tel que
	\begin{enumerate}

		\item
			le rang de $dG(a)\in L(\eR^n,\eR^{n-m})$ soit maximum (c'est à dire $n-m$) en tout $a\in M$,
		\item
			$M\cap\mU=\{ x\in\mU\tq G(x)=0 \}$.

	\end{enumerate}
\end{proposition}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Espace tangent}
%---------------------------------------------------------------------------------------------------------------------------

Soit $M$, une variété dans $\eR^n$, et considérons un chemin $\gamma\colon I\to \eR^n$ tel que $\gamma(t)\in M$ pour tout $t\in I$ et tel que $\gamma(0)=a$ et que $\gamma$ est dérivable en $0$. La \defe{tangente}{tangente à un chemin} au chemin $\gamma$ au point $a\in M$ est la droite
\begin{equation}
	s\mapsto a+s\gamma'(0).
\end{equation}
L'\defe{espace tangent}{espace!tangent} de $M$ au point $a$ est l'ensemble décrit par toutes les tangentes en $a$ pour tous les chemins $\gamma$ possibles.

\begin{proposition}			\label{PropDimEspTanVarConst}
	Une variété de dimension $m$ dans $\eR^n$ a un espace tangent de dimension $m$ en chacun de ses points.
\end{proposition}
