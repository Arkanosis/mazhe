% This is part of Mes notes de mathématique
% Copyright (c) 2011-2015
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Primitive et intégrale}
%---------------------------------------------------------------------------------------------------------------------------

\begin{enumerate}
    \item
        L'existence d'une primitive pour toute fonction continue est le théorème \ref{ThoEOMRooZPUfJg}.
    \item
        La définition d'une primitive est la définition \ref{DefXVMVooWhsfuI}.
\end{enumerate}

En termes de notations, si \( a<b\) nous posons
\begin{equation}
    \int_a^bf(t)dt=\int_{\mathopen[ a , b \mathclose]}f.
\end{equation}
Si par contre \( a>b\) nous posons \( \int_a^bf=-\int_b^af\).

\begin{proposition}[Primitive et intégrale] \label{PropEZFRsMj}
    Soit \( f\) une fonction intégrable sur \( \mathopen[ a , b \mathclose]\) et continue sur \( \mathopen] a , b \mathclose[\). Alors la fonction
    \begin{equation}
        \begin{aligned}
            F\colon \mathopen[ a , b \mathclose]&\to \eR \\
            x&\mapsto \int_{\mathopen[ a , x \mathclose]}f(t)dt.
        \end{aligned}
    \end{equation}
est une primitive de \( f\) sur \( \mathopen] a , b \mathclose[\).
\end{proposition}
\index{primitive!et intégrale}

\begin{proof}
Nous devons prouver que \( F\) est dérivable et que pour tout \( x_0\in\mathopen] a , b \mathclose[\) nous ayons \( F'(x_0)=f(x_0)\). Soit \( \epsilon>0\). Par continuité de \( f\) en \( x_0\), il existe une fonction \( \alpha\colon \eR\to \eR\) telle que
    \begin{equation}
        f(x_0+h)=f(x_0)+\alpha(h)
    \end{equation}
    avec \( \lim_{h\to 0} \alpha(h)=0\). De plus il existe un \( \delta>0\) tel que \( |\alpha(h)|<\epsilon\) pour tout \( h<\delta\). À partir de maintenant nous ne considérons plus que de tels \( h\).

    Nous calculons la dérivée de \( F\) en \( x_0\). Pour cela,
    \begin{subequations}
        \begin{align}
            F(x_0+h)-F(x_0)&=\int_{x_0}^{x_0+h}f(t)dt\\
        &=\int_0^hf(x_0+t)dt\\
        &=\int_0^h\big[ f(x_0)+\alpha(t) \big]dt\\
        &=hf(x_0)+\int_0^{h}\alpha(t)dt.
        \end{align}
    \end{subequations}
    Nous avons donc, pour tout \( h<\delta\),
    \begin{equation}
        hf(x_0)-h\epsilon\leq F(x_0+h)-F(x_0)\leq hf(x_0)+h\epsilon.
    \end{equation}
    En divisant par \( h\) et en prenant la limite \( h\to 0\),
    \begin{equation}
        F'(x_0)\in B\big( f(x_0),\epsilon \big).
    \end{equation}
    Cela étant valable pour tout \( \epsilon>0\) nous en déduisons que
    \begin{equation}
        F'(x_0)=f(x_0).
    \end{equation}
\end{proof}

\begin{remark}
    Le lien entre primitive et intégrale est fondamentalement lié à l'invariance par translation de la mesure de Lebesgue, et non à la construction précise de cette mesure. Mais en même temps, la mesure de Lebesgue est l'unique à être invariante par translation.
\end{remark}

Ce petit résultat nous donne une façon «pratique» de calculer des intégrales en cherchant des primitives. Nous rappelons qu'en vertu du corollaire \ref{CorZeroCst}, une fonction ne possède qu'une seule primitive à constante près.

Le théorème suivant est à utiliser pour calculer des intégrales des fonctions réelle lorsqu'on a des primitives sur un domaine strictement plus large que le domaine sur lequel nous voulons intégrer.
\begin{theorem}[Théorème fondamental du calcul intégral]    \label{ThoRWXooTqHGbC}
    Soit \( f\) une fonction continue sur un intervalle ouvert \( I\) contenant strictement l'intervalle \( \mathopen[ a , b \mathclose]\subset \eR\) et \( F\) une primitive de \( f\) sur \( I\). Alors
    \begin{equation}
        \int_a^bf(t)dt=F(b)-F(a).
    \end{equation}
\end{theorem}
\index{théorème!fondamental du calcul intégral}
Une version pour les intégrales impropres sera donnée au corollaire \ref{CorMUIooXREleR}.

\begin{proof}
    Nous avons vu par la proposition \ref{PropEZFRsMj} que la fonction
    \begin{equation}
        \begin{aligned}
            \tilde F\colon \mathopen[ a , b \mathclose]&\to \eR \\
            x&\mapsto  \int_a^xf(t)dt
        \end{aligned}
    \end{equation}
    était une primitive de \( f\); c'est même l'unique\footnote{Corollaire \ref{CorZeroCst}.} primitive de \( f\) sur \( \mathopen[ a , b \mathclose]\) à s'annuler pour \( x=a\). Nous avons évidemment
    \begin{equation}
        \int_a^bf(t)dt=\tilde F(b).
    \end{equation}
    Si \( F\) est une primitive quelconque, il suffit de soustraire sa valeur en \( x=a\) : \( \tilde F(x)=F(x)-F(a)\) et donc
    \begin{equation}
        \int_a^bf(t)dt=\tilde F(b)=F(b)-F(a),
    \end{equation}
    comme il fallait le prouver.
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Intégrales impropres}
%---------------------------------------------------------------------------------------------------------------------------
\label{SecGAVooBOQddU}

% TODO : l'exemple avec arcsin(1/x)-1/x de la page 
%  http://fr.wikipedia.org/wiki/Intégrale_impropre

\begin{definition}[\cite{TrenchRealAnalisys}]
    Une fonction \( f\colon D\subset\eR\to \eR\) est \defe{localement intégrable}{localement!intégrable} sur un intervalle \( I\) si \( f\) est intégrable sur tout intervalle compact contenu dans \( I\).
\end{definition}
\index{intégrale!impropre}

%Dans \cite{TrenchRealAnalisys}, la proposition \ref{PropCJAooQhNYkp} est prise comme une définition de \( \int_a^bf\) lorsque \( f\) est localement intégrable sur \( \mathopen[ a , b [\). Le point est que lui, il ne passe pas par Lebesgue et la construction abstraite d'intégrale par rapport à une mesure. Nous par contre nous avons déjà une définition de
%\begin{equation}
%    \int_a^bf=\int_{\mathopen[ a , b \mathclose]}f
%\end{equation}
%pour tout choix de \( a\), \( b\) et \( f\), que ce soit borné ou non.

\begin{proposition}     \label{PropCJAooQhNYkp}
    Soit \( f\colon \mathopen[ a , b \mathclose]\to \eR\) une fonction intégrable. Alors
    \begin{equation}    \label{EqPPMooBQDTYl}
        \int_{\mathopen[ a , b \mathclose]}f=\lim_{x\to b^-} \int_a^xf.
    \end{equation}
\end{proposition}

\begin{proof}
    Notons que la valeur de \( f\) en \( b\) n'a strictement aucune importance parce que l'intégrale de Lebesgue ne dépend pas du choix de la valeur de la fonction en un ensemble de mesure nulle; et en même temps la limite à gauche de \eqref{EqPPMooBQDTYl} ne dépend pas non plus de la valeur de \( f\) en \( b\). Bref si \( f\) n'est pas définie en \( b\), nous pouvons poser \( f(b)=42\).

    Notons de plus que du point de vue de l'intégrale de Lebesgue, \( \int_{\mathopen[ a , b \mathclose]}\) et \( \int_{\mathopen[ a , b [}\) sont identiques et valent toutes les deux \( \int_a^b\) (lorsque ça existe).

    Supposons d'abord que \( f\) est positive. Alors nous posons \( f_n=f\mtu_{\mathopen[ a , b-\frac{1}{ n } \mathclose]}\). Ponctuellement nous avons la limite croissante \( f_n\to f\) et de plus
    \begin{equation}
        \lim_{x\to b^-} \int_{\mathopen[ a , x \mathclose]}f=\lim_{n\to \infty} \int_{\mathopen[ a , b \mathclose]}f_n.
    \end{equation}
    Chacun des \( f_n\) est intégrable sur \( \mathopen[ a , b \mathclose]\). Le théorème de Beppo-Levi \ref{ThoRRDooFUvEAN} implique que \( f\) est intégrable sur \( \mathopen[ a , b \mathclose]\) et que
    \begin{equation}
        \lim_{n\to \infty} \int_a^bf_n=\int_a^bf.
    \end{equation}
    Cela montre que dans le cas d'une fonction \( f\) positive nous avons bien \eqref{EqPPMooBQDTYl}.

    Si \( f\) n'est pas positif, alors nous la décomposons en partie positive et négative \( f=f^+-f^{-}\) et par définition de l'intégrale d'une fonction non positive,
    \begin{equation}
        \lim_{x\to b^-} \int_{\mathopen[ a , x [}f=\lim\int f^{+}-\lim\int f^-.
    \end{equation}
\end{proof}

Il peut cependant arriver que la limite \( \lim_{x\to b} \int_a^bf\) existe alors que \( f\) n'est pas intégrable sur \( \mathopen[ a , b \mathclose]\). C'est l'ennui des fonctions non positives. Un exemple classique est
\begin{equation}\label{EqMMVooDSpgfz}
    \int_0^{\infty}\frac{ \sin(t) }{ t }dt
\end{equation}

\begin{definition}[\cite{DWNooWUZxRP}]
    Si
    \begin{equation}
        \lim_{x\to b} \int_a^bf
    \end{equation}
    existe alors nous disons que l'intégrale est \defe{convergente}{intégrale!convergente} en \( b\). Ce procédé de limite est l'intégrale \defe{impropre}{intégrale!impropre} de \( f\) sur \( \mathopen[ a , b \mathclose]\).
\end{definition}

\begin{example}[Intégale impropre]
    Nous considérons la fonction \( f\colon \mathopen[ 0 , \infty [\to \eR\) définie par
    \begin{equation}
        f(x)=\begin{cases}
            \frac{1}{ n }    &   \text{si \( x\in\mathopen[ 2n-2 , 2n-1 [\)}\\
                -\frac{1}{ n }    &    \text{si \( x\in\mathopen[ 2n-1 , 2n [\).}
        \end{cases}
    \end{equation}
    Par la divergence de la série harmonique, \( \int_{0}^{\infty}| f |\) n'existe pas. La fonction \( f\) n'est donc pas intégrable au sens de Lebesgue (définition \ref{DefTCXooAstMYl}).

    Cependant pour tout \( n\) pair nous avons
    \begin{equation}
        \int_0^nf=0.
    \end{equation}
    Du coup pour tout \( x\geq 0\) nous avons
    \begin{equation}
        \int_0^xf=\int_{2n}^xf
    \end{equation}
    où \( 2n\) est le plus grand nombre pair inférieur à \( x\). Nous avons \( | x-2n |\leq 2\) et \( | f(x) |\leq \frac{1}{ n }\) pour \( x\in\mathopen[ 2n , x \mathclose]\). Donc
    \begin{equation}
        \int_{2n}^xf\leq \frac{ 2 }{ n }.
    \end{equation}
    Nous avons par conséquent
    \begin{equation}
        \lim_{x\to \infty} \int_0^xf=0,
    \end{equation}
    ce qui signifie que l'intégrale de \( f\) sur \( \mathopen[ 0 , \infty [\) converge au sens des intégrales impropres.
\end{example}


L'intégrale \eqref{EqMMVooDSpgfz} est une intégrale convergente mais la fonction n'est pas intégrable (parce que pour être intégrale il faut que \( | f |\) soit intégrable). Nous pouvons ainsi dire que cette intégrale converge mais n'existe pas.

Le corollaire suivant nous autorise à utiliser le théorème fondamental du calcul intégral \ref{ThoRWXooTqHGbC} même dans les cas limites.
\begin{corollary}   \label{CorMUIooXREleR}
    Si \( f\) est localement intégrable sur \( \mathopen[ a , b \mathclose]\) et si \( F\) est une primitive de \( f\) sur tout ouvert de \( \mathopen[ a , b \mathclose]\) alors
    \begin{equation}
        \int_a^bf=\lim_{x\to b^-} F(x)-F(a).
    \end{equation}
\end{corollary}
\index{primitive!et intégrale}

\begin{proof}
    Pour chaque \( x\) dans \( \mathopen[ a , b [\) nous avons
    \begin{equation}
        \int_a^xf=F(x)-F(b).
    \end{equation}
    La proposition \ref{PropCJAooQhNYkp} nous explique que la limite \( x\to b^-\) du membre de gauche existe et vaut \( \int_a^bf\). Donc également le membre de droite :
    \begin{equation}
        \int_a^bf=\lim_{x\to b^-} \int_a^xf=\lim_{x\to b^-} F(x)-F(b).
    \end{equation}
\end{proof}

La convergence des intégrales de fonctions \( \frac{1}{ x^{\alpha} }\) en \( 0\) et \( \infty\) est une question classique de l'intégration. De plus ces fonctions servent souvent à utiliser une théorème de comparaison (type intégrale dominée de Lebesgue).
\begin{proposition} \label{PropBKNooPDIPUc}
    Deux intégrales remarquables.
    \begin{enumerate}
        \item
            
            Nous avons 
    \begin{equation}
        \int_0^1\frac{1}{ x^\alpha }=\infty
    \end{equation}
    si et seulement si \( \alpha\geq 1\).

\item

    Nous avons
    \begin{equation}
        \int_1^{\infty}\frac{1}{ x^{\alpha} }=\infty
    \end{equation}
    si et seulement si \( \alpha\leq1\).

    \end{enumerate}
    
\end{proposition}

\begin{proof}
La fonction \( \frac{1}{ x^{\alpha} }\) admet la primitive \( F(x)=\frac{1}{ 1-\alpha }\frac{1}{ x^{\alpha-1} }\) sur tout compact de \( \mathopen] 0 , \infty \mathclose[\). Le corollaire \ref{CorMUIooXREleR} nous permet\footnote{Tout ce que nous avons fait avec la borne \( b\) de l'intégrale \( \int_a^b\) reste valable avec la borne \( a\).} de dire que \( \int_0^1\frac{1}{ x^{\alpha} }\) vaudra
    \begin{equation}
        \lim_{x\to 0-^+} \frac{1}{ 1-\alpha }\frac{1}{ x^{\alpha-1} }.
    \end{equation}
    Cela est strictement plus petit que \( \infty\) si et seulement si \( \alpha<1\).
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Théorème de Fubini}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Mesure produit}
%---------------------------------------------------------------------------------------------------------------------------

\begin{theorem}[\cite{NBoIEXO}\footnote{Modèle non contractuel : des notations et la définition de \( \lambda\)-système peuvent varier entre la référence et le présent texte.}]    \label{ThoCCIsLhO}
    Soient \( (\Omega_i,\tribA_i,\mu_i)\) (\( i=1,2\)) deux espaces mesurés \( \sigma\)-finie. Soit \( A\in\tribA_1\otimes \tribA_2\). Alors les fonctions\footnote{Voir la notation du lemme \ref{subEqCTtPccK}.}
    \begin{subequations}
        \begin{align}
            x\mapsto\mu_2\big( A_2(x) \big)\\
            y\mapsto\mu_1\big( A_1(y) \big)
        \end{align}
    \end{subequations}
    sont mesurables et
    \begin{equation}    \label{EqRKXwsQJ}
        \int_{\Omega_1}\mu_2\big( A_2(x) \big)d\mu_1(x)=\int_{\Omega_2}\mu_2\big( A_1(y) \big)d\mu_2(y).
    \end{equation}
\end{theorem}

\begin{proof}
    Nous supposons d'abord que \( \mu_1\) et \( \mu_2\) sont finies et nous notons \( \tribD\) le sous-ensemble de \( \tribA_1\otimes \tribA_2\) sur lequel le théorème est correct. Nous allons commencer par prouver que \( \tribD\) est un \( \lambda\)-système.

    \begin{subproof}
        \item[\( \lambda\)-système : différence ensembliste]
            Soient \( A,B\in\tribD\) avec \( A\subset B\). Nous avons
            \begin{subequations}
                \begin{align}
                    (B\setminus A)_1(y)&=\{ x\in \Omega_1\tq(x,y)\in B\setminus A \}\\
                    &=\{ x\in \Omega_1\tq(x,y)\in B\}\setminus\{ x\in \Omega_1\tq(x,y)\in  A \}\\
                    &=B_1(y)\setminus A_1(y).
                \end{align}
            \end{subequations}
            Vu que \( A_1(y)\subset B_1(y)\) et que les mesure sont finies le lemme \ref{LemPMprYuC} nous donne
            \begin{equation}
                \mu_1\big( (B\setminus A)_1(y) \big)=\mu_1\big( B_1(y) \big)-\mu_1\big( A_1(y) \big),
            \end{equation}
            et similairement pour \( 1\leftrightarrow 2\). Les deux fonctions (de \( y\)) à droite étant mesurables, nous avons la mesurabilité de la fonction \( y\mapsto \mu_1\big( (B\setminus A)_1(y) \big)\).

            Prouvons la formule intégrale en nous rappelant que la formule \eqref{EqRKXwsQJ} est supposée correcte pour \( A\) et \( B\) séparément :
            \begin{subequations}
                \begin{align}
                    \int_{\Omega_2}\mu_1\big( (B\setminus A)_1(y) \big)d\mu_2(y)&=\int_{\Omega_2}\mu_1\big( B_1(y) \big)d\mu_2(y)-\int_{\Omega_2}\mu_1\big( A_1(y) \big)d\mu_2(y)\\
                    &=\int_{\Omega_1}\mu_2\big( B_2(x) \big)d\mu_1(x)-\int_{\Omega_1}\mu_2\big( A_2(x) \big)d\mu_1(x)\\
                    &=\int_{\Omega_1}\mu_2\big( (B\setminus A)_2(x) \big)d\mu_1(x).
                \end{align}
            \end{subequations}
            
    
        \item[\( \lambda\)-système : limite de suite croissante]

            Soit \( (A_n)\) une suite croissante dans \( \tribD\); nous posons \( B_n=A_n\setminus A_{n-1}\) et \( A_0=\emptyset\) de telle sorte à travailler avec une suite d'ensembles disjoints qui satisfait \( \bigcup_nA_n=\bigcup_nB_n\). Vu que la suite est croissante nous avons \( A_{n-1}\subset A_n\) et donc \( B_n\in\tribD\) par le point déjà fait sur la différence ensembliste. Nous avons :
            \begin{subequations}
                \begin{align}
                    \mu_1\big( (\bigcup_nB_n)_1(y) \big)&=\{ x\in \Omega_1\tq (x,y)\in\bigcup_nB_n \}\\
                    &=\bigcup_n\{ x\in\Omega_1\tq (x,y)\in B_n \}\\
                    &=\bigcup_n (B_n)_1(y).
                \end{align}
            \end{subequations}
            Par conséquent, par la propriété \ref{ItemQFjtOjXiii} d'une mesure nous avons
            \begin{equation}
                \mu_1\big( (\bigcup_nB_n)_1(y) \big)=\sum_n\mu_1\big( (B_n)_1(y) \big).
            \end{equation}
            En tant que somme de fonctions positives et mesurables, la fonction
            \begin{equation}
                y\mapsto\sum_n\mu_1\big( (B_n)_1(y) \big)
            \end{equation}
            est mesurable par la proposition \ref{PropFYPEOIJ}. Il faut encore vérifier la formule intégrale. Le gros du boulot est de permuter une somme et une intégrale par le corollaire \ref{CorNKXwhdz} :
            \begin{subequations}
                \begin{align}
                    \int_{\Omega_2}\sum_n\mu_1\big( (B_n)_1(y) \big)d\mu_2(y)&=\sum_n\int_{\Omega_2}\mu_1\big( (B_n)_1(y) \big)d\mu_2(y)\\
                    &=\sum_n\int_{\Omega_1}\mu_2\big( (B_n)_2(x) \big)d\mu_1(x)\\
                    &=\int_{\Omega_1}\sum_n\mu_2\big( (B_n)_2(x) \big)d\mu_1(x)\\
                    &=\int_{\Omega_1}\mu_2\big( (\bigcup_nB_n)_1(y) \big)d\mu_1(x).
                \end{align}
            \end{subequations}
    \end{subproof}
    Maintenant que \( \tribD\) est un $\lambda$-système contenant les rectangles, le lemme \ref{LemLUmopaZ} dit que la tribu engendrée par \( \tribD\) (c'est à dire \( \tribA_1\otimes \tribA_2\)) est le $\lambda$-système \( \tribD\) lui-même.

    La preuve est finie dans le cas de mesures finies. Nous commençons maintenant à prouver dans le cas où les mesures \( \mu_1\) et \( \mu_2\) sont seulement \( \sigma\)-finies. Nous considérons des suites croissantes \( \Omega_{i,n}\to\Omega_i\) d'ensembles mesurables et de mesure finie : \( \mu_i(\Omega_{i,n})<\infty\). D'abord remarquons que
    \begin{equation}\label{EqNFuBzBF}
        \mu_2\Big( (A\cap \Omega_{1,j}\times E_{2,j})_2(x) \Big)=\mu_2\Big( A_2(x)\cap \Omega_{2,j} \Big)\mtu_{\Omega_{1,j}}.
    \end{equation}
    En effet,
    \begin{subequations}
        \begin{align}
            \heartsuit&=(A\cap\Omega_{1,j}\times E_{2,j})_2(x)\\
            &=\{ y\in\Omega_2\tq (x,y)\in A\cap \Omega_{1,j}\times E_{2,j} \}\\
            &=\{ y\in \Omega_2\tq (x,y)\in A\times \Omega_{2,j} \}\cap\{ y\in\Omega_2\tq (x,y)\in \Omega_{1,j}\times \Omega_{2,j} \}.
        \end{align}
    \end{subequations}
    Si \( y\in \Omega_{1,j}\) alors \( \{ y\in \Omega_2\tq (x,y)\in \Omega_{1,j}\times \Omega_{2,j} \}=\Omega_{2,j}\) et dans ce cas
    \begin{equation}
        \heartsuit=\{ y\in \Omega_2\tq (x,y)\in A\times \Omega_{2,j} \}\cap \Omega_{2,j}=A_2(x)\cap E_{2,j}.
    \end{equation}
    Et inversement, si \( x\notin \Omega_{1,j}\) alors \( \heartsuit=\emptyset\). Dans les deux cas nous avons \eqref{EqNFuBzBF}.

    Les ensembles \( A\cap \Omega_{1,j}\times \Omega_{2,j}\) étant de mesure finie, nous pouvons leur appliquer la première partie :
    \begin{equation}
        \int_{\Omega_1}\mu_2\Big( (A\cap\Omega_{1,j}\times \Omega_{2,j})_2(x) \Big)d\mu_1(x)=\int_{\Omega_2}\mu_1\Big( (A\cap\Omega_{1,j}\times \Omega_{2,j})_1(y) \Big)d\mu_2(u),
    \end{equation}
    ou encore
    \begin{equation}
        \int_{\Omega_1}\mu_2\Big( A_2(x)\cap \Omega_{2,j} \Big)\mtu_{\Omega_{1,j}}(x)d\mu_1(x)=\int_{\Omega_2}\mu_1\Big( A_1(y)\cap \Omega_{1,j} \Big)\mtu_{\Omega_{2,j}}(y)d\mu_2(y).
    \end{equation}
    Ce que nous avons dans ces intégrales sont (par rapport à \( j\)) des suites croissantes de fonction positives; nous pouvons donc permuter une limite et une intégrale. En sachant que si \( k\to \infty\), alors
    \begin{subequations}
        \begin{align}
            \mtu_{1,j}(x)\to 1\\
            \mu_2\big( A_2(x)\cap \Omega_2,j \big)\to\mu_2\big( A_2(x) \big),
        \end{align}
    \end{subequations}
    nous trouvons le résultat demandé.
\end{proof}

\begin{theorem}[\cite{FubiniBMauray,MesIntProbb}]   \label{ThoWWAjXzi}
    Soient \( \mu_i\) des mesures $\sigma$-finies sur \( (\Omega_i,\tribA_i)\) (\( i=1,2\)). Il existe une et une seule mesure, notée \( \mu_1\otimes \mu_2\), sur \( (\Omega_1\times\Omega_2,\tribA_1\otimes\tribA_2)\) telle que
    \begin{equation}    \label{EqOIuWLQU}
        (\mu_1\otimes\mu_2)(A_1\times A_2)=\mu_1(A_1)\mu_2(A_2)
    \end{equation}
    pour tout \( A_1\in \tribA_1\) et \( A_2\in\tribA_2\). Cette mesure est donnée par la formule\footnote{Voir les notations du lemme \ref{LemAQmWEmN}.}
    \begin{equation}   \label{EqDFxuGtH}
        (\mu_1\otimes \mu_2)(A)=\int_{\Omega_1}\mu_2\big( A_2(x) \big)d\mu_1(x)=\int_{\Omega_2}\mu_1\big( A_1(y) \big)d\mu_2(y).
    \end{equation}
    Cette mesure est la \defe{mesure produit}{mesure!produit} de \( \mu_1\) par \( \mu_2\).
\end{theorem}
\index{mesure!produit}

\begin{proof}
    L'ensemble des rectangles de \( \Omega_1\times \Omega_2\) engendre la tribu \( \tribA_1\otimes\tribA_2\), est fermé par intersection et contient une suite croissante d'ensembles \( P_n\times R_n\) de mesure finie (\( \mu(P_n\times R_n)<\infty\)) telle que \( P_n\times R_n\to \Omega_1\times \Omega_2\). Cette suite est donné par le fait que \( \mu_1\) et \( \mu_2\) sont \( \sigma\)-finies. En effet si \( (X_n)\) et \( (Y_n)\) sont des recouvrements dénombrables de \( \Omega_1\) et \( \Omega_2\) par des ensembles de mesure finie, en posant \( P_n=\bigcup_{k=1}^nX_n\) et \( R_n=\bigcup_{k=1}^nY_n\) nous avons bien une suite croissante de rectangles qui tendent vers \( \Omega_1\times \Omega_2\). Avec ces rectangles en main, le théorème \ref{ThoJDYlsXu} donne l'unicité.

    Nous passons à l'existence de la mesure. Le théorème \ref{ThoCCIsLhO} dit que ces formules ont un sens et sont correctes. Il suffit donc de prouver que dans le cas des rectangles, ces formules se réduisent à \eqref{EqOIuWLQU}. Soit donc \( A=X_1\times X_2\) avec \( X_i\in\tribA_i\). Alors
    \begin{equation}
        A_1(y)=\{ x\in\Omega_1\tq (x,y)\in X_1\times X_2 \}
    \end{equation}
    et
    \begin{equation}
        \mu_1\big( A_1(y) \big)=\mtu_{X_2}(y)\mu_1(X_1),
    \end{equation}
    donc
    \begin{subequations}
        \begin{align}
            (\mu_1\otimes\mu_2)(A)&=\int_{\Omega_2}\mu_1\big( A_1(y) \big)d\mu_2(y)\\
            &=\int_{\Omega_2}\mu_1(X_1)\mtu_{X_2}(y)d\mu_2(y)\\
            &=\mu_1(X_1)\int_{\Omega_2}\mtu_{X_2}(y)d\mu_2(y)\\
            &=\mu_1(X_1)\mu_2(X_2).
        \end{align}
    \end{subequations}
    Pour cela nous avons utilisé le fait que l'intégrale de la fonction caractéristique d'un ensemble mesurable est la mesure de cet ensemble.
\end{proof}

\begin{definition}[Produit d'espaces mesurés]  \label{DefUMlBCAO}
    Si \( (\Omega_i,\tribA_i,\mu_i)\) sont deux espaces mesurés, l'\defe{espace produit}{produit!espaces mesurés} est l'ensemble \( \Omega_1\times \Omega_2\) muni de la tribu produit \( \tribA_1\otimes \tribA_2\) de la définition \ref{DefTribProfGfYTuR} et de la mesure produit \( \mu_1\otimes \mu_2\) définie par le théorème \ref{ThoWWAjXzi}.
\end{definition}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Théorème de Fubini-Tonelli et de Fubini}
%---------------------------------------------------------------------------------------------------------------------------

Il existe plusieurs résultats similaires. 
\begin{itemize}
    \item
        le théorème de Fubini-Tonelli \ref{ThoWTMSthY} demande que la fonction soit mesurable et positive;
    \item
        le théorème de Fubini \ref{ThoFubinioYLtPI} demande que la fonction soit intégrable (mais pas spécialement positive);
    \item
        le corollaire \ref{CorTKZKwP} demande l'intégrabilité de la valeur absolue des intégrales partielles pour déduire que la fonction elle-même est intégrable.
\end{itemize}

%TODO : des démonstrations de ces trois théorèmes seraient les bienvenues.

Nous rappelons que \( \eR^n\) muni de la mesure de Lebesgue est un espace mesuré \( \sigma\)-fini, conformément à la définition \ref{DefBTsgznn}.

\begin{theorem}[Fubini-Tonelli\cite{NBoIEXO}]\label{ThoWTMSthY}
    Soient \( (\Omega_i,\tribA_i,\mu_i)\) deux espaces mesurés \( \sigma\)-finis, et \( (\Omega,\tribA,\mu)\) l'espace produit. Soit une fonction \( f\colon \Omega_1\times \Omega_2\to \eR\) une fonction mesurable et positive (valant éventuellement \( \infty\) à certains endroits)
    Alors :
    \begin{enumerate}
        \item
            Les fonction
            \begin{equation}
                F_1\colon x\mapsto \int_{\Omega_2}f(x,y)d\mu_2(y)
            \end{equation}
            et
            \begin{equation}
                F_2\colon y\mapsto \int_{\Omega_1}f(x,y)d\mu_1(x)
            \end{equation}
            sont mesurables.
        \item
            Toutes les intégrales imaginables existent et sont égales :
            \begin{subequations}    \label{EqJRVtOGx}
                \begin{align}
                    \iint_{\Omega_1\times \Omega_2}f(x,y)d(\mu_1\otimes \mu_2)(x,y)&=\int_{\Omega_1}\left[ \int_{\Omega_2}f(x,y)d\mu_2(y) \right]d\mu_1(x)\\
                &=\int_{\Omega_2}\left[ \int_{\Omega_1}f(x,y)d\mu_1(x) \right]d\mu_2(y).
                \end{align}
            \end{subequations}
    \end{enumerate}
\end{theorem}
\index{théorème!Fubini-Tonelli}

\begin{proof}
    Commençons par prouver le théorème dans le cas d'une fonction caractéristique d'un ensemble mesurable : \( f(x,y)=\mtu_{A}(x,y)\) pour un certain ensemble \( A\subset \Omega_1\times \Omega_2\). Dans ce cas,
    \begin{equation}
        F_1(x)=\int_{\Omega_2}\mtu_A(x,y)d\mu_2(y)=\int_{\omega_2}\mtu_{A_1(y)}(x)d\mu_2(y)=\mu_2\big( A_1(x) \big),
    \end{equation}
    et nous avons déjà vu au théorème \ref{ThoCCIsLhO} que cette fonction \( F_1\) était alors mesurable. En utilisant maintenant les égalités \eqref{EqDFxuGtH} ainsi que le fait que \( \mtu_A(x,y)=\mtu_{A_2(x)}(y)\) nous avons
    \begin{subequations}
        \begin{align}
            \iint_{\Omega_1\times \Omega_2}\mtu_A(x,y)d(\mu_1\otimes \mu_2)(x,y)&=(\mu_1\otimes \mu_2)(A)\\
            &=\int_{\Omega_1}\mu_2\big( A_2(x) \big)d\mu_1(x)\\
            &=\int_{\Omega_1}\left[   \int_{\Omega_2}\mtu_{A_2(x)}(y)d\mu_2(y)  \right]d\mu_1(x)\\
            &=\int_{\Omega_1}\left[ \int_{\Omega_2}\mtu_A(x,y)d\mu_2(y) \right]d\mu_1(x).
        \end{align}
    \end{subequations}
    Le théorème étant valable pour les fonctions caractéristiques, il est valable pour les fonctions simples (définition \ref{DefBPCxdel}) par linéarité de l'intégrale.

    Si \( f\) n'est pas une fonction simple, alors la proposition \ref{PropWBavIf} nous donne une suite croissante de fonctions simples et positives convergeant ponctuellement vers \( f\). La partie du théorème sur les fonctions simples dit que pour chaque \( n\) l'intégrale
    \begin{equation}
        \iint_{\Omega_1\times \Omega_2}f_n(x,y)d(\mu_1\otimes\mu_2)(x,y)
    \end{equation}
    peut être décomposée comme il faut en suivant la formule \eqref{EqJRVtOGx}. Il faut pouvoir permuter la limite et l'intégrale dans chacun de cas. D'abord le théorème de la convergence monotone \ref{ThoRRDooFUvEAN} appliqué à l'espace \( \Omega_1\times \Omega_2\) dit que
    \begin{equation}
        \lim_{n\to \infty} \iint_{\Omega_1\times \Omega_2}f_n(x,y)d(\mu_1\otimes \mu_2)(x,y)= \iint_{\Omega_1\times \Omega_2}f(x,y)d(\mu_1\otimes \mu_2)(x,y).
    \end{equation}
    Ensuite, pour chaque \( x\in\Omega_1\), les fonctions
    \begin{equation}
        \sigma_n(y)=\int_{\Omega_1}f_n(x,y)d\mu_1(x)
    \end{equation}
    forment une suite croissante de fonctions mesurables; nous leur appliquons encore le théorème de la convergence monotone :
    \begin{subequations}
        \begin{align}
            \lim_{n\to \infty} \int_{\Omega_2}\left[ \int_{\Omega_1}f_n(x,y)d\mu_1(x) \right]d\mu_2(y)&=\lim_{n\to \infty} \int_{\Omega_2}\sigma_n(y)d\mu_2(y)\\
            &=\int_{\Omega_2}\left[\lim_{n\to \infty} \int_{\Omega_1}f_n(x,y)d\mu_1(x)\right]d\mu_2(y)\\
            &=\int_{\Omega_2}\left[ \int_{\Omega_1}f(x,y)d\mu_1(x) \right]d\mu_2(y)
        \end{align}
    \end{subequations}
    où nous avons utilisé une seconde fois Beppo-Levi.
\end{proof}

\begin{theorem}[Fubini\cite{MesIntProbb}]\label{ThoFubinioYLtPI}
    Soient \( (\Omega_i,\tribA_i,\mu_i)\) deux espaces mesurés \( \sigma\)-finis, et \( (\Omega,\tribA,\mu)\) l'espace produit. Soit 
    \begin{equation}
        f\in L^1\big( (\Omega,\tribA),\eR \big),
    \end{equation}
    c'est à dire une fonction à valeurs réelles mesurable et intégrable sur \( \Omega\). Alors :
    \begin{enumerate}
        \item
            Pour presque tout \( x\in \Omega_1\), la fonction \( y\mapsto f(x,y)\) est \( L^1(\Omega_2)\).
        \item
            Si nous posons
            \begin{equation}
                \varphi_f(x)=\int_{\Omega_2}f(x,y)d\mu_2(y);
            \end{equation}
            alors \( \varphi_f\in L^1(\Omega_1)\).
        \item   \label{ItemQMWiolgiii}
            Nous avons la formule d'inversion d'intégrale
            \begin{subequations}
                \begin{align}
                \int_{\Omega}fd(\mu_1\otimes \mu_2)&=\int_{\Omega_1}\varphi_fd\mu_1\\
                &=\int_{\Omega_1}\left[ \int_{\Omega_2}f(x,y)d\mu_2(y) \right]d\mu_1(x)\\
                &=\int_{\Omega_2}\left[ \int_{\Omega_1}f(x,y)d\mu_1(x) \right]d\mu_2(y).
                \end{align}
            \end{subequations}
    \end{enumerate}
\end{theorem}
\index{théorème!Fubini!espace mesuré}

Si la fonction \( (x,y)\mapsto f(x)g(y)\) satisfait aux hypothèse du théorème de Fubini alors
\begin{equation}    \label{EqTJEEsJW}
    \int_{\Omega_1\times \Omega_2} f(x)g(y)dx\otimes dy=\left( \int_{\Omega_1}f(x)dx \right)\left( \int_{\Omega_2}g(y)dy \right).
\end{equation}
Le théorème de Fubini est souvent utilisé sous cette forme.

\begin{corollary}\label{CorTKZKwP}
    Soient \( (\Omega_i,\tribA_i,\mu_i)\) deux espaces mesurés \( \sigma\)-finis, et \( (\Omega,\tribA,\mu)\) l'espace produit\footnote{Définition \ref{DefUMlBCAO}.}. Soit une fonction mesurable \( f\colon \Omega\to \eR\). Alors les conditions suivantes sont équivalentes
    \begin{enumerate}
        \item
            \( f\in L^1(\Omega)\),
        \item
            \begin{equation}
                \int_{\Omega_1}\left[ \int_{\Omega_2}| f |d\mu_2 \right]d\mu_1 <\infty,
            \end{equation}
        \item
            \begin{equation}
                \int_{\Omega_2}\left[ \int_{\Omega_1}| f |d\mu_1 \right]d\mu_2 <\infty.
            \end{equation}
    \end{enumerate}
\end{corollary}
En pratique, lorsqu'on ne sait pas a priori si \( f\) est intégrable sur \( \Omega_1\times \Omega_2\), nous testons l'intégrabilité en chaine de \( | f |\), et si c'est bon, alors nous savons que \( f\) est intégrable sur le produit et qu'on peut permuter les intégrales.

\begin{example}
    Nous montrons que le théorème ne tient pas si une des deux mesures n'est pas \( \sigma\)-finie. Soit \( I=\mathopen[ 0 , 1 \mathclose]\). Nous considérons l'espace mesuré
    \begin{equation}
        (I,\Borelien(I),\lambda)
    \end{equation}
    où \( \Borelien(I)\) est la tribu des boréliens sur \( I\) et \( \lambda\) est la mesure de Lebesgue (qui est $\sigma$-finie). D'autre part nous considérons l'espace mesuré
    \begin{equation}
        (I,\partP(I),m)
    \end{equation}
    où \( \partP(I)\) est l'ensemble des parties de \( I\) et \( m\) est la mesure de comptage. Cette dernière n'est pas $\sigma$-finie parce que les seuls ensembles de mesure finie pour la mesure de comptage sont des ensembles finis, or une union dénombrable d'ensemble finis ne peut pas recouvrir l'intervalle \( I\).

    Nous allons montrer que dans ce cadre, l'intégrale de la fonction indicatrice de la diagonale sur \( I^2\) ne vérifie pas le théorème de Fubini. Étant donné que \( \Borelien(I)\subset\partP(I)\) nous avons
    \begin{equation}
        \Borelien(I^2)\subset\Borelien(I)\otimes\partP(I).
    \end{equation}
    Soit \( \Delta=\{ (x,x)\tq x\in I \}\). La fonction
    \begin{equation}
        \begin{aligned}
            g\colon I^2&\to \eR \\
            (x,y)&\mapsto x-y 
        \end{aligned}
    \end{equation}
    est continue et \( \Delta=g^{-1}(\{ 0 \})\) est donc fermé dans \( I^2\). L'ensemble \( \Delta\) est donc un borélien de \( I^2\) et par conséquent un élément de la tribu \( \Borelien(I)\otimes\partP(I)\). La fonction indicatrice \( \mtu_{\Delta}\) est alors mesurable pour l'espace mesuré
    \begin{equation}
        (I\times I,\Borelien(I)\otimes\partP(I),\lambda\otimes m).
    \end{equation}
    Pour \( x\) fixé nous avons
    \begin{equation}
        \mtu_{\Delta}(x,y)=\begin{cases}
            1    &   \text{si \( y= x\)}\\
            1    &    \text{si \( y\neq x\)}
        \end{cases}=\mtu_{\{ x \}}(y),
    \end{equation}
    et donc
    \begin{subequations}
        \begin{align}
            A_1&=\int_I\left( \int_I\mtu_{\Delta}(x,y)dm(y) \right)d\lambda(x)\\
            &=\int_I\left( \int_I\mtu_{\{ x \}}(y)dm(y) \right)d\lambda(x)\\
            &=\int_I\Big( m(\{ x \}) \Big)d\lambda(x)\\
            &=\int_I 1d\lambda(x)\\
            &=1.
        \end{align}
    \end{subequations}
    Par contre le support de \( \mtu_{\Delta}\) étant de mesure nulle pour la mesure de Lebesgue, nous avons
    \begin{equation}
        \int_I\mtu_{\Delta}(x,y)d\lambda(x)=0
    \end{equation}
    et par conséquent
    \begin{equation}
        A_2=\int_I\left( \int_I\mtu_{\Delta}(x,y)d\lambda(x) \right)dm(y)=0.
    \end{equation}
    Nous voyons donc que le théorème de Fubini ne s'applique pas.
\end{example}

\begin{example} \label{ExrgMIni}
    Le théorème de Fubini est utilisé dans le calcul de l'intégrale gaussienne
    \begin{equation}
        G=\int_{\eR} e^{-x^2}dx,
    \end{equation}
    alors que la fonction \( x\mapsto  e^{-x^2}\) n'a pas de primitives parmi les fonctions élémentaires.

    Par symétrie nous pouvons nous contenter de calculer
    \begin{equation}
        G_+=\int_0^{\infty} e^{-x^2}dx.
    \end{equation}
    L'astuce est de passer par l'intermédiaire
    \begin{subequations}
        \begin{align}
            H&=\int_{\eR^+\times\eR^+} e^{-(x^2+y^2)}dxdy       \label{EqIntFausasub}\\
            &=\int_{\eR^+}\left( \int_{\eR^+} e^{-x^2} e^{-y^2}dx \right)dy\\
            &=\left( \int_{\eR^+} e^{-x^2} dx\right)^2\\
            &=G_+^2
        \end{align}
    \end{subequations}
    L'intégrale \eqref{EqIntFausasub} se calcule en passant aux coordonnées polaires et le résultat est \( H=\frac{ \pi }{ 4 }\). Nous avons alors \( G=\frac{ \sqrt{\pi} }{ 2 }\) et
    \begin{equation}
        \int_{\eR} e^{-x^2}=\sqrt{\pi}.
    \end{equation}
\end{example}

\begin{example}
    Une variante, qui n'applique pas Fubini sur un domaine non borné. Nous commençons par écrire
\begin{equation}
	I=\int_{-\infty}^{+\infty} e^{-x^2} dx := \lim_{R \to +\infty} \int_{-R}^{+R} e^{-x^2} dx 
\end{equation}
et puis nous faisons le calcul
\begin{equation}		\label{EqCalculInteeemoisxcar}
	\begin{aligned}[]
		I^2 &= \lim_{R \to +\infty} \left( (\int_{-R}^{+R} e^{-x^2} dx)( \int_{-R}^{+R} e^{-y^2} dy) \right) \\
		&= \lim_{R \to +\infty} \left( \iint_{K_R}e^{-(x^2+y^2)} dx dy \right) \\
		&= \lim_{R \to +\infty} \left( \iint_{C_R}e^{-(x^2+y^2)} dx dy \right) 
	\end{aligned}
\end{equation}
où $K$ est le carré de demi côté $R$ centré à l'origine et de côtés parallèles aux axes et $C_R$ est le cercle de rayon $R$ centré à l'origine.

	La première étape à justifier est simplement l'application de Fubini. Pour le passage de l'intégrale du carré vers le cercle, définissons
	\begin{equation}
		\begin{aligned}[]
			I_K(r)&=\int_{K_r}f,&I_C(r)&=\int_{C_r}f
		\end{aligned}
	\end{equation}
	où $K_r$ est la carré de demi côté $r$ et $C_r$ est le cercle de rayon $r$. Le demi côté du carré inscrit à $C_r$ est $\sqrt{2}$, donc pour tout $r$ nous avons
	\begin{equation}
		I_K(\sqrt{2}r)\leq I_C(r)<I_K(r),
	\end{equation}
	et en prenant la limite, nous avons évidement
	\begin{equation}
		\lim_{r\to \infty}I_K(\sqrt{2}r)=\lim_{r\to\infty}I_K(r),
	\end{equation}
	de telle façon à ce que cette limite soit également égale à $\lim_{r\to\infty}I_C(t)$.


    Il ne reste qu'à calculer la dernière intégrale sur le cercle en passant aux coordonnées polaires :
	\begin{equation}
        \iint_{C_R} e^{-(x^2+y^2)}dxdy=\int_0^{2\pi}d\theta\int_0^Rr e^{-r^2}dr=\pi(1- e^{-R^2}).
	\end{equation}
	La limite donne $\pi$, nous en déduisons que
    \begin{equation}    \label{EqFDvHTg}
		\int_{-\infty}^{\infty} e^{-x^2}dx=\sqrt{\pi}.
	\end{equation}

\end{example}

Le théorème de Fubini-Tonelli nous permet également d'inverser des sommes et des séries. En effet une somme n'est rien d'autre qu'une intégrale pour la mesure de comptage :
\begin{equation}
    \sum_{n=0}^{\infty}a_n=\int_{\eN}a_ndm(n).
\end{equation}
La proposition suivante montre comment il faut faire.

\begin{proposition}\label{PropInversSumIntFub}  
    Soient les espaces mesurés \( (\eN,\partP(\eN),m)\), \( (\eR^n,\Borelien(\eR^n),\lambda)\) où \( \lambda\) est la mesure de Lebesgue ainsi qu'une suite de fonctions positives \( f_n\colon \eR^d\to \eR\). Nous supposons de plus que la fonction \( f_n\) soit intégrable pour tout \( n\) et que les résultats forment une suite sommable. Alors
    \begin{equation}   
        \sum_{n=0}^{\infty}\int_{\eR^n}f_n(x)dx=\int_{\eR^d}\sum_{n\in \eN}f_n(x)dx.
    \end{equation}
\end{proposition}
\index{mesure!de comptage}
\index{permuter!intégrale!et série}

\begin{proof}
    Nous pouvons la récrire le membre de gauche sous la forme
    \begin{equation}
        \int_{\eN}\left( \int_{\eR^n}f(n,x)dx \right)dm(n)
    \end{equation}
    avec la notation évidente \( f(n,x)=f_n(x)\). Prouvons que la fonction \( f\colon \eN\times\eR^d\to \eR\) ainsi définie est une fonction mesurable pour l'espace mesuré
    \begin{equation}
        \big( \eN\times\eR^d,\partP(\eN)\otimes\Borelien(\eR^d),m\otimes\lambda \big).
    \end{equation}
    Si \( A\subset\eR\), nous avons
    \begin{equation}
        f^{-1}(A)=\bigcup_{n\in\eN}\{ n \}\times f_n^{-1}(A).
    \end{equation}
    Chacun des ensembles dans l'union appartient à la tribu \( \partP(\eN)\times\Borelien(\eR^d)\) tandis que les tribus sont stables sous les unions dénombrables. La fonction \( f\) est donc mesurable. Comme nous avons supposé que \( f\) était positive, le théorème de Fubini-Tonelli s'applique et nous avons
    \begin{equation}
        \int_{\eR^d}\left( \int_{\eN}f(n,x)dm(n) \right)dx=\int_{\eR^d}\sum_{n\in \eN}f_n(x)dx.
    \end{equation}
\end{proof}

\begin{theorem}[Fubini]\label{ThoFubini}
Soit $(x,t)\mapsto f(x,y)\in\bar \eR$ une fonction intégrable sur $B_n\times B_m\subset\eR^{n+m}$ où $B_n$ et $B_m$ sont des ensembles mesurables de $\eR^n$ et $\eR^m$. Alors :
\begin{enumerate}
\item pour tout $x\in B_n$, sauf éventuellement en les points d'un ensemble $G\subset B_n$ de mesure nulle, la fonction $y\in B_m\mapsto f(x,y)\in\bar\eR$ est intégrable sur $B_m$
\item
la fonction
\begin{equation}
	x\in B_n\setminus G\mapsto\int_{B_m}f(x,y)dy\in\eR
\end{equation}
est intégrable sur $B_n\setminus G$

\item 
On a
\begin{equation}
	\int_{B_n\times B_m}f(x,y)dxdy=\int_{B_n}\left( \int_{B_m}f(x,y)dy \right)dx.
\end{equation}

\end{enumerate}
\end{theorem}
\index{théorème!Fubini!dans $ \eR^n$}
\index{Fubini!théorème!dans $ \eR^n$}


Notons en particulier que si $f(x,y)=\varphi(x)\phi(y)$, alors $\int_{B_m}\varphi(y)dy$ est une constante qui peut sortir de l'intégrale sur $B_n$, et donc
\begin{equation}		\label{EqFubiniFactori}
	\int_{B_n\times B_m}\varphi(x)\phi(y)dxdy=\int_{B_n}\varphi(x)dx\int_{B_m}\phi(y)dy.
\end{equation}

%++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Changement de variables dans une intégrale}
%++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Le théorème de changement de variables est long. Il nous faut beaucoup de lemmes pour commencer\ldots dans toutes la suite, \( U\) et \( V\) sont des ouverts de \( \eR^N\) et \( \phi\colon U\to V\) est une \( C^1\)-difféomorphisme.

\begin{lemma}
    soient des ouverts \( U\) et \( V\) de \( \eR^N\) et un \( C^1\)-difféomorphisme \( \phi\colon U\to V\). Si \( E\subset U\) est borélien, alors \( \phi(E)\) l'est.
\end{lemma}

\begin{proof}
    Soit \( \psi=\phi^{-1}\); c'est une application continue et donc borélienne\footnote{Par le théorème \ref{ThoJDOKooKaaiJh}.}. Étant donné que \( \phi\) et \( \psi\) sont des bijections, nous avons \( \psi(\phi(E))=E\) et donc \( \phi(E)=\psi^{-1}(E)\). L'ensemble \( \phi(E)\) est donc image inverse d'un borélien par une application continue (et donc borélienne).
\end{proof}

\begin{theorem}[Changement de variable\cite{VSMEooLwNLHd}]
    Soient \( U\) et \( V\) des ouverts de \( \eR^N\) ainsi qu'un \( C^1\)-difféomorphisme \(\phi\colon U\to V\).
    \begin{enumerate}
        \item
            Si \( E\subset U\) est mesurable, alors \( \phi(E)\) est mesurable et
            \begin{equation}
                \lambda_N\big( \phi(E) \big)=\int_E| J_{\phi} |d\lambda_N.
            \end{equation}
        \item
            Si \( f\colon V\to \mathopen[ 0 , +\infty \mathclose]\) est mesurable alors la fonction
            \begin{equation}
                (f\circ\phi)\times | J_{\phi} |\colon U\to \mathopen[ 0 , \infty \mathclose]
            \end{equation}
            l'est également et
            \begin{equation}
                \int_Vfd\lambda_N=\int_U(f\circ\phi)(x)| J_{\phi}(x) |d\lambda_N(x).
            \end{equation}
        \item
            Si \( f\colon V\to \eC\) est mesurable alors elle est intégrable si et seulement si \( (f\circ \phi)\times | J_{\phi} |\colon U\to \eC\) est intégrable.

        \item

            Si \( f\colon V\to \eC\) est mesurable et intégrable alors
            \begin{equation}
                \int_Vfd\lambda_N=\int_U (f\circ \phi)| J_{\phi} |d\lambda_N.
            \end{equation}
    \end{enumerate}
\end{theorem}

% Attention : ce théorème est utilisé avec \varphi dans ce sens-ci.
\begin{theorem} \label{ThomFeRCi}
    Soit \( \mO\) un ouvert de \( \eR^n\) et \( \varphi\colon \mO\to \varphi(\mO)\) un difféomorphisme \( C^1\). Si \( f\colon \mO\to \eR\) est une fonction mesurable, positive et intégrable, alors
    \begin{equation}
        \int_{\mO}f(u)du=\int_{\varphi(\mO)}f\big( \varphi^{-1}(v) \big)| J_{\varphi^{-1}}(v) |dv.
    \end{equation}
\end{theorem}

\begin{theorem}		\label{ThoChmVarInt}
  Soient $U$ et $V$ deux ouverts bornés de $\eR^p$, $\phi$ un difféomorphisme de classe $\mathcal{C}^1$ de $U$ sur $V$ et $f$ une fonction intégrable de $V$ sur $\eR$. Alors nous avons la formule de changement de variables 
  \begin{equation}
    \int_{V}f(y)\, dy= \int_{U} f(\phi(x))\, \left| J_{\phi}(x)\right|\, dx,
  \end{equation}
  où $J_{\phi}$ est le déterminant de la matrice jacobienne\index{jacobienne} de $\phi$. 
\end{theorem}
Si $\phi$ est linéaire  alors le facteur $|J_{\phi}|$ est la mesure de l'image par $\phi$ d'une portion de $\eR^p$ de mesure $1$, sinon  $|J_{\phi}|$ est le rapport entre la mesure de l'image d'un élément infinitésimale de volume de $\eR^p$ et sa mesure originale. 
Soit $\phi(u,v)=g(u,v)e_1+h(u,v)e_2$ un difféomorphisme dans $\eR^2$. Soit $(x_0, y_0)$ l'image par $\phi$ de $(u_0,v_0)$. On considère le petit rectangle $R$ de sommets $(u_0,v_0)$, $(u_0+\Delta u,v_0)$, $(u_0+\Delta u,v_0+\Delta v)$ et $(u_0,v_0+\Delta v)$. L'image de $R$ n'est pas un rectangle en général, mais peut être bien approximée par le rectangle de sommets $(x_0,y_0)$, $(x_0 ,y_0)+ \phi_{u}\Delta u$, $(x_0 ,y_0)+\phi_{u}\Delta u +\phi_{v}\Delta v$ et  $(x_0 ,y_0)+ \phi_{v}\Delta v$ et son aire est $\| \phi_{u}\times \phi_{v}\| \Delta u\Delta v$. La valeur $|\phi_{u}\times \phi_{v}|$ est exactement $|J_{\phi}|$ 

\begin{example}
Soit $V$ la région trapézoïdale de sommets $(0,-1)$, $(1,0)$, $(2,0)$, $(0,-2)$, comme à la figure \ref{LabelFigZTTooXtHkcissLabelSubFigZTTooXtHkci0}. Calculons ensemble l'intégrale double  
\[
\int_{V}e^{\frac{x+y}{x-y}}\,dV,
\] 
avec le changement de variable $\psi(x,y)=(x+y,x-y)$. C'est à dire que nous considérons les nouvelles variables
\begin{subequations}
	\begin{numcases}{}
		u=x+y\\
		v=x-y.
	\end{numcases}
\end{subequations}
Il faut remarquer d'abord que le changement de variable proposé est dans le mauvais sens. On écrit alors $\phi(u,v)=\psi^{-1}(u,v)=\big((u+v)/2, (u-v)/2\big)$, c'est à dire
\begin{subequations}
	\begin{numcases}{}
		x=\frac{ u+v }{ 2 }\\
		y=\frac{ u-v }{2}.
	\end{numcases}
\end{subequations}
La région qui correspond à $V$ est $U$, le trapèze de sommets  $(-1,1)$, $(1,1)$, $(2,2)$ et $(-2,2)$, qu'on voit sur la figure \ref{LabelFigZTTooXtHkcissLabelSubFigZTTooXtHkci1} et qu'on décrit par
\[
U=\{ (u,v)\in\eR^2\,\vert\, 1\leq v\leq 2, \, -v\leq u\leq v\}.
\] 

% Celui-ci a été supprimée le 17 juillet 2014
%\ref{LabelFigexamplechangementvariables}
%\newcommand{\CaptionFigexamplechangementvariables}{Avant et après le changement de variables}
%\input{Fig_examplechangementvariables.pstricks}

%The result is on figure \ref{LabelFigZTTooXtHkci}. % From file ZTTooXtHkci
%See also the subfigure \ref{LabelFigZTTooXtHkcissLabelSubFigZTTooXtHkci0}
%See also the subfigure \ref{LabelFigZTTooXtHkcissLabelSubFigZTTooXtHkci1}
\newcommand{\CaptionFigZTTooXtHkci}{Avant et après le changement de variables}
\input{Fig_ZTTooXtHkci.pstricks}

On observe que $U$ est une région du premier type tandis que $V$ n'est pas du premier ou du deuxième type. Le déterminant de la  matrice  jacobienne de $\psi^{-1}$ est  $J_{\psi^{-1}}$,
\begin{equation}
 J_{\psi^{-1}}(u,v)= \left\vert\begin{array}{cc}
\frac{1}{2} & \frac{1}{2} \\
\frac{1}{2}  & -\frac{1}{2}
\end{array}\right\vert= -\frac{1}{2}.
\end{equation}
On a alors 
\[
\int_{V}e^{\frac{x+y}{x-y}}\,dV=\int_{U}e^{\frac{u}{v}}\,\frac{1}{2}\,dV=\int_1^2\int_{-v}^{v}e^{\frac{u}{v}}\,\frac{1}{2}\, du\,dv= \frac{3}{4}(e-e^{-1}).
\] 
\end{example}

\begin{example} 
\textbf{Coordonnées polaires : }On veut évaluer l'intégrale de la fonction $f(x,y)= x^2+y^2$ sur la région $V$ suivante :
\[
V=\{(x,y) \in \eR^2\,\vert\, x^2+y^2\leq 1,\, x>0,\, y>0\}.
\]
On peut faire le calcul directement,
\[
\int_{V}f(x,y)\, dV=\int_0^1\int_0^{\sqrt{1-x^2}}x^2+y^2\, dy\,dx=\int_0^1x^2\sqrt{1-x^2} + \frac{(1-x^2)^{3/2}}{3}\, dx  
\] 
mais c'est un peu ennuyeux. On peut simplifier beaucoup les calculs avec un changement de variables vers les coordonnées polaires. Dans ce cas, on sait bien que le difféomorphisme à utiliser est $\phi(r,\theta)=(r\cos \theta, r\sin\theta)$. Le jacobien  $J_{\phi}$ est
\begin{equation}
 J_{\phi}(r, \theta)= \left\vert\begin{array}{cc}
\cos \theta & \sin \theta \\
-r\sin \theta  & r\cos \theta
\end{array}\right\vert= r,
\end{equation}
qui est toujours positif. La fonction $f$ peut s'écrire comme $f(\phi(r,\theta))=r^2$ et $\phi^{-1}(V)=]0,1]\times]0, \pi/2[$.  
La formule du changement de variables nous donne
\[
\int_{V}f(x,y)\, dV=\int_0^{\pi/2}\int_0^{1}r^3 dr\,d\theta=\int_0^{\pi/2}\frac{1}{4}\,d\theta=\frac{\pi}{8}.  
\] 
\end{example}

\begin{example}
\textbf{Coordonnées cylindriques : }On veut calculer le volume de la région $A$ définie par  l'intersection entre la boule unité et le cylindre qui a pour base un disque de rayon $1/2$ centré en $(0, 1/2)$
\[
A=\{(x,y,z) \in\eR^3 \,\vert\, x^2+y^2+z^1\leq 1\}\cap\{(x,y,z) \in \eR^3\,\vert\, x^2+(y-1/2)^2\leq 1/4\}.
\]
On peut décrire $A$ en coordonnées cylindriques
\begin{equation}
  \begin{aligned}
    A=\Big\{(r,\theta,z) &\in ]0, +\infty[\times [-\pi,\pi[\times \eR\,\vert\,\\
& -\pi/2<\theta<\pi, \, 0<r\leq \sin\theta, \, -\sqrt{1-r^2}\leq z\leq\sqrt{1-r^2} \Big\}.
  \end{aligned}
\end{equation}
Le jacobien de ce changement de variables,  $J_{cyl}$, est
\begin{equation}
 J_{cyl}(r, \theta), z= \left\vert\begin{array}{ccc}
\cos \theta & \sin \theta & 0\\
-r\sin \theta  & r\cos \theta &0 \\
0&0&
\end{array}\right\vert= r,
\end{equation}
qui est toujours positif. Le volume de $A$ est donc
\[
\int_{\eR^3}\chi_{A}(x,y,z)\, dV=\int_{-\pi/2}^{\pi/2}\int_0^{\sin\theta}\int_{-\sqrt{1-r^2}}^{\sqrt{1-r^2}} r dz\,dr\,d\theta=\frac{2\pi}{8}+\frac{8}{9}.  
\] 
\end{example}

\begin{example}
\textbf{Volume d'un solide de révolution : }Soit $g:[a,b]\to\eR_+$ une fonction continue et positive. On dit que le solide $A$ décrit par
\[
A=\left\{(x,y,z)\in\eR^3\, \vert \, z\in[a,b], \,\sqrt{x^2+y^2}\leq g^2(z) \right\}
\]
est un solide de révolution. Afin de calculer son volume, on peut décrire $A$ en coordonnées cylindriques, 
\[
A=\left\{(r,\theta,z) \in ]0, +\infty[\times [-\pi,\pi[\times \eR\,\vert\, a\leq z\leq b, \, 0<r^2\leq g^2(z) \right\}.
\]
Le jacobien de ce changement de variables est  $J_{cyl}=r$, comme dans l'exemple précédent. Le volume de $A$ est donc
\[
\int_{\eR^3}\chi_{A}(x,y,z)\, dV=\int_a^{b}\int_{-\pi}^{\pi}\int_{0}^{g(z)} r  \,dr\,d\theta\, dz=\int_a^{b} \pi g^2(z) \, dz.
\] 
Cette formule peut être utilisée pour tout solide de révolution. 
\end{example}

\begin{example}
\textbf{Coordonnées sphériques : }On veut calculer le volume du cornet de glace  $A$ 
\[
A=\left\{(x,y,z)\in\eR^3\, \vert \, (x,y)\in \mathbb{S}^2, \,\sqrt{x^2+y^2}\leq z\leq \sqrt{1-x^2-y^2} \right\}. 
\]
On peut décrire $A$ en coordonnées sphériques. 
\[
A=\{(\rho,\theta,\phi) \in ]0, +\infty[\times [-\pi,\pi[\times [0,\pi[\,\vert\, 0<\phi\leq\pi/4, \, 0<\rho\leq 1 \}.
\]
Le jacobien de ce changement de variables  $J_{sph}$ est
\begin{equation}
 J_{sph}(\rho, \theta, \phi)= \left\vert\begin{array}{ccc}
\cos \theta \sin\phi & \sin \theta\sin\phi & \cos\phi\\
-\rho\sin \theta\sin\phi  & \rho\cos \theta\sin\phi & 0 \\
\rho\cos\theta\cos\phi&\rho\sin\theta\cos\phi& -\rho\sin\phi
\end{array}\right\vert= \rho^2\sin\phi,
\end{equation}
Le volume de $A$ est donc
\[
\int_{\eR^3}\chi_{A}(x,y,z)\, dV=\int_{-\pi}^{\pi}\int_0^{\pi/4}\int_{0}^{1}\rho^2\sin\phi \,d\rho\,d\phi\,d\theta=\frac{2\pi}{3}\left(1-\frac{1}{\sqrt{2}}\right).  
\] 
\end{example}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Récapitulatif des changements de variables}
%---------------------------------------------------------------------------------------------------------------------------

En pratique, nous retiendrons les formules suivantes:
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Coordonnées polaires}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

\begin{subequations}
    \begin{numcases}{}
        x=r\cos\theta\\
        y=r\sin\theta
    \end{numcases}
\end{subequations}
avec \( r\in\mathopen] 0 , \infty \mathclose[\) et \( \theta\in\mathopen[ 0 , 2\pi [\). Le jacobien vaut \( r\).

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Coordonnées cylindriques}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

\begin{subequations}
    \begin{numcases}{}
        x=r\cos\theta\\
        y=r\sin\theta\\
        z=z
    \end{numcases}
\end{subequations}
avec \( r\in\mathopen] 0 , \infty \mathclose[\), \( \theta\in\mathopen[ 0 , 2\pi [\) et \( z\in\eR\). Le jacobien vaut \( r\).

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Coordonnées sphériques}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

\begin{subequations}
    \begin{numcases}{}
        x=\rho\cos\theta\sin\phi\\
        y=\rho\sin\theta\sin\phi\\
        z=\rho\cos\phi
    \end{numcases}
\end{subequations}
avec \( \rho\in\mathopen] 0 , \infty \mathclose[\), \( \theta\in\mathopen[ 0 , 2\pi [\) et \( \phi\in\mathopen[ 0 , \pi [\). Le jacobien vaut \( -\rho^2\sin(\phi)\). 

N'oubliez pas que lorsqu'on effectue un changement de variables dans une intégrale, la \emph{valeur absolue} du jacobien apparaît.

Cependant notre convention de coordonnées sphériques fait venir \( \sin(\phi)\) avec \( \phi\in\mathopen[ 0 , \pi [\); vu que le signe de \( \sin(\phi)\) y est toujours positif, cette histoire de valeur absolue est sans grandes conséquent. Ce n'est pas le cas de toutes les conventions possibles.

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Changement de variables}
%---------------------------------------------------------------------------------------------------------------------------

Le domaine $E=\{ (x,y)\in\eR^2\tq x^2+y^2<1 \}$ s'écrit plus facilement $E=\{ (r,\theta)\tq r<1 \}$ en coordonnées polaires. Le passage aux coordonnées polaire permet de transformer une intégration sur un domaine rond à une intégration sur le domaine rectangulaire $\mathopen]0,2\pi\mathclose[\times\mathopen]0,1\mathclose[$. La question est évidement de savoir si nous pouvons écrire
\begin{equation}
	\int_Ef=\int_{0}^{2\pi}\int_0^1f(r\cos\theta,r\sin\theta)drd\theta.
\end{equation}
Hélas, non; la vie n'est pas aussi simple.

\begin{theorem}
Soit $g\colon A\to B$ un difféomorphisme. Soient $F\subset B$ un ensemble mesurable et borné et $f\colon F\to \eR$ une fonction bornée et intégrable. Supposons que $g^{-1}(F)$ soit borné et que $Jg$ soit borné sur $g^{-1}(F)$. Alors
\begin{equation}
	\int_Ff(x)dy=\int_{g^{-1}(F)f\big( g(x) \big)}| Jg(x) |dx
\end{equation}
\end{theorem}
Pour rappel, $Jg$ est le déterminant de la matrice \href{http://fr.wikipedia.org/wiki/Matrice_jacobienne}{jacobienne} (aucun lien de \href{http://fr.wikipedia.org/wiki/Jacob}{parenté}) donnée par
\begin{equation}
	Jg=\det\begin{pmatrix}
	\partial_xg_1	&	\partial_yg_1	\\ 
	\partial_xg_2	&	\partial_tg_2	
\end{pmatrix}.
\end{equation}
Un \defe{difféomorphisme}{difféomorphisme} est une application $g\colon A\to B$ telle que $g$ et $g^{-1}\colon B\to A$ soient de classe $C^1$.

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
					\subsubsection{Coordonnées polaires}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Les coordonnées polaires sont données par le difféomorphisme
\begin{equation}
	\begin{aligned}
		g\colon \mathopen]0,\infty\mathclose[\times\mathopen]0,2\pi\mathclose[ &\to\eR^2\setminus D\\
		(r,\theta)&\mapsto \big( r\cos(\theta),r\sin(\theta) \big)
	\end{aligned}
\end{equation}
où $D$ est la demi droite $y=0$, $x\geq 0$. Le fait que les coordonnées polaires ne soient pas un difféomorphisme sur tout $\eR^2$ n'est pas un problème pour l'intégration parce que le manque de difféomorphisme est de mesure nulle dans $\eR^2$. Le jacobien est donné par
\begin{equation}
	Jg=\det\begin{pmatrix}
	\partial_rx	&	\partial_{\theta}x	\\ 
	\partial_ry	&	\partial_{\theta}y
\end{pmatrix}=\det\begin{pmatrix}
	\cos(\theta)	&	-r\sin(\theta)	\\ 
	\sin(\theta)	&	r\cos(\theta)	
\end{pmatrix}=r.
\end{equation}

\begin{example}    
    Montrons comment intégrer la fonction $f(x,y)=\sqrt{1-x^2-y^2}$ sur le domaine délimité par la droite $y=x$ et le cercle $x^2+y^2=y$, représenté sur la figure \ref{LabelFigQXyVaKD}. Pour trouver le centre et le rayon du cercle $x^2+y^2=y$, nous commençons par écrire $x^2+y^2-y=0$, et ensuite nous reformons le carré : $y^2-y=(y-\frac{ 1 }{2})^2-\frac{1}{ 4 }$.
    \newcommand{\CaptionFigQXyVaKD}{Passage en polaire pour intégrer sur un morceau de cercle.}
\input{Fig_QXyVaKD.pstricks}

    Le passage en polaire transforme les équations du bord du domaine en
    \begin{equation}
        \begin{aligned}[]
            \cos(\theta)&=\sin(\theta)\\
            r^2&=r\sin(\theta).
        \end{aligned}
    \end{equation}
    L'angle $\theta$ parcours donc $\mathopen] 0 , \pi/4 \mathclose[$, et le rayon, pour chacun de ces $\theta$ parcours $\mathopen] 0 , \sin(\theta) \mathclose[$. La fonction à intégrer se note maintenant $f(r,\theta)=\sqrt{1-r^2}$. Donc l'intégrale à calculer est
    \begin{equation}		\label{PgRapIntMultFubiniBoutCercle}
        \int_{0}^{\pi/4}\left( \int_0^{\sin(\theta)}\sqrt{1-r^2}r\,rd \right).
    \end{equation}
    Remarquez la présence d'un $r$ supplémentaire pour le jacobien.

    Notez que les coordonnées du point $P$ sont $(1,1)$.
\end{example}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Coordonnées sphériques}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Les coordonnées sphériques sont données par
\begin{equation}		\label{EqChmVarSpherique}
	\left\{
\begin{array}{lllll}
x=r\cos\theta\sin\varphi	&			&r\in\mathopen] 0 , \infty \mathclose[\\
y=r\sin\theta\sin\varphi	&	\text{avec}	&\theta\in\mathopen] 0 , 2\pi \mathclose[\\
z=r\cos\varphi			&			&\phi\in\mathopen] 0 , \pi \mathclose[.
\end{array}
\right.
\end{equation}
Le jacobien associé est $Jg(r,\theta,\varphi)=-r^2\sin\varphi$. Rappelons que ce qui rentre dans l'intégrale est la valeur absolue du jacobien.

Si nous voulons calculer le volume de la sphère de rayon $R$, nous écrivons donc
\begin{equation}
	\int_0^Rdr\int_{0}^{2\pi}d\theta\int_0^{\pi}r^2 \sin(\phi)d\phi=4\pi R=\frac{ 4 }{ 3 }\pi R^3.
\end{equation}
Ici, la valeur absolue n'est pas importante parce que lorsque $\phi\in\mathopen] 0,\pi ,  \mathclose[$, le sinus de $\phi$ est positif.

Des petits malins pourraient remarquer que le changement de variable \eqref{EqChmVarSpherique} est encore une paramétrisation de $\eR^3$ si on intervertit le domaine des angles : 
\begin{equation}
	\begin{aligned}[]
		\theta&\colon 0 \to \pi\\
		\phi	&\colon 0\to 2\pi,
	\end{aligned}
\end{equation}
alors nous paramétrons encore parfaitement bien la sphère, mais hélas
\begin{equation}		\label{EqVolumeIncorrectSphere}
	\int_0^Rdr\int_{0}^{\pi}d\theta\int_0^{2\pi}r^2 \sin(\phi)d\phi=0.
\end{equation}
Pourquoi ces «nouvelles» coordonnées sphériques sont-elles mauvaises ? Il y a que quand l'angle $\phi$ parcours $\mathopen] 0 , 2\pi \mathclose[$, son sinus n'est plus toujours positif, donc la \emph{valeur absolue} du jacobien n'est plus $r^2\sin(\phi)$, mais $r^2\sin(\phi)$ pour les $\phi$ entre $0$ et $\pi$, puis $-r^2\sin(\phi)$ pour $\phi$ entre $\pi$ et $2\pi$. Donc l'intégrale \eqref{EqVolumeIncorrectSphere} n'est pas correcte. Il faut la remplacer par
\begin{equation}
	\int_0^Rdr\int_{0}^{\pi}d\theta\int_0^{\pi}r^2 \sin(\phi)d\phi- \int_0^Rdr\int_{0}^{\pi}d\theta\int_{\pi}^{2\pi}r^2 \sin(\phi)d\phi = \frac{ 4 }{ 3 }\pi R^3
\end{equation}

\subsection{Coordonnées polaires}
Soit $T$ la fonction de $]0, +\infty[\times \eR$ dans $\eR^2\setminus\{(0,0)\}$ définie par
\begin{equation}
  \begin{array}{lccc}
    T: &]0, +\infty[\times \eR & \to & \eR^2\setminus\{(0,0)\}\\
 & (r, \theta)&\mapsto& (r\cos \theta, r \sin \theta),
  \end{array}
\end{equation}
Cette fonction est surjective. Elle est bijective sur chaque bande de la forme  $]0, +\infty[\times [a-\pi,a+\pi[$. Si $a=0$ l'inverse de $T$  est la fonction $T^{-1}(x,y)= (\sqrt{x^2+y^2}, \arctg (y/x))$. Soit $P=(x,y)$ un élément dans $\eR^2$, on dit que $r=\sqrt{x^2+y^2}$ est le rayon de $P$ et que $\theta=\arctg (y/x) $ est son argument principal. L'origine ne peut pas être décrite en coordonnées polaires parce que si son rayon est manifestement zéro, on ne peut pas lui associer une valeur univoque de l'angle $\theta$. 

\begin{example}
L'équation du cercle de rayon $a$ et centre $(0, 0)$ en coordonnées polaires est $r=a$. 
\end{example}

\begin{example}
	Une équation possible pour la demi-droite $x=y$, $x>0$,  est $\theta=\pi/4$.         
\end{example}

%++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++   
\subsection{Coordonnées cylindriques}
%++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Soit $T$ la fonction de $]0, +\infty[\times \eR^2$ dans $\eR^3\setminus\{(0,0,0)\}$ définie par
\begin{equation}
  \begin{array}{lccc}
    T: &]0, +\infty[\times \eR\times \eR & \to & \eR^3\setminus\{(0,0,0)\}\\
 & (r, \theta, z)&\mapsto& (r\cos \theta, r \sin \theta, z),
  \end{array}
\end{equation}
Cette fonction est surjective. Elle est bijective sur chaque bande de la forme  $]0, +\infty[\times [a-\pi,a+\pi[\times \eR$, $a$ dans $\eR$. Il n'y a presque rien de nouveau par rapport aux coordonnées polaires. Les coordonnées  cylindriques sont intéressantes si on décrit un objet invariant par rapport aux rotations autour de l'axe des $z$. 

\begin{example}
Il faut savoir ce que décrivent les équations les plus simples en coordonnées cylindriques, 
\begin{itemize}
\item $r\leq a$, pour $a$ constant dans  $]0, +\infty[$, est le cylindre de hauteur infinie qui a pour axe l'axe des $z$ et pour base le disque de rayon $a$ centré à l'origine, 
\item $r= a$ est  la surface du cylindre,
\item $\theta = b$ est un demi-plan ouvert et sa fermeture contient l'axe des $z$,
\item $z=c$ est un plan parallèle au plan $x$-$y$. 
\end{itemize}
\end{example}

\begin{example}
  Un demi-cône qui a  son sommet en l'origine et  pour axe l'axe des $z$ est décrit par $z=d r$.  Si $d$ est positif  il s'agit  de la moitié supérieure du cône, si $d<0$ de la moitié inférieure.
\end{example}

\begin{example}
 De même,  la sphère de rayon $a$ et centrée à l'origine est l'assemblage des calottes $z=\sqrt{a^2-r^2}$ et $z=-\sqrt{a^2-r^2}$. 
\end{example}

%++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++   
\subsection{Coordonnées sphériques}
%++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Soit $T$ la fonction de $]0, +\infty[\times \eR^2$ dans $\eR^3\setminus\{(0,0,0)\}$ définie par
\begin{equation}
  \begin{array}{lccc}
    T: &]0, +\infty[\times \eR\times \eR & \to & \eR^3\setminus\{(0,0,0)\}\\
 & (\rho, \theta, \phi)&\mapsto& (\rho\cos \theta\sin \phi, \rho \sin \theta\sin \phi, \rho\cos \phi),
  \end{array}
\end{equation}
Cette fonction est surjective. Elle est bijective sur chaque bande de la forme  $]0, +\infty[\times [a-\pi,a+\pi[\times [b-\pi/2, b+\pi/2[$, $a$ et $b$ dans $\eR$.  Si $a =0$ et $b=-\pi/2$ la fonction inverse $T^{-1}$ est donnée donnée
\begin{equation}
  \begin{array}{lccc}
    T: &\eR^3\setminus\{(0,0,0)\} & \to & ]0, +\infty[\times [-\pi,\pi[\times [0, \pi[\\
 & (x,y,z)&\mapsto& \left(\sqrt{x^2+y^2+z^2}, \arctg \frac{y}{x}, \arccos \left(\frac{z}{\sqrt{x^2+y^2+z^2}}\right)\right). 
  \end{array}
\end{equation}
Soit $ P$ un point dans $\eR^3$. L'angle $\phi$ est l'angle entre le demi-axe positif des $z$ et le vecteur $\overrightarrow{OP}$, $\rho$ est la norme de $\overrightarrow{OP}$ et $\theta$ est l'argument en coordonnées polaires de la projection de $\overrightarrow{OP}$ sur le plan $x$-$y$.  

\begin{remark}
	Dans la littérature, les angles $\theta$ et $\phi$ sont parfois inversés (voire, changent de nom, par exemple $\varphi$ au lieu de $\phi$). Il faut donc être très prudent lorsqu'on veut utiliser dans un cours des formules données dans un autre cours.
\end{remark}

\begin{example}
Il faut connaître le sens des équations plus simples, 
\begin{itemize}
\item $\rho\leq a$, pour $a$ constant dans  $]0, +\infty[$, est la boule fermée de rayon $a$ centrée à l'origine, 
\item $\rho= a$ est  la sphère de rayon $a$ centrée à l'origine,
\item $\theta = b$ est un demi-plan ouvert et sa fermeture contient l'axe des $z$,
\item $\phi= c$ est un demi-cône qui a  son sommet à l'origine et  pour axe l'axe des $z$.  Si $c$ est positif  il s'agit  de la moitié supérieure du cône, si $d<0$ de la moitié inférieure. 
\end{itemize}
 \end{example}
