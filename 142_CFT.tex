% This is part of (almost) Everything I know in mathematics
% Copyright (c) 2015-2016
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{The conformal group}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Preliminary discussion}
%---------------------------------------------------------------------------------------------------------------------------

If one looks at \cite{ooIYOHooMRMfXl,ooDPRUooOFPyPH}, one sees that a conformal transformation is a transformation of a (pseudo)riemannian manifold that leaves the metric unchanged up to a positive scalar function : \( g'_{\mu\nu}(x')=\Omega(x)g_{\mu\nu}(x)\). Thus we are looking for the maps \( \phi\colon M\to M\) that realise that condition.

Since our objective is to do differential geometry, we cannot follow the computations in \cite{ooIYOHooMRMfXl,ooDPRUooOFPyPH} because there are too much «infinitesimal» in that and we don't understand anything\footnote{No pun intended : these books are very okay, but as far as we are interested in bundles, there are some works to do.}.

In order to determine the Poincaré group that leaves the metric invariant, we were fortunate because of theorem \ref{ThoDsFErq} that ensured linearity of the map \( \phi\). Our search for the Poincaré group\footnote{By the way given by theorem \ref{THOooQJSRooMrqQct}.} was thus simplified by two circumstances :
\begin{itemize}
    \item \( \phi\) and \( d\phi\) are the same.
    \item the condition \( g_{\mu\nu}=g'_{\mu\nu}\) does not involves a specific point, so that we had not to ask ourself questions about the «base point» of the vectors.
\end{itemize}
Here we are in a more complicated situation. 

\begin{definition}
Let \( (M,g)\) be a (pseudo)riemannian manifold. A conformal map will be \( \phi\colon M\to M\) such that
\begin{equation}        \label{EQooCCMMooXVbTAd}
    g_{\phi(x)}\big( d\phi_xv,d\phi_xw \big)=\Omega(x)g_x(v,w)
\end{equation}
for a function \( \Omega\in C^{\infty}(M)\). The condition \eqref{EQooCCMMooXVbTAd} has to hold for every \( x\in M\) and \( v,w\in T_xM\).
\end{definition}

We particularise ourself to the case where the manifold \( M\) is a vector space \( V\) of dimension \( d\) with constant metric \( \eta\). If \( \{ e_i \}_{i=1,\ldots, d}\) is a basis of \( V\), we consider the same basis on each \( T_xV\) and for \( v,w\in T_xV\) we have
\begin{equation}
    v\cdot w=\sum_{ij}\eta_{ij}v_iw_j.
\end{equation}
All the sums are intended from \( 1\) to \( d\).

\begin{definition}      \label{DEFooVKNBooFBWQQM}
    A \defe{conformal map}{conformal map} is a \(  C^{\infty}\) map \( \phi\colon V\to V\) for which there exists a function \( \Omega\in C^{\infty}(V)\) satisfying
    \begin{equation}        \label{EQooOZDUooCDaIrh}
        v\cdot w=\Omega(x) d\phi_x(v)\cdot d\phi_x(w)
    \end{equation}
    for every \( x\in V\) and every \( v,w\in V_x\).
\end{definition}
    

\begin{normaltext}  \label{NorooVEVOooRBpvXF}
    This is not the group of ``angles preserving'' transformations, but rather the group of \emph{locally} preserving the angles.

In order to understand that, let us imagine a deforming material. A vector at point \( A\) is an arrow joining point \( A\) to a point \( B\). The image of the vector \( \vect{ AB }\) has to be \( \vect{ \phi(A)\phi(B) }\) when the material is deformed. Thus instead of moving the vector by \( d\phi\), we should move both extremities by \( \phi\) itself. We could speak about affine spaces as described around definition \ref{DEFooQELZooEXvxgw}, but instead we will describe our subject with a vector bundle.

We will discuss this point in \ref{sebsecooCBKEooQOWqFo}.
\end{normaltext}

\begin{remark}
    We are going not to determine all the conformal transformations\quext{Can you answer the question \url{http://math.stackexchange.com/questions/1549670/rigorous-definition-of-a-generator-for-a-transformation-group} ?}, but the (connected to the identity) Lie group of conformal transformations. That is : we are searching for a Lie group \( G\) of diffeomorphisms \( M\to M\) satisfying the condition \eqref{EQooCCMMooXVbTAd}.
\end{remark}

We will use the strategy presented in \ref{NORMooMGAUooIoLtjW}, as in the proof of proposition \ref{PROPooDVIWooAFDNPy}
% When its done, give a more precise reference at position 10906-29466

Since \( G\) is a Lie group, each element can be written under the form \( g= e^{X}\) for some \( X\in\lG\) (here \( \lG\) is the Lie algebra, that is \( T_eG\)). Following the definition \ref{DEFooUYOZooWdcClz} we define \( X\colon V\to V\) by
\begin{equation}
    X(v)=\Dsdd{  \exp(-tX)(v) }{t}{0}
\end{equation}
The exponential here is the one from the Lie algebra to the Lie group. We also define
\begin{equation}
    \phi_t(x)=\Dsdd{  e^{-tX}x }{t}{0}
\end{equation}
for \( t\in \eR\) and \( x\in V\) (\( t\) being restricted to an open set around \( 0\)). 

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{The computations}
%---------------------------------------------------------------------------------------------------------------------------

We consider the case in which the metric is flat an \( g_x=\eta\) for every \( x\).  The starting point is the condition \eqref{EQooOZDUooCDaIrh}. We write it for the map
\begin{equation}
    \phi_t(x)= e^{-tX}(x)
\end{equation}
and we search the function \( X\colon V\to V\). We derive with respect to \( t\) the equality (for fixed \( x\in V\))
\begin{equation}        \label{EQooJZDTooVJEUyo}
    (d\phi_t)_x(v)\cdot (d\phi_t)_x(w)=\Omega_t(x)v\cdot w.
\end{equation}
Permuting two derivatives, we have
\begin{subequations}
    \begin{align}
        \Dsdd{ (d\phi_t)_x(v) }{t}{0}&=\Dsdd{ \Dsdd{   \phi_t(x+uv)  }{u}{0} }{t}{0}\\
        &=\Dsdd{\Dsdd{ \phi_t(x+uv) }{t}{0} }{u}{0}\\
        &=\Dsdd{ \Dsdd{  e^{-tX}(x+uv) }{t}{0} }{u}{0}\\
        &=\Dsdd{ -X(x+uv) }{u}{0}\\
        &=-dX_x(v).
    \end{align}
\end{subequations}
If \( t=0\) we also have
\begin{equation}
    (d\phi_0)_x(w)=d(\id)_x(w)=w.
\end{equation}
Thus the derivative of \eqref{EQooJZDTooVJEUyo} produces the following differential equation for \( X\) :
\begin{equation}
    dX_x(v)\cdot w+dX_x(w)\cdot v=\omega(x)v\cdot w.
\end{equation}
Let \( \{ e_i \}\) be a basis of \( V\). We have \( dX_x(e_i)=\frac{ \partial X }{ \partial x_i }(x)\) and
\begin{equation}
    dX_x(e_i)\cdot e_j=\sum_{kl}\big( dX_x(e_i) \big)(e_j)_l\eta_{kl}=\sum_k\eta_{kj}\frac{ \partial X_k }{ \partial x_i }=\partial_i\tilde X_j
\end{equation}
where \( \tilde X=\eta X\), this is \( \tilde X_i=\sum_k\eta_{ik}X_k\). The equation for \( X\), if \( v=e_i\) and \( w=e_j\) is
\begin{equation}
    \frac{ \partial \tilde X_j }{ \partial x_i }+\frac{ \partial \tilde X_i }{ \partial x_j }=\omega(x)\eta_{ij}.
\end{equation}

\begin{lemma}[\cite{ooDPRUooOFPyPH}]
    Let \( V\) be a vector space of dimension \( d\geq 3\) endowed with the constant metric \( \eta\). The solutions of the differential equation
    \begin{equation}    \label{EQooVBIMooOBKAKQ}
        \partial_if_j+\partial_jf_i=\omega(x)\eta_{ij}
    \end{equation}
    for a function \( f\colon V\to V\) of class \(  C^{\infty}\) are
    \begin{equation}    \label{EQooEFOMooUhcgfT}
        f(x)=a+\sum_{km}b_{km}xe_m+\sum_{klm}q_{klm}x_kx_le_m
    \end{equation}
    where
    \begin{enumerate}
        \item
            \( a\in V\) is any vector.
        \item
            the antisymmetric part of \( b\) is free
        \item
            the symmetric part of \( b\) is proportional to \( \eta\).
        \item
            \( q_{ijk}=-d_j\eta_{ik}+d_k\eta_{ij}-d_i\eta_{jk}\) and \( d\) is arbitrary.
    \end{enumerate}
    In this case, \( \omega\) is given by \( \omega(x)=\frac{ 2 }{ d }(\nabla\cdot f)(x)\) where the divergence is the one of proposition \ref{PROPooLIJTooKFTwPY}.
\end{lemma}

\begin{proof}
    We can initiate our work by expression \( \omega\) in terms of \( f\). For that, multiply both sides by \( (\eta^{-1})_{ij}\) and make the sum ove \( i\) and \( j\). On the right hand side we have
    \begin{equation}
        \omega(x)\sum_ij(\eta^{-1})_{ij}\eta_{ij}=\omega(x)\sum_j(\eta^{-1}\eta)_{jj}=\omega(x)d.
    \end{equation}
    On the left hand side we have (reaming the summation indices \( i\leftrightarrow j\) in one of the two terms) :
    \begin{equation}
        2\sum_{ij}(\eta^{-1})_{ij}\frac{ \partial  f_j }{ \partial x_i }=2\nabla\cdot  f.
    \end{equation}
    For the divergence, see the proposition \ref{PROPooLIJTooKFTwPY}. Thus \( \omega(x)=\frac{ 2 }{ d }\nabla\cdot f\) and the equation is
    \begin{equation}    \label{EQooAPOPooBdKskD}
        \partial_i f_j+\partial_j f_i=\frac{ 2 }{ d }(\nabla\cdot f)\eta_{ij}.
    \end{equation}
    We apply on both sides the operator\footnote{Since the function \( f\) is supposed to be of class \(  C^{\infty}\), we derivatives commute.}
    \begin{equation}
        \sum_{ijkl}(\eta^{-1})_{ik}(\eta^{-1})_{jl}\partial_k\partial_l
    \end{equation}
    which is nothing else than the contraction with \( \partial^i\partial^j\) when one uses the uppper-lower index notation.
    The first term is
    \begin{equation}
        \sum_{ijkl}(\eta^{-1})_{ik}(\eta^{-1})_{jl}\partial_k\partial_l\partial_i f_j=\sum_{jl}(\eta^{-1})_{jl}\partial_l(\Box  f_j)=\nabla\cdot(\Box f)
    \end{equation}
    where we introduced the operator
    \begin{equation}
        \Box=\sum_{kl}(\eta^{-1})_{kl}\partial_k\partial_l.
    \end{equation}

    The second term gives the same result. On the right hand side,
    \begin{equation}
        \frac{ 2 }{ d }\sum_{ijkl}(\eta^{-1})_{ik}(\eta^{-1})_{jl}\partial_k\partial_l\eta_{ij}\nabla\cdot  f=\frac{ 2 }{ d }\sum_{kl}(\eta^{-1})_{kl}\partial_k\partial_l\nabla\cdot f=\frac{ 2 }{ d }\nabla\cdot\Box f.
    \end{equation}
    If \( d\neq 1\) we are left with\footnote{By the way, if \( d=1\), the question about the angle preserving diffeomorphisms does not make much sense.}
    \begin{equation}
        \Box(\nabla\cdot  f)=0.
    \end{equation}
    Now we go back to equation \eqref{EQooAPOPooBdKskD}.
    \begin{equation}
        \underbrace{\partial_i f_j}_{A}+\underbrace{\partial_j f_i}_{B}=\underbrace{\frac{ 2 }{ d }(\nabla\cdot f)\eta_{ij}}_C.
    \end{equation}
    We apply the operator
    \begin{equation}
        \sum_{im}\partial_l(\eta^{-1})_{im}\partial_m,
    \end{equation}
    which is the contraction with \( \partial_l\partial^i\).

    On \( A\), we recognize the \( \Box\) operator :
    \begin{equation}
        \partial_l\Box f_j.
    \end{equation}
    On \( B\) we recognize the divergence operator :
    \begin{equation}
        \partial_j\partial_l\nabla\cdot  f.
    \end{equation}
    On \( C\) we have \( \eta^{-1}\eta=\mtu\) and
    \begin{equation}
        \frac{ 2 }{ d }\partial_l\partial_j\nabla\cdot f.
    \end{equation}
    Putting the whole together,
    \begin{equation}    \label{EQooCHJAooVzpeos}
        \partial_l\Box f_j+\big( 1-\frac{ 2 }{ d } \big)\partial_j\partial_l\nabla\cdot f=0.
    \end{equation}
    Let us write the same equation with \( l\leftrightarrow j\) :
    \begin{equation}    \label{EQooSMQVooBqKvdO}
        \partial_j\Box f_l+\big( 1-\frac{ 2 }{ d } \big)\partial_l\partial_j\nabla\cdot f=0.
    \end{equation}
    We sum \eqref{EQooCHJAooVzpeos} with \eqref{EQooSMQVooBqKvdO}  and use the equation \eqref{EQooAPOPooBdKskD} :
    \begin{equation}
        \Box\big( \underbrace{\partial_l f_j+\partial_j f_l}_{=\frac{ 2 }{ d }\eta_{lj}\nabla\cdot f} \big)+2\big( 1-\frac{ 2 }{ d } \big)\partial_l\partial_j\nabla\cdot  f=0.
    \end{equation}
    Using the fact that \( \Box\nabla\cdot f=0\), the first term vanishes. If \( d\neq 2\) we have
    \begin{equation}
        \partial_l\partial\j\nabla\cdot  f=0.
    \end{equation}

    Applying the operation \( \partial_k\partial_l\) on the equation \eqref{EQooAPOPooBdKskD},
    \begin{equation}
        \partial_i\partial_k\partial_l\nabla\cdot f_j+\partial_k\partial_l\partial_j f_i=\frac{ 2 }{ d }\eta_{ij}\underbrace{\partial_k\partial_l\nabla\cdot f}_{=0}=0
    \end{equation}
    If we write \( \Delta_{ijkl}=\partial_i\partial_k\partial_k f_l\) we have
    \begin{equation}    \label{EQooFBXSooLncZtv}
        \Delta_{ijkl}=-\Delta_{ijlk}
    \end{equation}
    while \( \Delta\) is symmetric with respect to its first three indices. Starting from \( \Delta_{ijlk}\) we permute the two inner indices and apply \eqref{EQooFBXSooLncZtv}; the whole two time :
    \begin{equation}
        \Delta_{i\,jk\,l}=\Delta_{i\,kj\,l}=-\Delta_{iklj}=-\Delta_{il\,kj}=\Delta_{il\,jk}=\Delta_{ijlk}.
    \end{equation}
    Thus \( \Delta_{ijlk}=0\), and
    \begin{equation}
        \partial_i\partial_j\partial_kf_l=0
    \end{equation}
    for every \( i,j,k,l\). Thus each component of the function \( f\) is a polynomial of degree \( 2\) with respect to \( x\). This leaves us with
    \begin{equation}
        f(x)=a+\sum_{km}b_{km}x_ke_m+\sum_{klm}q_{klm}x_kx_le_m.
    \end{equation}
    We get constrains on \( a,b,q\) putting that solution into the equation \eqref{EQooVBIMooOBKAKQ} with \( \omega(x)=\frac{ 2 }{ d }\nabla\cdot f\). Using the fact that \( \partial_ie_m=\delta_{im}\) we get
    \begin{equation}
        \partial_if_j=\sum_kb_{kj}\delta_{ki}+\sum_{kl}q_{klj}(\delta_{ki}x_l+x_k\delta_{li})=b_{ij}+2\sum_kq_{kij}x_k,
    \end{equation}
    and
    \begin{equation}
        \nabla\cdot f=\sum_{ij}(\eta^{-1})_{ij}b_{ij}+2\sum_{ijk}q_{kij}(\eta^{-1})_{ij}x_k=\tr(b\eta^{-1})+2\sum_{ijk}q_{kij}(\eta^{-1})_{ij}x_k.
    \end{equation}
    Putting all together we have the condition
    \begin{equation}
        b_{ij}+b_{ji}+2\sum_{k}q_{kij}x_k+2\sum_kq_{kji}x_k=\frac{ 2 }{ d }\eta_{ij}\big( \tr(b\eta^{-1})+2\sum_{klm}q_{klm}(\eta^{-1})_{lm}x_k \big).
    \end{equation}
    Since that condition has to hold for every choice of \( x\) we can separate the part with and without \( x\).

    \begin{subproof}
    \item[Part without \( x\)]
        We have 
        \begin{equation}
            b_{ij}+b_{ji}=\frac{ 2 }{ d }\eta_{ij}\tr(b\eta^{-1}).
        \end{equation}
        The antisymmetric part of \( b\) gives zero on left, but also zero on right because \( \eta^{-1}\) is symmetric. Let us be more specific; if \( A\) is antisymmetric and \( S\) be symmetric. Then \( (AS)^t=-SA\) and \( \tr(AS)=\tr\big( (AS)^t \big)=-\tr(SA)=-\tr(AS)\) by the cyclic invariance of the trace. We conclude that the antisymmetric part of \( b\) is free.

        The symmetric part of \( b\) is proportional to \( \eta\), and the coefficient of proportionality is \( \frac{ 2 }{ d }\tr(b\eta^{-1})\). We can check that this is not a new constraint by putting directly \( b=\alpha\eta\) into the equation :
        \begin{equation}
            \alpha\eta_{ij}+\alpha\eta_{ji}=\frac{ 2 }{ d }\eta_{ij}\tr(\alpha\eta\eta^{-1}),
        \end{equation}
        after simplifications and taking into account \( \tr(\alpha)=\alpha d\), we see that it is valid for every \( \alpha\).
    \item[Path with \( x\)]

        We can factorize \( x_k\) and write the condition as
        \begin{equation}
            2q_{kij}+2q_{kji}=\frac{ 4 }{ d }\eta_{ij}\sum_{lm}(\eta^{-1})_{lm}q_{klm}.
        \end{equation}
        Thus there exists a vector \( d\) such that \( q_{ijk}=-q_{ikj}-2d_i\eta_{jk}\) (the coefficient \( 2\) is for later convenience). Maybe each vector \( d\) will not produce a solution; we'll have to check it later. Using three times the symmetry of \( q\) with respect to the first two indices and the latter formula,
        \begin{subequations}        
            \begin{align}
                q_{kij}&=-q_{kji}-2d_k\eta_{ij}\\
                &=-q_{jki}-2d_k\eta_{ij}\\
                &=q_{jik}+2d_j\eta_{ik}-2d_k\eta_{ij}\\
                &=q_{ijk}+2d_j\eta_{ik}-2d_k\eta_{ij}\\
                &=-q_{ikj}-2d_i\eta_{kj}+2d_j\eta_{ik}-2d_k\eta_{ij}.
            \end{align}
        \end{subequations}
        Thus 
        \begin{equation}    \label{EQooKZVTooWSMmyM}
            q_{ijk}=-d_j\eta_{ik}+d_k\eta_{ij}-d_i\eta_{jk}.
        \end{equation}
    \end{subproof}
    
    At this point we proved that every solution of \eqref{EQooVBIMooOBKAKQ} are of the given form \eqref{EQooEFOMooUhcgfT} with the constrains. We still have to check that for every choice of antisymmetric \( b\) and every choice of \( d\) (giving \( q\) by the formula \eqref{EQooKZVTooWSMmyM}), the corresponding function actually is a solution.

    \begin{subproof}
    \item[Antisymmetric]
        Let us check for \( f(x)=\sum_{km}b_{km}x_ke_m\) when \( b\) is antisymmetric. We have
        \begin{equation}
            \partial_if_j=\sum_kb_{kj}\underbrace{\partial_ix_k}_{=\delta_{ik}}=b_{ij}
        \end{equation}
        and
        \begin{equation}
            \nabla\cdot f=\sum_{kl}(\eta^{-1})_{kl}\partial_kf_l=\sum_{kl}(\eta^{-1})_{kl}b_{kl}=0.
        \end{equation}
        The lase zero is because of the contraction of a symmetric matrix (\( \eta^{-1}\)) with an antisymmetric matrix. Now \( \partial_if_j+\partial_jf_i=b_{ij}+b_{ji}=0\) and the equation is satisfied.

    \item[The quadratic part]
        We have to check that the function
        \begin{equation}
            f(x)=\sum_{klm}\big( -d_l\eta_{km}+d_m\eta_{kl}-d_k\eta_{lm} \big)x_kx_lem
        \end{equation}
        is a solution of \( \partial_if_j+\partial_jf_i=\frac{ 2 }{ d }\eta_{ij}\nabla\cdot f\). Few computations provide on the one hand
        \begin{equation}
            \partial\if_j=2\sum_k\big( -d_i\eta_{kj}+d_j\eta_{ki}-d_k\eta_{ij} \big)x_k,
        \end{equation}
        and on the other hand,
        \begin{equation}
            \nabla\cdot f=-2d\sum_kd_kx_k.
        \end{equation}
        A few more computations show that the equation is satisfied for every choice of vector \( d\).
    \end{subproof}
\end{proof}


%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{What about really preserving the angles ?}
%---------------------------------------------------------------------------------------------------------------------------
\label{sebsecooCBKEooQOWqFo}

We continue the discussion of \ref{NorooVEVOooRBpvXF}. If one wants a map \( \phi\colon M\to M\) that preserves the angles in the sense that for any three points \( A,B,C\in M\) the angle formed by \( \vect{ AB }\) and \( \vect{ AC }\) is the same as the angle formed by the vectors \( \vect{ \phi(A)\phi(B) }\) and \( \vect{ \phi(A)\phi(C) }\), we need more structure, since there are no notion of ``vector from one point to another'' in a general manifold. So we particularize ourself to the case in which \( M\) is a vector space. Thus we can write differences like \( \phi(x)-\phi(y)\).

Let \( V\) be a finite dimensional vector space and \( E=V\times V\) be the trivial vector bundle with fibre \( V\). We denote \( V_x=\{ (x,v)\tq v\in V \}\) and for each \( x\in V\) we have a non-degenerate bilinear form \( g_x\colon V\to V\). We define
\begin{equation}
    g\big( (x,v),(x,w) \big)=g_x(v,w)
\end{equation}
and we will often directly write \( g_x(v,w)\) or \( v\cdot w\) when \( v,w\) belong to \(V_x\) instead of \( V\).

A map \( \phi\colon V\to V\) also acts on the vector bundle as
\begin{equation}        \label{EQooFICEooQACFoU}
    \phi(x,v)=\big( \phi(x),\phi(x+v)-\phi(x) \big).
\end{equation}
This way to act translates the fact that for a vector, we displace the ending point as well as the starting point with \( \phi\). This is not the same as displacing the vector by \( d\phi_x\).

\begin{remark}
    We consider a vector bundle with fibre \( V\) in order to make sense to the definition \eqref{EQooFICEooQACFoU}. One can also working on the more intuitive setting of the tangent bundle \( TM\), but in this case, on has to deal with a linear bijection between \( T_xM\) and \( V\).
\end{remark}

With no abuse of notations, the condition \eqref{EQooOZDUooCDaIrh} reads, for \( v,w\in V\) :
\begin{equation}\label{EQooFZUFooTGWpBn}
    g_x(v,w)=\Omega(x)g_{\phi(x)}\big(  \phi(x+v)-\phi(x),\phi(x+w)-\phi(x)  \big).
\end{equation}

Moreover we consider the case in which the metric is flat an \( g_x=\eta\) for every \( x\).
