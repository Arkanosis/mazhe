Cette partie est entièrement pompée du cours \cite{ChaDjelil}.

%
%
\chapter{Qu'est-ce que la simulation ?}
%
%

Considérons une suite de chiffres $x_0,x_1,x_2,\ldots,x_n$ de l'intervalle $[0,1]$
ou d'entiers entre $0$ et $9$. Quand peut-on dire qu'elle est constituée de
réalisations indépendantes d'une loi uniforme sur $[0,1]$ (resp. sur
$\{0,\ldots,9\}$) ? Et bien dans tout les cas bien sûr. Cependant, l'intuition nous
indique que ce sont les propriétés «statistiques» des suites qui sont
importantes, et pas celles d'\emph{une} suite donnée\ldots{} Pour certains, une
suite qui peut être générée par un algorithme n'est pas aléatoire. De ce point
de vue, une suite finie n'est jamais aléatoire ! Cf. \cite[chap. IV, page
73]{bouleau} et \cite{knuth-taocp-2-3}. Les notions de complexité de
Kolmogorov et d'entropie de Shannon, brièvement présentées dans les sections
\ref{ss:kolmogorov} et \ref{ss:shannon} qui suivent, permettent de mieux
définir et quantifier le caractère «désordonné» d'une suite.

Pour nous, simuler une loi de probabilité $\cL$ consistera à écrire un
programme informatique pouvant générer des suites finies dont on considèrera
que ce sont des réalisations indépendantes de loi $\cL$. Bien entendu, comme
nous ferons appel le plus souvent à des algorithmes déterministes, les suites
générées ne sont pas du tout aléatoires et encore moins indépendantes. On
parlera de suites \emph{pseudo-aléatoires}. Cependant, elles se montreront
suffisantes dans la pratique et l'on vérifiera expérimentalement plus loin
qu'elles ont de «bonnes» propriétés en utilisant des tests statistiques.

La loi uniforme est la première loi que l'on simule. Diverses méthodes
permettent ensuite de simuler à partir de la loi uniforme, un grand nombre de
lois, plus ou moins quelconques. Dans la pratique, on met en {\oe}uvre des
algorithmes rapides de génération de suites pseudo-aléatoires.

\ML{} permet de simuler une loi uniforme (resp. normale) via la fonction
\texttt{rand} (resp. \texttt{randn}). La bibliothèque \SB{} fournit de
nombreuses autres simulations de lois discrètes et continues qui en sont
dérivées~: faites \texttt{help stixbox} ou reportez vous à la table
\ref{ta:stixbox-rand}, page \pageref{ta:stixbox-rand}, qui donne la liste des
générateurs aléatoires de la bibliothèque \SB{}.

%
\section{Complexité de Kolmogorov et entropie de Shannon}
%

Les sections \ref{ss:kolmogorov} et \ref{ss:shannon} peuvent être ignorées en
première lecture. Les notions évoquées sortent du cadre du programme de
l'oral. Elles donnent cependant des idées et enrichissent l'intuition
probabiliste. Commençons par un exemple tout simple. La suite de dix chiffres
suivante
$$1,1,1,1,1,1,1,1,1,1$$
nous semble beaucoup moins complexe que la suite
$$1,2,3,1,0,9,0,8,0,5.$$
Pour coder brièvement la première, il suffit d'écrire
«dix fois un», alors que la seconde nécessite plus de «détails». On peut
également observer que ce phénomène se constate immédiatement sur les
fréquences des chiffres dans ces deux suites. En revanche, contraîrement à un
algorithme de génération, les fréquences ne contiennent aucune information sur
la structure de la deuxième suite, et l'information retenue est donc pauvre, à
moins de faire intervenir les fréquences d'apparition des couples et plus
généralement des $n$-uplets.

Ce sont ces deux idées qui sont à la base des notions de complexité de
Kolmogorov et d'entropie de Shannon~: la complexité pour le versant
algorithmique de description minimale et l'entropie pour le versant
probabiliste lié aux fréquences d'apparition. Nous allons voir de plus que
contraîrement à ce que l'on pourrait croire, ces deux notions sont intimement
reliées.

Pour la petite histoire, Shannon a introduit l'entropie qui porte son nom à la
fin des années $1940$ -- en s'inspirant de l'entropie thermodynamique de
Boltzmann en théorie cinétique des gaz -- pour les besoins de ce qui sera
appelé plus tard théorie de l'information ou de la communication. Kolmogorov,
père fondateur des probabilités modernes (i.e. basées sur la théorie de la
mesure), a repris et développé cette idée d'entropie-information pour l'étude
des systèmes dynamiques en particulier. Ses élèves ont beaucoup contribué à
donner un cadre mathématique rigoureux à la théorie de l'information. La
notion de complexité de Kolmogorov constitue une tentative de quantification
de l'aléatoire par une approche algorithmique.

\subsection{Complexité de Kolmogorov}\label{ss:kolmogorov}

Considérons une machine informatique $M$ pouvant exécuter des programmes.  On
dit que cette machine est universelle lorsqu'elle peut émuler n'importe quelle
autre machine informatique. La machine universelle de Turing en est un exemple
\cite{turing-girard}.
 
On note $\cP_M$ l'ensemble des programmes écrits pour la machine $M$. Pour un
programme $p\in\cP_M$, on note $l(p)$ sa longueur en nombre d'instructions pour
la machine $M$ et $s(p)$ sa sortie. La complexité de Kolmogorov $\bK_M(x)$, ou
complexité algorithmique, d'une suite $x:=(x_i)_i$ pour une machine $M$ est
définie par~:
$$
\bK_M(x):=\min_{p\in\cP_M,\,s(p)=x} l(p).
$$
C'est donc la longueur du plus petit programme écrit pour la machine $M$
qui génère la suite $x$.  Une suite constante a une complexité faible car les
programmes qui la génèrent peuvent être très courts.

Reste à savoir dans quelle mesure la fonction $\bK_M$ dépend de la machine
$M$, car on peut tout à fait imaginer une machine possèdant des instructions
simples pour générer certaines suites complexes. La réponse est la suivante~:
soit $U$ une machine universelle et $M$ une machine, alors il existe une
constante $c_M$ telle que pour toute suite $x$, on ait~:
$$
\bK_U(x) \leq \bK_M(x)+c_M.
$$
On parle alors d'universalité de la complexité de Kolmogorov, en ce sens
qu'elle ne dépend pas, à une constante additive près, de la machine
considérée. Ainsi, on peut se ramener à une machine universelle dont la
définition est élémentaire (celle de Turing). Une suite peut alors être
considérée comme d'autant plus «aléatoire» que sa complexité est grande par
rapport à sa taille. De ce point de vue, les décimales des nombres $\pi$, $e$ ou
$\sqrt{2}$ ne sont pas vraiment aléatoires puisqu'il existe des algorithmes
très simples pour les générer. Cela dit, on montre qu'il n'existe pas
d'algorithme pour calculer la complexité de Kolmogorov en toute généralité !
On peut cependant obtenir des encadrements et des estimations. Mais arrêtons
là cette digression culturelle, elle nous mènerait trop loin ! Pour en savoir
plus, consultez par exemple \cite[chap. 7]{cover-thomas}.

\subsection{Entropie de Shannon}\label{ss:shannon}

Une autre approche au «désordre» d'une suite est celle de Shanonn. L'entropie
de Shannon d'une loi de probabilité discrète 
$$P:=p_1\delta_1+\cdots+p_n\delta_n$$
est définie par~:
$$
\bH(P):=\sum_{i=1}^n p_i\log \frac{1}{p_i}.
$$
Elle est maximale pour la loi uniforme pour laquelle elle vaut $\log n$ et
minimale pour les masses ponctuelles pour lesquelles elle est nulle (car la
fonction $x\geq 0\mapsto x\log x$ est nulle en $0$ et $1$). Elle mesure donc
le désordre en quelque sorte. On pourra consulter \cite[chap. 6]{applebaum}
pour plus d'explications.

Soit $m\in\eN^*$ un entier non nul, $U$ une machine universelle et $\cP_m$
l'ensemble des programmes écrits pour cette machine dont la longueur de la
sortie est de $m$. On note $\bK(x|m)$ la complexité de Kolmogorov de taille
$m$ d'une suite $y=(y_1,\ldots,y_m)$ de longueur $m$, définie par~:
$$
\bK(y|m):=\min_{p\in\cP_m,\,s(p)=y} l(p).
$$
Soit à présent une suite de variables aléatoires i.i.d. $(X_i,i\in\eN)$ de
loi discrète $P:=p_1\delta_{x_1}+\cdots+p_n\delta_{x_n}$ où les $x_i$ sont tous
différents. On note $\cX:=\{x_1,\ldots,x_n\}$, qui représente un alphabet dans lequel
les suites seront écrites. Alors, on montre qu'il existe une constante $c>0$
telle que pour tout $m\in\eN^*$~:
$$
\bH(P) \leq\frac{1}{m}\,\sum_{y\in\cX^m}\! p_{y_1}\cdots p_{y_m} \bK(y|m)
\leq\bH(P)+\frac{n\log m}{m}+\frac{c}{m}.
$$
Cf. \cite[théorème 7.3.1 page 154]{cover-thomas} pour une preuve. Ainsi, on
a~:
$$
\lim_{m\to+\infty}\eE\PAR{\frac{1}{m}\,\bK\PAR{(X_1,\ldots,X_m)|m}}=\bH(P).
$$
La complexité de Kolmogorov et l'entropie de Shannon sont donc très liées.

%
\section{Loi uniforme et théorème fondamental de la simulation}
%

Les générateurs de nombres aléatoires sont très importants dans les
applications. Ils permettent d'une part de simuler des phénomènes dont la
modélisation fait appel à des lois de probabilités et d'autre part de
sécuriser les échanges de données, dans les réseaux téléinformatiques par
exemple. Dans la pratique, les générateurs aléatoires sont basés sur des
algorithmes déterministes, comme nous allons le voir, ou encore sur une source
d'«entropie» extérieure difficilement prédictible liée au fonctionnement de la
machinerie informatique (par exemple le temps séparant deux interruptions du
processeur), ces deux approches pouvant être combinées dans un même
processus\footnote{Sur le système Linux, on dispose d'une source algorithmique
  \textsf{/dev/urandom} et d'une source «entropique» \textsf{/dev/random}
  utile pour la sécurisation car difficilement prédictible.}.

Simuler la loi uniforme consiste à produire une suite de nombres qui peuvent
être considérés comme autant de réalisations indépendantes de variables
aléatoires uniformes sur $[0,1]$. Bien entendu, un algorithme est toujours
déterministe lorsqu'on le connaît, et il vaut donc mieux parler de générateur
pseudo-aléatoire de la loi uniforme. Mathématiquement, les $n$ sorties
successives d'un tel générteur seront considérées comme la donnée de
$U_1(\om),\dots,U_n(\om)$ pour un $\om\in\Om$ où les $U_i$ sont des v.a.r.
i.i.d. $U_i:(\Om,\cA,\eP)\to[0,1]$ de loi uniforme.

La mémoire des ordinateurs étant finie, il est impossible de stocker des
suites infinies. En conséquence, les nombres réels sont toujours approximés,
avec une certaine précision. Soit donc $p\in\eN^*$ qui va jour le rôle de
précision. Un réel $x_n$ dans $[0,1]$ s'écrira $y_n/p$ où $y_n$ est un entier
dans $\{0,\ldots,p\}$. Un algorithme très usité pour générer les $y_n$
consiste à utiliser la relation de récurrence $x_n=y_n/p$ où $y_{n+1}\equiv a
y_n [m]$ où $a$ et $m$ sont des entiers et $m$ est assez grand.

En général, la période de $(y_n)_n$ est plus petite que $m$. Plus précisément,
si $a$ et $m$ sont premiers entre eux, et si $0<y_0<m$, alors $y_n$ n'est
jamais nul et la période de $(y_n)_n$ n'est rien d'autre que l'ordre de $a$
dans $\dZ_m$. On rappelle que d'après le (petit) théorème de Fermat-Euler,
l'ordre de $a$ divise l'indicateur d'Euler de $a$ (qui vaut $m-1$ quand $m$
est premier).

\ML{} 4 utilise un algorithme de ce type pour implémenter la fonction
\texttt{rand} mais les versions plus récentes de \ML{} utilisent un algorithme
différent et plus performant. Dans certaines bibliothèques de calcul
scientifique, on utilise $(a,m)=(13^{13},2^{59})$ ou encore
$(a,m)=(7^5,2^{31}-1)$, cf. \cite[page 74]{bouleau}.  L'algorithme utilisé par
\OC{} 2.1 pour \texttt{rand} est le «Mersenne Twister», cf.
\url{http://www.math.keio.ac.jp/~matumoto/emt.html}.  On pourra également
consulter \cite{knuth-taocp-2-3} à propos de la génération aléatoire en
général. Le théorème suivant nous assure la possibilité, théorique, de simuler
n'importe quelle loi de probabilité sur $\dR^d$ à partir de la loi uniforme~:

\begin{thm}[Théorème fondamental de la simulation]
  Soit $m>1$ un entier, et $U_1,\ldots,U_m$ des variables aléatoires i.i.d. de loi
  uniforme sur $[0,1]$. Pour toute loi de probabilité $\mu$ sur $\dR^d$, il
  existe une fonction borélienne $f_{\mu,m}:\dR^m\to\dR^d$ dont l'ensemble des
  points de discontinuité est Lebesgue-négligeable telle que la variable
  aléatoire $Y:=f_{\mu,m}(U_1,\ldots,U_m)$ suive la loi $\mu$.
\end{thm}

Ce théorème donne un résulat théorique intéressant, bien que l'on ne s'en
serve pas dans la pratique. On en trouvera une preuve dans \cite[chap. X page
267]{bouleau}. En lisant la preuve, on s'aperçoit que la fonction $f$ peut
être explicitée. On peut donc théoriquement simuler toute loi à partir d'une
simulation de la loi uniforme. En effet, supposons que nous désirions obtenir
$n$ réalisations indépendantes de loi $\mu$. Prenons alors $m=1$ dans le
théorème précédent. Un générateur pseudo-aléatoire uniforme, du type
\texttt{rand}, nous fournit une suite $U_1(\om),\ldots,U_n(\om)$, qui sont
considérées comme les réalisations pour $\om\in\Om$ de $n$ v.a.r. i.i.d. suivant
une loi uniforme sur $[0,1]$. Le théorème précédent affirme alors l'existence
d'une fonction $f_\mu$ telle que $f_\mu(U_1(\om)),\ldots,f(U_n(\om))$ soient les
réalisations de $n$ v.a. i.i.d. de loi $\mu$.

\begin{rem}
  Remarquons que d'après la loi des grands nombres, si
  $$(X_n:(\Om,\cA,\eP)\to\dR^d,n\in\eN^*)$$
  est une suite de v.a. i.i.d. de loi
  $\mu$, en d'autre termes un «échantillon de taille infinie»,
  alors pour $\mu$-presque tout $\om\in\Om$, la mesure empirique
  $$
  \cE_n(\om):=\frac{1}{n}\,\sum_{i=1}^n \delta_{X_i(\om)}
  $$
  converge étroitement vers la loi $\mu$. Il en découle que pour $\mu$-presque
  tout $\om\in\Om$, la donnée de la \emph{suite infine} $(X_n(\om),n\in\eN^*)$
  caractérise \emph{théoriquement} la loi $\mu$. 
  Un générateur de nombres pseudo-aléatoires ne
  fournit que des \emph{suites finies} $(X_1(\om),\ldots,X_n(\om))$, qui ne
  suffisent pas à caractériser la loi $\mu$. De même,
  les échantillons provenant de données réelles utilisés en statistique sont 
  toujours \emph{finis}, et
  l'un des objectifs principaux de la statistique est de se servir de ces
  suites finies de ce type pour approximer ou estimer la loi $\mu$ de certains
  phénomènes, à laquelle on n'a pas directement accès.
\end{rem}

%
\section{Simulation de lois par leur fonction de répartition}
%

Soit $\mu$ une loi sur $\dR$ de fonction de répartition $F$. Si $G$ désigne
l'inverse continue à gauche de $F$, définie pour tout $y$ dans $[0,1]$ par
$$
G(p):=\inf\{x:F(x)\geq p\},
$$
alors, pour toute v.a. uniforme $U$ sur $[0,1]$, la v.a. $G(U)$ est de loi
$\mu$. Par exemple, pour la loi de Cauchy, de densité $(\pi(1+x^2))^{-1}$ sur
$\dR$, on a $F(x)=\arctan(x)/\pi+1/2$ et $G(p)=\tan(\pi(p-1/2))$. La
bibliothèque \SB{} pour \ML{} fournit les fonctions de répartitions inverses
pour quelques lois usuelles, cf. tableau \ref{ta:stixbox-rand} page
\pageref{ta:stixbox-rand}.

\begin{thm}[Simulation de la loi exponentielle]\label{th:simexp}
  Soit $U$ une v.a.r. de loi uniforme sur $[0,1]$ et $\la>0$ un réel, alors la
  v.a.r. $-\lambda^{-1} \log U$ suit la loi exponentielle de paramètre
  $\lambda$.
\end{thm}
Cette méthode s'applique bien entendu aux lois de Weibull (cf. section
\ref{ss:loi:weibull} page \pageref{ss:loi:weibull}), dont les lois
exponentielles ne constituent qu'un cas très particulier. Voici un exemple
d'illustration en \ML{} dont la sortie graphique est donnée par la figure
\ref{fi:simexp}~:
%
\MFILE{simexp}
%
\FIG{simexp}{1}{htbp}{Simulation de la loi exponentielle de paramètre $1/2$ au
  moyen de sa fonction de répartition.}
%
La biliothèque \SB{} fournit la fonction \texttt{rexpweib} qui permet
d'obtenir des réalisations de loi de Weibull et donc en particulier de loi
exponentielle. Faites \texttt{help rexpweib}.
 

%
\section{Simulation de lois par la méthode du rejet}
%

On attribue parfois cette méthode à J. von Neumann. Soit une loi $\mu$ de
densité $f$ sur $\dR$, que l'on désire simuler.

\begin{enumerate}
\item Supposons que $f$ est continue et à support compact $[a,b]$. Le graphe
  de $f$ est donc contenu dans un rectangle $[a,b]\times[0,M]$. On considère alors
  des vecteurs aléatoires indépendants $((X_n,Y_n))_{n\geq0}$ suivant une loi
  uniforme sur $[a,b]\times[0,M]$. On définit ensuite $T$ comme le plus petit $n$
  tel que $f(X_n) \leq Y_n$. Alors on montre que $T$ est fini presque sûrement et
  que $X_T$ a pour loi $\mu$.
\item Supposons qu'il existe une densité $g$ facile à simuler telle que $f\leq c
  g$ pour une constante $c>0$. Soit alors $(W_n)_n$ et $(U_n)_n$ deux suites
  de v.a.r. i.i.d. indépendantes avec les $W_n$ de loi de densité $g$ et les
  $U_n$ de loi uniforme sur $[0,1]$.  On pose $Y_n=cU_ng(W_n)$ et $T$ le plus
  petit $n$ tel que $Y_n<f(W_n)$. Alors la loi de $U_{T}$ a pour densité $f$.
\end{enumerate}
Ces deux méthodes s'étendent sans difficultés à des lois à densité sur
$\dR^d$. Les méthodes de rejet ont été développées et améliorées, et sont
largement utilisées dans la pratique. Elles ont l'avantage de nécessiter peu
de calculs lorsqu'elles sont couplées à des tables. La bibliothèque \SB{}
fournit trois fonctions \texttt{rjbinom}, \texttt{rjgamma} et \texttt{rjpoiss}
qui permettent d'obtenir des réalisations de lois binomiales, gamma et de
Poisson avec la méthode du rejet. On pourra consulter \cite[IV.4.3, p.
79]{bouleau} ou encore \cite[VI.5.15, p. 180]{barbe-ledoux} pour des preuves.

%
\section{Simulation de lois discrètes}
%

Soit $p_1,\ldots,p_n$ des nombres dans $[0,1]$ tels que $p_1+\cdots+p_n=1$. En
partitionnant l'intervalle $[0,1]$ en morceaux adjacents de longueurs
$p_1,\ldots,p_n$, il vient~:


\begin{thm}[Simulation d'une loi discrète à support fini]\label{th:simdiscr}
  Soit $U$ une v.a.r. de loi uniforme sur $[0,1]$ et $P:=p_1\delta_{x_1}+\cdots+p_n
  \delta_{x_n}$ une loi discrète où les $x_i$ sont tous différents. Alors la v.a.r.
  $$
  x_1 \rI_{\{U < p_1\}} 
  + x_2 \rI_{\{p_1\leq U \leq p_1+p_2\}} 
  + \cdots + x_n \rI_{\{p_1 + \cdots + p_{n-1} \leq U \leq 1\}}
  $$
  suit la loi $P$.
\end{thm}
Le code \ML{} suivant fournit la fonction \texttt{rdist} qui
implémente le résultat du théorème \ref{th:simdiscr}~:
%
\MFILE{rdist}
%
\begin{exo}
  Montrez que cette méthode s'étend sans difficultés aux lois discrètes à
  support dénombrable. Donnez un petit programme d'illustration.
\end{exo}
La bibliothèque \SB{} fournit la fonction \texttt{quantile} qui permet
d'obtenir les quantiles d'une loi à partir d'un échantillon empirique. Faites
\texttt{help quantile}.

Le nombre moyen d'instructions \texttt{if} exécutées dans le code de la
fonction \texttt{rdist} est voisin de $\log n$. On pourra consulter par
exemple \cite{knuth-taocp-2-3} pour des méthodes plus rapides faisant
intervenir des tables précalculées à partir des probabilités $p_i$. La loi
uniforme discrète peut être simulée très rapidement, sans aucune instruction
conditionnelle, comme le montre le code suivant :
%
\MFILE{randiscr}
%

\begin{thm}[Simulation de la loi binomiale]
  Soient $U_1,\ldots,U_n$ des v.a.r. i.i.d. de loi uniforme sur $[0,1]$,
  alors la v.a.r. 
  $$
  \sum_{i=1}^n \rI_{\{U_i < p\}}
  $$
  suit une loi binomiale de taille $n$ et de paramètre $p$.
\end{thm}

\begin{thm}[Simulation de la loi de Poisson]
  Soient $(E_i)_{i\geq 1}$ des v.a.r. i.i.d. de loi exponentielle de paramètre
  $\lambda >0$, alors la v.a.r.
  $$
  \rI_{\{E_1\leq 1 < E_1+E_2\}} 
  + 2 \rI_{\{E_1+E_2\leq 1 < E_1+E_2+E_3\}}
  + 3 \rI_{\{E_1+E_2+E_3\leq 1 < E_1+E_2+E_3+E_4\}}
  + \cdots
  $$
  suit une loi de Poisson de paramètre $\lambda$. Il en est de même pour :
  $$
  \rI_{\{E_1\leq 1\}} 
  + \rI_{\{E_1+E_2\leq 1\}}
  + \rI_{\{E_1+E_2+E_3\leq 1\}}
  + \cdots
  $$
\end{thm}
Comme nous le verrons plus loin, cette méthode correspond à la simulation de
la loi de $N_1$ où $(N_t)_{t\geq 0}$ est un processus de Poisson simple
d'intensité $\lambda$. L'événement $\BRA{E_1+\cdots+E_i \leq 1 < E_1+\cdots+E_{i+1}}$ correspond
au cas où le processus a sauté exactement $i$ fois avant le temps $1$.

%
\subsection{Lois fractales}
\label{ss:lois-fractales}
%

Soit $n\in\eN^*$ une base de numération.  Chaque résultat d'un schéma de
Bernoulli consistant en une suite d'expériences i.i.d. $(X_i,i\in\eN^*)$ à $n$
issues possibles de loi uniforme sur $\{0,\ldots,n-1\}$ peut se représenter
par l'écriture en base $n$ d'un nombre réel dans $[0,1]$. En d'autres termes,
on a la surjection $\cI_n$ suivante :
$$
\cI_n: (x_1,\ldots,x_k,\ldots)\in\{0,\ldots,n-1\}^{\eN^*} 
\mapsto \sum_{i=1}^{+\infty} n^{-i}\,x_i 
= \underbrace{0,x_1\cdots x_k\cdots}_{\text{en base }n} \in [0,1].
$$
On pourra penser à la base $n=2$ et au schéma de Bernoulli classique de pile ou face
avec une pièce équilibrée. La variable aléatoire $U$ définie par :
$$
U:=\cI_n(X_1,\ldots,X_k,\ldots):=\sum_{i=1}^{+\infty} n^{-i}\,X_i,
$$
suit une loi uniforme sur $[0,1]$.  
En effet, si $a:=a_1 n^{-1}+\cdots+a_m n^{-m}$ est un nombre $n$-adique, on a :
$$
\eP( a < U < a+n^{-m})
=
\eP( X_1 = a_1,\ldots,X_m=a_m)
=
\eP( X_1 = a_1) \cdots \eP(X_m=a_m)
=
n^{-m}.
$$
Réciproquement, ce calcul montre que les coefficients $(X_m)_{m\geq 1}$ de
l'écriture en base $n$ d'une variable aléatoire uniforme sur $[0,1]$ sont
i.i.d. de loi uniforme sur $\{0,\ldots,n-1\}$. Remarquons que l'ensemble des
nombres $n$-adiques est de mesure nulle pour la loi uniforme. Ainsi, les
nombres de $[0,1]$ dont l'écriture en base $n$ est constante à partir d'un
certain rang «ne comptent pas» en quelque sorte, et $\cI_n$ est
presque-sûrement une injection, et donc une bijection p.s.

\begin{exo}
  En déduire une méthode pour générer d'un seul coup $k$ réalisations
  indépendantes de loi uniforme sur $\{1,\ldots,n\}$ à partir d'une
  réalisation de précision $k$ en base $n$ d'une loi uniforme sur $[0,1]$.
  Implémenter ce résultat en écrivant une fonction \ML.
\end{exo}

Que se passe-t-il pour $U$ si l'on suppose que les $X_i$ ne suivent plus une
loi uniforme sur $\{0,n-1\}$ mais plutôt une loi $\{p_1,\ldots,p_n\}$ quelconque fixée
d'avance ? En d'autres termes, quelles sont les lois images possibles pour la
fonction $\cI_n$ sur $[0,1]$ ?  Comme $(n^rU)\text{ mod } n^r$ a la même loi
que $U$ pour tout $r\in\eN$, le graphe de la fonction de répartition de $U$
possède une propriété d'invariance d'échelle : c'est un fractal. La fonction
de répartition de $U$ est continue, mais la la loi de $U$ est étrangère à la
mesure de Lebesgue et les lois de $U$ sont toutes étrangères entre elles quand
la loi des $X_i$ balaye l'ensemble des lois discrètes sur $\{0,\ldots,n-1\}$.
L'exemple de code pour \OC{} qui suit avec sa sortie graphique \ref{fi:base2}
page \pageref{fi:base2} illustre ce phénomène. On pourra consulter \cite[exe.
3.3.15 page 81]{dacunha-castelle-duflo}, \cite[expl. IV.3.6.iii pages 100-103
et V.5.3 page 144]{barbe-ledoux} et enfin \cite[exe. V.6.15 page
155]{barbe-ledoux} à propos de ces «lois fractales»


%
\MFILE{loisfrac}
%
\FIG{base2}{1}{htbp}{Lois fractales associées à un schéma de Bernoulli.}
%

\subsection{Simulation des chaînes de Markov à valeurs dénombrables}

Soit $(X_n,n\geq 0)$ une chaîne de Markov à espace d'états $\eN$ (pour
simplifier). On note
$$K:\eN\times\eN\to[0,1]$$
son noyau de transition. On a donc par définition
$K(x,y):=\eP(X_{n+1}=y\,|\,X_n=x)$. Le noyau de transition itéré est
$K_n(x,y):=\eP(X_{n+1}=y\,|\,X_1=x)$. Comme
$$\cL(X_n\,|\,X_0=x)=\sum_{y\in\eN}K_n(y,x)\delta_y,$$
on peut utiliser le théorème
\ref{th:simdiscr} pour simuler $\cL(X_n\,|\,X_0=x)$ lorsque l'on connaît
$K_n$. Pour simuler $\cL(X_n)$ lorsque $\cL(X_0)$ est connue, on simule
d'abord $X_0$ puis $\cL(X_n\,|\,X_0)$, toujours avec le théorème
\ref{th:simdiscr}.

Lorsque la chaîne de Markov est à espace d'états fini, $K$ peut être identifié
à une matrice de transition $P$ et on a $K_n=P^n$. Il suffit donc de calculer
la puissance de la matrice de transition $P$ sous \ML{} pour pouvoir appliquer
ensuite le théorème \ref{th:simdiscr}. Voici un code \ML{} illustrant la
méthode décrite pour une matrice de transition $3\times3$. Il fait appel à la
fonction \ML{} \texttt{rdist} donnée page \pageref{co:rdist}.
%
\MFILE{simchma}

\subsection{Simulation du processus de Poisson simple}

Un processus de Poisson simple d'intensité $\la>0$ est une famille
$\PAR{N_t,t\in\dR_+}$ de v.a. indexée par $\dR_+$ et à valeurs dans $\eN$
telle que~:
\begin{enumerate}
\item Pour tout $t\in\dR_+$, la v.a. $N_t$ suit une loi de Poisson de paramètre
  $\la t$
\item Pour tout $(s,t)\in\dR_+\times\dR_+$, les v.a. $N_{t+s}-N_s$ et $N_s$ sont
  indépendantes.
\end{enumerate}
On définit les instants de saut de ce processus par récurrence en posant
$T_0:=0$ et :
$$
T_n:=\inf\BRA{t\geq 0,\,N_t>N_{T_{n-1}}}.
$$
On montre facilement que les v.a.r. $(S_n:=T_n-T_{n-1},n\in\eN^*)$ sont i.i.d.
de loi exponentielle de paramètre $\la$, et l'on a la décomposition suivante~:
\begin{equation}\label{eq:def-pps}
N_t=\sum_{n=1}^{+\infty} \rI_{\{T_n \leq t\}},
\end{equation}
Réciproquement, si l'on considère des v.a.r. $(S_n,n\in\eN^*)$ i.i.d. de loi
exponentielle de paramètre $\la>0$, et si l'on pose $T_0:=0$ et
$T_n=S_1+\cdots+S_n$, alors l'équation \eqref{eq:def-pps} définit un processus de
Poisson $\PAR{N_t,t\in\dR_+}$ d'intensité $\la$.  Les v.a.r. $(S_n,n\eN^*)$
représentent les temps inter-sauts du processus. On montre enfin à partir de
la propriété des accroissements i.i.d. du processus que l'on a une «loi des
grands nombres» :
\begin{equation}
\frac{N_t}{t} \limPS{t} \la.\label{eq:LGN-ppoiss}
\end{equation}
Le processus $\PAR{N_t,t\in\dR+}$ apparaît comme le \emph{processus de comptage}
de la suite à accroissements indépendants $(T_n)_n$. Il permet de modéliser
des \emph{files d'attentes} pour lesquelles les v.a.r. $T_n$ représentent les
temps d'arrivées dans la file et $N_t$ le nombre d'éléments dans la file à
l'instant $t$. Pensez par exemple à un guichet d'une administration, à une
caisse de supermarché ou encore à un aéroport. Dans la pratique, une fois que
l'on a décidé de simuler un phénomène avec un tel processus, il nous faut
ajuster l'intensité $\la$ en se servant des données (échantillons) dont on
dispose sur le phénomène en question. On parle alors d'estimation, et la
statistique pointe le bout de son nez. Ici, les choses sont très simples
puisque $\eE(N_t)=(t\la)^{-1}$, moyenne que l'on peut estimer à partir des
données réelles.

Pour simuler une trajectoire du processus $\PAR{N_t,t\in\dR+}$, il suffit de
simuler des lois exponentielles (par exemple avec le théorème \ref{th:simexp})
et de «sauter» en conséquence. Voici un exemple de code \ML{} faisant appel au
générateur exponentiel \texttt{rexpweib} de la bibliothèque \SB{}, dont la
sortie graphique est donnée par la figure \ref{fi:simpp0}
%
\MFILE{simps-short}
%
\FIG{simpp0}{1}{htbp}
    {Simulation d'une trajectoire d'un processus de Poisson simple.}
%
\FIG{simpp1}{1}{htbp}
    {Simulation d'une trajectoire renormalisée d'un processus de Poisson simple.}
%
\begin{exo}
  Assurez-vous de bien avoir compris le code précédent.  En simulant plusieurs
  fois ce genre de trajectoire, retrouver empiriquement que la v.a. $N_t$ suit
  bien une loi de Poisson de paramètre $\la t$ où $\la$ est le paramètre de la
  loi exponentielle des sauts.
\end{exo}

\begin{rem}[Assurances et réservoir percé]
La valeur $X_t$ du compte en banque à l'instant $t$ d'un assureur communiste peut être 
modélisée par un processus de Poisson avec dérive :
$$
X_t:=\alpha t - N_t,
$$
où la partie $\alpha t$ représente les apports, supposés continus et positifs
des assurés (cotisations) et $N_t$ les dépenses correspondant aux
remboursements liés aux sinistres des assurés. L'assureur étant communiste, il
ne touche aucun intérêt lié à son capital, et ne place pas son argent en
bourse par conviction.  Modéliser le compte en banque d'un assureur capitalise
est plus compliqué, et nécessite l'intervention de processus du type
«exponentielle de brownien» pour modéliser les placements destinés à faire des
bénéfices.  Une mutuelle constitue un cas intermédiaire, puisqu'elle ne doit
pas faire de bénéfices mais fait quand même fructifier son capital, y compris
en bourse, pour mieux servir ses adhérents.  On peut aussi voir $-X_t$ comme
la quantité d'eau dans un réservoir à ciel ouvert percé d'un petit trou :
$N_t$ représente l'eau apportée par les averses, supposées brèves, et $-\alpha t$
l'eau qui s'écoule continûement par le petit trou.
\end{rem}

%
\section{Simulation des lois gaussiennes}
\label{ss:simu-gauss}
%

Dans la pratique, les méthodes du type «Marsaglia» semblent être de loin les
plus performantes. Cependant, nous commençons par la méthode «polaire», qui
est à la fois très classique et\ldots{} très lente.

\subsection{Méthode polaire pure}

\begin{thm}[Simulation d'une loi normale]
  Soit $(X,Y)=(r\cos(\te),r\sin(\te))$ un vecteur aléatoire de $\dR^2$. Alors
  $(X,Y)$ suit une loi $\cN(0,\rI_2)$ si et seulement si $r^2=X^2+Y^2$ et
  $\te=\arg(X+iY)$ sont indépendantes et suivent respectivement une loi
  exponentielle de paramètre $1/2$ et une loi uniforme sur $[0,2\pi]$.
\end{thm}

Il en découle que si $U_1$ et $U_2$ sont indépendantes et uniformes sur
$[0,1]$, alors les v.a.r.
$$
\sqrt{-2\log U_1} \cos(2\pi U_2) \text{\quad et\quad} \sqrt{-2\log U_1}\sin(2\pi U_2)
$$
sont i.i.d. de loi normale centrée réduite. Bien entendu, pour tout
$(m,\si)\in\dR\times\dR_+^*$, une variable aléatoire réelle $Z$ suit la loi
$\cN(0,1)$ si et seulement si la v.a.r. $m+\si Z$ suit la loi $\cN(m,\si^2)$.
Nous avons donc là une méthode de simulation de lois gaussiennes
unidimensionnelles quelconques. Voici un exemple d'illustration dont la sortie
graphique est donnée par la figure \ref{fi:simnorm}~:
%
\MFILE{simnorm}
%
\FIG{simnorm}{1}{htbp}{Simulation de la loi normale par méthode «polaire»}
%
Il est préférable d'utiliser la fonction \ML{} \texttt{randn} (ou bien la
fonction \SB{} \texttt{rnorm}) qui est déjà toute programmée et qui fait appel
à une méthode plus efficace. Cette méthode de simulation polaire est coûteuse
en temps de calcul car elle nécessite l'évaluation des fonctions $\log$,
$\sqrt{\ }$ et $\cos$. On peut se passer du $\cos$ en faisant appel à la
méthode du rejet, comme décrit ci-après.

\subsection{Méthode polaire - rejet}

Si $(X,Y)=(\rho\cos(\theta),\rho\sin(\theta))$ suit la loi uniforme sur le
disque unité du plan, alors le vecteur aléatoire

$$
\frac{\sqrt{-4\log(\rho)}}{\rho}\,(X,Y)
$$
suit une loi normale centrée réduite bidimensionnelle.  La loi de $(X,Y)$
est facile à simuler par la méthode du rejet à partir d'une loi uniforme sur
le carré $[-1,+1]^2$ (rejet dans 21\% des cas puisque $\pi/4\simeq 0.79$).

On remarquera qu'ici, $\theta$ et $\rho$ sont indépendantes, que $\rho$ suit une loi de
densité $u\mapsto 2u\mathrm{I}_{[0,1]}(u)$ et que $\theta$ suit une loi uniforme sur
$[0,2\pi]$. D'autre part, on a
$$
\frac{\sqrt{-4\log(\rho)}}{\rho}\,(X,Y) 
= \sqrt{-4\log(\rho)}\,(\cos(\theta),\sin(\theta)).
$$
On vérifie alors facilement que $-4\log(\rho)$ suit une loi exponentielle de
paramètre $1/2$ :
$$
\int_0^1 \!\!\!f(-4\log(\rho))\,2\rho\,d\rho
=
\int_0^{+\infty} \!\!\!f(u)\,\frac{1}{2}\,e^{-u/2}\,du.
$$
Cette méthode, que l'on peut qualifier de «polaire - rejet», est celle
utilisée dans \ML{} 4 pour implémenter la fonction \texttt{randn}.
Elle demeure cependant assez lente, en raison à la fois des 21\% de rejet et de
l'évaluation des fonctions $\log$ et $\sqrt{\ }$.

\subsection{Méthode de Marsaglia (algorithme du Ziggurat)}

Les versions 5 et 6 de \ML{} utilisent plutôt une méthode due à Marsaglia,
appelée «algorithme du Ziggurat\footnote{Il s'agit de temples de Mésopotamie,
  dont la forme consiste en un empilement de parallélépipèdes rectangles de
  plus en plus petits.}».  Elle consiste à utiliser la méthode du rejet
conjointement avec des tables donnant une approximation de la densité
gaussienne par des rectangles.  Ces tables étant précalculées, la génération
de nombres aléatoires gaussiens est très rapide, quasiment aussi rapide que
celle des nombres aléatoires uniformes.  On pourra en trouver une version
moins optimisée dans le tome II du livre de Knuth : «The Art of Computer
Programming» \cite{knuth-taocp-2-3}.

On observe tout d'abord qu'il suffit de savoir simuler une v.a.r.  de
densité
$$
f(u):=\sqrt{\frac{\pi}{2}}\,e^{-u^2/2}\,\mathrm{I}_{[0,+\infty[}(u),
$$
puisque le signe peut être obtenu via une loi de Bernoulli symétrique.
Considérons à présent $n$ points $x_1<\cdots<x_n$.  En prenant $x_1=0$ et
$x_{n+1}=+\infty$, les points du plan de coordonnées $(x_i,f(x_i))$ constituent les
coins inférieurs droits de $n$ rectangles plats adjacents (horizontaux), qui
recouvrent par excès l'aire sous la courbe de $f$.  La hauteur du
$k^\text{ième}$ rectangle vaut $f(x_k)-f(x_{k+1})$.

On choisit les $x_i$ de telle sorte que la portion d'aire de $f$ située dans
chaque rectangle soit constante (et égale à $1/n$). Ensuite, l'algorithme
consiste à choisir l'un des rectangles en simulant une loi uniforme sur les
entiers $\{1,\ldots,n\}$. Une fois le rectangle choisi, on utilise :
\begin{itemize}
\item la méthode du rejet exacte pour le premier et le dernier
  rectangle, via l'expression de $f$;
\item la méthode du rejet approximative pour les rectangles
  intermédiaires, qui consiste à utiliser la partie du rectangle sous
  la courbe de $f$, via le rapport $\sigma_k:=x_{k-1}/x_k$, sans faire
  appel à l'expression de $f$.
\end{itemize}
Les $x_i$ et les $\sigma_i$ sont précalculés une fois pour toutes et stockés dans
une table, et $n$ est choisi suffisamment grand\footnote{Dans \ML{}, $n=128$.}
pour que les taux de rejet soient faibles et les approximations bonnes.  Les
calculs sont très réduits une fois la phase d'initialisation passée.

Il n'est pas nécessaire de considérer la partie positive de la densité
gaussienne, puisque le découpage en rectangles est symétrisable.

%
\subsection{Simulation d'un vecteur gaussien}\label{se:simvg}
%

%FIXME: utiliser imagec et contourplot
% Matrice de covariance et matrice des coefficients de corrélation

Soit $m\in\dR^n$ et $\Ga\in\cS_n^+(\dR)$ une matrice réelle de taille $n$,
symétrique positive, et soit $Y$ est un vecteur aléatoire gaussien standard de
moyenne nulle et de matrice de covariance $\ID_n$, alors le vecteur aléatoire
$X:=\Ga^{\frac{1}{2}} Y + m$ est un vecteur gaussien de moyenne $m$ et de
matrice de covariance $\Ga$. Réciproquement, si $X$ est un vecteur gaussien de
loi $\cN(m,\Ga)$, alors $\Ga^{-1/2}(X-m)$ est un vecteur aléatoire gaussien de
loi $\cN(0,\ID_n)$.

On peut également utiliser la décomposition de Cholesky de $\Ga=AA^\top$ où
$A$ est une matrice triangulaire inférieure, en lieu et place de la
décomposition en racine carrée $\Ga=\Ga^{1/2}\Ga^{1/2}$, ce qui moins coûteux
en terme de calculs (on évite de diagonaliser $\Ga$ et $A$ est creuse).

Si $Y$ est un vecteur gaussien de loi $\cN(0,\ID_n)$, ses coordonnées sont
i.i.d. de loi $\cN(0,1)$. Ainsi, on peut simuler une réalisation de $Y$ en
simulant $n$ réalisations indépendantes $Y_1(\om),\ldots,Y_n(\om)$ de loi
$\cN(0,1)$. Il suffit alors de calculer $\Ga^{1/2}Y(\om)+m$ pour
obtenir une réalisation de loi $\cN(m,\Ga)$.

Voici un exemple de simulation de vecteur gaussien écrit en \ML{}~:
%
\MFILE{simvg}
%

%
\subsection{Simulation d'un mouvement brownien}
%

Vers 1827, le jeune botaniste écossais Robert Brown obserse au microscope le
mouvement incessant de grains de pollen dans une goûte d'eau, et a alors
l'intuition que cette agitation est d'origine physique, et non pas biologique.
Ce faisant, il vient de mettre en évidence le phénomène qui porte aujourd'hui
son nom : le mouvement brownien. Vers 1900, le mathématicien Louis Bachelier
s'intéressa dans sa thèse intitulée «La théorie de la spéculation», méprisée à
l'époque et tombée longtemps dans l'oubli, à l'évolution des cours de la
bourse, dont le comportement ressemble à un mouvement brownien. Quelques
années plus tard (1905), et de façon indépendante, le physicien Albert
Einstein donne une explication théorique du mouvement brownien à base de
physique classique : chaque particule subit des chocs incessants du milieu qui
provoquent son agitation «brownienne». Un peu plus tard, le physicien Paul
Langevin améliorera cette approche en tenant compte de l'effet du fluide ou
d'une force extérieure sur la diffusion des particules. Tous ces
développements vont conduire le mathématicien Norbert Wiener à introduire vers
1923 la notion mathématique de mouvement brownien, telle que nous la
connaissons aujourd'hui. Ce travail fondamental constitue le socle d'un pan
important de la théorie des probabilités modernes construites à partir de la
théorie de la mesure, au milieu du vingtième siècle, par de nombreux
mathématiciens dont les plus illustres sont sans doute Kolmogorov, Doob et
Lévy\footnote{Citons également Wolfang Doeblin, qui appartient au club très
  ouvert des oubliés de l'histoire \cite{doeblin}.}. Les objets et assertions
mathématiques construits à partir du mouvement brownien forment ce que l'on
appelle de nos jours la «théorie des processus stochastiques»
\cite{bass-2,karatzas-shreve}. Très dévoloppée par l'école française de
probabilités, elle possède un vaste champ d'application : analyse
mathématique, géométrie, physique, biologie, finance\ldots

Un mouvement brownien unidimentionnel standard sur l'intervalle de temps
$[0,1]$, issu de $x\in\dR$, est une famille $(B_t,t\in[0,1])$ de variables
aléatoires
$$
\begin{array}[c]{rcl}
B_t:\PAR{\Om,\cA,\eP}&\to&\dR\\
\om&\mapsto&B_t(\om),
\end{array}
$$
indexée par $t\in[0,1]$ et vérifiant les propriétés suivantes :
\begin{enumerate}
\item $B_0=x$
\item Pour presque tout $\om$, la fonction $t\in[0,1]\mapsto B_t(\om)$ est
  continue.
\item Pour tout $t\in\,]0,1]$, la v.a. $B_t$ est gaussienne centrée de
  variance $t$.
\item Pour tous $(t,s)\in\,]0,1]^2$, les variables $B_t$ et $B_{t+s}-B_t$ sont
  indépendantes.
\end{enumerate}
Pour résumer, il s'agit d'un \emph{processus gaussien centré à trajectoires
  continues et à accroissement indépendants}. On montre de différentes
manières qu'il est possible de construire un tel processus\footnote{Un
  théorème de Kolmogorov assure l'unicité de la loi du processus lorsque l'on
  fixe les lois marginales fini-dimensionnelles.}, cf. par exemple
\cite{karatzas-shreve}. Le processus $B:=(B_t,t\in[0,1])$ peut également être
vu comme \emph{une} variable aléatoire à valeurs dans l'espace des fonctions
continues nulles en zéro $\cC_0([0,1],\dR)$, muni de la topologie
adéquate\footnote{Topologie de la convegence simple sur $\cC([0,1],\dR)$,
  induite sur $\cC([0,1],\dR)\subset\dR^{[0,1]}$ par celle générée sur
  $\dR^{[0,1]}$ par les cylindres $A_1 \times\cdots \times A_m \times \dR \times \cdots \subset
  \dR^{[0,1]}$ où $m\geq 0$ et les $A_1,\ldots,A_m$ sont des ouverts de $\dR$.
  C'est-à-dire la plus petite topologie qui rend les applications
  $b_t:\om\in\cC([0,1],\dR)\mapsto \om(t)$ continues pour tout $t\in[0,1]$.} :
$$
\begin{array}[c]{rcl}
B:\PAR{\Om,\cA,\eP}&\to&\cC_0([0,1],\dR)\\
\om&\mapsto&\PAR{t\in[0,1]\mapsto B_t(\om)}.
\end{array}
$$
On parle de loi du processus pour désigner la loi de cette variable
aléatoire à valeurs dans un espace de fonctions. La loi $\cW$ du mouvement
brownien standard est appelée \emph{mesure de Wiener}. C'est en quelque sorte
une mesure gaussienne de dimension infinie sur $\cC_0([0,1],\dR)$ puisque pour
tout $t$, la variable aléatoire à valeurs réelles
$$
\begin{array}[c]{rcl}
b_t:\PAR{\cC_0([0,1],\dR),\cW}&\mapsto&\dR\\
f&\mapsto& \om_t(f):=f(t)
\end{array}
$$
est une gaussienne dans $\dR$ de même loi que $B_t$.  Ainsi, les v.a.r.
$B_t$ apparaîssent comme les lois marginales de la loi gaussienne de dimension
infinie $\cW$. Nous vérons plus loin que la coraviance de $B_t$ et $B_s$ est
exactement $\min(t,s)$.

On généralise sans trop de difficultés la définition précédente à tout $\dR_+$
en temps. Un mouvement brownien quelconque à valeurs dans $\dR^d$ s'obtient en
considérant l'image de $(B^{(1)}_t,\ldots,B^{(d)}_t)$ par une matrice
constante $M\in\cM_d(\dR)$, où les
$(B^{(1)}_t,t\in\dR_+),\ldots,(B^{(d)}_t,t\in\dR_+)$ sont des mouvements
brownien unidimentionnels standards et \emph{indépendants} sur $\dR_+$.

Le mouvement brownien joue un rôle central dans la théorie des probabilités.
Heuristiquement, il constitue l'analogue continu d'une marche aléatoire
simple, dont il peut d'ailleurs se déduire par le théorème central limite (cf.
théorème \ref{th:pid} page \pageref{th:pid}). À chaque instant, une marche
aléatoire simple choisit de façon indépendante de son passé l'accroissement de
sa position actuelle dans son voisinage, un peu comme un ivrogne. Le mouvement
brownien est l'analogue continu de ce processus dans la mesure où les instants
de choix de nouvelle position ne sont plus discrets mais «infiniment
rapprochés». Si l'on revient à l'image physique d'une particule brownienne,
$B_t$ représente la position (ou la vitesse selon que l'on considère les
modèles d'Einstein ou de Langevin) de la particule à l'instant $t$.

Pour simuler une trajectoire d'un mouvement brownien, il suffit de remarquer
que pour tout $0<t_1<\cdots<t_n$, le vecteur aléatoire
$\PAR{B_{t_1},\ldots,B_{t_n}}$ suit une loi gaussienne centrée de matrice de
covariance $\Ga$ connue. En effet, pour $i<j$, on a~:
$$
\Ga_{i,j}
=\moyp{}{B_{t_i}B_{t_j}}
=\moyp{}{B_{t_i}\PAR{B_{t_j}-B_{t_i}}}+\moyp{}{B_{t_i}^2}=t_i.
$$
On a donc $\Ga_{i,j}=\min(t_i,t_j)$, et de façon plus générale :
$$
\cov{}{B_t}{B_s}=\min(t,s)=\frac{1}{2}\PAR{t+s-|t-s|}
\text{\quad et \quad} 
\eE(|B_t-B_s|^2)=|t-s|^2.
$$
Il ne reste donc plus qu'à utiliser la méthode présentée dans la section
\ref{se:simvg} pour simuler une réalisation du vecteur gaussien
$\PAR{B_{t_1},\ldots,B_{t_n}}$.  Cette méthode peut être utilisée pour simuler
la loi d'un processus gaussien quelconque $\PAR{X_t,t\in\dR_+}$ à partir de sa
fonction de covariance $(t,s)\in\dR_+^2\mapsto\cov{}{X_t}{X_s}$. Le code \ML{}
suivant en donne un exemple, dont la sortie graphique est donnée par la figure
\ref{fi:simmb}~:
%
\MFILE{simmb}
%
\FIG{simmb}{1}{htbp}{Simulation d'une trajectoire d'un processus gaussien à
  partir de sa fonction de covariance (mouvement brownien ici).}
%
Le mouvement brownien étant à accroissements indépendants, il satisfait en
particulier à la propriété de Markov. En d'autre termes, le futur du processus
est indépendant du passé lorsque l'on connaît le présent. Il a donc une
mémoire courte en quelque sorte. Ainsi, pour prolonger une trajectoire
simulée, on peut utiliser la même méthode à partir du dernier point de cette
trajectoire, ce qui n'est pas possible avec des processus à mémoire longue.
Ainsi, on a pour un mouvement brownien standard $\PAR{B_t,t\in\dR_+}$ avec
$B_0:=0$
$$
(B_{t_1},\ldots,B_{t_n}):=(Z_1,Z_1+Z_2,\ldots,Z_1+\cdots+Z_n), \text{ où }
Z_k:=B_{t_k}-B_{t_{k-1}}.
$$
Les $Z_k$ sont des v.a.r. gaussiennes indépendantes de variances
respectives $t_{k+1}-t_k$.  Ceci est bien conforme à l'intuition que l'on peut
avoir du mouvement brownien~: une succession de petits sauts gaussiens
indépendants. Voici un code \ML{} faisant appel à cette méthode pour simuler
une trajectoire brownienne, et dont la sortie graphique est donnée par la
figure \ref{fi:simmb}~:
%
\MFILE{simmb2}
%
Cette méthode est beaucoup plus efficace que la précédente, mais repose de
façon cruciale sur l'indépendance des accroissements du mouvement brownien,
propriété que n'a pas forcément un processus gaussien quelconque.
%
\FIG{simmb2}{1}{htbp}{Simulation d'une trajectoire d'un mouvement brownien.}
%  
Comme nous l'avons dit, les trajectoires browniennes sont presque-sûrement
continues. En revanche, elles ne sont pas dérivables, mais sont hölderiennes
d'indice $1/2-\veps$ pour tout $\veps>0$, c'est-à-dire que pour presque tout
$\om$, il existe une constante $c>0$ telle que pour tous $t$ et $s$ :
$$
\ABS{B_t(\om)-B_s(\om)} \leq c\,\ABS{t-s}^{1/2-\veps}.
$$
Cela a motivé l'introduction et l'étude de processus gaussiens de
régularité höldérienne arbitraire, appelés «browniens fractionnaires», de
fonction de covariance $(t^h+s^h+|t-s|^{2h})/2$ avec $0<h<1$ fixé (paramètre
de Hurst). Le brownien fractionnaire d'indice $h$ a des trajectoires
höldériennes d'indice $h-\veps$, et il correspond au mouvement brownien pour
$h=1/2$. Ces processus ne sont pas à accroissements indépendants, et ne sont
pas de Markov, pour $h\neq 1/2$. Il permettent donc de modéliser des
phénomènes à mémoire longue. À l'heure actuelle, de nouveaux processus à
régularité non constante en temps ou en espace, qualifiés de
«multifractionnaires», font l'objet de recherches dans le monde des
probabilités.

\begin{rem}
  Le mouvement brownien pouvant être vu comme une somme infinie de petits
  accroissements gaussiens indépendants, il est naturel de s'attendre à une
  sorte de «loi des grands nombres». Cette intuition est juste, et l'on montre
  que l'on a :
  \begin{equation}
    \frac{B_t}{t} \limPS{t} 0.\label{eq:LGN-brown}
  \end{equation}
\end{rem}

\begin{rem}
  Insistons sur le fait que chaque «trajectoire simulée» obtenue par ces
  procédés correspond plutôt à une réalisation
  $(X_{t_1}(\om),\ldots,X_{t_n}(\om))$, pour un $\om$ donné, de la loi
  fini-dimentionnelle du processus $(X_t,t\in\dR_+)$ aux instants
  $t_1,\ldots,t_n$.  Simuler la véritable loi du processus n'a pas beaucoup de
  sens car il s'agirait alors de d'obtenir une courbe 
  $$t\in\dR_+\mapsto X_t(\om),$$
  or $\dR$ est infini donc inaccessible dans sa
  totalité sur un ordinateur !  On simule donc des lois marginales
  fini-dimentionnelles de la variable aléatoire à valeurs fonctionnelles
  $(\om\in\Om\mapsto\PAR{t\in\dR_+\mapsto X_t(\om)})$. Elle sont à percevoir
  comme des discrétisations de trajectoires probables du processus.
\end{rem}

%
\section{Simulation de la loi uniforme sur les p-sphères}
\label{se:unif-pspheres}
%

Nous savons que si $(X,Y)$ est un vecteur gaussien de loi normale centrée
réduite, et si $(r,\theta)$ désigne son écriture en coordonnées polaires :
$(X,Y)=(r\cos(\theta),r\sin(\theta))$, alors $r^2$ et $\theta$ sont des v.a.r. indépendantes
qui suivent respectivement une loi exponentielle de paramètre $1/2$ et une loi
uniforme sur $[0,2\pi]$. Le vecteur aléatoire $(X,Y)/r$ suit la loi uniforme sur
le cercle unité. De façon générale, si $(X_1,\ldots,X_n)$ est un vecteur gaussien
de loi $\cN(0,\rI_n)$ et
$$
\NRM{X}_2:=\sqrt{X_1^2+\cdots+X_n^2},
$$
alors $(X_1/\NRM{X}_2,\ldots,X_n/\NRM{X}_2)$ et $\NRM{X}_2$ sont
indépendants, $\NRM{X}_2^2$ suit une loi du $\chi^2$ à $n$ degrés de liberté,
et $(X_1/\NRM{X}_2,\ldots,X_n/\NRM{X}_2)$ suit la loi uniforme sur la sphère
euclidienne unité de $\dR^n$. Attention, les v.a.r. $X_i/(\sqrt{n}\NRM{X}_2)$
ne suivent pas des lois de Student, car $\NRM{X}_2$ et $X_i$ ne sont pas
indépendantes !

Ce qui précède peut s'étendre à des normes non euclidiennes : pour tout
$n\in\{2,3,\ldots\}$, tout $p\in\dR_+^*$ et tout $x\in\dR^n$, on pose
$$
\NRM{x}_p:=(\ABS{x_1}^p+\cdots+\ABS{x_n}^p)^{1/p}.
$$ 
On étend cette définition au cas $p=\infty$ en posant
$$
\NI{x}:=\max\PAR{\ABS{x_1},\ldots,\ABS{x_n}}.
$$
La $p$-sphère positive de $\dR^n$, notée $\dS(n,p)$, est définie par :
$$
\dS_+(n,p):=\BRA{x\in\dR_+^n,\,\NRM{x}_p=1}.
$$
Pour $p=1$, on obtient le «simplexe» standard, pour $p=2$, la portion à
coordonnées positives de la sphère euclidienne de rayon $1$, et pour
$p=\infty$, la surface du cube unité $[0,1]^n$.  Des dessins peuvent aider à
mieux se repérer. $\dS_+(n,p)$ est donc une surface compacte de $\dR^n$, de
dimension $n-1$.  Il serait possible de définir une mesure uniforme sur
$\dS_+(n,p)$, en considérant la trace de la mesure de Lebesgue sur
$\dS_+(n,p)$. Par soucis de simplicité, nous ne le feront pas ici, et nous
nous restreignons volontairement aux cas $p\in\{1,2,\infty\}$.

En tant que surface du cube $[0,1]^n$, $\dS_+(n,\infty)$ peut être vu comme la
réunion disjointe, mais connexe, de $2n$ faces, chacune étant identifiable à
$[0,1]^{n-1}$. La mesure uniforme sur $\dS_+(n,\infty)$ peut donc être définie
en considérant la mesure uniforme sur chaque face. Cette loi uniforme sur
$\dS_+(n,\infty)$ est très simple à simuler puisqu'il suffit de choisir la
face uniformément sur $\{1,\ldots,2n\}$, puis de générer une réalisation d'un
vecteur aléatoire $(X_1,\ldots,X_{n-1})$ dont les entrées sont i.i.d. et de
loi uniforme sur $[0,1]$, obtenues par \texttt{rand} par exemple.  Si l'on
désigne par $(A,I)\in\{0,1\}\times\{1,\ldots,n\}$ la face aléatoirement
choisie, le vecteur aléatoire $(Y_1,\ldots,Y_n)$ obtenu en insérant $A$ en
position $I$ de la suite $X_1,\ldots,X_{n-1}$ suit la loi uniforme sur
$\dS_+(n,\infty)$.

Pour $p=2$, la loi uniforme sur $\dS_+(n,2)$ est la restriction normalisée de
la mesure uniforme sur la sphère. Cette dernière se simule comme expliqué à la
fin de la section \ref{ss:simu-gauss}, à partir d'une loi gaussienne. En fait,
si $(X_1,\ldots,X_n)$ est un vecteur aléatoire à composantes i.i.d.
\emph{positives} de loi de densité
$\sqrt{2/\pi}\,\exp(-x^2/2)\,\rI_{[0,+\infty[}\,dx$, alors le vecteur aléatoire
$X/\sqrt{X_1^2+\cdots+X_n^2}$ suit la loi uniforme sur $\dS_+(n,2)$.

Pour $p=1$, $\dS_+(n,1)$ est un simplexe, qui est constitué de la partie à
coordonnées positives de l'hyperplan $\dH_n$ d'équation $x_1+\cdots+x_n=1$.
Pour $n=2$, on obtient un segment de longueur $\sqrt{2}$, pour $n=3$, un
triangle équilatéral de côté $\sqrt{2}$, pour $n=4$, un tétrahèdre régulier de
côté $\sqrt{2}$, etc.  Mentalement, nous effectuons naturellement une
identification entre $\dH_n$ et $\dR^{n-1}$ lorsque $n$ vaut $2$ et $3$, en
identifiant par rotation de centre $(1,0,\ldots,0)$ l'hyperplan $\dH_n$ à
$\dR^{n-1}\times\{0\}$. En considérant la mesure Lebesgue $\la_{n-1}$ sur
$\dH_n$ découlant de celle de $\dR^{n-1}$ par cette identification, l'ensemble
$\dS_+(3,2)$ par exemple a pour mesure $\sqrt{3}/2$, qui est la surface du
triangle équilatéral de côté $\sqrt{2}$ (souvenez-vous, «base fois hauteur sur
2»). De façon plus générale, on montre que
$\la_{n-1}(\dS_+(n,1))=\sqrt{n}/(n-1)!$. Il est naturel d'appeler loi uniforme
sur $\dS_+(n,1)$ la restriction de $\la_{n-1}$ à $\dS_+(n,1)$, normalisée en
la divisant par $\la_{n-1}(\dS_+(n,1))$. Comment simuler cette loi ? En
d'autres termes, comment faire pour obtenir des réalisations i.i.d. d'un
vecteur aléatoire $(X_1,\ldots,X_n)$ dont la loi serait la loi uniforme sur
$\dS_+(n,1)$ que nous venons de décrire ?

On pourrait croire que si $X:=(X_1,\ldots,X_n)$ est un vecteur aléatoire de
$\dR^n$ à coordonnées i.i.d. et uniformes sur $[0,1]$, alors le vecteur
aléatoire $X/(X_1+\cdots+X_n)$, qui est à valeurs dans $\dS_+(n,1)$, suit la
loi uniforme sur $\dS_+(n,1)$. C'est faux malheureusement, comme on peut s'en
convaincre déjà lorsque $n=2$.

La solution consiste à imiter la méthode gaussienne utilisée pour $p=2$. Si
$X:=(X_1,\ldots,X_n)$ est un vecteur aléatoire à coordonnées i.i.d. de loi
exponentielle de paramètre $1$, alors le vecteur aléatoire
$X/(X_1+\cdots+X_n)$ suit la loi uniforme sur $\dS_+(n,1)$. La preuve n'est
pas difficile, mais nous l'omettons ici.

De manière plus générale, pour tout $p\in\dR_+$, on peut montrer que si
$X:=(X_1,\ldots,X_n)$ est un vecteur aléatoire à composantes i.i.d. suivant
une loi de densité
$$
\frac{p}{\Ga(p)}\,\exp(-t^p)\,\rI_{\dR_+}(t)
$$
alors le vecteur aléatoire $X/\NRM{X}_p$ suit la loi uniforme sur
$\dS_+(n,p)$, et qu'il est de plus indépendant de la v.a.r. $\NRM{X}_p$.

Le cas $p=1$, pour lequel $\dS_+(n,1)$ est un simplexe, est très important car
$\dS_+(n,1)$ représente l'ensemble des lois de probabilités discrètes sur
$\{1,\ldots,n\}$. Simuler la loi uniforme sur $\dS_+(n,1)$ revient à choisir
uniformément une loi de probabilité discrète sur $\{1,\ldots,n\}$.  La loi
uniforme sur $\dS_+(n,1)$ est un cas particulier de la loi de Dirichlet, cf.
\ref{ss:loi:dirichlet}. Voici un exemple de fonction \ML{} qui renvoie une
réalisation de la loi de Dirichlet :
%
\MFILE{rdirichlet}
%
Cette méthode permet également de choisir de manière «uniforme» la matrice de
transition d'une chaîne de Markov, en utilisant des réalisations indépendantes
de la loi uniforme sur le simplexe. Voici un exemple de code \ML{} :
%
\MFILE{rmatmar}
%
Bien entendu, tout repose sur le sens que l'on donne à la «loi uniforme» sur
les classes d'objets considérés. Il y a une part d'arbitraire que l'on ne peut
pas évacuer.

%
\section{Un exemple : processus de Poisson composé gaussien}
%

Soit $\PAR{X_n,n\in\eN^*}$ une suite de v.a.r. i.i.d. de loi normale et
$\PAR{U_n,n\in\eN^*}$ une suite de v.a.r. i.i.d. de loi exponentielle de
paramètre $\la>0$, indépendante de la suite précédente. On pose $T_0:=0$ et
$T_n:=U_1+\cdots+U_n$ pour tout $n\in\eN\*$. On définit à présent le processus
$\PAR{Y_t,t\in\dR_+}$ par~:
$$
Y_t:=\sum_{n=0}^{+\infty} X_n\,\rI_{[T_n,T_{n+1}[}(t).
$$
Ce type de processus peut par exemple modéliser la quantité d'argent dans
une caisse commune. Les temps de sauts correspondent à des apports (sauts
positifs) des membres ou à des dépenses (sauts négatifs). Bien entendu, on
tolère alors des dettes arbitrairement grandes ici\ldots On dit que
$(Y_t,t\in\dR_+)$ suit un \emph{processus de Poisson composé}.  Cette
terminologie n'est pas très heureuse dans la mesure où la loi du processus à
un instant donné n'est pas forcément une loi de Poisson. Ici, on peut vérifier
sans difficulté (exercice !) que le processus est bien défini et que sa loi
conditionnelle sachant les instants de sauts $(T_n,n\in\eN^*)$ est gaussienne.
La loi de $Y_t$ pour $t>0$ fixé n'est pas une loi de Poisson. Voici un code
\ML{} simulant une trajectoire d'un tel processus, dont la sortie graphique
est donnée par la figure \ref{fi:simpsn} :
%
\MFILE{simpscg-short}
%
\FIG{simpsn}{1}{htbp}{Simulation d'une trajectoire d'un processus à temps de
  sauts exponentiels et à amplitudes de sauts gaussiennes.}
%
\begin{exo}
  À votre avis, que permet de simuler le code suivant~?
  \begin{center}
    \texttt{stairs(cumsum(rgamma(30,3,1)),cumsum(rpoiss(30,1)+randn(30,1)));}
  \end{center}
\end{exo}

%
\section{Évaluation de la qualité d'une simulation}
%

%DCD section 4.4, pages 101 et suivantes.
%FIXME:
De nombreuses méthodes existent. Les tests statistiques, comme le test du
chi-deux ou le test de Kolmogorov-Smirnov, permettent de comparer la loi
empirique avec la loi véritable, cf. chapitre \ref{ch:ic+tests} page
\pageref{ch:ic+tests}. 

%
\section{Un exemple de simulation d'une loi compliquée}
%

On se propose de transposer en \ML{} un petit exercice qui figure dans
\cite[page 82]{bouleau}. La figure \ref{fi:fiab} représente un réseau
électrique constitué de $7$ éléments entre deux points $A$ et $B$. Les durées
de vie des éléments sont représentées par des variables aléatoires
$T_1,\ldots,T_7$. La durée de vie du système est alors donnée par
$$
 T := T_7 \lor \PAR{\PAR{T_1 \lor T_2 \lor T_3} \land \PAR{T_6 \lor \PAR{T_4 \land T_5}}}
$$
où $\lor$ désigne le supremum et $\land$ l'infimum. On peut donc simuler $T$
à partir d'une simulation de la loi jointe des $T_i$.
%
\FIG{fiab}{.6}{htbp}{Schéma d'un réseau}
%
On considère le cas où $(T_1,T_2,T_3,T_4)$ sont indépendants de loi
exponentielles de paramètres respectifs $(1/2,1/2,1/2,1/3)$ et que le couple
$(T_5,T_6)$ sont indépendantes des précédentes, de loi jointe de densité
$$
\frac{1}{6} 1_{\{2\leq x+y \leq 8\}} 1_{\{-1\leq x-y \leq 1\}} dx dy,
$$
et enfin, $T_7=T_4$.  Notons que le couple $((T_5+T_6-2)/6,(T_5-T_6+1)/2)$
suit une loi uniforme sur $[0,1]^2$, produit tensoriel de deux lois uniformes
sur $[0,1]$ (donc indépendantes).
%
\MFILE{fiab}
%
Intéressons nous à la durée de vie moyenne du système, qui n'est rien d'autre
que $\eE(T)$.  Si $X_1,\ldots,X_n$ sont $n$ v.a.r. i.i.d. de même loi que $T$,
nous savons simuler des réalisations $X_1(\om),\ldots,X_n(\om)$. L'inégalité
de Chebychev donne :
$$
\eP\PAR{\ABS{\frac{X_1+\cdots+X_n}{n}-\eE(T)}>\veps} \leq\frac{\varp{}{T}}{n\veps^2}.
$$
La quantité $(X_1+\cdots+X_n)/n$ représente la moyenne empirique que nous
pouvons obtenir par simulation. Reste à majorer la variance $\varp{}{T}$.
L'encadrement $T_7 \leq T \leq T_7+T_1+T_2+T_3$ permet d'écrire :
\begin{align*}
  \varp{}{T}&=\moyp{}{T^2}-\moyp{}{T}^2\\
  &\leq\eE(\PAR{T_7+T_1+T_2+T_3}^2)-\eE(T_7)^2\\
  &=\varp{}{T_7+T_1+T_2+T_3}+\PAR{\eE(T_7)+\eE(T_1)+\eE(T_2)+\eE(T_3)}^2-\eE(T_7)^2\\
  &=\frac{1}{\la_1^2}+\frac{1}{\la_2^2}+\frac{1}{\la_3^2}+\frac{1}{\la_4^2}
  +\PAR{\frac{1}{\la_1}+\frac{1}{\la_2}+\frac{1}{\la_3}+\frac{1}{\la_4}}^2
  -\frac{1}{\la_4^2}\\
  &=93.
\end{align*}
On constate empiriquement que cette majoration de la variance est très
mauvaise puisque la variance empirique est plutôt de l'ordre de quelques
unités. Cependant, elle a le mérite d'exister.  On peut donc affirmer que l'on
a
$$
\eP\PAR{\ABS{\frac{X_1+\cdots+X_n}{n}-\eE(T)}>\frac{1}{10}}
\leq\frac{1}{10},
$$
pour $n\geq n_0:=93000$. Bien évidemment, ce seuil $n_0$ sur $n$ sera
d'autant meilleur (i.e. petit) que notre majoration de la variance $\varp{}{T}$
sera bonne. 

\begin{exo}
  Supposons que $T_7$ suive une loi exponentielle indépendante des autres de
  paramètre $\te$. Écrire un programme \ML{} qui détermine une valeur de $\te$
  telle que $\eE(T_7)$ soit minimale et $\eE(T) \geq 10$.
\end{exo}

%
\subsection{Rudiments de fiabilité}
%

Soit $T$ la date de première défaillance d'un système mis en marche à
la date $t=0$, alors :
\begin{itemize}
\item La \emph{durée de vie du système} est la variable $T$.
\item La \emph{fiabilité} à la date $t$ est : $R(t):=\eP(T \geq t)$.
\item La \emph{durée de survie} du système à l'instant $t$ est la
  variable $T_t$ de distribution :
  $$
  \eP(T_t \geq s) =\eP(T-t\geq s\ |\ T\geq t) =\frac{R(t+s)}{R(t)}
  \text{ pour } s \geq 0.
  $$
\item Le \emph{taux de défaillance} ou \emph{taux de panne} du système
  est la fonction~: $$h(t):=-\frac{R'(t)}{R(t)}.$$
\item Le \emph{temps moyen de panne} du système (Mean Time To Failure,
  MTTF) est : $m:=\eE(T)$.
\end{itemize}

Soit un système à $n$ composantes, de durée de vie respectives
$T_1,\ldots,T_n$. On note $T$ la durée de vie du système. Alors:
\begin{itemize}
\item Si les composants sont en série, $T=\min(T_1,\ldots,T_n)$ et
  $R(t)=R_1(t)R_2(t)\ldots R_n(t)$.
\item Si les composants sont en parallèle, $T=\max(T_1,\ldots,T_n)$ et
  $R(t)=1-(1-R_1(t))(1-R_2(t))\cdots(1-R_n(t))$.
\end{itemize}

La loi exponentielle (de paramètre $\la$) est souvent utilisée pour
modéliser une durée de vie $T$, sa fiabilité est $R(t)=e^{\la
  t}\,\rI_{\dR_+}(t)$. Sa durée de survie à l'instant $t$ est
indépendante de $t$, et l'on parle alors de \emph{système sans
  mémoire} :
$$
\eP(T \geq t+s\,|\,T\geq t)=\eP(T \geq s).
$$
On peut montrer que la loi exponentielle est la seule loi non
triviale à support dans $\dR^+$ qui a cette propriété.  La somme de
$n$ v.a. i.i.d. de loi exponentielle de paramètre $\la$ est une loi
Gamma de paramètres $(\la,n)$, dite aussi loi de Erlang. Une autre loi
utilisée pour modéliser les durées de vie est la de Weibull $W(a,b)$,
définie à partir de sa fiabilité, qui vaut par définition
$R(t)=1-F(t)=e^{-(bt)^a}\rI_{\{t \geq 0\}}$. Elle modélise bien le
comportement de $a$ composants de loi exponentielle de paramètre $b$
en parallèle pour $t$ pas trop grand.  La loi exponentielle de
paramètre $\la>0$ correspond à $W(\la,1)$.

\begin{table}[tbp]
\begin{center}
\begin{sideways}
\begin{tabular}[c]{|l|l|l|l|l|l|}\hline
\textbf{Loi}&\textbf{Densité}&\textbf{F. de Rép.}&\textbf{F. R. Inverse}&\textbf{Générateur}&
 \textbf{Remarques}\\\hline\hline
Beta          &\texttt{dbeta} &\texttt{pbeta}&\texttt{qbeta} &\texttt{rbeta}   &\\\hline
Binômiale     &\texttt{dbinom}&\texttt{pbinom}&\texttt{qbinom}&\texttt{rbinom}  &
 Voir aussi \texttt{rjbinom}\\\hline
Chi-2         &\texttt{dchisq}&\texttt{pchisq}&\texttt{qchiq} &\texttt{rchiq}   &\\\hline
Fisher        &\texttt{df}    &\texttt{pf}&\texttt{qf}    &\texttt{rf}      &\\\hline
Gamma         &\texttt{dgamma}&\texttt{pgamma}&\texttt{qgamma}&\texttt{rgamma}  &
 Voir aussi \texttt{rjgamma}\\\hline
Géométrique   &               &&               &\texttt{rgeom}   &\\\hline
Hyper géom.   &\texttt{dhypg} &\texttt{phypg}&\texttt{qhypg} &\texttt{rhypg}   &\\\hline
Normale       &\texttt{dnorm} &\texttt{pnorm}&\texttt{qnorm} &\texttt{rnorm}   &
 Voir aussi \texttt{randn} de \ML\\\hline
Poisson       &               &&               &\texttt{rpoiss}  &
 Voir aussi \texttt{rjpoiss}\\\hline
Student       &\texttt{dt}    &\texttt{pt}&\texttt{qt}    &\texttt{rt}      &\\\hline
Weibull \& exp.&              &&               &\texttt{rexpweib}&\\\hline
Kolmog.-Smir. &               &\texttt{pks}&  & &\\\hline
\end{tabular}
\end{sideways}
\end{center}
\caption{Générateurs aléatoires de la bibliothèque \SB.}\label{ta:stixbox-rand}
\end{table}

\begin{rem}[Terminologie anglaise]
En anglais, la densité est souvent appelée
«probability density function» (pdf),
et la fonction de répartition «distribution function»
ou encore «cumulative distribution function» (cdf).
La connaissance de cette terminologie peut vous aider à la 
compréhension de l'aide des fonctions de \SB.
Les noms des générateurs aléatoires de \SB{} commencent par 
la lettre \texttt{r}
comme «random», les densités ou lois par \texttt{d}
comme «density», les fonctions de répartitions
inverses par \texttt{q} comme «quantile»,
les fonctions de répartitions par \texttt{p} comme
«probability» et enfin les générateurs aléatoires via la méthode
de rejet par \texttt{rj} comme «reject».
\end{rem}

%% Local Variables: 
%% x-symbol-8bits: t
%% x-symbol-coding: iso-8859-1
%% mode: latex
%% TeX-master: "agregation"
%% End:
%
%
\chapter{Théorèmes limites classiques}
%
%

Dans ce chapitre, on s'intéresse aux «théorèmes limites» classiques comme la
loi des grands nombres (LGN) et le théorème central limite (TCL), ainsi qu'à
certains de leurs rafinements et extensions.

%
\section{Lois des grands nombres \& théorème de Glivenko-Cantelli}\label{se:lgn}
%

Pour des variables aléatoires centrées et de carré intégrable, l'indépendance
deux à deux entraîne l'orthogonalité. La somme de $n$ vecteurs orthogonaux de
même norme étant de l'ordre de $\sqrt{n}$, on s'attend donc à ce que la
moyenne arithmétique des v.a. soit de l'ordre de $1/\sqrt{n}$, et donc à ce
qu'elle converge vers $0$. C'est ce que confirme la loi des grands nombres
(LGN) :

\begin{thm}[Loi des Grands Nombres]
  Soit $(X_n,n\in\eN^*)$ une suite de variables aléatoires i.i.d. de loi $\mu$ sur
  $\dR$, alors leur moyenne arithmétique 
  $$
  S_n:=\frac{X_1+\cdots+X_n}{n}
  $$
  converge $\mu$-presque-surement si et seulement si les $X_n$ sont
  intégrables. De plus, dans ce cas, la limite vaut $m_\mu:=\moyp{}{X_1}$ et la
  convergence a également lieu dans $\bL^1$.
\end{thm}

Ce théorème est très facile à démontrer si l'on renforce les hypothèses.
Supposons par exemple que les v.a. $\PAR{X_n,n\in\eN^*}$ sont i.i.d., dans
$\bL^4$ et indépendantes $4$ à $4$. On peut supposer sans perdre de généralité
qu'elles sont centrées. On a alors~:
$$
\moyp{}{\PAR{S_n}^4}=\frac{1}{n^3}\,\moyp{}{X_1^4}+\frac{4n(n-1)}{n^4}\,\moyp{}{X_1^2},
$$
d'où $\sum_{n=1}^{+\infty}\moyp{}{\PAR{S_n}^4}<+\infty$, or d'après le théorème
de convergence monotone~:
$$
\sum_{n=1}^{+\infty}\moyp{}{\PAR{S_n}^4}
=\moyp{}{\sum_{n=1}^{+\infty}\PAR{S_n}^4}.
$$
Cette espérance étant finie, la v.a. $\sum_{n=1}^{+\infty}\PAR{S_n}^4$ est
finie p.s. et donc $\PAR{S_n}^4$ converge p.s. vers $0$ en tant que terme
général d'une série convergente, d'où la convergence p.s. vers $0$ de $S_n$,
CQFD.

\begin{rem}
  On parle souvent de «loi faible des grands nombres» lorsque seule la
  convergence en probabilité est énoncée. Pour les lois discrètes, cette
  version faible est ancienne et remonte sans doute aux travaux de Markov.
  D'autre part, le fait qu'il y ait convergence $\bL^1$ dans la LGN est
  souvent désigné sous le nom de «loi des grands nombres de Kolmogorov».
\end{rem}

\begin{rem}
  Les hypothèses faites sur la suite des v.a. dans la LGN peuvent être
  considérablement affaiblies, au détriment de la preuve qui est alors plus
  difficile (par exemple le théorème d'Etemadi qui ne requière que
  l'indépendance deux à deux \cite{borkar}). De façon générale, la LGN reste
  encore vraie lorsque les v.a. n'ont pas la même loi -- il faut toute fois
  contrôler certains moments.  Nous avons évoqué une sorte de LGN pour le
  processus de Poisson (équation \eqref{eq:LGN-ppoiss} page
  \pageref{eq:LGN-ppoiss}) et pour le mouvement brownien (équation
  \eqref{eq:LGN-brown} page \pageref{eq:LGN-brown}).  Nous verrons plus
  généralement dans le chapitre \ref{ch:markmart} page \pageref{ch:markmart}
  que des théorèmes du type LGN et TCL existent pour des suites de variables
  aléatoires «dépendantes».
\end{rem}

%
\subsection{Mesure empirique}
%

Soit $(X_i,n\in\{1,\ldots,n\})$ une suite finie de variables aléatoires i.i.d.
de loi $\mu$ sur un espace probabilisé $(\Om,\cA,\eP)$.  En statistique, on
parle de $n$-\emph{échantillon} de loi $\mu$. On note $F:\dR\to[0,1]$ la
fonction de répartition de la loi $\mu$, donnée par $F(t):=\mu(]-\infty,t])$.
À l'échantillon $(X_i,n\in\{1,\ldots,n\})$, on associe une \emph{mesure
  empirique} $L_n(\om)$ définie par
$$
L_n(\om):=\frac{1}{n}\,\sum_{i=1}^n \delta_{X_i(\om)},
$$
et une \emph{fonction de répartition empirique}
$F_n(\om)(\cdot):\dR\to[0,1]$ par
$$
F_n(\om)(t):=\frac{1}{n}\,\sum_{i=1}^n \rI_{\BRA{X_i\leq t}}(\om).
$$
En regroupant suivant les valeurs des $X_i(\om)$, on obtient les écritures
suivantes faisant apparaître les \emph{effectifs cumulés} et les
\emph{fréquences empiriques} :
$$
L_n(\om)
=\sum_{x\in\BRA{X_1(\om),\ldots,X_n(\om)}}
\!\!\!\frac{\#\BRA{1\leq i \leq n, X_i(\om)=x}}{n}\,\delta_x,
$$
et :
$$
F_n(\om)(t)=\frac{1}{n}\, \#\BRA{1\leq i \leq n, X_i(\om)\leq t}.
$$
Notons que $L_n$ est une variable aléatoire à valeurs dans l'ensemble des
lois de probabilité sur $\dR$, et que $F_n$ est une variable aléatoire à
valeurs dans l'ensemble des fonctions de répartitions sur $\dR$. Ainsi, pour
tout $\om\in\Om$, $L_n(\om)$ est une loi sur $\dR$, de fonction de répartition
$F_n(\om)(\cdot)$.

Une conséquence de la LGN est que la mesure empirique $L_n(\om)$ converge
étroitement vers la loi $\mu$. On rappelle qu'une suite de mesures de
probabilités $(\mu_n)_n$ converge étroitement vers une mesure de probabilité
$\mu$ lorsque pour toute fonction bornée $f$, $\moyp{\mu_n}{f}$ converge vers
$\moyp{\mu}{f}$ quand $n\to\infty$.  Une suite de variables aléatoires converge
en loi si et seulement si la suite de leurs lois converge étroitement. Dans le
cas des mesures empiriques, on a pour $\mu$-presque tout $\om$ :
$$
L_n(\om)\limL{n}\mu.
$$
Pour le voir, il suffit d'écrire, pour une fonction $f\in\cC_b(\dR,\dR)$,
$$
\moyp{L_n(\om)}{f}=\frac{1}{n}\,\sum_{i=1}^n f(X_i(\om)).
$$
Les variables aléatoires $Y_i:=f(X_i)$ sont i.i.d. et la loi des grands
nombres nous assure la convergence presque sûre de $\moyp{L_n(\om)}{f}$ vers
$\moyp{}{Y_1}=\moyp{\mu}{f}$. La permutation des quantificateurs universels sur
$f$ et $\om$ se fait en utilisant la séparabilité de $\dR$. Ce résultat de
convergence étroite des mesures empiriques peut être affiné en une convergence
uniforme des fonctions de répartition, comme le précise le théorème de
Glivenko-Cantelli :

\begin{thm}[Glivenko-Cantelli]\label{th:gc}
  Soit $(X_n,n\in\eN^*)$ une suite de variables aléatoires i.i.d. de loi $\mu$
  sur $\dR$, de fonction de répartition $F$, alors on a pour
  $\mu$-presque-tout $\om$
 \begin{equation}\label{eq:gc} 
 \lim_{n\to\infty} \PAR{\sup_{t \in \dR} \ABS{F_n(\om)(t)-F(t)}} = 0, 
\end{equation}
où $F_n(\om)(\cdot)$ désigne la fonction de répartition empirique des
$X_1(\om),\ldots,X_n(\om)$.
\end{thm}

\begin{exo}[Polynômes de Bernstein \& théorème de Weierstrass]
  
  Le théorème de Weierstrass sur la densité de $\dR[X]$ dans
  $\mathcal{C}([0,1],\|\cdot\|_\infty)$ peut-être établi en utilisant une
  forme faible de la loi des grands nombres (convergence en probabilité de
  $S_n$ vers la moyenne de la loi $\mu$).
  
  En effet, si $f:[0,1]\to \dR$ est continue, le polynôme de Bernstein
  $$
  P_n(f)(x):=\sum_{k=0}^n x^k(1-x)^kC_n^k f(k/n)
  $$
  converge uniformément vers $f$ sur $[0,1]$. Pour le voir, il suffit
  d'exprimer $P_n(f)(x)$ comme la moyenne de $f$ sous la loi binomiale de
  paramètre $x$ sur $\{0,1/n,\ldots,1\}$, puis de découper autour de la
  moyenne $p$ et d'utiliser l'inégalité de Chebychev et l'absolue continuité
  de $f$ (théorème de Heine).  Pour illustrer ce qui précède, créer un fichier
  \textsf{ber.m} contenant le code suivant :
  %
  \MFILE{ber} 
  %
  Voici maintenant un petit programme faisant appel à cette fonction, dont la
  sortie graphique est donnée par la figure \ref{fi:bertest} :
  %
  \MFILE{bertest}
  %
  \FIG{bertest}{1}{htbp}{Illustration du théorème de Weierstrass avec les
    polynômes de Bernstein.}
  %
\end{exo}
La méthode de Monte-Carlo pour le calcul approché d'intégrales est également
basée sur la loi des grands nombres, cf. section \ref{ss:mc} page
\pageref{ss:mc}.

%
\section{Théorème Central Limite \& principe d'invariance}\label{se:tcl}
%

Poursuivant l'analogue avec les vecteurs orthogonaux d'un espace euclidien
(cf. section \ref{se:lgn} page \pageref{se:lgn}), on s'attend à ce que la
somme des $n$ premiers vecteurs divisée par $\sqrt{n}$ «n'explose pas» lorsque
$n$ tend vers l'infini. Cette intuition est confirmée par le Théorème Central
Limite (TCL\footnote{On parle également parfois de «Théorème de la Limite
  Centrale».  En anglais, on dit tout simplement «Central Limit Theorem», que
  l'on abrège en CLT.}) :
\begin{thm}[Théorème Central Limite]
  Si $(X_n,n\in\eN^*)$ est une suite de v.a.r. i.i.d. de carré intégrable de
  moyenne $m$ et de variance $\si^2$, alors
  $$Y_n:=\frac{X_1+\cdots+X_n-nm}{\si\sqrt{n}}\limL{n}\cN(0,1).$$
\end{thm}
De manière équivalente, si $Q_n$ désigne la fonction de répartition de la
v.a.r. $Y_n$ et $\Phi$ la fonction de répartition de la loi normale $\cN(0,1)$~:
$$
\Phi(t):=\frac{1}{\sqrt{2\pi}}\,\int_{-\infty}^t\!\exp\PAR{-\frac{x^2}{2}}\,dx,
$$
alors on a pour tout $t$ dans $\dR$~:
$$
Q_n(t)\limn{n}\Phi(t).
$$
On peut également utiliser le théorème de Lévy de caractérisation de la
convergence en loi par la transformée de Fourier~:
$$
\PAR{\forall s\in\dR}\;\; \moyp{}{e^{isY_n}} \limn{n} e^{-s^2/2}.
$$
Pour établir le TCL, on peut supposer sans perdre de généralité que les
v.a. sont centrées réduites, on a alors~:
$$
\moyp{}{e^{isY_n}}=\PAR{\moyp{}{e^{isn^{-1/2}\,X_1}}}^n,
$$
qui donne le résultat par un développement en série entière, mais il faut
prendre garde au fait que l'on a affaire à une fonction complexe dont il faut
choisir la détermination\ldots

De même que pour la LGN, de nombreuses versions du TCL existent, notamment
avec des hypothèses plus faibles sur les lois des v.a. On peut par exemple
affaiblir l'indépendance requise ou encore se passer du fait que les v.a.
aient la même loi, moyennant une hypothèse sur leurs moments. Historiquement,
le premier TCL concernait les lois de Bernoulli :

\begin{thm}[Théorème de Moivre-Laplace]\label{th:moivre-laplace}
  Soit $(X_n,n\in\eN^*)$ des v.a. i.i.d. de loi de Bernoulli sur $\{0,1\}$ et
  de paramètre $p\in[0,1]$, alors, pour tout $a\in\dR$ et $b\in\dR$ avec
  $a<b$, on a :
  $$
  \lim_{n\to+\infty}
  \eP\PAR{a\leq \frac{S_n-np}{\sqrt{npq}}\leq b} 
    =\PAR{2\pi}^{-1/2}\,\int_a^b\!e^{-x^2/2}\,dx,
  $$
  où $q:=1-p$.
\end{thm}
On en trouvera une preuve dans \cite[cor. 8.9]{applebaum} et dans
\cite[expl. V.5.5(i) pages 145-146]{barbe-ledoux}. Voici un exemple de code
\ML{} illustrant le TCL, dont la sortie graphique est donnée par la figure
\ref{fi:tcl1} :
%
\MFILE{tcl1}
%
\FIG{tcl1}{1}{htbp}{Illustration du TCL (lois uniformes).}
%
Le théorème suivant est une conséquence du TCL. Il affirme que les courbes
affines par morceaux construites à partir des sommes partielles renormalisées
d'une suite de v.a. i.i.d., vues comme des courbes aléatoires, «convergent en
loi vers la loi d'un mouvement brownien». Il constitue donc une justification
de l'intuition selon laquelle une marche aléatoire est un analogue discret du
mouvement brownien :

\begin{thm}[Principe d'invariance de Donsker-Prohorov]\label{th:pid}
  Soit $(X_n,n\in\eN^*)$ une suite de v.a.r. i.i.d. centrées de variance
  $\si^2$. On définit la suite de v.a. $\PAR{Y_n,n \in \eN^*}$ à valeurs dans
  $\cC(\dR_+,\dR)$ muni de sa tribu borélienne associée à la topologie
  cylindrique par~:
  $$
  Y_n(t):=\frac{X_1+\cdots+X_{[nt]}+\PAR{nt-[nt]}X_{[nt]+1}}{\si\sqrt{n}}.
  $$
  où $[r]$ désigne la partie entière de $r$.  Alors, la suite de v.a.
  $\PAR{Y_n,n\in\eN^*}$ converge faiblement vers une loi de probabilité $\mu^*$
  sur $\cC(\dR_+,\dR)$ telle que la v.a. $(B_t,t\geq0)$ définie par
  \begin{eqnarray*}
  B_t:\PAR{\cC(\dR_+,\dR),\mu^*}&\to&\dR\\
  \om&\mapsto&B_t(\om):=\om(t)
  \end{eqnarray*}
  soit un mouvement brownien standard sous $\mu^*$, c'est-à-dire un processus
  gaussien à trajectoires presque-sûrement continues, centré, à accroissements
  indépendants, tel que $B_0=0$ et $\eE(B_t-B_s)^2=|t-s|$.  En particulier,
  pour tout $0\leq t_1<\cdots<t_n$, on a~:
  $$
  \PAR{Y_n(t_1),\ldots,Y_n(t_n)}\limL{n}\PAR{B(t_1),\ldots,B(t_n)}.
  $$
\end{thm}
Voici une illustration de ce théorème en \ML{}, dont la sortie graphique est
donnée par la figure \ref{fi:donsker}~:
%
\MFILE{donsker}
%
\FIG{donsker}{1}{htbp}{Illustration du théorème de Donsker.}
%

%
\section{Vitesse de convergence dans le TCL}
%

Considérons une suite $(X_n,n\in\eN^*)$ de v.a. i.i.d. de carré intégrable de
moyenne $m$ et de variance $\si^2$. Soit $G_n$ la fonction de répartition de
la v.a.r.
$$
Y_n:=\frac{X_1+\cdots+X_n-nm}{\si\sqrt{n}}
$$
et $\Phi$ la fonction de répartition de la gaussienne standard $\cN(0,1)$. Le
théorème central limite (TCL) indique que pour tout $t\in\dR$~:
$$
\lim_{n\to+\infty}\ABS{G_n(t)-\Phi(t)}=0
$$
Le théorème suivant donne une estimée uniforme sur la vitesse de cette
convergence, cf. \cite{petrov} pour une preuve :

\begin{thm}[Berry-Essen]
  Soit $(X_n,n\in\eN^*)$ une suite de v.a.r. i.i.d. de variance $\si^2>0$ et
  possédant un moment d'ordre $3$. Alors on a~:
  $$
  \sup_{t\in\dR}\ABS{G_n(t)-\Phi(t)} \leq \frac{C\rho}{\si^3\sqrt{n}},
  $$
  où $\rho:=\moyp{}{\ABS{X_1-\moyp{}{X_1}}^3}$ et $C$ est une constante positive qui ne
  dépend pas de la loi des $X_n$.
\end{thm}

Il existe des versions dites «locales», du TCL, qui donnent des estimées sur
les densités plutôt que sur les fonctions de répartition. Elles sont plus
fortes que celles du type «Berry-Essen».  La plus élémentaire est sans doute
la version forte du théorème de Moivre-Laplace \ref{th:moivre-laplace}, dont
on trouvera une preuve faisant appel à la formule de Stirling dans \cite[thm
2.2.4 page 35]{dacunha-castelle-duflo} :

\begin{thm}[Théorème de Moivre-Laplace «fort»]\label{th:moivre-laplace-fort}
  Soit $(S_n,n\in\eN^*)$ des v.a. i.i.d. de loi binomiale $\cB(n,p)$ de taille
  $n$ et de paramètre $p\in]0,1[$. On pose $q:=1-p$. Alors, pour tout couple
  $(a,b)\in\dR^2$ avec $a<b$, on a~:
  $$
  \sup_{x\in I_n\cap[a,b]}
  \ABS{\sqrt{npq}\,\eP\PAR{\frac{S_n-np}{\sqrt{npq}}=x}-\PAR{2\pi}^{-1/2}\,e^{-x^2/2}}
  \limn{n} 0,
  $$
  où $I_n$ désigne le support de la v.a. discrète $\PAR{S_n-np}/\sqrt{npq}$.
\end{thm}

%
\section{Vitesse de convergence dans le théorème de Glivenko-Cantelli}
\label{se:vitesse-tgc}
%

Reprenons à présent le cadre du Théorème de Glivenko-Cantelli \ref{th:gc} page
\pageref{th:gc} et supposons que $F$ est \emph{continue}, et donc que $\mu$
n'a pas de masses ponctuelles. Alors, on montre que~:
\begin{equation}\label{eq:ks-gc-0}
\cL\PAR{\sqrt{n}\,\sup_{x \in \dR}\ABS{F_n(x)-F(x)}} \limE{n} \cL_{\bF},
\end{equation}
où $\cL_{\bF}$ est la loi de probabilité sur $\dR_+$, appelée «distribution de
Kolmogorov-Smirnov», dont la fonction de répartition $\bF:\dR\to[0,1]$ est
donnée par :
\begin{equation}\label{eq:def-ks-distrib}
\bF(u):=
\begin{cases}
  0 & \text{si } u\leq0,\\
  \ds{1+2 \sum_{k=1}^{+\infty} (-1)^k e^{-2k^2u^2}} & \text{si } u>0.
\end{cases}
\end{equation}
La bibliothèque \SB{} fournit la fonction \ML{} \texttt{pks} qui permet de
la calculer. Comme nous allons le voir ultérieurement dans la section
\ref{ss:test-ks} page \pageref{ss:test-ks}, cette convergence en loi permet de
construire un test d'adéquation appelé \emph{test de Kolmogorov-Smirnov}.

Si $(B_t,t\in[0,1])$ est un mouvement brownien standard, on appelle \emph{pont
  brownien sur $[0,1]$} le processus $(X_t,0\leq t\leq 1):=(B_t-tB_1,0\leq
t\leq 1)$. Il doit son nom au fait qu'il s'interprète comme un «passage
brownien» entre les deux extrémités de l'intervalle $[0,1]$ en lesquelles il
est nul. On montre que la v.a.r. $\sup_{0\leq t\leq1}|X_t|$ a pour loi
$\cL_{\bF}$. De plus, lorsque la fonction de répartition $F$ de $\mu$ est
continue, on a :
\begin{equation}\label{eq:ks-gc-1}
\sqrt{n}\,\sup_{x \in \dR}(F_n(x)-F(x))\limL{n}\sup_{0\leq t\leq1}X_t,
\end{equation}
et que~:
\begin{equation}\label{eq:ks-gc-2}
\sqrt{n}\,\sup_{x \in \dR}\ABS{F_n(x)-F(x)}\limL{n}\sup_{0\leq t\leq1}|X_t|.
\end{equation}
La convergence en loi \eqref{eq:ks-gc-2} n'est qu'une réécriture de
\eqref{eq:ks-gc-0}. En voici une illustration en \ML, dont la sortie graphique
est donnée par la figure \ref{fi:pontbrown} :
%
\MFILE{pontbrown}
%
\FIG{pontbrown}{1}{htbp}{Convergence vers la distribution de Komogorov-Smirnov pour
  le théorème de Glivenko-Cantelli (loi normale).}
%

%
\section{Principes de Grandes Déviations}\label{se:pgd}
%

La loi des grands nombres indique que la moyenne arithmétique $S_n$ de v.a.
i.i.d. de loi $\mu$, intégrables, à valeurs dans $\dR^n$, se «concentre»
autour de leur moyenne $m_\mu$. Ainsi, on s'attend à ce que la probabilité de
l'évènement $\BRA{S_n \in A}$ tende vers $0$ lorsque $A$ est «loin» de la
moyenne $m_\mu$. Prenons pour simplifier $m_\mu=0$, $n=1$ et $A=[r,+\infty[$.
On a pour tout $\theta\in\dR^+$, d'après l'inégalité de Markov :
\begin{align*}
\eP(S_n\in [r,+\infty[) 
 &= \eP(\exp\PAR{\theta (X_1+\cdots+X_n) \geq nr\theta}\\
 &\leq \exp\PAR{-(nr\theta-\log\moyp{}{\exp\PAR{\theta (X_1+\cdots+X_n)}})}\\
 &= \exp\PAR{-n(r\theta-\log\moyp{}{\exp\PAR{\theta X_1}})}.
\end{align*}
Cette inégalité étant valable pour tout $\theta>0$, on s'attend donc à un
comportement du type :
$$
\eP(S_n\in [r,+\infty[) \simeq 
\exp\PAR{-n\sup_\theta (r\theta-\log\moyp{}{\exp\PAR{\theta X_1}})}.
$$
Le théorème de Cramér confirme cette intuition. Il affirme que si $\mu$
possède des moments exponentiels de tous ordres, c'est-à-dire que
$\moyp{\mu}{\exp\PAR{\theta\cdot X_1}}<+\infty$ pour tout $\theta\in\dR$, alors
on a pour tout borélien $A$ :
$$
-\inf_{int(A)} \Lambda_\mu^*
\leq\liminf_{n\to+\infty} \frac{1}{n}\log\eP(S_n\in A)
\leq\limsup_{n\to+\infty} \frac{1}{n}\log\eP(S_n\in A)
\leq-\inf_{adh(A)} \Lambda_\mu^*,
$$
où $\Lambda_\mu^*$ désigne la transformée de Cramér\footnote{Ça n'est rien d'autre
  que la transformée de Legendre du logarithme de la transformée de Laplace de
  $\mu$.}  de $\mu$, définie par :
$$
\Lambda_\mu^*(x)
:=\sup_{\te\in\dR^n}\SBRA{x\cdot\te - \log\int\!e^{z\cdot\te\,d\mu(z)}}.
$$
On dit alors que la suite de v.a. satisfait à \emph{un principe de grandes
  déviations} par rapport à leur moyenne (PGD), de \emph{vitesse} $1/n$ et de
\emph{fonction de taux} $\Lambda_\mu^*$. On montre que la fonction de taux est
positive, semi-continue inférieurement, convexe, qu'elle décroit sur
$]-\infty,m_\mu]$, croit sur $[m_\mu,+\infty[$, qu'elle tend vers $+\infty$ en
$±\infty$ et qu'elle admet un unique minimum en $m_\mu$ pour lequel elle est
nulle. Quelques exemples de transformées de Cramér sont donnés dans la table
\ref{tab:exple-transfo-cramer}.

\begin{table}[htbp]
  \begin{center}\small
    \begin{tabular}[c]{|l|l|}\hline
      Bernoulli $p\delta_1 + (1-p)\delta_0$ avec $0<p<1$&
      $x\log\frac{x}{p} + (1-x)\log\frac{1-x}{1-p}$ si
      $0\leq x\leq 1$ et $+\infty$ sinon \\ \hline
      Poisson de paramètre $\lambda>0$ &
      $\lambda-x+x\log\frac{x}{\lambda}$ si $x>0$ et $+\infty$ sinon \\ \hline
      Exponentielle de paramètre $\lambda>0$ &
      $\lambda x -1 -\log(\lambda x)$ si $x>0$ et $+\infty$ sinon\\ \hline
      Gaussienne de moyenne $m$ et de variance $\si^2>0$ &
      $(x-m)^2/{2\si^2}$ \\ \hline
    \end{tabular}
    \caption{Quelques transformées de Cramér}
    \label{tab:exple-transfo-cramer}
  \end{center}
\end{table}
De nombreux autres théorèmes autour des PGD existent, notamment celui de Sanov
qui concerne la convergence de la mesure empirique vers la loi $\mu$ :
\begin{thm}[Théorème de Sanov]
  Soit $(X_n,n\in\eN^*)$ une suite de v.a. i.i.d. intégrables, de loi commune
  $\mu$ sur $\dR^n$. On note $(L_n,n\in\eN^*)$ les mesures empiriques associées et
  on munit l'ensemble $\cP(\dR^n)$ des lois de probabilité sur $\dR^n$ de la
  topologie de la convergence étroite (i.e. en loi).  Alors, pour tout
  $A\subset\cP(\dR^n)$, on a~:
$$
-\inf_{\nu\in int(A)} \ent{}{\nu\,\vert\,\mu}
\leq
\liminf_{n\to+\infty} \frac{1}{n}\log\eP(L_n\in A)
\leq 
\limsup_{n\to+\infty} \frac{1}{n}\log\eP(L_n\in A)
\leq
-\inf_{\nu\in adh(A)} \ent{}{\nu\,\vert\,\mu},
$$
où $\ent{}{\nu\,\vert\,\mu}$ désigne l'entropie relative de $\nu$ par rapport
à $\mu$, définie par~:
$$
\ent{}{\nu\,\vert\,\mu}:=
\begin{cases}
\moyp{\mu}{\frac{d\nu}{d\mu}\log \frac{d\nu}{d\mu}} & \text{si } \nu \ll \mu,\\
+\infty & \text{sinon}.
\end{cases}
$$
\end{thm}
Le symbole $\ll$ désigne l'absolue continuité. On peut retrouver le théorème
de Cramér à partir d'un théorème du «type Sanov» pour les lois de probabilité
sur $\{1,\ldots,n\}$. L'entropie relative se muant en transformée de Cramér.

\begin{xpl}
  Considérons une suite $\PAR{X_n,n\in\eN^*}$ de v.a. i.i.d. de loi de
  Bernoulli sur $\BRA{0,1}$ de paramètre $p\in]0,1[$. Soit $r$ un réel
  positif. On note $S_n:=(X_1+\cdots+X_n)/n$ leur moyenne arithmétique. La
  v.a. $S_n$ est de moyenne $p$. Comme $nS_n$ suit une loi binomiale
  $\cB(n,p)$ de taille $n$ et de paramètre $p$, on a, en notant $F$ la
  fonction de répartition de $\cB(n,p)$~:
  $$
  \log \eP\PAR{S_n-p \geq r}= \log \PAR{1-F(n(p+r))}.
  $$
  D'autre part, le TCL indique que la loi de
  $\sqrt{n}\,\PAR{S_n-p}/\sqrt{pq}$ est approximativement $\cN(0,1)$. On a
  donc, en notant $\Phi$ la fonction de répartition de la loi $\cN(0,1)$~:
  $$
  \log \eP\PAR{S_n-p \geq r} \simeq \log \PAR{1-\Phi\PAR{r\sqrt{\frac{n}{pq}}}}
  = \log \Phi\PAR{-r\sqrt{\frac{n}{pq}}}.
  $$
  Enfin, d'après le théorème de Cramér, on a par le PGD et par la formule
  explicite pour la transformée de Cramér pour la loi de Bernoulli donnée par
  la table \ref{tab:exple-transfo-cramer} :
  $$
  \log \eP\PAR{S_n-p \geq r}
  \simeq -n\PAR{(p+r)\log\frac{p+r}{p} + (1-p-r)\log\frac{1-p-r}{1-p}}.
  $$  
  Voici un code \ML{} illustrant ces trois estimées, dont la sortie graphique
  est donnée par la figure \ref{fi:tclvspgd} :
  %
  \MFILE{tclvspgd}
  %
  \FIG{tclvspgd}{1}{htbp}{Comparaison des approximations par TCL et PGD pour
    un écart à la moyenne de la loi binomiale.}
  %
\end{xpl}


%
\section{Loi du logarithme itéré}
%

À mi-chemin entre la LGN et le TLC, la loi du logarithme itéré précise ce qui
se passe lorsque l'on divise la somme partielle d'une suite de v.a.r. i.i.d.
par une suite réelle de vitesse intermédiaire entre $\sqrt{n}$ et $n$. En
effet, si $(X_n,n\in\eN^*)$ est une suite de v.a.r. i.i.d. de loi $\mu$,
intégrables, de moyenne $m$ et de variance $\si^2$, alors on a $\mu$-presque
sûrement :
$$
\varlimsup_{n\to+\infty} Y_n=+\si 
\text{\quad et \quad} 
\varliminf_{n\to+\infty} Y_n=-\si,
$$
où
$$
Y_n:=\frac{X_1+\cdots+X_n-nm}{\sqrt{2n\log\log n}}.
$$
D'après Strassen, on a plus précisément~:
$$
\mathrm{adh}\PAR{\PAR{Y_n}_{n\in\eN^*}}=[-\si,+\si]
\text{\quad et \quad}
\mathrm{dist}\PAR{Y_n,[-\si,+\si]}\limPS{n} 0.
$$
De nombreuses sophistications existent, avec des suites $(a_n)_n$
quelconques. Il est sans doute vain de vouloir illustrer par une simulation la
convergence des valeurs d'adhérence de $\PAR{Y_n,n\in\eN^*}$ car la propriété
est «trop asymptotique» pour être vue sur un échantillon de taille finie. En
effet, ici, la suite $\PAR{Z_n,n\in\eN^*}$ qui converge p.s. par exemple vers
$+\sigma$ est donnée par la définition de $\varlimsup$~:
$$
Z_n:=\inf_{n\geq 1}\sup_{k\geq n}\,\frac{X_1+\cdots+X_k-km}{\sqrt{2k\log\log k}},
$$
qui fait déjà intervenir un nombre infini de $X_i$ et n'est donc pas
accessible numériquement puisque les échantillons dont on dispose sont finis.
Voici un petit bout de code pour s'en convaincre (à exécuter plusieurs
fois\ldots)~:
%
\MFILE{lli}
%
En revanche, on peut visualiser la convergence vers $0$ de la distance de la
suite $\PAR{Y_n,n\in\eN^*}$ à l'intervalle $[-\si,+\si]$. Voici un code \ML{}
dont la sortie graphique est donnée par la figure \ref{fi:llid}~:
%
\MFILE{llid}
%
\FIG{llid}{1}{htbp}{Illustration de la loi du log. itéré de Strassen (distance
  à $[-\si,+\si]$).}
%
\begin{rem}[Sens des simulations]
  Le code précédent pose le problème de ce qu'apporte une simulation numérique
  d'un point de vue rationnel. Contraîrement au calcul formel, une simulation
  numérique ne prouve rien. C'est plutôt la théorie qui permet de justifier
  son utilisation dans la pratique. En revanche, la simulation peut s'averer
  très utile pour expérimenter et guider l'intuition. Enfin, elle permet
  parfois de mettre jour des comportements étranges ou inattendus qui font
  progresser la théorie en posant des questions nouvelles.
  
  En fait, les «preuves» de théorèmes obtenues par calcul formel sur
  ordinateurs ne font pas l'unanimité dans la communauté des mathématiciens.
  Malgrès les problèmes philosophiques posés, cela n'est peut-être après tout
  qu'une manifestation d'un certain conservatisme. Les progrès futurs de
  l'informatique nous promettent sans doute de nombreux débats sur le
  sujet\ldots{} À la fin du dix-neuvième siècle, les preuves non
  constructives, fussent-elles dues à Hilbert, étaient jugées irrecevables par
  de nombreux mathématiciens, comme Kronecker par exemple. Les choses ont un
  peu changé depuis, comme vous l'avez constaté au cours de votre cursus
  mathématique !
\end{rem}


%
\section{Convergence des histogrammes}
%

Simuler $n$ réalisations indépendantes d'une loi $\mu$ sur $\dR$ correspond à la
donnée, pour un $\om\in\Om$, de la suite $X_1(\om),\ldots,X_n(\om)$ où les $(X_n,
n\in\eN^*)$ sont des variables aléatoires indépendantes de même loi $\mu$. On note
ici $F$ la fonction de répartition de $\mu$, $L_n$ la mesure empirique et $F_n$
la fonction de répartition empirique.

Si l'on considère un intervalle $I_n=[a_n,b_n]$ de $\dR$ dont les bornes
peuvent dépendre a priori de $n$, le théorème de Glivenko-Cantelli
\eqref{eq:gc} page \pageref{th:gc} nous permet d'écrire, pour $\mu$-presque tout
$\om$~:
$$
\varlimsup_{n\to\infty} \ABS{L_n(I_n)(\om)-\mu(I_n)}
\leq\varlimsup_{n\to\to\infty}\PAR{\ABS{F_n(b_n)-F(b_n)}+\ABS{F_n(a_n)-F(a_n)}}= 0.
$$
On rappelle que la quantité
$$
L_n(I_n)(\om)=\frac{\#\BRA{i\leq n, X_i(\om)\in I_n}}{n}
$$
représente la fréquence empirique de l'intervalle $I_n$.  Partant des
réalisations $X_1(\om),\ldots,X_n(\om)$ obtenues par simulation, on subdivise
l'intervalle $[\min_i X_i(\om),\max_i X_i(\om)]$ en $m$ sous-intervalles
disjoints $A_{i,n,m}(\om)$, $i=1,\ldots,m$ de longueurs égales.  L'histogramme
en $m$ classes associé aux valeurs simulées correspond au tracé de la fonction
constante par morceaux $H_{n,m}(\om)$ définie par
$$
H_{n,m}(\om):=\sum_{i=1}^m \#\BRA{j, X_j(\om)\in A_{i,n,m}(\om)]}\,\rI_{A_{i,n,m}(\om)}.
$$
Les $A_{i,n,m}(\om)$ étant de même longueur $l_{n,m}(\om)$, la surface de
l'histogramme est donnée par la formule $n(\max_i X_i(\om)-\min_i
X_i(\om))/m$.  On définit à présent la fonction $D_{n,m}(\om)$ comme la
densité de probabilité sur $\dR$ obtenue en renormalisant l'histogramme
$$
D_{n,m}(\om)=\frac{m}{n(\max_i X_i(\om)-\min_i X_i(\om))} H_{n,m}(\omega).
$$
Les $A_{i,n,m}(\om)$ étant de même longueur, on a aussi
$$
D_{n,m}(\om):=
\frac{1}{n}\sum_{i=1}^m\frac{\#\BRA{j, X_j(\om)\in A_{i,n,m}(\om)]}}{l_{n,m}(\om)}\,\rI_{A_{i,n,m}(\om)},
$$
et $D_{n,m}(\om)$ apparaît alors comme une combinaison linéaire convexe de
densités uniformes sur les $A_{i,n,m}(\om)$. On voit bien que la mesure de
probabilité de densité $D_{n,m}(\om)$ et la mesure empirique $L_n(\om)$
affectent la même probabilité aux $A_{i,n,m}(\om)$, et l'on peut montrer que
pour tout $n$, la mesure de probabilité de densité $D_{n,m}(\om)$ converge
étroitement vers la mesure empirique $L_n(\om)$.

Il existe donc une suite $m_n(\om)$ telle que la mesure de probabilité de
densité $D_{n,m_n(\om)}(\om)$ converge étroitement vers $\mu$ quand
$n\to\infty$.

\subsection{Estimées uniformes sur les densités}

%  FIXME: Ce qui est dit dans cette section est douteux
%   - Comprendre les implications véritables du thm de Glivenko-Cantelli.
%   - Cas où \mu est à support compact.
%   - Il n'y a pas de TCL ici car c'est du Glivenko-Cantelli.

Nous avons vu que l'on avait convergence faible. Il est plus délicat d'obtenir
des estimées uniformes sur la proximité des densités de $\mu$ et de $D_{n,m}$.
Les $A_{i,n,m}(\om)$ sont tous de même longueur $l_{n,m}(\om)$, et l'on peut
donc écrire, en omettant la dépendance à $\om$ dans les notations
$$
D_{n,m}=\frac{1}{l_{n,m}} \sum_{i=1}^m L_n(A_{i,n,m})\,1_{A_{i,n,m}}.
$$
Si l'on définit à présent la densité approchée en $m$ escaliers de $\mu$
par
$$
 f_m:=\frac{1}{l_{n,m}} \sum_{i=1}^m \mu(A_{i,n,m})\,1_{A_{i,n,m}},
$$
on peut écrire
$$
\ABS{D_{n,m}-f_m} 
\leq \frac{2\sup_{t\in I} \ABS{F_n(t)-F(t)}}{l_{n,m}} 
     \sum_{i=1}^m 1_{A_{i,n,m}}
\leq \frac{2\sup_{t\in I}\ABS{F_n(t)-F(t)}}{l_{n,m}}.
$$
Lorsque $\mu$ a pour support un intervalle compact $I$,
$m\,l_{n,m}=\max_{1\leq i\leq n} X_i-\min_{1\leq i\leq n} X_i$ tend vers
$\ABS{I}$ presque sûrement quand $n$ tend vers l'infini (pourquoi ?).
Malheureusement, le théorème de Glivenko-Cantelli ne donne pas la vitesse de
convergence de $\sup_{t\in I} \ABS{F_n(t)-F(t)}$ vers $0$. Pour aller plus
loin, il faudrait faire appel à un théorème plus fort du type Berry-Essen par
exemple (hors programme), qui donne une vitesse de l'ordre de $\sqrt{n}$, ce
qui conduit à prendre $m=m_n=\sqrt{n}$ pour obtenir la convergence uniforme de
$\ABS{D_{n,m}-f_m}$ vers $0$.
%FIXME : VRAI TOUT CA ???

Notons que si $\mu$ admet une densité $f$ sur $I$ de classe $\cC^2$, alors, le
théorème de Heine entraîne que $f_{m}$ converge uniformément vers $f$
lorsque $m$ tendent vers l'infini (méthodes des rectangles !).
%FIXME : VRAI TOUT CA ???

\subsection{Un exemple avec une illustration du théorème central limite}

Soient $(U_n,n\in\eN^*)$ une suite de v.a. i.i.d. suivant une loi uniforme sur
$[0,1]$.  On rappelle que la loi uniforme sur $[0,1]$ a pour moyenne $1/2$ et
variance $1/12$. En vertu du théorème central limite, la variable aléatoire
\begin{equation}\label{eq:tcl-loiunif}
\frac{U_1+\cdots+U_{p}-p/2}{\sqrt{p/12}}
\end{equation}
converge en loi vers la loi normale centrée réduite lorsque $p\to\infty$. Pour
$p=12$, la formule précédente a une expression très simple ($U_1+\cdots+U_{12}-6$)
et fournit déjà une «bonne» approximation de la loi normale. 

On effectue alors $n$ simulations indépendantes $X_1(\om),\ldots,X_n(\om)$ de la
v.a. \eqref{eq:tcl-loiunif} et l'on trace sur un même graphique l'histogramme
$H_{n,m_n}$ et la densité de la loi normale centrée réduite correctement
dilatée pour être comparée à l'histogramme. Pour obtenir un joli graphique, on
choisit $m_n$ plus petit que $n$, par exemple $m_n=\sqrt{n}$. Ce facteur
$\sqrt{n}$ ne représente pas la normalisation du Théorème Central Limite mais
plutôt la vitesse de convergence dans le théorème de Glivenko-Cantelli. 
%FIXME: vrai ?

%
\MFILE{tcl2}
%
\FIG{tcl2}{1}{htbp}{Approximation de la loi normale par TCL (lois uniformes).}
%

%
\section{Le théorème de Wigner}
%

Le théorème de Wigner, qui ressemble à la loi des grands nombres, est ignoré
par la plupart des cours de probabilités. Il est pourtant très simple à
énoncer et sa démonstration n'est pas si difficile et fait appel à un peu de
combinatoire. Il en existe de nombreuses versions avec des hypothèses plus
faibles que celles requises ici.
Considérons un tableau symétrique de taille infinie dont les entrées sont des
v.a.r.~:
$$
\PAR{\begin{array}[c]{ccc}
 w_{1,1} & w_{1,2} & \cdots \\
 w_{2,1} & w_{2,2} & \cdots \\
 \vdots     & \vdots    & \ddots 
\end{array}}
$$
On note $W_n$ la matrice aléatoire carrée symétrique réelle de taille $n$
obtenue en tronquant le tableau à partir de son coin supérieur gauche. 
Les valeurs propres de $W_n$ sont réelles
d'après le théorème spectral.

\begin{thm}[Wigner]
  Supposons que les v.a. $\PAR{w_{i,j},1\leq i<j}$ sont i.i.d. de variance finie
  $\si^2$ et que les v.a. $\PAR{w_{i,i},1\leq i}$ sont i.i.d.  Si
  $\PAR{\la_{n,1}(\om),\ldots,\la_{n,n}(\om)}$ désigne le spectre de
  $n^{-1/2}\,W_n(\om)$, alors, pour presque tout $\om$, la mesure empirique
  $$
  \frac{1}{n}\,\sum_{i=1}^n\delta_{\la_{i,n}(\om)}
  $$
  converge étroitement (i.e. en loi) vers la loi du demi-cercle de
  paramètre $\si$, de densité par rapport à la mesure de Lebesgue $dx$ sur $\dR$~:
  $$
  \frac{1}{2\pi\si^2}\,\sqrt{4\si^2-x^2}\;\rI_{\BRA{-2\si\leq x \leq 2\si}}(x).
  $$
\end{thm}
Remarquons que les v.a. $\la_{n,i}$ ne sont pas i.i.d. et on ne peut donc pas
appliquer la loi des grands nombres. Voici un code \ML{} pour illustrer ce
théorème, dont la sortie graphique est donnée par la figure \ref{fi:wigner}~:
%
\MFILE{wigner}
%
\FIG{wigner}{1.0}{htbp}{Illustration du théorème de Wigner.}
%
%FIXME: blabla sur le role des matrices aléatoires en physique, en théorie des
%nombres, en statistique, ...

%% Local Variables: 
%% x-symbol-coding: iso-8859-1
%% x-symbol-8bits: t
%% mode: latex
%% TeX-master: "agregation"
%% End: 
%
%
\chapter{Intervalles de confiance \& tests statistiques}
\label{ch:ic+tests}
%
%

%FIXME:
%Parler de vraissemblance
%DCD autour des pages 45 et 50
%DCD section 4.4, pages 101 et suivantes. 
% «Échantillon d'une loi et estimation de cette loi»

La statistique paramétrique consiste à considérer qu'un phénomène aléatoire
obéit à une loi de probabilité qui appartient à une famille de loi indexée par
un paramètre. Le choix de la famille constitue la «modélisation». La véritable
valeur du paramètre est inconnue est l'on cherche à la déterminer à partir
d'un «échantillon», c'est à dire d'un suite finie de réalisations i.i.d. qui
suivent la loi inconnue cherchée. Les intervalles ou parallélépipèdes de
confiance consistent alors en des «morceaux» de l'ensemble des paramètres qui
contiennent la «véritable valeur» avec au moins une certaine probabilité $p$,
appelée niveau de confiance.  On parle de «risque» pour désigner la
probabilité $1-p$. Pour estimer le paramètre, on construit une fonction de
l'échantillon, appelée «estimateur», qui convergence, en un certain sens, vers
la valeur du paramètre.

%
\section{Rudiments de statistique paramétrique}
%

Un modèle paramétrique de paramètre $\te\in\Te\subset\dR^k$ consiste en la donnée d'un
triplet $(\cE,\cA,(\eP_\te)_{\te\in\Te})$. En d'autres termes, on se donne une
famille de lois de probabilité $\{\eP_\te,\te\in\Te\}$ sur l'espace mesurable
$(\cE,\dA)$ indexée par un ouvert $\Te$ de $\dR^k$. L'exemple le plus
classique est donné par $\cE=\dR$ et
$$
(\eP_\te)_{\te\in\Te}:=\BRA{\cN(m,\si^2),\,(m,\si^2)\in\dR\times\dR^+}.
$$
En voici un autre, encore plus simple : $\cE=\{0,1\}$ et
$$
(\eP_\te)_{\te\in\Te}:=\BRA{{\cB}ern(\{0,1\},p),\,p\in[0,1]}.
$$
On parle de statistique bayésienne lorsque l'on muni l'ensemble $\Te$ des
paramètres d'une loi de probabilités, sensée représenter une \emph{information
  a priori} sur la valeur du paramètre.

Idéalement, on dispose de données $x_1,\ldots,x_n$, qui constituent un
\emph{échantillon}, et que l'on suppose être des \emph{réalisations}
$X_1(\om),\ldots,X_n(\om)$ de v.a. i.i.d. $X_1,\ldots,X_n$ de \emph{loi inconnue}
$\eP_{\te_0}$ qui appartient à la famille $\{\eP_\te,\te\in\Te\}$. On parle
parfois d'\emph{observations} pour désigner les données. Chaque $\om\in\Om$
correspond à une réalisation de la suite de v.a. i.i.d. $(X_i)_{1\leq i\leq n}$, et
donc à un jeu de données possible. Le terme «échantillon» de loi $\eP_{\te_0}$
est utilisé pour désigner aussi bien la suite finie de v.a. i.i.d.
$(X_1,\ldots,X_n)$ que l'une de ses réalisations $x_1,\ldots,x_n$.

L'un des objectif de la statistique paramétrique est de déterminer au mieux le
paramètre $\te$ de la loi inconnue en utilisant les données. On construit pour
ce faire une v.a. $Y_n:=f_n(X_1,\ldots,X_n)$, fonction des $X_i$, qui
\emph{approche le paramètre} recherché lorsque la taille $n$ de l'échantillon
tend vers l'infini. On s'intéresse en particulier à la \emph{nature} de cette
\emph{convergence} et à sa \emph{vitesse}.  La fonction
$$
f_n:(x_1,\ldots,x_n)\in\eE^n\mapsto f_n(x_1,\ldots,x_n)\in\eE
$$
est appelée \emph{estimateur} du paramètre $\te$. Le \emph{biais} d'un
estimateur est par définition l'écart
$\moyp{\eP_{\te_0}}{f_n}-\te:=\moyp{}{Y_n}-\te$ entre sa moyenne et la véritable
valeur du paramètre.  On dit que l'estimateur est non biaisé lorsque son biais
est nul. Lorsque $\Te=\dR$, on dit qu'un intervalle $I\subset\Te$ qui dépend de
$Y_n$ est un \emph{intervalle de confiance} de \emph{niveau de confiance}
$p\in[0,1]$ lorsque la probabilité que $I$ contienne $\te$ est $p$.

Par exemple, pour le modèle $\cE=\dR$ et
$(\eP_\te)_{\te\in\Te}:=\BRA{\cN(m,1),\,m\in\dR}$, on cherche à estimer la moyenne
$m$. L'estimateur le plus naturel est constitué par la \emph{moyenne
  empirique} :
$$
Y:=f_n(X_1,\ldots,X_n):=\frac{X_1+\cdots+X_n}{n}.
$$
La loi des grands nombres indique que \emph{presque-sûrement} pour
$\cN(m,1)$, l'estimateur $Y_n$ converge vers $\te$ lorsque $n$ tend vers $+\infty$.
Ainsi, pour presque-tout jeu de données $(x_1,\ldots,x_n)$, la moyenne arithmétique
$(x_1+\cdots+x_n)/n$ converge vers $m$ lorsque la taille $n$ de l'échantillon tend
vers $+\infty$.  Par ailleurs, $Y_n$ est la moyenne arithmétique de $n$ v.a. i.i.d.
de loi $\cN(m,1)$, et donc a pour loi $\cN(m,1)$. Ainsi, pour tout $a>0$,
$$
\eP(Y_n\in [m-a,m+a]):=p_a:=(2\pi)^{-1/2}\,\int_{-a}^{+a}\!e^{-u^2/2}\,du.
$$
Or on a
$$
\BRA{Y_n\in [m-a,m+a]}=\BRA{m\in[Y_n-a,Y_n+a]}.
$$
Ainsi, l'intervalle $[Y_n-a,Y_n+a]$ contient la moyenne $m$ cherchée avec
une probabilité $p_a$. On parle alors d'\emph{intervalle de confiance} de
\emph{niveau de confiance} $p_a$. Dans des modèles non gaussiens, on ne
connait pas forcément la loi de l'estimateur, mais l'inégalité de Chebychev
donne :
$$
\eP(\ABS{Y_n-m} \geq a) \leq \frac{\si^2}{na^2},
$$
où $\si^2$ désigne la variance de la loi des $X_i$. Cette inégalité n'est
rien d'autre que la loi faible des grands nombres, qui indique que $Y_n$
converge vers $m$ en probabilité. Les principes de grandes déviations
introduits dans la section \ref{se:pgd} page \pageref{se:pgd} indiquent que la
probabilité que $\ABS{Y_n-m}$ dépasse le seuil $a>0$ décroit exponentiellement
vite. Dans la pratique, $\si^2$ est inconnu et l'on est parfois amené à le
remplacer par la variance empirique.

De façon plus générale, lorsque le paramètre à estimer n'est pas la moyenne,
on est parfois amené à utiliser des théorèmes de convergence en loi pour
l'estimateur $Y_n$ et des résultats de rapidité de convergence en loi pour
déterminer une valeur acceptable de $n$ pour laquelle la loi de l'estimateur
est identifiée à la loi limite du théorème de convergence en loi.

\subsection{L'exemple des sondages binaires : une approche naïve}

On modélise l'intention de vote des électeurs à un référendum par $0$ pour
\emph{non} et $1$ pour \emph{oui}. On cherche à estimer la probabilité
$p\in[0,1]$ qu'un électeur vote \emph{oui}. Pour ce faire, on interroge $n$
personnes choisies au hasard, dont les réponses $x_1,\ldots,x_n$ sont
considérées comme des réalisations de v.a. $X_1,\ldots,X_n$ i.i.d. de même loi
de Bernoulli $(1-p)\delta_0+p\delta_1$. On propose donc le modèle paramétrique
$\cE=\{0,1\}$, $P_\te=(1-\te)\delta_0+\te\delta_1$ avec $\te\in\Te=[0,1]$. On désire
donc estimer la moyenne $p$ des $X_i$. Pour ce faire, on utilise l'estimateur
«moyenne empirique» :
$$
Y_n:=\frac{X_1+\cdots+X_n}{n}.
$$
D'après la LGN, $Y_n$ converge p.s. vers la valeur cherchée $p$, et on peut
donc considérer que $(x_1+\cdots+x_n)/n$ converge vers $p$.  D'après
l'inégalité de Chebychev,
$$
\eP(\ABS{Y_n-p} \geq a) \leq \frac{p(1-p)}{na^2}.
$$
Comme $p\in[0,1]\mapsto p(1-p)$ a pour maximum
$1/4$, on a
$$
\eP(\ABS{Y_n-p} \geq a) \leq \frac{1}{4na^2},
$$
et de façon équivalente
$$
\eP([Y_n-a,Y_n+a] \text{ contient } p) > 1-\frac{1}{4na^2}.
$$
On a donc un intervalle de confiance $[Y_n-a,Y_n+a]$ pour $p$ de niveau de
confiance au moins égal à $1-(4na^2)^{-1}$. Autrement dit,
$[Y_n-((1-\al)/(4n))^{-1/2}\;,\;Y_n+((1-\al)/4n)^{-1/2}]$ est un intervalle de
confiance pour $p$ de niveau de confiance au moins égal à $\al$.

Alternativement, la loi de l'estimateur $Y_n$ n'est rien d'autre qu'une loi
binomiale, et le théorème de Moivre-Laplace \ref{th:moivre-laplace} page
\pageref{th:moivre-laplace} indique que
$Z_n:=(X_1+\cdots+X_n-np)/\sqrt{np(1-p)}$ converge en loi vers $\cN(0,1)$
lorsque $n$ tend vers $+\infty$. Lorsque $n$ est grand, il est préférable
d'utiliser cette approximation gaussienne de la loi de $Y_n$, plus précise que
celle obtenue par l'inégalité de Chebychev, et dont la vitesse en $n$ est
fournie par le théorème de Moivre-Laplace «fort» \ref{th:moivre-laplace-fort}
page \pageref{th:moivre-laplace-fort}. Comme
$$
Y_n=\frac{\sqrt{p(1-p)}}{\sqrt{n}}\PAR{\frac{X_1+\cdots+X_n-np}{\sqrt{np(1-p)}}}+p
=\frac{\sqrt{p(1-p)}}{\sqrt{n}}\,Z_n+p,
$$
on peut consirérer que pour $n$ «assez grand», la loi de $Z_n$ est bien
approximée par la loi $\cN(0,1)$. On écrit alors pour tout $a>0$ :
\begin{align*}
  \eP(\ABS{Y_n-p} \leq a) 
  &= \eP\PAR{\ABS{Z_n} \leq a\,\frac{\sqrt{n}}{\sqrt{p(1-p)}}}\\
  &\geq \eP\PAR{\ABS{Z_n} \leq a\,\sqrt{4n}} \\
  &\simeq \Phi(a\sqrt{4n})-\Phi(-a\sqrt{4n}) = 2\,\Phi(a\sqrt{4n})-1,
\end{align*}
où $\Phi$ est la fonction de répartition de la loi gaussienne standard
$\cN(0,1)$. Ainsi, on obtient l'intervalle de confiance
$$
\SBRA{Y_n-(4n)^{-1/2}\,\Phi^{-1}((1+\al)/2)\;,\;Y_n+(4n)^{-1/2}\,\Phi^{-1}((1+\al)/2)}
$$
de niveau de confiance voisin de $\al$.

Voici un petit code \ML{} comparant les bornes obtenues par l'inégalité de
Chebychev et par l'utilisation de la loi gaussienne. On voit bien sur la
figure \ref{fi:iconfcompare} que l'estimation gaussienne est meilleure
lorsque le niveau de confiance est proche de $1$, à condition bien sûr que
l'approximation gaussienne soit justifiée (i.e. $n$ grand). A contrario, la
borne obtenue par l'inégalité de Chebychev est toujours valide.

%
\MFILE{iconfcompare}
%
\FIG{iconfcompare}{1}{htbp}{Comparaison des bornes des intervalles de
  confiance lors de l'estimation de la moyenne d'une loi de Bernoulli par la
  moyenne empirique.}
%

\begin{rem}
  En France, les instituts de sondages font souvent appel à des techniques de
  «fourchettes», qui permettent de construire un échantillon «représentatif»
  de la population par quotas en fonction de critères sociaux-culturels par
  exemple.  Cette approche, sensée améliorer les intervalles de confiance, est
  discutable dans la mesure où elle fait intervenir une information a priori
  dont on mesure mal l'impact.
\end{rem}

%
\section{Divers procédés d'obtention d'intervalles de confiances}
%

Pour un $n$-échantillon $(X_1,\ldots,X_n)$ constitué de v.a.r. i.i.d. de loi
$\mu$ d'espérance $m$ et de variance $\sigma^2$, on note
$$
\bar{X}_n := \frac{S_n}{n}:=\frac{X_1+\cdots+X_n}{n} 
\text{\quad et \quad}
\widehat{\si_n}^2:=\frac{1}{n-1}\,\sum_{i=1}^n (X_i-\bar{X}_n)^2.
$$
%FIXME: expliquer pourquoi on divise par n-1.
Ces deux valeurs $\bar{X}_n$ et $\widehat{\si_n}$ peuvent être obtenues avec
les fonctions \texttt{mean} et \texttt{std} de \ML.

%
\subsection{Intervalles sur la moyenne quand la variance est connue} 
%

On suppose que la variance $\si^2$ est connue. Alors:
$$
\sqrt{n}\,\frac{\bar{X}_n -m}{\si} \limL{n} \cN(0,1).
$$
Ce qui donne, lorsque l'on a une réalisation de $(X_1,\ldots,X_n)$,
l'intervalle de confiance:
$$
I_\al=\SBRA{\bar{X}_n-\frac{\si \, q_{(1-\al/2)}}{\sqrt{n}},
  \bar{X}_n+\frac{\si \, q_{(1-\al/2)}}{\sqrt{n}}} \;,\;
\text{\quad pour un niveau de confiance voisin de $1-\alpha$},  
$$
où $q_a$ représente le \emph{quantile} d'ordre $a$ pour la loi $\cN(0,1)$.
En pratique, on utilise ce résultat dès que $n \geq 30$, ce qui est justifié
par des résultat de rapidité de convergence que nous ne donnons pas ici.

\subsubsection{Cas particulier des lois gaussiennes}

Si la loi $\mu$ de l'échantillon est gaussienne, alors on a
$$
\cL\PAR{\sqrt{n}\,\frac{\bar{X}_n-m}{\si}} = \cN(0,1),
$$
et l'intervalle de confiance est le même que précédemment, sans limitations
sur la valeur de $n$.


\subsection{Intervalles sur la moyenne quand la variance est inconnue} 

On suppose que la variance $\si^2$ est inconnue. Alors on a :
$$
\sqrt{n}\,\frac{\bar{X}_n-m}{\widehat{\si_n}} \limL{n} \cN(0,1),
$$
ce qui donne l'intervalle de confiance
$$
I_\al=\SBRA{\bar{X}_n-\frac{\widehat{\si}_n\,q_{(1-\al/2)}}{\sqrt{n}},
  \bar{X}_n+\frac{\widehat{\si}_n\,q_{(1-\al/2)}}{\sqrt{n}}},
\text{\quad pour un niveau de confiance voisin de $1-\alpha$},
$$
où $q_a$ représente le quantile d'ordre $a$ pour la loi $\cN(0,1)$.
Remarquons que ce résultat est vrai avec tout autre estimation convergente
de $\si$. On l'utilise en pratique dès que $n \geq 30$.

\subsubsection{Loi de Student} 

Si l'on suppose que la loi $\mu$ de l'échantillon est gaussienne, le résultat
précédent reste vrai mais peut être amélioré pour les petites valeurs de $n$
en utilisant le fait que pour tout $n\geq 2$, on a :
$$
\cL\PAR{\sqrt{n}\,\frac{\bar{X}_n-m}{\widehat{\si_n}}} = t(n-1),
$$
où $t$ est la loi de Student à $(n-1)$ degrés de liberté. Ceci donne
l'intervalle de confiance suivant pour un niveau de confiance voisin de
$1-\alpha$ :
$$
I_\al=\SBRA{\bar{X}_n-\frac{\widehat{\si_n}\,t_{(1-\al/2)}(n-1)}{\sqrt{n}},
  \bar{X}_n+\frac{\widehat{\si_n}\,t_{(1-\al/2)}(n-1)}{\sqrt{n}}},
$$
où $t_a(n)$ représente le quantile d'ordre $a$ pour la loi $t(n)$.

\subsubsection{Loi binomiale} 

Si la loi $\mu$ de l'échantillon est une loi de Bernoulli de paramètre $p$,
alors on a :
$$
\sqrt{n}\,\frac{(\bar{X}_n-p)}{\sqrt{n\,\bar{X}_n\,(1-\bar{X}_n)}}
\limL{n}\cN(0,1).
$$
Ce résultat est utilisé en pratique pour $np(1-p)\geq 20$.


\subsection{Intervalles sur la variance} 


\subsubsection{Moyenne connue} 

Si la loi $\mu$ de l'échantillon est \emph{gaussienne} de moyenne $m$ connue,
alors on a pour tout $n \geq 2$ :
$$
\cL\PAR{\frac{1}{\si^2}\,\sum_{i=1}^n (X_i-m)^2}= \chi^2 (n).
$$
On obtient donc l'intervalle de confiance suivant, sur la variance, pour le
niveau de confiance $1-\alpha$ :
$$
I_\al=\SBRA{\frac{1}{c_{(1-\al/2)}(n)}\sum_{i=1}^n (X_i-m)^2\;,\;
  \frac{1}{c_{\al/2}(n)}\sum_{i=1}^n (X_i-m)^2},
$$
où $c_a(n)$ représente le quantile d'ordre $a$ pour la loi $\chi^2(n)$.

\subsubsection{Moyenne inconnue} 

Si la loi $\mu$ de l'échantillon est \emph{gaussienne}, alors
pour tout $n \geq 2$, on a :
$$
\cL\PAR{\frac{(n-1)}{\si^2}\,\widehat{\si_n}^2} = \chi^2 (n-1),
$$
On obtient donc l'intervalle de confiance sur la variance suivant :
$$
I_\al=\SBRA{\frac{(n-1)}{c_{(1-\al/2)}(n)}\widehat{\si_n}^2\;,\; 
  \frac{(n-1)}{c_{\al/2}(n)}\widehat{\si_n}^2},
\text{\quad pour le niveau de confiance $1-\alpha$},
$$
où $c_a(n)$ représente le quantile d'ordre $a$ de la loi $\chi^2(n)$.

\subsection{Intervalles sur la différence de deux moyennes}

On suppose que $(X_1,\ldots,X_n)$ et $(Y_1,\ldots,Y_m)$ sont deux échantillons
indépendants de \emph{loi gaussienne de même variance mais pas forcément de
  même moyenne}. On note $d:=m_X-m_Y$ la différence entre les moyennes de $X$
et de $Y$, alors pour tout $n \geq 2$ et $m \geq 2$ on a :
$$ 
\cL\PAR{
\sqrt{\frac{nm(n+m-2)}{n+m}} 
\frac{(\bar{X}_n-\bar{Y}_m)-d}
{\sqrt{(n-1)\widehat{\si_n(X)}^2+(m-1)\widehat{\si_n(Y)}^2}}}
=t(n+m-2),
$$
où $t(n+m-2)$ est la loi de Student à $n+m-2$ degrés de liberté. On en
déduit l'intervalle de confiance $I=[a_\al,b_\al]$ pour $d$ avec :
$$
a_\al:=(\bar{X}_n-\bar{Y}_m)-t_{(1-\al/2)}(n+m-2)\,
       \sqrt{\frac{(n+m)((n-1)\widehat{\si_n(X)}^2
                     +(m-1)\widehat{\si_n(Y)}^2)}{nm(n+m-2)}}
$$
et
$$
b_\al:=(\bar{X}_n -\bar{Y}_m)+t_{(1-\al/2)}(n+m-2)\,
       \sqrt{\frac{(n+m)((n-1)\widehat{\si_n(X)}^2
                   +(m-1)\widehat{\si_n(Y)}^2)}{nm(n+m-2)}},
$$
et où $t_a(n)$ représente le le quantile d'ordre $a$ de la loi $t(n)$.


%
\subsection{Méthode de Monte-Carlo}\label{ss:mc}
%

La méthode de Monte-Carlo (cf. par exemple \cite[p. 103]{dacunha-castelle-duflo})
permet le calcul de valeurs approchées d'intégrales multiples en utilisant des
réalisations i.i.d. de loi uniforme. Si $(X_n)_{n\geq 1}$ est une suite de
v.a. i.i.d. de loi uniforme sur $[0,1]^m$ et si $f:[0,1]^m\to\dR$ est une
fonction mesurable, alors la loi des grands nombre (cf. section \ref{se:lgn}
page \pageref{se:lgn}) appliquée à la suite de v.a.r. i.i.d. $(f(X_n))_{n\geq
  1}$ entraîne la convergence presque-sûre suivante :
$$
\frac{1}{n}\,\PAR{f(X_1)+\cdots+f(X_n)}
\limn{n}
\bE{}(f(X_1))=\int_{[0,1]^m}\! f(x)\,dx,
$$
Si la variance de $f(X_1)$ est majorable, on est en mesure d'utiliser les
intervalles de confiance pour la moyenne lorsque la variance est connue. On
voit alors que la convergence à lieu en $\sqrt{n}$. Cette vitesse est assez
lente, comparée aux méthodes déterministes, mais on observera qu'aucune
régularité sur $f$ n'est requise ici. La méthode de Monte-Carlo reste valable
lorsque $f$ est à support quelconque, en prenant par exemple des $X_i$ de loi
gaussienne.

\begin{xpl}
  On se propose d'évaluer la valeur de $\pi$ à partir des trois intégrales
  suivantes, en utilisant la méthode de Monte-Carlo :
\begin{enumerate}
\item \ds{\int_0^1 4 \sqrt{1-x^2}\,dx} \quad (aire du disque unité)
\item \ds{\int_{[-1,+1]^2} 1_{\{x^2+y^2\leq 1\}}\,dx dy} \quad (aire du disque unité)
\item \ds{\int_{[-1,+1]^3} 1_{\{x^2+y^2+z^2\leq 1\}}\,dx dy dz} \quad (volume de la boule
  unité).
\end{enumerate}
%
\MFILE{montecarlo}
%
Testez le avec $n=10^4$, $10^5$, $10^6$.
%
\MFILE{montecarlo2}
%
\FIG{montecarlo2}{1}{htbp}{Approximation de $\pi$ par méthodes de
  Monte-Carlo.}
%
\end{xpl}

\subsection{Exercices sur les intervalles de confiance}

\begin{itemize}
\item \texttt{test1n} permet d'obtenir des intervalles de confiance sur la
  moyenne et la variance pour un échantillon simple (Student\ldots). Pour $n$
  grand, on obtient également l'intervalle de confiance sur la moyenne dans le
  cas non-gaussien.
\item \texttt{test2n} permet dans le cas de deux échantillons gaussiens de
  même variance d'obtenir des intervalles de confiance sur la différence des
  moyennes et sur la variance. Pour $n$ grand, on obtient aussi l'intervalle
  de confiance sur la différence des moyennes dans le cas non-gaussien.
\item \texttt{ciquant} fournit un intervalle de confiance sur le quantile
  d'ordre $p$ de la loi d'un échantillon.
\end{itemize}

\begin{exo}
  Simuler un $n$-échantillon de variables de Bernoulli de paramètre $p$.
  Donner un intervalle de confiance à $95\%$ pour $p$. Reproduire $N$ fois la
  simulation précédente et déterminer le nombre de fois où l'intervalle de
  confiance proposé contient bien le véritable paramètre $p$. Reprendre cette
  étude avec des échantillons gaussiens (on calculera alors des intervalles de
  confiance pour la moyenne et pour la variance de ces variables).
\end{exo}

\begin{exo}
  Dans le cadre de l'exercice précédent, comparer les intervalles de
  confiances exacts (obtenus avec la loi binomiale) à ceux donnés par le TCL.
\end{exo}

\begin{exo}
  Générer un $n$-échantillon de loi gaussienne centré. Comparer les
  intervalles de confiance sur la variance obtenus avec la loi de la variance
  empirique et avec un TLC portant sur les $X_i^2$. Utiliser d'autres lois. Le
  deuxième intervalle de confiance est-il utilisable si la moyenne est
  inconnue ?
\end{exo}

\begin{exo}
  Générer deux $n$-échantillons de loi gaussiennes dont les moyennes sont
  données par deux réalisations de v.a. de loi uniforme sur $[-1,+1]$. Donner
  des intervalles de confiance de niveaux $1-\alpha$ sur la différence des
  moyennes. Recommencer $100$ fois et donner des intervalles de confiance sur
  la moyenne des différences à la moyenne.
\end{exo}

\begin{exo}
  On considère $10$ réalisations indépendantes de loi quelconque (par exemple,
  exponentielle, Poisson, Weibull, \ldots). Donnez des intervalles de niveau
  de confiance $1-\alpha$ sur la moyenne et sur la variance en utilisant des
  quantiles empiriques calculés à partir des estimations des lois de la
  moyenne et de la variance.
\end{exo}

%
\section{Tests statistiques}\label{se:tests}
%

%FIXME: Newman-Pearson pour notions de UPP etc...
%FIXME: Tests paramétriques, tests d'adéquation, tests asymptotiques.
%FIXME: KS: qd \mu <> \nu i.e. mauvais chois d'hyp. mq -> +\infty
%           comme pour khi^2
%FIXME: Utiliser getdata et des exemples tirés du Tomassone ou DCD.
%FIXME: vocabulaire : statistique de test = fonction des données, à regarder
%FIXME: vocabulaire: risque pour 1-confiance
%FIXME: définir la convergence d'un estimateur.

La théorie des tests constitue un pan important de la statistique. Ce chapitre
a pour but d'en donner quelques éléments. Dans l'optique de la préparation à
l'oral, on pourra par exemple consulter les ouvrages en français \cite{vokac},
\cite{dacunha-castelle-duflo}, \cite{paul-toulouse}, \cite{saporta} et
\cite{tomassone}. Dans ce qui suit, nous commençons par introduire la notion
de test en statistique paramétrique de façon succincte. Nous définissons
ensuite les notions de niveau et de puissance d'un test. La section suivante
présente brièvement le test du $\chi^2$, illustré par quelques exemples.
Enfin, la dernière section est consacrée au test de Kolmogorov-Smirnov, qui
fait appel au résultat sur la vitesse de convergence dans le théorème de
Glivenko-Cantelli présenté dans la section \ref{se:vitesse-tgc} page
\pageref{se:vitesse-tgc}.

%
\subsection{Tests : niveau, puissance et notions asymptotiques}
%

Dans le cadre de la statistique paramétrique, un test consiste à confronter
les données à une hypothèse sur le paramètre. Ainsi, si des considérations
extérieures (théorie, expérience historique, etc) nous font penser que la loi
recherchée est $\eP_{\te_0}$, on définit les sous-ensembles $H_0$ et $H_1$ de
$\Te$ par
$$
H_0:=\{\te_0\}
\text{\quad et \quad}
H_1: \Te\bs\{\te_0\}.
$$
Un test $T$ de \emph{niveau} $\al\in[0,1]$ (resp. au plus $\al$) associé aux
deux hypothèses antagonistes $H_0$ et $H_1$ est une application mesurable des
données $Y$, à valeurs dans $\{0,1\}$, telle que
$$
\tout\te\in H_0,\,\eP_\te(T(Y)=1) = \al\; (\text{rep.} \leq \al).
$$
On parlera de \emph{niveau asymptotique} lorsque cela est vrai quand la
taille $n$ de l'échantillon tend vers l'infini. La \emph{région d'acceptation}
de $H_0$ du test $T$ est l'ensemble des valeurs des observations $Y$ pour
lesquelles $T(Y)=H_0$. On dit qu'un test $T$ de niveau $\al$ est \emph{sans
  biais} pour $H_0$ lorsque
$$
\tout\te\in H_1, \eP_\te(T(Y)=1) \geq \al.
$$
La \emph{puissance} du test est par définition la fonction $\te\in H_1
\mapsto \eP_\te(T(Y)\in H_1)$.

%FIXME: tests UPP ? Intervalles de confiance ? fourchettes ?

%
\subsection{Test du khi deux}
\label{ss:test-chideux}
%

Considérons un phénomène aléatoire de loi inconnue $P=p_1\delta_1+\cdots+p_k\delta_k$ où
l'on suppose que les $p_i$ sont tous non nuls. Nous allons supposer que des
considérations extérieures (théorie, etc) nous font penser que la loi du
phénomène aléatoire est $Q=q_1\delta_1+\cdots+q_k\delta_k$, où les $q_k$ sont tous non
nuls. Partant d'observations supposées indépendantes du phénomène aléatoire,
on désire tester l'hypothèse $H_0 : P=Q$ contre l'hypothèse antagoniste
générale $H_1: P\neq Q$. On définit la pseudo-distance du $\chi^2$ entre deux
distributions $A$ et $B$ discrètes sur $\{1,\ldots,k\}$ par :
$$
\chi^2(A,B):=\sum_{i=1}^k \frac{\PAR{A_i-B_i}^2}{B_i}.
$$
Si les effectifs des $n$ observations indépendantes sont donnés par
$N_1^n,\ldots,N_k^n$, on note 
$$
P_n:=(p^n_1,\ldots,p^n_k)
$$ 
la distribution empirique associée donnée par $p^n_i:=N_i^n/n$. 
On montre alors que :
\begin{enumerate}
\item La variable aléatoire $\sqrt{n}
  \PAR{\frac{p_1^n-p_1}{\sqrt{p_1}},\ldots,\frac{p_k^n-p_k}{\sqrt{p_k}}}$
  converge en loi vers la loi normale centrée sur $\dR^k$ de matrice de
  covariance $I_k-\sqrt{P}(\sqrt{P})^T$.
\item Sous $H_0$, $n\chi^2(P_n,Q)$ converge en loi vers la loi $\chi^2(k-1)$.
\item Sous $H_1$, $n\chi^2(P_n,Q)$ converge en probabilité vers $+\infty$.
\end{enumerate}
Le fait que la loi limite ne dépende du paramètre $P$ qu'à travers sa taille
$k$ est très important ici.  Un test du $\chi^2$ de niveau (asymptotique)
$\al\in[0,1]$ consiste en ce qui suit, pour $n$ «assez grand» :
\begin{itemize}
\item si $n\chi^2(P_n,Q)>\chi_\al^2(k-1)$, on choisit $H_1$,
\item si $n\chi^2(P_n,Q)\leq\chi_\al^2(k-1)$, on choisit $H_0$,
\end{itemize}
où $\chi^2_\al$ est le fractile $1-\al$ de la loi $\chi^2(k-1)$.
On montre facilement que la puissance de ce test tend vers $1$ quand $n$ tend
vers l'infini.

\subsubsection{Test d'ajustement ou d'adéquation}

Soit $(X_1,\ldots,X_n)$ un $n$-échantillon réel de loi inconnue $\mu$. On
suppose que les $X_i$ prennent leurs valeurs dans $k$ classes $I_1,\ldots,I_k$
constituées de $k$ intervalles ou de $k$ nombres selon que la loi $\mu$ est
discrète ou continue. On note $\hat f_i$ la fréquence empirique associée à la
classe $i\in\{1,\ldots,k\}$, définie par :
\begin{equation*}
  \hat f_i=\frac{1}{n}\,\sum_{m=1}^n \rI_\BRA{X_m \in I_k}.
\end{equation*}
Soit $\nu$ une loi de probabilité connue, de même nature que $\mu$. On désire
tester l'hypothèse :
$$
H_0:=\text{« La loi des } X_i \text{ est } \nu \text{ »} 
$$
contre l'hypothèse antagoniste 
$$
H_1:=\text{« La loi des } X_i \text{ n'est pas } \nu \text{ »}.
$$
Les $f_i:=\nu(I_i)$ sont calculables a priori, et on a alors sous $H_0$ :
\begin{equation*}
  n\sum_{i=1}^k \frac{(f_i-\hat f_i)^2}{f_i} \limL{n} \chi^2(k-1).
\end{equation*}
On utilise en pratique ce résultat lorsque pour tout $i$, $n f_i \geq 5$.

\subsubsection{Test d'homogénéité} 

Soit $(X_1,\ldots,X_n)$ un $n$-échantillon réel de loi inconnue $\mu_1$ et
$(Y_1,\ldots,Y_m)$ un $m$-échantillon réel de loi inconnue $\mu_2$, les deux
échantillons étant indépendants l'un de l'autre. On suppose que les $X_i$ et
$Y_i$ prennent leurs valeurs dans $k$ classes $(I_1,\ldots,I_k)$. On note
$\hat f^X_i$ et $\hat f^Y_i$ les fréquences empiriques associées à la classe
$i\in\{1,\ldots,k\}$. On désire tester l'hypothèse :
$$
H_0:=\text{« } \mu_1 \text{ et } \mu_2 \text{ sont identiques »}
$$
contre l'hypotèse antagoniste
$$
H_1:=\text{« } \mu_1 \text{ et } \mu_2 \text{ sont différentes »}
$$
On définit une sorte de fréquence empirique commune aux deux échantillons
en posant, pour tout $i\in\{1,\ldots,k\}$ :
\begin{equation*}
  \hat f_i := \frac{n\hat f^X_i + m\hat f^Y_i}{n+m}.
\end{equation*}
On a alors sous $H_0$ :
\begin{equation*}
  n\sum_{i=1}^k \frac{(\hat f_i-\hat f^X_i)^2}{\hat f_i}
 +m\sum_{i=1}^k \frac{(\hat f_i-\hat f^Y_i)^2}{\hat f_i} 
 \limL{n,m} \chi^2(k-1).
\end{equation*}

\subsubsection{Test d'indépendance}

Soit $((X_1,Y_1),\ldots,(X_n,Y_n))$ un $n$-échantillon réel de loi inconnue
$\mu$. On note $\mu_1$ et $\mu_2$ les lois marginales de $\mu$, et l'on
suppose que les $(X_i,Y_i)$ prennent respectivement leurs valeurs sur $k$
classes $(I_1,\ldots,I_k)$ et $l$ classes $(J_1,\ldots,J_l)$. On note $\hat
f_{ij}$ la fréquence empirique associée à $(I_i,J_j)$, définie par :
\begin{equation*}
  \hat f_{ij}
  :=\frac{1}{n}\sum_{k=1}^n \rI_\BRA{\{X_k \in I_i\}\cap\{Y_k \in J_j\}}.
\end{equation*}
On désire tester l'hypothèse
$$
H_0 := \text{« } \mu=\mu_1\otimes\mu2 \text{ »}
$$
contre l'hypothèse antagoniste
$$
H_1 := \text{« } \mu \neq \mu_1\otimes\mu2 \text{ »}.
$$
Pour cela, on définit $f_{ij}$ par :
\begin{equation*}
  f_{ij}:=
  \frac{1}{n}\sum_{k=1}^n\rI_\BRA{X_k \in I_i}
  \,
  \frac{1}{n}\sum_{k=1}^n\rI_\BRA{Y_k \in I_i}.
\end{equation*}
On a alors sous $H_0$ :
\begin{equation*}
  n\sum_{i=1}^k 
  \sum _{j=1}^l \frac{(f_{ij}-\hat f_{ij})^2}{f_{ij}} 
  \limL{n} \chi^2(k-1)(l-1).
\end{equation*}

\subsubsection{Exercices sur les tests du Khi Deux}

\begin{exo}
  Générez un échantillon de taille $100$ de loi uniforme sur $[0,1]$,
  décomposez le en $k$ classes de même longueur et faites un test du $\chi^2$
  d'ajustement à la loi uniforme. Recommencez en augmentant la taille de
  l'échantillon, le nombre de classes, puis en changeant de loi : normale,
  binomiale, Poisson par exemple.
\end{exo}

\begin{exo}
  Générez un échantillon de taille $100$ de loi exponentielle et testez si
  l'échantillon est de loi normale, de Poisson ou binomiale.
\end{exo}

\begin{exo}
  Générez deux échantillons de même loi -- par exemple uniforme ou normale ou
  exponentielle ou binomiale -- et de tailles différentes, par exemple $1000$ et
  $10000$. Testez ensuite l'homogénéité de ces deux échantillons. Faire de
  même avec deux échantillons de lois distinctes mais de même support.
\end{exo}

\begin{exo}[Les matheux sont-ils philosophes ?]
  On a relevé sur $100$ bacheliers les notes obtenues en mathématiques $X$ et
  en philosophie $Y$ :
 \begin{center}
 \begin{tabular}{|l||r|r|r|r|r|} \hline
  X \ Y & [0,4[ & [4,8[ & [8,12[ & [12,16[ & [16,20] \\ \hline\hline
  [0,4[&3&4&2&0&0\\ \hline
  [4,8[&6&10&8&2&0\\ \hline
  [8,12[&1&8&20&12&3\\ \hline
  [12,16[&0&0&8&7&3\\ \hline
  [16,20]&0&0&1&0&2\\ \hline
 \end{tabular} 
 \end{center}
 Testez l'hypothèse d'indépendance entre les notes obtenues dans les deux
 disciplines.
\end{exo}

\begin{exo}
  Générez un échantillon $(X_1,\ldots,X_n)$ de taille $n=1000$ de loi normale
  centrée réduite. Considérer $Y_i:=X_i^2$, puis testez l'indépendance de $X$
  et de $Y$. Faire de même avec d'autres lois : Bernoulli, exponentielle,
  uniforme\ldots.
\end{exo}

\begin{exo}[Cas où l'asymptotique du $\chi^2$ ne s'applique pas]
  On reprend l'exercice \cite[page 97]{tomassone}. On désire
  savoir si la couleur du verre à une influence sur l'appréciation de la
  qualité d'un vin. On dispose des données suivantes :
 \begin{center}
 \begin{tabular}{|c|c|c|c|c|c|}
  \hline Couleur du verre (du moins foncé au plus foncé)&1&2&3&4&5  \\
  \hline Nombre de personnes désignant le vin comme le meilleur & 0&1&0&5&4 \\
  \hline
 \end{tabular}
 \end{center}
 Simulez la loi de la distance du $\chi^2$ entre la loi uniforme sur
 $\{1,\ldots,5\}$ et la loi d'un échantillon équidistribué suivant une loi
 uniforme sur $\{1,\ldots,5\}$. En déterminant les quantiles à partir de
 l'histogramme de cette distance, testez l'hypothèse d'influence ($H_0$) pour
 un niveau de confiance quelconque.
\end{exo}

\begin{exo}
  En reprenant les données de \SB{} obtenues par \texttt{getdata}, faites des
  tests d'ajustement pour les modéliser par des lois connues, que vous
  proposerez en traçant des histogrammes.
\end{exo}


%
\subsection{Test de Kolmogorov-Smirnov}\label{ss:test-ks}
%

Comme nous l'avons vu dans la section \ref{se:vitesse-tgc} page
\pageref{se:vitesse-tgc}, la distribution de Kolmogorov-Smirnov $\bF$ définie
en \eqref{eq:def-ks-distrib} page \pageref{eq:def-ks-distrib} intervient pour
exprimer la vitesse de convergence dans le théorème de Glivenko-Cantelli
\ref{th:gc} page \pageref{th:gc}.

\subsubsection{Test d'adéquation}

Soit $(X_1,\ldots,X_n)$ un $n$-échantillon de loi $\mu$ de fonction de répartition
$F$ continue. Si $F_n$ désigne la fonction de répartition empirique de
l'échantillon, on identifie la loi de $\sqrt{n}\,\sup _{x \in \dR}
|F_n(x)-F(x)|$ à celle de Kolmogorov-Smirnov pour $n$ assez grand, $n \geq 80$
par exemple. On peut alors utiliser les quantiles à $0.95$ et $0.99$
correspondants à $u=1.3581$ et $u=1.629$, pour obtenir un test de risque
$0.05$ et $0.01$ sur l'adéquation de la loi de l'échantillon à $\mu$. Pour $n$
petit, on peut utiliser des tables, cf. \cite{saporta}.  La bibliothèque \SB{}
founit la fonction \texttt{pks} qui donne la valeur de la fonction de
répartition de Kolmogorov-Smirnov et la fonction \texttt{kstwo} qui permet de
tester l'homogénéité de deux lois continues. Il est très important de se
souvenir que la convergence vers la loi de Kolmogorov-Smirnov n'est garantie
que lorsque la loi $\mu$ n'a pas d'atomes.

\begin{exo}[Test d'adéquation pour les générateurs aléatoires]
  Voici deux petits programmes \ML{} qui font appel au test de
  Kolmogorov-Smirnov pour tester les générateurs aléatoires gaussiens. Ils
  sont aisément adaptables aux autres générateurs aléatoires de distributions
  continues.
\end{exo}

\MFILE{gauss}
\MFILE{gauss2}

\subsubsection{Test d'homogénéité}

Soient $(X_1,\ldots,X_n)$ et $(Y_1,\ldots,Y_m)$ deux échantillons de lois continues
inconnues. On a la convergence en loi suivante pour tester si leurs lois sont
identiques :
$$
\sqrt{\frac{nm}{n+m}}
\,
\sup_{x \in \dR}|F_n^{(X)}(x)-F_m^{(Y)}(x)|
\limL{n,m} 
\bF,
$$
où $\bF$ désigne la fonction de répartition de Kolmogorov-Smirnov.

\subsubsection{Exercices faisant appel aux processus empiriques}

\begin{exo}
  Générez un échantillon de taille $100$ de loi uniforme sur $[0,1]$ puis
  tracez sur le même graphique la fonction de répartition empirique et la
  fonction de répartition théorique. Faites un test de Kolmogorov-Smirnov sur
  cet échantillon pour un risque de $0.05$, recommencer $100$ fois le test.
  Combien de fois l'hypothèse $H_0$ est-elle acceptée ? Faites la même chose
  pour la loi normale centrée réduite et comparez au résultat obtenu avec
  un test du $\chi^2$.
\end{exo}

\begin{exo}
  Reprenez l'exercice précédent avec un échantillon de taille $10$ de loi
  uniforme, et tracer les fonctions de répartitions emprique et théorique.
  Pour utiliser le test, déterminez la distribution empirique de
  $\sqrt{10}\sup _{x \in [0,1]} |F_n(x)-F(x)|$ en utilisant $1000$
  échantillons de taille $10$ de loi uniforme sur $[0,1]$. En déduire le
  quantile empirique à $0.95$ et conclure pour le test du premier échantillon.
  Refaites la même chose avec la loi normale.
\end{exo}

\begin{exo}
  Faire un test d'homogénéité de Kolmogorov-Smirnov pour deux échantillons de
  loi uniformes sur $[0,1]$ et de tailles respectives $100$ et $1000$.
\end{exo}

\begin{exo}
  La mesure empirique d'un échantillon $(X_1,\ldots,X_n)$ constitue une
  approximation discrète (atomique) de la densité de la loi commune de
  l'échantillon.  On peut la lisser en remplaçant les masses de Dirac par des
  approximations lisses : on parle alors de \emph{méthode d'estimation par
    noyaux}. Le plus souvent, le lissage est obtenu en prenant la convolée de
  la distribution empirique par une fonction lisse appellée \emph{noyau}.
  Plus précisément, soit $K:\dR \to \dR^+$ une fonction bornée, intégrable
  pour la mesure de Lebesgue et nulle à l'infini, par exemple $K=\rI_{[-5,5]}$
  ou encore $K(x)=(2\pi)^{-1/2} \exp(-x^2/2)$.  On considère alors
  $$
  \hat{f}_{n,h}(x)(\om)
  :=\frac{1}{n}\,\sum_{k=1}^n \frac{1}{h} K\PAR{\frac{x-X_i(\om)}{h}}.
  $$
  Si $h$ est une fonction de $n$ telle que $\lim_{n \to +\infty} h(n)=0$ et
  $\lim_{n \to +\infty} (n/\log n) h(n)=+\infty$, si $f$ est continue en $x$
  avec $f(x) \neq 0$, et enfin si $K$ est à support compact, alors
  $$
  \ABS{\hat{f}_{n,h}(x)-f(x)} \limPS{n} 0.
  $$
  $\hat f_{n,h}(x)$ est donc un estimateur convergent de $f(x)$. Ecrivez un
  code \ML{} qui implémente cette méthode d'estimation de la densité par
  noyaux.
\end{exo}

%% Local Variables: 
%% x-symbol-8bits: t
%% x-symbol-coding: iso-8859-1
%% mode: latex
%% TeX-master: "agregation"
%% End:
%
%
\chapter{Vecteurs aléatoires gaussiens}
%
%

Un vecteur aléatoire gaussien de dimension $n$ est un vecteur aléatoire
$X:(\Om,\cA,\eP)\to\dR^n$ tel que pour tout $\al\in\dR^n$, la variable
aléatoire réelle $\al^\top X:=\al_1 X_1+\cdots+\al_n X_n$ suit une loi
gaussienne sur $\dR$. La loi d'un vecteur gaussien est caractérisée par son
vecteur moyenne $m:=(\eE(X_1),\ldots,\eE(X_n))\in\dR^n$ et sa matrice de
covariance $\Ga\in\cS_n^+$ définie par
$$
\Ga:=\PAR{\eE[(X_i-m_i)(X_j-m_j)]}_{1\leq i,j \leq n}
    = \PAR{\eE(X_iX_j)-m_im_j}_{1\leq i,j \leq n}.
$$
La loi d'un tel vecteur, notée $\cN(m,\Ga)$, a pour densité sur $\dR^n$
$$
(2\pi)^{-\frac{n}{2}}\,\det \Ga^{-\frac{1}{2}}\,
\exp\PAR{-\frac{1}{2}\,(x-m)^\top \Ga^{-1} (x-m)}\,dx.
$$
On parle de loi gaussienne standard lorsque $(m,\Ga)=(0,\ID_n)$. Les
composantes d'un vecteur gaussien sont indépendantes si et seulement si sa
matrice de covariance est diagonale. En conséquence, un vecteur gaussien
\emph{centré} a des composantes indépendantes si et seulement si elles sont
orthogonales dans $\bL^2(\Om,\cA,\eP)$, c'est-à-dire que pour tous $1\leq i,j
\leq n$, on a $\eE(X_iX_j)=0$. 

De plus, on montre, que pour un vecteur gaussien \emph{centré} $X$ de $\dR^n$,
le sous espace vectoriel de $\bL^2(\Om,\cA,\eP)$ constitué par les variables
aléatoires centrées de carré intégrable $\si(X_{k+1},\ldots,X_n)$-mesurables
est constitué par les combinaisons linéaires des v.a.r. $X_{k+1},\ldots,X_n$.
En conséquence, $\eE(X_i\vert X_{k+1},\ldots,X_n)$ est la projection
orthogonale dans $\bL^2(\Om,\cA,\eP)$ de $X_i$ sur l'espace vectoriel engendré
par les $X_{k+1},\ldots,X_n$.

\section{Lois conditionnelles}

Soit $X$ un vecteur gaussien \emph{centré} de $\dR^n$ de matrice de covariance
$\Ga\in\cS_n^+$. Soit $k\in\{1,\ldots,n\}$ et soit $Z:=(X_1,\ldots,X_k)$ et
$Y:=(X_{k+1},\ldots,X_n)$. On démontre en utilisant la transformée de Fourier
que la loi conditionnelle $\cL(Z\vert Y=y)$ de $Z$ sachant que $Y=y$ est
encore une loi gaussienne, de moyenne $\eE(Z\vert Y=y)\in\dR^k$ et de matrice
de covariance $\Si\in\cS^+_k$ donnée par
$$
\Si_{i,j}:=\eE\PAR{\PAR{X_i-\eE\PAR{X_i\vert Y}}\PAR{X_j-\eE\PAR{X_j\vert
      Y}}} = \Ga_{ij}-\eE\PAR{\eE\PAR{X_i\vert Y}\eE\PAR{X_j\vert Y}},
$$
qui ne dépend pas de $y$. Or on sait que $\eE(X_i\vert Y)=\la_{i,k+1}
X_{k+1}+\cdots+\la_{i,n} X_n$, d'où, en multipliant par $X_{k+j}$ puis en
prenant l'espérance : $\Ga_{i,k+j}=\la_{i,k+1} \Ga_{k+1,k+j}+\cdots+\la_{i,n}
\Ga_{n,k+j}$ car comme $X$ est centré on a $\Ga=(\eE(X_i X_j))_{1\leq i,j \leq
  n}$. On en déduit qu'il suffit de résoudre les $k$ systèmes linéaires
$$
\begin{pmatrix} \Ga_{k+1,k+1} & \cdots & \Ga_{n,k+1} \\ 
                \vdots        &        & \vdots \\ 
                \Ga_{k+1,n}   & \cdots & \Ga_{n,n}
\end{pmatrix}
\begin{pmatrix} \la_{i,k+1} \\ \vdots \\ \la_{i,n}\end{pmatrix} 
=\begin{pmatrix} \Ga_{i,k+1} \\ \vdots \\ \Ga_{i,n}\end{pmatrix}
$$
Pour cela, il suffit d'inverser la matrice
$\Ga^{\PAR{k}}:=(\Ga_{i,j})_{k+1\leq i,j \leq n}$ une fois pour toute. On a
alors~:
$$
\Si_{ij}=\Ga_{ij}-\la_i^\top\Ga^\PAR{k}\la_j
        =\Ga_{ij}-\Ga_\PAR{k,i}^\top \Ga_\PAR{k}^{-1} \Ga_\PAR{k,i},
$$
où $\Ga_\PAR{k,i}:=(\Ga_{i,k+1},\ldots,\Ga_{i,n})^\top$. Voici un
exemple d'illustration en \ML{}~:
%
\MFILE{normproj}
%
%

\section{Entropie de Shannon d'un vecteur aléatoire}
%
L'entropie de Shannon de base $b>0$ d'une loi discrète $p_1\delta_1+\cdots+
p_n\delta_n$ est définie par $-\sum_{i=1}^n p_i\log_b p_i$.  Elle mesure le
nombre moyen de chiffres en base $b$ nécessaires au codage de $X$. L'entropie
de base $2$ d'une loi de Bernoulli de paramètre $1/2$ vaut $1$ (il ne faut
qu'un bit). L'entropie discrète est toujours positive (inégalité de Jensen) et
est maximisée à $n$ et $b$ fixés par la loi uniforme.  De la même manière,
l'entropie de Shannon d'un vecteur aléatoire $X$ de $\dR^n$ de loi de densité
$f:\dR^n\to\dR^+$ est définie par
$$
\sent{X}:=-\eE(\log f(X))=-\int\!f\log f\,dx.
$$
Elle prend ses valeurs dans tout $\dR$, contrairement à l'entropie
discrète.  Calculée avec un logarithme de base $b$, elle mesure la précision
nécessaire au codage de $X$ en base $b$. La quantité $\sent{X}$ ne dépend que
de la loi $\cL(X)$ de $X$. Elle ne dépend pas de sa moyenne. L'entropie d'une
loi gaussienne $\cN(m,\Ga)$ est donnée par $(1/2) \log \PAR{(2\pi e)^n\det
  \Ga}$.  Si l'on note $K_{\!X}$ la matrice des corrélations de $X$, qui n'est
rien d'autre que la matrice de covariance quand $X$ suit une loi gaussienne.
On montre alors en utilisant l'inégalité de Jensen que pour toute matrice
symétrique positive $K\in\cS_n^+$, on a
$$
\sup_{K_{\!X}=K}\sent{X} = \sent{\cN(0,K)} = \frac{1}{2} \log \PAR{(2\pi
  e)^n\det K}.
$$
Ainsi, les lois gaussiennes maximisent l'entropie à covariance fixée. Pour
mesurer la perte d'information entre deux vecteurs gaussiens de matrices de
covariances respectives $\Ga_1$ et $\Ga_2$, on peut calculer la réduction
d'entropie (ER), qui vaut $(-1/2)\log(\det(\Ga_1\Ga_2^{-1}))$. Une autre
méthode consiste utiliser ce que l'on appelle le degrés de liberté (DF), qui
est donné par $\Tr(\ID_n-\Ga_1\Ga_2^{-1})$. En diagonalisant
$\Ga_1\Ga_2^{-1}$, la comparaison classique entre moyenne arithmétique et
géométrique $(\la_1\cdots\la_n)^{1/n} \leq (\la_1+\cdots+\la_n)/n$, appliquée au spectre de
$\Ga_1\Ga_2^{-1}$ donne que $ER\geq -(n/2)\log_2(1-DF/n)$. Voici un exemple écrit
en \ML{} illustrant la perte en degrés de liberté et la réduction d'entropie
dans le programme précédent. Sa sortie graphique est donnée par la figure
\ref{fi:erdfs}~:
%
\MFILE{erdfs}
%
%
\FIG{erdfs}{1}{htbp}{Reduction d'entropie et de DFS empirique/théorique lors
  d'une simulation d'un vecteur gaussien.}
%

%
\section{Le filtre de Kalman}
%

%FIXME: 

\textbf{Partie à intégrer}

%
\section{Le modèle linéaire gaussien}
%

%FIXME:

\textbf{Partie à intégrer}

%% Local Variables: 
%% x-symbol-8bits: t
%% x-symbol-coding: iso-8859-1
%% mode: latex
%% TeX-master: "agregation"
%% End:
%
%
\chapter{Chaînes de Markov \& martingales}
\label{ch:markmart}
%
%

Les processus à accroissements indépendants comme la marche aléatoire simple,
le processus de Poisson et le mouvement brownien sont à la fois des
martingales et des processus de Markov. Ces deux propriétés correspondent à
deux descriptions différentes de la façon dont le passé du processus
intervient dans son évolution future. Les chaînes de Markov et les martingales
constituent des généralisations naturelles de la notion de suites de v.a. à
accroissements indépendants.

%
\section{Chaînes de Markov à espace d'état fini}
\label{se:chaines2marov}
% 
       
Une chaîne de Markov sur un espace d'état fini $E:=\{x_1,\ldots,x_n\}$ est une suite
de variables aléatoires $(X_n)_{n\geq 0}$ à valeurs dans $E$ telles que pour tout
$n$,
$$
\cL(X_{n+1}\vert X_0,\ldots,X_n) = \cL(X_{n+1} \vert X_n).
$$
Le «futur» et le «passé» de la chaîne sont conditionnellement
indépendants par rapport au «présent».

Lorsque $\cL(X_{n+1} \vert X_n)$ ne dépend pas de $n$, on dit que la
chaîne est homogène et il suffit alors, pour caractériser sa loi, de donner la
loi $\mu$ sur $E$ de $X_0$ ainsi que la «matrice de transition» $P$ donnée
par~:
$$
(P_{ij})_{1\leq i,j\leq n} 
:=\left(\mathrm{P}(X_{n+1}=x_j\vert X_n=x_i)\right)_{1\leq i,j\leq n}.
$$
Ainsi, les entrées de cette matrice sont dans $[0,1]$ et chaque ligne est
une loi conditionelle (donc de somme égale à $1$). On parle alors de matrice
markovienne ou stochastique. Si l'on assimile les lois sur $E$ à des vecteurs
ligne et les fonctions de $E$ dans $\dR$ à des vecteurs colonne, on a, en
notant $\mu$ la loi de $X_0$ et $f$ une fonction quelconque de $E$ dans
$\dR$~:
$$
\cL(X_n) = \mu P^n \text{\quad et \quad}
\bE(f(X_{n+k})\vert X_n=x_i)=(P^k f)_i.
$$
Dans la suite, nous nous intéresseront qu'aux chaînes de Markov homogènes.
On dit qu'une loi $\mu$ sur $E$ est invariante pour une chaîne de Markov de
matrice de transition $P$ ssi on a $\mu P = \mu$. En d'autres termes, le
vecteur $\mu^\top$ est un vecteur propre de $P^\top$ associé à la valeur
propre $1$. Un théorème du cours affirme qu'il existe toujours une loi
invariante. Si $X_0$ suit la mesure invariante, il en sera de même de tous les
$X_n$. 

%
\subsection{Récurrence et irréductibilité}
%

Pour tout $x_i,y_j$ dans $E$, on dit que $x_i > x_j$ ssi $P_{ij}>0$ et que
$x_i >> x_j$ lorsqu'il existe une suite finie de points
$x_{k_1},\ldots,x_{k_n}$ de $E$ avec $x_i > x_{k_1} > \ldots x_{k_n} > x_j$.
Un point $x_i$ de $E$ est dit récurrent lorsque pour tout $x_j$ de $E$, $x_i
>> x_j$ entraîne $x_j >> x_i$. Les points non récurrents sont dit
transitoires. On montre que sur l'ensemble des points récurrents, la relation
de récurrence $>>$ est une relation d'équivalence. 

On peut montrer qu'une mesure invariante ne charge pas les points transitoires.
On dit qu'une matrice markovienne est récurrente-irréductible lorsqu'il n'y
pas de points transitoires et qu'il n'y a qu'une seule classe de récurrence.
Dans ce cas, on peut montrer l'unicité de la mesure invariante.

Un théorème du cours montre que si $(X_n)_{n\geq 0}$ est une chaîne de Markov
dont la matrice de transition $P$ est récurrente-irréductible, alors, quelque
soit la loi $\mu$ de $X_0$, la moyenne arithmétique des lois
$\cL(X_0),\ldots,\cL(X_{n-1})$ converge vers l'unique mesure
invariante $\nu$ de la chaîne. En d'autres termes, pour tout vecteur ligne
$\mu$ sur $E$, $(\mu+\mu P + \cdots + \mu P^{n-1})/n$ converge vers $\nu$.

%
\subsection{Apériodicité}
%

On appelle période d'un point $x_i$ de $E$ le PGCD des entiers $n$ tels que
$P^n_{ii}>0$. On peut montrer que la période est constante sur chaque classe
de récurrence. On dit qu'une matrice markovienne $P$ récurrente-irréductible
est apériodique lorsque la période est égale à $1$. On peut montrer que si $P$
est récurrente-irréductible, alors il y a équivalence entre son apériodicité,
l'existence d'un entier $m$ tel que $P^m$ a toutes ses entrées strictement
positives et enfin le fait que $1$ est la seule valeur propre de module $1$ de
$P$.

On montre que si $(X_n)_{n\geq 0}$ est une chaîne de Markov de matrice de
transition $P$ récurrente-irréductible, alors elle est apériodique ssi pour
toute loi initiale $\mu$ (de $X_0$), la suite $(X_n)_{n\geq 0}$ converge en
loi vers l'unique mesure invariante $\nu$ (i.e. $\mu P^n$ converge vers $\nu$
pour tout vecteur ligne $\mu$).

% exemple simple de matrice de transition RI no-apé : [0,1;1,0]

%
\subsection{Théorème ergodique}
%

Si $(X_n)_{n\geq 0}$ est une chaîne de Markov de matrice de transition $P$
récurrente-irréductible et de mesure invariante $\nu$, alors pour toute
fonction $f$ de $E$ dans $\dR$ et toute loi initiale $\mu$ (loi de $X_0)$, on
a~:
$$
\lim_{n\to+\infty} \frac{f(X_0) + \cdots + f(X_{n-1})}{n} =
\mathbf{\nu}(f) \text{ p.s.}
$$
En d'autres termes, la mesure empirique converge presque sûrement vers la
mesure invariante. Appliqué à $f(x)=\delta_{x}$ avec $x\in E$, on obtient que
$\#\{k\leq n, X_k = x\}/n$ converge presque sûrement vers $\nu(x)$.

Les trois théorèmes de convergence que nous avons énoncés expriment le fait
que la mesure initiale (loi de $X_0$) est «oubliée» au profit de la mesure
invariante.


\begin{exo}
  Déterminez la matrice de transition de la chaîne de Markov sur $\{0,1\}$ telle
  que $\mathrm{P}(X_{n+1}=1\vert X_n=1)=p$ et $\mathrm{P}(X_{n+1}=0\vert
  X_n=0)=q$. Dans quels cas est-elle récurrente-irréductible ? apériodique ?
  Dans ce dernier cas, déterminer sa mesure invariante théorique et la
  vérifier numériquement, d'abord en considérant les puissances de la matrice
  de transition pour différentes valeurs de $p$, puis en diagonalisant la
  matrice de transition.
\end{exo}

\begin{exo}
  En utilisant la méthode décrite dans la feuille «Simulation», écrire une
  fonction \ML{} $rtpsim$ de simulation d'une loi discrète
  $p\delta_0+q\delta_1+r\delta_2+s\delta_3$ sur $\{0,1,2,3\}$ à partir de la loi uniforme, qui prend
  comme paramètre les probabilités $p$, $q$ et $r$.  S'en servir pour écrire
  une fonction $rmtpsim$ qui permet de simuler la loi d'une chaîne de Markov à
  l'étape $n$ sur $\{0,1,2,3\}$ à partir de sa matrice de transition et du point
  initial.
\end{exo}

\begin{exo}
  Construire une matrice de transition sur $\{0,1,2,3\}$
  récurrente-irréductible, d'abord apériodique, puis non-apériodique. En
  utilisant la fonction $rmtpsim$, regarder dans les deux cas les différents
  régimes asymptotiques suivant les valeurs initiales de la chaîne.
\end{exo}


%
\subsection{L'exemple du modèle d'Ehrenfest}
%

On considère deux urnes contenant respectivement $k$ et $n-k$ boules. À
chaque étape, on choisit aléatoirement une des $n$ boules et on la change
d'urne. Si $X_n$ représente le nombre de boules dans la première urne à
l'étape $n$, et si $X_i=j$, alors on déplace une boule de la première urne
vers la seconde avec probabilité $j/n$ et réciproquement avec la probabilité
$1-j/n$. Ainsi définie, la suite $(X_n)_{n\geq 0}$ est une chaîne de Markov
homogène. 

Déterminez la matrice de transition, puis montrez qu'elle est
récurrente-irréductible. Vérifier que la loi binomiale de taille $n$ et de
paramètre $1/2$ est invariante (car symétrique, i.e. $\nu(i) P_{ij} = \nu(j)
P_{ji}$ pour tout $i$ et $j$). 
 
Voici un programme \ML{} qui compare la distribution empirique à la loi
binomiale (on a convergence presque sûre d'après le théorème ergodique)~:
%
\MFILE{ehrenfest}
%
\FIG{ehrenfest}{1}{htbp}{Comparaison des mesures ivariantes théorique et
  simulée pour le modèle d'Ehrenfest.}
%
\begin{exo}
  On pourrait adapter la fonction $rmtpsim$ pour simuler une loi
  $p_1\delta_0,\ldots,p_n\delta_n$ sur $\{0,\ldots,n\}$ à partir de la donnée
  des probabilités $p_i$, ce qui permettrait de simuler une chaîne de Markov
  quelconque à partir de la donnée de sa matrice de transition et de son état
  initial. Cela pourrait faire une illustration amusante pour la leçon sur la
  simulation de v.a.
\end{exo}

%
\section{Martingales et temps d'arrêt}\label{se:martingales}
%

%
\subsection{Temps d'arrêt}
\label{ss:tda}
%

Le théorème de convergence des martingales est parfois implicitement utilisé.
On notera que certaines propriétés, comme la finitude p.s. des temps d'arrêt, 
ne peuvent pas se constater numériquement.

%
\subsubsection{Un exemple simple de temps d'arrêt: la ruine du joueur}
%

Le jeux consiste à partie avec une somme dárgent initiale $a$, puis à
jouer à plusieurs parties indépendantes dont le gain est $+1$ avec
probabilité $p$ et $-1$ avec probabilité $q:=1-p$.  Le joueur s'arrête
dès qu'il a atteint une somme $b$ avec $b>a$ fixée d'avance (il a
gagné) ou dès qu'il est ruiné (il a perdu).  On modélise sa fortune à
l'issue de la $n$-ième partie par la variable aléatoire
$$
S_n:=a+X_1+\cdots+X_n,
$$
où $(X_i)_{i\in\eN^*}$ est une suite de v.a. i.i.d. de loi de
Bernoulli $p\delta_{+1}+q\delta_{-1}$. Par convention, $S_0:=a$.  L'instant
de fin du jeu $T$ est alors donné par :
$$
T:=\inf\BRA{n\in\eN,\; S_n=b \text{\quad ou \quad} S_n=0}.
$$
On désire calculer la probabilité de gain, qui n'est rien d'autre
que $\eP(S_T=b)$, et également la durée moyenne du jeu $\eE(T)$.  Il
nous faut cependant vérifier que le jeu s'arrête bien
presque-sûrement. Traitons le cas où $m=p-q\neq 0$. Nous savons que
$(M_n)_{n\in\eN}:=(S_n-nm)_{n\in\eN}$ est une martingale pour
$(\si(X_k,k\leq n))_{n\in\eN^*}$.  La v.a.r.  $T$ est un temps d'arrêt
mais n'est pas finie p.s. a priori.  En appliquant le théorème d'arrêt
à la martingale $(M_k)_{k\in\eN}$ et au temps d'arrêt $T\land n$, on
obtient :
$$
\eE(M_0)=\eE(M_{T\land n})
=\eE((b-Tm)\,\mathrm{1}_{T\leq n})+\eE((S_n-nm)\,\mathrm{1}_{T>n}).
$$
Or sur l'évènement $\{T>n\}$, on a $S_n<b$ d'où :
$$
a\leq b-m\eE(T\mathrm{1}_{T\leq n}).
$$
Si $m>0$, on en déduit par convergence monotone $\eE(T)\leq
(b-a)/m$, et donc $T$ est fini presque-sûrement. Le cas $m<0$ se
déduit par symétrie en permutant les rôles de $p$ et $q$ et de $a$ et
$b-a$, ce qui donne la majoration $\eE(T)\leq -a/m$.  Il nous reste
maintenant à calculer $\eP(S_T=b)$ et $\eE(T)$.  Remarquons que la
variable aléatoire $S_T$ ne prend que deux valeurs distinctes $b$ et
$0$, et on a donc toujours $\eE(S_T)=b\eP(S_T=b)$.  La suite
$(r^{S_n})_{n\in\eN^*}$ est une martingale pour $r=q/p$, et le
théorème d'arrêt appliqué avec le t.d.a. fini p.s. $T$ donne alors :
$$
r^a=\eE(r^{S_0})=\eE(r^{S_T})=r^b\eP(S_T=b)+r^0\eP(S_T=0),
$$
d'où enfin :
$$
\eP(S_T=b)=\frac{r^a-1}{r^b-1}.
$$
D'autre part, le théorème d'arrêt appliqué à la martingale 
$(S_n-nm)_{n\in\eN}$ et au t.d.a. fini p.s. $T$ donne :
$$
a=\eE(S_0)-0m=\eE(S_T)-\eE(T)m,
$$
d'où enfin puisque\footnote{De façon plus générale, le théorème
  d'arrêt permet de montrer que si $(X_n)_{n\in\eN}$ est une suite de
  v.a. i.i.d. et si $T$ est un t.d.a. intégrable relatif à la
  filtration naturelle associée à la suite précédente, alors
  $\eE(S_T)=\eE(X_1)\eE(T)$ où $S_n:=X_1+\cdots+X_n$. On parle alors
  d'identité ou de Lemme de Wald.}  $\eE(S_T)=b\eP(S_T=b)$ :
$$
\eE(T)=\frac{1}{m}\,\PAR{\frac{r^a-1}{r^b-1}b-a}.
$$
Lorsque $m=0$, on peut utiliser la martingale $(S_n^2-n)_{n\in\eN}$
pour montrer que $T$ est fini p.s., puis pour montrer que
$a^2=\eE(S_T^2)-dE(T)$, puis la martingale $(S_n)_{n\in\eN}$, qui
donne $a=\eE(S_T)$ comme pour le cas $m\neq 0$. En défintive, puisque
$\eE(S_T)=b\eP(S_T=b)$ et $\eE(S_T^2)=b^2\eP(S_T=b)$, on obtient :
$$
\eP(S_T=b)=\frac{a}{b}
\text{\quad et \quad} 
\eE(T)= a(b-a).
$$
Ces formules peuvent également s'obtenir en passant à la limite
$m\to0$ dans les formules obtenues pour $m\neq 0$.

%FIXME:
% Mettre les nouveau devs, Dirichlet et aussi rajouter du blabla
% sur la façon dont on obtient les formules par le théorème d'arr^et
% Enveloppe de Snell. cf. poly de Bakry page 17

Voici un exemple de code \ML{} illustrant ce qui précède. Le fait que
$T$ soit fini presque sûrement et même intégrable assure théoriquement
que le programme ne fera pas de boucle infinie !  Cela dit, l'infini
pratique n'est pas l'infini théorique, et nous savons juste qu'en
moyenne, une boucle aura $\eE(T)$ tours, ce qui peut être énorme selon
les valeurs de $a$, $b$ et $p$.  La connaissance de la variance de $T$
serait alors utile. On peut calculer la transformée de Laplace
$\eE(\exp(\be T))$ de $T$ en utilisant la martingale $(\exp(\al
S_n-\be n m))_{n\in\eN}$ où $\al$ est bien choisit en fonction de
$\be$ :
$$
\al=\frac{e^{\be m}±\sqrt{e^{2\be m}-4pq}}{2p},
$$
cf. \cite[exercice 8.8 page 247]{cottrell-duhamel}.

%
\MFILE{ruine}
% 

Tentez de retrouver les formules précédentes pour $\eE(T)$ et
$\eP(S_T=b)$ par la simulation, aussi bien pour $m=0$ que pour $m\neq
0$. Tracez un histogramme de la loi approchée de $T$ obtenu à partir
de plusieurs réalisations indépendantes de $T$.

%
\subsubsection{Autre exemple : enveloppe de Snell et arrêt optimal}
%

Soit $X_0,\ldots,X_N$ une suite finie de variables aléatoires adaptée
pour une filtration $\cF_0,\ldots,\cF_N$. On cherche un temps d'arrêt
$T$ pour cette filtration, à valeurs dans $\{0,\ldots,N\}$, qui
maximise la quantité $\eE(X_T)$. On parle alors de problème d'arrêt
optimal. La solution est fournie par l'\emph{enveloppe de Snell}
$S_0,\ldots,S_N$ de la suite $X_0,\ldots,X_N$, définie par récurrence
décroissante en partant de $N$ de la façon suivante :
$$
S_N=X_N,
$$
et pour $k \in \{0,\ldots,N-1\}$
$$
S_k=\max\PAR{X_k,\eE(S_{k+1}\,\vert\,\cF_k}
$$
Le temps d'arrêt recherché s'exprime alors comme le plus petit entier
pour lequel la suite se confond avec son enveloppe de Snell :
$$
T:=\inf\BRA{k,\; X_k=S_k}.
$$
L'enveloppe de Snell est également la plus petite sur-matingale qui
majore la suite $X_1,\ldots,X_n$. Le théorème d'arrêt permet de
montrer que $T$ a bien la propriété recherchée.  On pourra consulter
\cite{lamberton-lapeyre} pour une application à la finance (call pour
option américaine).

%FIXME: Expliquer, donner le cas des chaines de Markov.

%
\subsubsection{Temps d'atteinte pour une marche aléatoire}
%

Soit $A$ un sous-ensemble \emph{fini} de $\dZ^d$, $x\in A$ et
$(S_n)_{n\in\eN}$ la marche aléatoire simple issue de $x$.  On
considère alors le est le temps de sortie $T$ de $A$, définit par :
$$
T:=\inf\BRA{n,\;S_n\not\in A}.
$$
Bien entendu, $T$ dépend à la fois de $A$ et de $x$ et est un temps
d'arrêt pour la filtration naturelle de la marche aléatoire. Il est
facile de montrer qu'il existe un $C<\infty$ et un $\rho<1$ dépendants
de $A$ tels que pour tout $n$ et pour tout $x\in A$ :
$$
\eP^x(T\geq b) \leq C\,\rho^n.
$$
En conséquence $T$ est fini p.s. et a tous ses moments finis.

Prouvons le. Soit $R=\sup\BRA{\ABS{x},\,x\in A}$. Alors, pour tout $x$
dans $A$, il existe un chemin de longueur $R+1$ partant de $x$ et se
terminant à l'extérieur de $A$, et donc :
$$
\eP^x(T \leq R+1) \geq \PAR{\frac{1}{2d}}^{R+1}.
$$
Par la propriété de Markov, on a pour tout entier $k$ :
\begin{align*}
\eP^x(T>k(R+1))
&=\eP^x(T>k(R+1)\,\vert\,T>(k-1)(R+1)) \eP^x(T>(k-1)(R+1)) \\
&\leq (1-(\frac{1}{2d})^{R+1})\eP^x(T>(k-1)(R+1)),
\end{align*}
et donc, si $\rho:=(1-(\frac{1}{2d})^{1+R})^{1/(R+1)}$ :
$$
\eP^x(T>k(R+1)) \leq \rho^{k(R+1)}.
$$
Enfin, pour un entier $n$, il suffit d'écrire $n=k(R+1)+i$ avec
$j\in\{1,\ldots,R+1\}$, et on a alors :
$$
\eP^x(T\geq n) \leq \eP^x(T>k(R+1)) \leq \rho^{k(R+1)} \leq
\rho^{-(R+1)}\rho^n.
$$
Il suffit donc de prendre $C:=\rho^{-(R+1)}$.  Cette démonstration
se trouve dans \cite[Lemme 1.4.4]{lawler}.  De façon générale, le
théorème central limite permet de voir que le temps de sortie d'un
ensenble fini (ou compact) est toujours fini p.s.  pour une marche
aléatoire dont l'acroissement a par exemple pour loi
$p\delta_{+1}+q\delta_{-1}+r\delta_0$ (avec $0\leq p,q,r<1$) dans $\dZ^1$, cf.
\cite[exercice 8.8 page 247]{cottrell-duhamel}.

%FIXME:
% cf. Lawler ?$
% Incruster Dirichlet ici et DLA aussi

\begin{exo}
Utilisez ce qui précère pour résoudre le problème de Dirichlet discret.
\end{exo}

%
\subsubsection{Exercices sur les temps d'arrêt}
%

\begin{enumerate}
\item On considère $(X_n)_n$ des v.a indépendantes à valeurs dans
  $\{0,1,-1\}$, telles que:
  $$
  P(X_n=1)=P(X_n=-1)=(1-p_n)/2~\mbox{et}~ P(X_n=0)=p_n.$$
  On suppose que
  $\ds{\sum _{n=1} ^{+\infty}(1-p_n)=+\infty}$. Soit
  $S_n=X_1+\cdots+X_n$ et soit $T=\inf \{n~|~S_n \notin ]-a,b[\}$, où
  $(a,b)\in \mathbf{N}^{*2}$. Vérifier expérimentalement que $T$ est presque
  sûrement fini (prendre diverses valeurs de $a$ et $b$). Montrer
  numériquement que $\ds{P(S_T=-a)=\frac b {a+b}}$. Que se
  passe-t-il si $\ds{\sum _{n=1} ^{+\infty}(1-p_n)<+\infty}$?
\item Soit $(X_n)$ des v.a. i.i.d. suivant une loi de Bernoulli de paramètre
  $p$, et soit $S_n=X_1+\cdots+X_n$. Soit $m \in \mathbf{N}^*$ et soit
  $\tau=\inf \{n~|~S_n=m\}$. Vérifier que $\tau$ est fini presque sûrement,
  représenter la loi de $\tau-m$ (histogramme) et donner une approximation de
  $\mathbf{E}(\tau)$ pour différentes valeurs de $m$ et de $p$. La loi de
  $\tau$ est appelée «loi binomiale négative BN(p,m)», et correspond au nombre
  d'essais indépendants nécessaires pour obtenir m succès lorsque la
  probabilité de réussite est $p$.
\item On considère des objets produits par une machine, dont chacun a une
  probabilité $p$ d'être défectueux ($0 \leq p <1$). On choisit $100$ objets
  et on note $X_i=1$ si l'objet $i$ est défectueux, $X_i=0$ sinon. Soit
  $\tau=\inf \{n~|~X_n=1\}$. Vérifier que $\nu=\inf(\tau,100)$ est fini,
  donner des approximations de $P(\tau \leq 100)$ et de $\mathbf{E}(\nu)$ (en
  fonction de $p$ que vous ferez varier). 
\item Soit $(X_n)$ des v.a.i.i.d. suivant une loi de Poisson de paramètre
  $\lambda \leq 1$. Soit $Y_n=X_n-1$ pour $n \in \mathbf{N}^*$ et soit
  $S_n=X_1+\cdots+X_n$. On note $T=\inf \{n~|~S_n =-1\}$. Vérifier que $T$ est
  presque sûrement fini et donner une approximation de son espérance. Qu'en
  pensez-vous? Peut-on obtenir par simulation la loi de $T$? Faire le même
  exercice avec pour loi des $X_i$ une loi géométrique de paramètre $1/2$ et
  $Y_n=X_n-2$. Conclusion?
\item Reprendre le modèle d'Ehrenfest. En notant $n$ le nombre total de
  boules, et en supposant que l'on ait aucune boule initialement dans l'urne
  $1$, donner une approximation de l'espérance du temps nécessaire pour avoir
  à nouveau aucune boule dans l'urne $1$ (vérifier que cette espérance est
  $2^n$).
\end{enumerate}    

%
\subsection{Convergence des martingales}
%

\begin{enumerate}
\item On considère $(X_n)$ des v.a. i.i.d. suivant une loi normale centrée 
  réduite. On pose $\ds{Y_i=X_iX_{i+1}}$. Vérifier que les $Y_i$ ne sont pas
  indépendantes. Vérifier que $\ds{M_n=\sum _{i=0}^n\frac{Y_i}{a_i}}$
  est une martingale, avec $a_i$ suite de réels strictement positifs. Dans le
  cas où $a_n=n$, faire un programme permettant d'observer la convergence de
  $M_n$. Quelle est la distribution de la limite $M_{\infty}$. Recommencer avec
  $a_n=\sqrt{n}$. Qu'observe-t-on ?
\item L'urne de Polya~: une urne contient des boules blanches et noires. A
  l'étape $1$, il y a une boule blanche et une boule noire. À l'étape $n$,
  on tire une boule au hasard, on la remet ensuite dans l'urne et on rajoute
  une boule de la même couleur. On appelle $X_n$ le nombre de boules
  blanches et $Y_n$ le nombre de boules noires à l'étape $n$. Montrer que
  $X_n + Y_n = n+1$ et que $P(X_n=j)=1/n \ , \ \ \ 1\leq j \leq n.$ Simuler
  plusieurs expériences, et tracer sur un même graphique les différentes
  trajectoires $(X_n)$ obtenues. Soit $\ds{M_n=\frac {X_n}{n+1}}$.
  Montrer que $M_n$ est une martingale convergente. Tracer sur un même
  graphique les différentes trajectoires de $(M_n)$. Quelle est la
  distribution de $M_{\infty}$ ?
\item On considère $(X_n)$ des v.a.i.i.d. suivant une loi normale centrée
  réduite et $S_n=X_1+\cdots+X_n$. On pose
  $\ds{Z_n^u=\exp(uS_n-\frac{nu^2}2)}$. Vérifier que $Z_n^u$ est une
  martingale pour toute valeur de $u$. Pour différentes valeurs de $u$, faire
  un programme permettant d'observer la convergence de $Z_n^u$ et la
  distribution de $Z_\infty^u$. Déterminer $\mathbf{E} Z_n^u$, et en déduire
  que la convergence n'a lieu dans $\mathbf{L}^1$ que si $u=0$. Est-ce
  observable numériquement ?
\item On considère $(X_n)$ des v.a.i.i.d. suivant une loi normale centrée
  réduite et on note $Y_n=X_n^2$. Que vaut $\mathbf{E} Y_n$ ? Vérifier
  numériquement que $\mathbf{E} \sqrt{Y_n}<1$. On pose
  $\ds{Z_n=\prod _{k=1}^n Y_n}$.  Montrer que $(Z_n)$ est une
  martingale et que $(\sqrt{Z_n})$ est une surmartingale. Etudier la
  convergence et la limite de $(\sqrt{Z_n})$, puis de $(Z_n)$. A-t-on
  convergence dans $\mathbf{L}^1$ ?
\item Soit $(X_n)$ des v.a.i.i.d. à valeurs dans $\{-1,0,1\}$, telles que
  $P(X_i=1)=p$ et $P(X_i=-1)=q$ avec $q>p$. On note $S_n=X_1+\cdots+X_n$
  ($S_0=0$) et $\ds{W=\sup_{n \geq 0}S_n}$. Vérifier sur de
  nombreuses trajectoires que $W<+\infty$ p.s. Calculer explicitement
  $\ds{\psi(\lambda)=\log \mathbf{E}(e^{\lambda X_i})}$. Résoudre
  numériquement l'équation $\psi(\lambda_0)=0$ pour différentes valeurs de $p$
  et $q$. Vérifier numériquement que $W$ est distibuée suivant une loi
  géométrique de paramètre $(1-e^{\lambda_0})$ (pour des explications
  théoriques et des généralisations, voir \cite{baldi-mazliak-priouret}.
\end{enumerate}    

%% Local Variables: 
%% x-symbol-coding: iso-8859-1
%% x-symbol-8bits: t
%% mode: latex
%% TeX-master: "agregation"
%% End: 
%
%
\chapter{Files d'attente}
%
%

On pourra consulter par exemple \cite{bon}, \cite{bouleau2},
\cite{dacunha-castelle-duflo-2} et \cite{ross-1}.


%
\section{Notion de générateur infinitésimal}
%

Soit $(N_t)_{t\geq 0}$ un processus de Poisson d'intensité $\la$. Si l'on pose
$p_{t,m}(n):=\eP(N_t=m\,\vert\,N_0=n)$, un simple calcul fournit :
\begin{align*}
\frac{d}{dt}\,p_{t,m}(n)
&=\la \PAR{p_{t,m}(n+1)-p_{t,m}(n)}\\
&=(\bL p_{t,m})(n)
\end{align*}
où la matrice infinie $\bL$ est donnée pour tout $(i,j)\in\eN^2$ par
$$
\bL_{i,j}:=
\begin{cases}
  -\la & \text{ si $j=i$} \\
  \la & \text{ si $j=i+1$} \\
  0 & \text{sinon}
\end{cases}
$$
La matrice $\bL$ joue le même rôle que la matrice de transition des chaînes
de Markov, et l'on parle de générateur infinitésimal du processus
$(N_t)_{t\geq 0}$. Sa donnée caractérise la loi du processus de Markov
$(N_t)_{t\geq 0}$ et l'on a $p_{t,m}(n)=(\exp(t\bL))_{m,n}$. Si $N_0$ a pour
loi $\si$, vue comme un vecteur colonne de longueur infinie, alors $N_t$ a
pour loi $\exp(t\bL)\si$ où le produit est «matriciel».

Réciproquement, donnons nous une matrice infinie $(\bL_{i,j},(i,j)\in\eN^2)$,
telle que $\bL_{ij}\geq 0$ si $i\neq j$ et dont la somme de chaque ligne est
nulle. Alors elle constitue le générateur infinitésimal d'un processus de
Markov $(N_t)_{t\geq 0}$ sur $\eN$, qui reste en $i\in\eN$ un temps
exponentiel de paramètre
$$
\sum_{j\neq i}\bL_{ij},
$$
puis saute en $j\neq i$ avec probabilité
$$
\frac{\bL_{ij}}{\sum_{j\neq i}\bL_{ij}}.
$$
Un cas particulier important est constitué par les processus de \emph{vie
  et de mort} :
$$
\bL_{i,j}:=
\begin{cases}
  -\la_{i}-\mu_j & \text{ si $j=i$ (attente)} \\
  \la_{i} & \text{ si $j=i+1$ (vie)} \\
  \mu_{i} & \text{ si $j=i-1$ (mort)} \\
  0 & \text{sinon}
\end{cases}
$$
où $(\la_n)_{n\in\eN}$ et $(\mu_n)_{n\in\eN}$ sont deux suites de réels
strictements positifs avec $\mu_0=0$. Ces processus ne peuvent sauter que de
$+1$ ou $-1$. De tels processus sont très faciles à simuler. Ils modélisent
bien un certain type de files d'attente : les incrémentations correspondant à
l'arrivée poissonienne des clients et les décrémentations aux résultats du
travail des serveurs qui réduisent la file d'attente.  La dénomination «vie ou
mort» provient de l'interprétation en terme de population de particules qui
augmente ou diminue d'une unité. Le processus de Poisson d'intensité $\la$
correspond à $\la_n=\la$ et $\mu_n=0$ pour tout $n\in\eN$.

Pour certaines suites $(\la_n)_{n\in\eN}$ et $(\mu_n)_{n\in\eN}$, la loi du
processus à l'instant $t$ converge vers une loi limite sur $\eN$ lorsque $t$
est grand, qui correspond à un état d'équilibre. Formellement, cette loi
stationnaire est solution de l'équation $\bL\si=0$. Pour le processus de
Poisson, les mesures stationnaires sont les mesures constantes sur $\eN$, qui
ne sont pas des probabilités. En revanche, nous allons voir que certains
processus de vie ou de mort admettent des lois de probabilités stationnaires,
et l'on comprend que le rapport entre les coefficients de vie $\la_n$ et de
mort $\mu_n$ va jouer un rôle.

%
\section{File d'attente M/M/1}
%

En anglais, on parle de queues. Les files d'attente apparaissent naturellement
dans beaucoup de situations : un guichet déservant des usagers, une piste
d'aéroport sur laquelle les avions atterissent, un serveur informatique
répondant à des requêtes, etc.  Les clients arrivent à des instants aléatoires
et attendent leur tour devant le guichet (serveur). Le serveur met un temps
aléatoire pour servir chaque client.  On suppose ici que les clients sont
servis dans leur ordre d'arrivée (on parle alors de file FIFO : «First In
First Out»).

On suppose que les instants d'arrivée des clients correspondent à un processus
de Poisson d'intensité $\la$ et que les instants de fin des services
correspondent à un autre processus de Poisson, indépendant du premier, et de
paramètre $\mu$.  Ainsi, si $A_t$ désigne le nombre d'arrivées de clients dans
l'intervalle $[0,t[$, alors $(A_t)_{t\geq 0}$ est un processus de Poisson et
$A_t/t$ tend presque sûrement vers $\la$.

On s'intéresse par exemple au nombre de clients $N_t$ à l'instant $t$ dans la
file d'attente, en comptant l'éventuel client qui est en train d'être servi,
et on suppose que $N_0=0$. Le processus $(N_t)_{t\geq0}$ est un processus de
Markov qui appartient à la classe des processus de «vie ou de mort» : il
s'agit d'un processus à saut, dont les sauts ne peuvent valoir que $+1$ ou
$-1$, et dont les durées inter-sauts suivent des lois exponentielles. Ce
processus est plus complexe que le processus de Poisson car les temps
inter-sauts et la loi des sauts dépendent de la valeur du processus. À ce
stade, il est important d'observer que le minimum de deux v.a.r. de loi
exponentielles de paramètres respectifs $\la$ et $\mu$ suit encore une loi
exponentielle de paramètre $\la+\mu$ et que la loi exponentielle est sans
mémoire.  On peut alors simuler la valeur de $N_t$ de la manière suivante :
$$
N_t(\om)=\sum_{n=0}^{+\infty} X_n(\om)
\,\rI_{[T_n(\om),T_{n+1}(\om)[}(t),
$$
où $X_0=0$, $T_0=0$ et pour $n>0$ :
$$
\cL(T_{n+1}-T_{n}\,\vert\,X_n)=
\begin{cases}
\cE(\la) & \text{si $X_n=0$} \\
\cE(\la+\mu) & \text{si $X_n>0$}
\end{cases}
$$
et 
$$
\cL(X_{n+1}-X_n\,\vert\,X_n)=
\begin{cases}
\delta_{+1} & \text{si $X_n=0$} \\
\frac{\mu}{\la+\mu}\,\delta_{-1}+\frac{\la}{\la+\mu}\,\delta_{+1} & \text{si $X_n>0$}
\end{cases}
$$
Sur chaque intervalle de temps $[T_n,T_{n+1}[$, $N_t$ vaut $X_n$ et chaque
instant de saut $T_n$ correspond à l'arrivée d'un nouveau client ou à la fin
d'un service (départ d'un client). Voici un code \ML{} illustrant ce procédé :

\MFILE{fileattente}

Lorsque $\rho:=\la/\mu<1$, $N_t$ converge en loi vers la loi géométrique de
paramètre $\rho$ lorsque $t$ tend vers $+\infty$. La file d'attente atteint
alors un équilibre asymptotique, et la moyenne du nombre de clients dans la
file lorsque $t$ est grand devient proche de la moyenne $\rho/(1-\rho)$ de la
loi géométrique limite.  La probabilité que la file d'attente dépasse le seuil
$K$ à l'équilibre est alors de $\rho^K$. Le paramètre $\rho$ représente la
\emph{charge du système}. Lorsque $\rho>1$, les clients arrivent trop vite
pour qu'un équilibre s'installe. Si $W_n$ représente le temps de séjour dans
la file du $n$-ième client, on montre que lorsque $\rho<1$, les quantités
suivantes sont  :
$$
\la\,\eE\PAR{\lim_{n\to+\infty}\,\frac{W_1+\cdots+W_n}{n}}
=\eE\PAR{\lim_{t\to+\infty}\,\frac{1}{t}\,\int_0^t\!\!N_s\,ds}
=\frac{\la}{\mu-\la}.
$$
En fait, on peut même montrer que
$T:=\lim_{n\to+\infty}(W_1+\cdots+W_n)/n$ suit une loi exponentielle
de paramètre $\mu-\la$. La variable aléatoire $T$ représente le
\emph{temps de réponse du système} à l'équilibre.

\begin{exo}
  En utilisant le programme \ML{} précédent, vérifier que tout ceci a
  bien lieu par des simulations. Qu'elle est la variance asymptotique
  de $N_t$ lorsque $t$ tend vers $+\infty$ ?  Que se passe-t-il
  lorsque $\rho=1$ ?  Que représente la quantité $\log \veps / \log
  \rho$ pour $\veps \in]0,1[$ ?
\end{exo}

La dénomination M/M/1 correspond à un cas particulier de la
nomenclature suivante utilisée pour les files d'attente :
\textbf{A}/\textbf{B}/\textbf{s}/\textbf{K}/\textbf{n}/\textbf{d} où
\begin{itemize}
\item \textbf{A} indique la loi des temps d'arrivée des clients
\item \textbf{B} indique la loi des temps de service
\item \textbf{s} indique le nombre de serveurs
\item \textbf{K} indique la capacité maximale de la salle d'attente ($+\infty$ si
  omis)
\end{itemize}
Voici quelques codes utilisés pour \textbf{A} et \textbf{B} :
\begin{itemize}
\item M pour des v.a. i.i.d. de loi exponentielles («memoryless»)
\item U pour des v.a. i.i.d. de loi uniforme
\item D pour des temps constants (déterministes)
\item GI pour des v.a. i.i.d. de même loi
\item G pour des loi quelconques
\end{itemize}

\begin{exo}[File d'attente M/M/s]
  Simulez une file M/M/s (i.e. avec s serveurs).  On pourra remarquer
  que dans ce cas, $\la_n=\la$ et $\mu_n=n\mu$ si $n\leq s$ et
  $\mu_n=ns$ si $n=s$.  La condition de stationnarité est donnée par
  $\rho:=\la/s\mu<1$. Qu'elle est la loi stationnaire ?
\end{exo}

\begin{exo}[File d'attente M/M/1/K]
  Simulez une file M/M/1/K (i.e. un seul serveur et une salle
  d'attente de capacité maximale K).  Dans ce cas, $\la_n=\la
  \rI_{0\leq n < K}$ et $\mu_n=\mu \rI_{1\leq n \leq K}$.  La
  condition de stationnarité est donnée par $\rho:=\la/\mu<1$.
  Vérifiez que la loi stationnaire est donnée par
  $$
  \frac{1-\rho}{1-\rho^{K}}\,\sum_{n=0}^K \rho^n\,\delta_n.
  $$
\end{exo}

\begin{exo}[File d'attente M/M/$\infty$]
  Simulez une file M/M/$\infty$ (i.e. une infinité de serveurs).  Dans
  ce cas, $\la_n=\la$ et $\mu_n=n\mu$.  Vérifiez que la loi
  stationnaire est la loi de Poisson de paramètre $\rho:=\la/\mu$.
\end{exo}

\begin{exo}[File d'attente avec impatience]
  Dans ce cas, chaque nouveau client décide d'entrer dans la file avec
  une probabilité $r_n$ où $n$ désigne le nombre de clients déjà
  présents dans la file. Simulez une telle file (on a $\la_n=r_n\la$
  et $\mu_n=\mu$).
\end{exo}

%
\section{Exercices}
%

\begin{enumerate} 
\item Simuler un processus de Poisson à l'aide d'exponentielles de
  paramètre $\la$. Tracer la trajectoire de ce processus. Pour une
  valeur de $t$ quelconque, donner $N_t$. Déterminer un estimateur de
  $\la$ et donner un intervalle de confiance sur la valeur obtenue
  pour une trajectoire.
\item On considère une machine qui peut tomber en panne, mais qui est
  réparée instantanément. Par exemple, une machine avec une pile, une
  lampe avec une ampoule, etc. On suppose que la durée de vie moyenne
  entre chaque panne est de $m$. On note par $N$ le processus de
  renouvellement correspondant au nombre de pannes, et par $T_k$ la
  durée de vie après la panne $k$ (possédant un moment d'ordre $2$).
  On choisit pour loi des $T_k$ une loi exponentielle de paramètre
  $0.5$ (unité de temps = le mois ?). Représenter $N_t$, puis $N_t/t$
  pour $t \in [0,100]$.
\item Simuler un processus de renouvellement pour lequel $T_1$ a une
  loi uniforme et les durées d'arrivées une loi de Weibull. Vérifier
  que $N_t/t$ tend vers une constante. Quelle est la loi asymptotique
  de $N_t/t$ ?
\item On suppose que $(T_n)$ est un processus de renouvellement avec
  $T_n=\sum_{k=1}^n \ta_k$, les v.a.i.i.d. $\tau_k$ étant distribuées
  suivant une loi sur $\dR^+$ possédant un moment d'ordre $2$. On
  considère ensuite un processus de Poisson $N:=(N_t\geq 0)$
  d'intensité $\te$, indépendant du processus $T_n$. On pose
  $X_n:=N_{T_n}$ pour $n\in\eN$. Construire $T_n$, $N$, et en déduire
  $X_n$ (choisir différentes lois pour $\ta_k$).  Vérifier que la
  suite $(X_n/n)_n$ possède une limite lorsque $n$ tend vers $+\infty$
  et qu'il existe $a_n$ et $b_n$ tels que $(X_n-a_n)/b_n$ converge
  vers une loi ${\cN}(0,1)$.
\item On considère une machine qui peut tomber en panne pendant un
  certain temps. Soient $(X_n)_n$ (resp. $(Y_n)_n$) des v.a.i.i.d. à
  valeurs dans $\dR^+$, de loi de densité $f_X$ (resp. $f_Y$),
  d'espérance $m_X$ finie (resp. $m_Y$ finie). Les $(X_n)_n$ sont les
  durées de bon fonctionnement et sont indépendantes des $(Y_n)_n$,
  qui sont les durées de pannes successives.  On pose $T_0:=0$ et pour
  $n \geq 1$, $S_n:=T_{n-1}+X_n$ et $T_n:=S_n+Y_n$.  Ainsi, les
  intervalles $[T_n,S_{n+1}[$ sont les intervalles de bon
  fonctionnement et les $[S_n,T_n[$ les intervalles de panne.
  \begin{enumerate}
  \item On prend pour $f_X$ une densité de Weibull $(5,1)$ et pour
    $f_Y$ une densité exponentielle de paramètre $3$. Représenter
    $(T_n)_n$ dont on montre que c'est un processus de renouvellement.
  \item Montrer que~:
    $$
    \lim_{t\to+\infty}
    \eP\PAR{t \in \bigcup_{n \in\eN}[T_n,S_{n+1}[}=\frac{m_X}{m_X+m_Y}.
    $$
  \end{enumerate}  
\item On considère un processus de Poisson d'intensité $\la$. À chaque
  saut du processus, on note $A$ le saut avec une probabilité $p$ et
  $B$ avec une probabilité $1-p$. Vérifier que les processus de
  comptage des $A$ et des $B$, notés $N^A$ et $N^B$, sont des
  processus de Poisson. Quelles sont leurs intensités ? Sont-ils
  indépendants ? Le vérifier à l'aide d'un test du $\chi^2$.
\end{enumerate}  

%% Local Variables: 
%% x-symbol-8bits: t
%% x-symbol-coding: iso-8859-1
%% mode: latex
%% TeX-master: "agregation"
%% End:
%
%
\chapter[Évolution de la taille d'une population]%
{Évolution de la taille d'une population 
 lorsque la loi de reproduction est homogène} 
%
%

On pourra consulter par exemple \cite{harris-63}, \cite{harris-fr} et
\cite{williams} pour les preuves des résultats énoncés. On se propose
d'étudier l'évolution d'une population de taille $Z_n$ à la génération
$n$, modélisée par le processus suivant, appelé \emph{processus de
  branchement} ou processus de Galton-Watson :
\begin{itemize}
\item $Z_0=1$.
\item Chaque individu a pour probabilité $p_k$ d'avoir $k$ descendants, avec
  $k\in\eN$.
\end{itemize}
En supposant que les enfantements se font de manière indépendante, on
a la formule de récurrence suivante pour $n\in\eN^*$ :
$$
Z_{n+1}=\sum_{i=1}^{Z_n} X_{n,i},
$$
où les variables aléatoires $(X_{n,i})_{n,i\in\eN}$ sont i.i.d. et
de loi
$$
P:=\sum_{k=0}^{+\infty} p_k\,\delta_k. 
$$
Cette loi de probabilité discrète sur $\eN$ est appelée \emph{loi
  de fécondité} du processus. On note $m$ son espérance et $\si$ sa
variance.  On supposera toujours pour simplifier que :
\begin{itemize}
\item La loi $P$ a tout ses moments finis (donc $m<\infty$ et
  $\si<\infty$)
\item Pour tout $k$, $p_k\neq 1$, et $p_0+p_1<1$
\end{itemize}
On vérifie facilement que $\eE(Z_n)=m^n$ et 
$$
\varp{}{Z_n}=
\begin{cases}
  n\si^2 & \text{ si $m=1$}\\
  \si^2m^{n-1}(m^n-1)(m-1)^{-1} & \text{ si $m\neq 1$}.
\end{cases}
$$
D'autre part, si $f_n$ est la fonction génératrice de $Z_n$, on
vérifie facilement que
$$
f_n=\underbrace{f\circ \cdots \circ f}_{n \text{ fois}},
$$
où $f$ est la fonction génératrice de la loi $P$. Les hypothèses
faites sur $P$ entraînent alors que $f$ est strictement convexe sur
$[0,1]$ et que $f'(1)$ est finie.

On s'intéresse naturellement à la \emph{probabilité d'extinction} de
la population modélisée par $(Z_n)_{n\in\eN}$.  La suite $\BRA{Z_n=0}$
est croissante, et la probabilité d'extinction $q$ est donnée par :
$$
q:=\eP(\exists n,\,Z_n=0) =\lim_{n\to+\infty} \eP(Z_n=0)
=\lim_{n\to+\infty} f(0),
$$
On peut alors montrer que $q=1$ si $m\leq 1$ et que si $m>1$, $q$ est point
fixe de $f$. En fait, la suite $(Z_n)_{n\in\eN}$ est instable quelque soit la
valeur de $m$ :
$$
\forall k>0,\,\lim_{n\to+\infty}\eP(Z_n=k)=0, 
$$
et la suite $(Z_n)_{n\in\eN}$ converge vers $0$ avec probabilité $q$ et
vers $+\infty$ avec probabilité $1-q$. Le processus $(Z_n)_{n\in\eN}$ est une
chaîne de Markov de probabilité de transition
$$
\cL(Z_{n+1}\,\vert\,Z_n=k)=P^{*k}.
$$
D'autre part, on vérifie facilement que $(Z_n/m^n)_{n\in\eN}$ est une
martingale, bornée dans $\bL^2$ (car $\si<+\infty$).

Suivant la valeur de $m$, trois comportements asymptotiques distincts pour
$(Z_n)_{n\in\eN}$ vont se présenter :
\begin{enumerate}
\item Si $m<1$, on est dans le cas \emph{sous-critique} et la population va
  s'éteindre presque sûrement (i.e. $Z_n$ tend vers $0$ p.s.). De plus la loi
  conditionnelle de $Z_n$ sachant que $Z_n>0$ admet une loi limite
  $B=b_1\,\delta_1+b_2\,\delta_2+\ldots$ :
  $$
  \forall k\in\eN^*,\,\lim_{n\to+\infty} \eP(Z_n=k\,\vert\,Z_n>0) = b_k,
  $$
  et la fonction génératrice $g$ de $B$ vérifie $g\circ f=mg+1-m$.
\item Si $m >1$, on est dans le cas \emph{sur-critique} et la probabilité
  d'extinction $q$ est l'unique point fixe de $f$.  De plus, $m^{-n} Z_n$
  converge presque-sûrement et dans $\bL^2$ vers la variable aléatoire $W$, de
  moyenne $1$ et de variance $\si^2/(m^2-m)$, $\eP(W=0)=q$ et la transformée
  de Laplace $\vphi(s):=\eE(\exp(-sW))$ de $W$ vérifie
  $$
  \forall s\geq 0,\,\vphi(ms)=f(\vphi(s)).
  $$
\item Si $m =1$, on est dans le cas \emph{critique}, et $Z_n$ est une
  martingale qui tend presque sûrement vers $0$ (elle ne converge donc pas en
  moyenne quadratique). On a de plus :
  $$
   n\,\eP(Z_n>0) \limn{n} \frac{2}{\si^2}
   \text{\quad et \quad} 
   \frac{1}{n}\,\eE(Z_n\ |\ Z_n>0) \limn{n} \frac{\si^2}{2}
   $$
   et enfin, pour tout $u\geq 0$
  $$
  \eP\PAR{\frac{Z_n}{n} \geq u\ |\ Z_n>0} \limn{n} \exp(-\frac{2u}{\si^2}).
  $$
\end{enumerate}

Pour $P=p_0\,\delta_0+p_1\,\delta_1+p_2\,\delta_2$, on a $m=p_1+2*p_2$,
$f(s)=p_0+p_1s+p_2s^2$ et $f(s)=s$ si et seulement si
$s\in\{1,p_0/p_2\}$, d'où $q=p_0/p_2$.

%
\MFILE{gwpop-discr}
%

Pour $P=p\,\sum_{k=0} (1-p)^k\,\delta_k$, on a $m=(1-p)/p$,
$f(s)=p/(1-(1-p)s)$ et $f(s)=s$ si et seulement si $s\in\{1,1/m\}$,
d'où $q=p/(1-p)$.

%
\MFILE{gwpop-geom}
%

%
\MFILE{gwpop-histo}
%

%
\MFILE{gwpop-pext}
%

%
\FIG{gwpop-pext}{0.5}{htbp}{Probabilité d'extinction empirique}
%

\begin{exo}
Dans le cas d'une loi de reproduction géométrique de paramètre $p$,
calculez la probabilité d'extinction en fonction de $p$. Choisir $p$
de façon à obtenir les cas critique, sur-critique et sous-critique.
Tracez des histogrammes et des trajectoires simulées dans chacuns de
ces cas et confrontez vos résultats aux comportements prévus par la
théorie.
\end{exo}

On trouvera dans \cite{ruget} deux chapitres consacrés à des modèles
de Galton-Watson. Le modèle avec immigration est très simple à simuler
puisqu'il suffit d'ajouter à $Z_n$ une réalisation d'une loi fixée à
l'avance (par exemple une loi de Poisson) qui modélise le flux
migratoire à la $n$-ième génération.

%% Local Variables: 
%% x-symbol-8bits: t
%% x-symbol-coding: iso-8859-1
%% mode: latex
%% TeX-master: "agregation"
%% End:
%
%
\chapter{Quelques lois classiques}
%
%

%FIXME: mieux présenter et intégrer les thm et convol.
On renvoie principalement à \cite{borkar}, \cite{rudin}, \cite{bouleau} et
\cite{dacunha-castelle-duflo}. Dans toute la suite, on note $\cL(X)$ la loi de
la v.a. $X$ et $*$ la convolution des fonctions ou des lois de probabilité,
définies par~:
$$
(f*g)(x):=\int\!f(x-y)g(y)\,dy=\int\!f(z)g(x-z)\,dz=(g*f)(x),
$$
et
$$
\moyp{\mu*\nu}{\vphi} :=\int\!\vphi(x+y)\,d(\mu\otimes\nu)(x,y)
=\int\!\vphi(x+y)\,d(\nu\otimes\mu)(x,y)=\moyp{\nu*\mu}{\vphi}.
$$
Si $\mu$ et $\nu$ ont pour densités respectives $f$ et $g$ par rapport à la
mesure de Lebesgue, alors $\mu*\nu$ a pour densité $f*g$. On rappelle que la
convolée $\mu*\nu$ de deux mesures de probabilité représente la loi de la
somme de deux v.a. indépendantes $X,Y$ de loi respectives $\mu$ et $\nu$~:
$$
X,Y \text{ indépendantes} \Rightarrow \cL(X+Y)=\cL(X) * \cL(Y).
$$
La réciproque est fausse en général. On note $\mu^{*n}$ la loi obtenue en
convolant $n$ fois $\mu$~:
$$
\mu^{*n}:=\underbrace{\mu* \cdots * \mu}_{n \text{ fois.}}.
$$
D'autre part~:
$$
X,Y \text{ indépendantes} \Leftrightarrow \cL((X,Y))=\cL(X)\otimes\cL(Y).
$$
On note $\delta_a$ la masse de Dirac en $a$, c'est à dire la mesure de
probabilité qui affecte la masse $1$ aux ensembles mesurables contenant le
point $a$ et $0$ aux autres. C'est la loi d'une v.a. constante de valeur $a$.
Sa moyenne vaut $a$ et sa variance est nulle. Pour tout $\mu$ et $\nu$, on a
$\mu*\nu=\nu*\mu$ et $\mu*\delta_0=\delta_0*\mu=\mu$ et $\delta_a*\delta_b=\delta_{a+b}$. La
masse de Dirac en $0$ est donc l'élément neutre de la convolution.

\begin{eur}[Convolution = lissage]
  Convoler une fonction $f$ par une fonction $g$ revient à prendre en $x$ une
  moyenne des valeurs de $f$ pondérées par la translation de $g$ en $x$. Il
  est donc naturel que la masse de Dirac en $0$ soit l'élément neutre de la
  convolution. Si $g$ est lisse, on fait donc du lissage de $f$. Pour ce
  faire, on prend souvent pour $g$ une fonction $\cC^\infty$ paire et à
  décroissance rapide voire même à support compact de façon à remplacer $f(x)$
  par une «$g$-moyenne» de $f$ au voisinage de $x$.  Penser à la technique de
  régularisation par convolution utilisée en analyse, en particulier pour
  montrer la densité de $\cC^\infty_c$ dans les espaces $\bL^p$ de Lebesgue.
\end{eur}

\begin{eur}[Convolution des densités = addition d'un bruit indépendant sur la v.a.]
  Soit $X$ et $Y$ des v.a. de densités respectives $f$ et $g$.  Dire que $g$
  est \emph{lisse} signifie que la v.a. $Y$ est purement \emph{continue},
  c'est à dire que les valeurs prises sont bien réparties et sans sauts.
  Ainsi, si $X$ est indépendante de $Y$, la v.a. $X+Y$ aura en général des
  valeurs mieux réparties que celles de $X$ lorsque $g$ est lisse.  La densité
  de $X+Y$ est la convolée de la densité $f$ de la v.a. $X$ par la densité $g$
  de la v.a. $Y$.  Si $g$ est lisse, il en sera de même pour $f*g$.  Ainsi,
  lisser une densité se traduit sur les v.a. par l'addition d'une v.a.
  indépendante à densité lisse (penser par exemple au lissage d'une v.a.
  discrète $X$ par addition d'une v.a. indépendante $Y$ de loi uniforme où
  gaussienne, centrée et de faible variance par rapport à l'écart entre les
  valeurs discrètes prises pas $X$).
\end{eur}

\begin{rem}[Fonctions de répartition et densité]
  Considérons une loi de probabilité $\mu$ sur $\dR$, de fonction de
  répartition $F$. En tant que fonction de répartition, la fonction $F$ est
  croissante, continue à droite, et $F(\dR)=[0,1]$. On montre alors qu'elle ne
  peut avoir qu'un nombre au plus infini dénombrable de points de discontinuité, notés
  $(s_n)_n\subset\dR$, cf.  \cite[prop. III.2.2 page
  48]{barbe-ledoux}. On montre de plus, \cite[III, pages 49-50]{barbe-ledoux},
  qu'il existe trois réels positifs ou nuls $\al, \be, \gamma$ vérifiant
  $\al+\be+\gamma=1$, tels que $F$ possède la décomposition suivante :
  $$
  F=\al F_{\text{disc}} + \be F_{\text{sing}} + \gamma F_{\text{cont}},
  $$
  où les fonctions $F_\bullet$, qui vérifient les propriétés suivantes,
  n'existent que lorsque le coefficient associé est non nul :
  \begin{enumerate}
  \item $F_{\text{disc}}$ est constante par morceaux, et c'est la fonction de
    répartition de la loi de probabilité discrète
    $\sum_n\delta_{s_n}$
  \item $F_{\text{cont}}$ est absolument continue et c'est la fonction de
    répartition d'une loi de probabilité à densité par rapport à la mesure de
    Lebesgue sur $\dR$
  \item $F_{\text{sing}}$ est continue et c'est la fonction de répartition
    d'une mesure de probabilité singulière par rapport à la mesure de Lebesgue
    sur $\dR$
  \end{enumerate}
  $F$ est continue si et seulement si $\al=0$ et $\mu$ admet une densité si et
  seulement si $\al=\be=0$.  Il ne suffit donc pas que $F$ soit continue pour
  que $\mu$ admette une densité par rapport à la mesure de Lebesgue. En
  d'autre termes, la composante étrangère à la mesure de Lebegue de $\mu$ dans
  sa décomposition de Lebesgue-Radon-Nikodym (cf. \cite[thm 6.9, page
  117]{rudin}) ne se réduit pas aux sauts de la fonction $F$. Un exemple
  simple est fourni par les lois fractales de la section
  \ref{ss:lois-fractales} page \pageref{ss:lois-fractales}.  Bien entendu, si
  $F$ est $C^1$, alors $\mu$ admet une densité qui n'est rien d'autre que
  $F'$.
\end{rem}

\begin{rem}[Densité au sens de la théorie des distributions]
  Une loi de probabilité est, en tant que mesure de Radon, une distribution.
  Elle s'identifie à sa densité lorsque cette dernière existe.  La fonction de
  répartition $F_X$ d'une v.a.r. $X$ existe toujours. Sa dérivée $F'_X$ au
  sens des distributions a donc toujours un sens. Lorsque la loi $\cL(X)$
  admet une densité $f$, cette dernière n'est rien d'autre que $F'_X$.  Les
  points de discontinuité de $F_X$ se traduisent sur $F'_X$ par des masses de
  Dirac au sens des distributions, tandis que les «plats» du graphe de $F_X$
  correspondent à des intervalles qui ne sont par portées par $\cL(X)$. Il ne
  suffit pas que $F_X$ soit continue pour que $\cL(X)$ admette une densité,
  i.e. que $F'_X$ soit une fonction en tant que distribution.  Les $F_X$ pour
  lesquelles c'est le cas sont dites «absolument continues» et s'écrivent
  comme l'intégrale d'une fonction $\bL^1$ (qui est alors la densité
  associée). Une condition suffisante d'absolue continuité est que $F_X$ soit
  $\cC^1$.
\end{rem}

\begin{rem}
  Les générateurs aléatoires de la bibliothèque \SB{} pour \ML{} sont listés
  dans la table \ref{ta:stixbox-rand} page \pageref{ta:stixbox-rand}.  Le
  tableau \ref{tab:lois} page \pageref{tab:lois} recense quelques lois
  usuelles. Pour les démonstrations et des extensions, on renvoie
  principalement à \cite{dacunha-castelle-duflo} et \cite{bouleau}.
\end{rem}

%
\section{Fonctions génératrices -- la transformée du pauvre}
%

Si $X$ est une variable aléatoire entière (i.e. à valeurs dans
$\bar{\eN}:=\eN\cup\PAR{+\infty}$), on définit sa fonction génératrice par~:
\begin{align*}
  G_X:[0,1[ & \to\dR \\
         s & \mapsto G_X(s):=\moyp{}{s^X}=\sum_{k=0}^{+\infty}s^k\,\eP(X=k).
\end{align*}
Elle ne dépend que de la loi de $X$, qu'elle caractérise.  En d'autre termes,
si $X$ et $Y$ sont deux v.a. entières, alors $\cL(X)=\cL(Y)$ si et seulement
si $G_X=G_Y$. De plus, $G_{X+Y}=G_X G_Y$ lorsque $X$ et $Y$ sont indépendantes
(la réciproque est fausse). On peut définir la fonction génératrice du couple
de v.a. entières $(X,Y)$ en $(s_1,s_2)\in[0,1[^2$ par~:
$G_{(X,Y)}(s_1,s_2):=\moyp{}{s_1^Xs_2^Y}$. Les v.a. $X$ et $Y$ sont alors
indépendantes si et seulement si $G_{(X,Y)}(s_1,s_2)=G_X(s_1)G_Y(s_2)$ pour
tout $(s_1,s_2)\in[0,1[^2$.

La fonction génératrice permet également de calculer les moments puisque
$\eP(X=n)=\frac{1}{n!}\,G^{n}_X(0)$ et $G_X'(1)=\moyp{}{X}$ et plus
généralement~: $G_X^{(n)}(1)=\moyp{}{X(X-1)\cdots(X-n+1)}$.


%
\section{Lois discrètes à support sur entiers naturels}
%

On rappelle que si $X$ et $Y$ sont deux v.a. entières (i.e. à valeurs dans
$\bar{\eN})$ indépendantes alors~:
$$
\eP(X+Y=n)=\sum_{k_1+k_2=n}\eP(X=k_1)\eP(Y=k_2).
$$
En terme de lois, cela donne~:
$$
(\mu*\nu)=\sum_{k_1+k_2=n}\mu\PAR{\BRA{k_1}}\,\nu\PAR{\BRA{k_2}}\,\delta_n.
$$

%
\subsection{Loi uniforme discrète}\label{ss:loi:uniforme-discrete}
%

C'est la loi donnée par~: $\PAR{\delta_{a_1}+\cdots+\delta_{a_n}}/n$, où les $a_i$ sont
tous différents. Elle a pour moyenne $(a_1+\cdots+a_n)/n$ et pour variance
$(n\NRM{a}_2^2/n-(a_1+\cdots+a_n)^2)/n^2$. On l'utilise pour modéliser un phénomène
pouvant prendre $n$ valeurs différentes $a_1,\ldots,a_n$ avec la même probabilité
$1/n$. Elle a pour propriété remarquable de maximiser, à $n$ fixé, l'entropie
de Shannon $\bH(p_1,\ldots,p_n)$ définie pour une loi de probabilité
$p_1\delta_{a_1}+\cdots+p_n\delta_{a_n}$ par~:
$$
\bH(p_1,\ldots,p_n):=-\sum_{k=1}^n p_i\log p_i.
$$

%
\subsection{Loi de Bernoulli}\label{ss:loi:bernoulli}
%

C'est la loi $q\delta_a+p\delta_b$ où $p\in[0,1]$, $q:=1-p$ et $a\neq b$. Le plus
souvent, on utilise $q\delta_{-1}+p\delta_1$ ou $q\delta_0+p\delta_1$.  La loi
$q\delta_0+p\delta_1$, notée $\cB(1,p)$, est de moyenne $p$ et de variance $pq$.
Elle permet de modéliser le résultat d'une expérience à deux issues possibles,
comme par exemple un jet de pièce dans un jeu de pile ou face, avec
probabilité $p$ de gagner (codé $1$) et probabilité $1-p$ de perdre (codé
$0$). Elle a pour fonction génératrice $q+ps$.

%
\subsection{Loi binomiale}\label{ss:loi:binomiale}
%

Notée $\cB(n,p)$, c'est la loi~:
$$
\sum_{k=0}^n C_n^k\,p^k(1-p)^{n-k}\,\delta_k=(q\delta_0+p\delta_1)^{*n}.
$$
Elle permet de modéliser le nombre de gains pour $n$ lancés au jeu de pile
ou face avec probabilité de gain de $p$. Si $X_1,\ldots,X_n$ sont i.i.d. de loi de
Bernoulli $q\delta_0+p\delta_1$, alors $X_1+\cdots+X_n$ suit la loi $\cB(n,p)$. La
probabilité de gagner $k$ fois en $n$ lancés vaut $C_n^k p^k(1-p)^{n-k}$. Sa
moyenne est $np$ et sa variance $npq$. Elle a pour fonction génératrice~:
$$
G_{\cB(n,p)}(s):=\moyp{\cB(n,p)}{s^\bullet}=\PAR{q+ps}^n.
$$
La loi gaussienne peut être obtenue par passage à la limite, cf. théorème
\ref{th:moivre-laplace}, page \pageref{th:moivre-laplace}.

%
\subsection{Loi géométrique}\label{ss:loi:geometrique}
%

La loi géométrique $\cG(p)$ de paramètre $p\in[0,1]$, ou loi de Pascal,
correspond à la loi du premier succès à un jeu de pile ou face avec
probabilité de gain $p$. Si $\PAR{X_n,n\in\eN^*}$ est une suite de v.a. i.i.d.
de loi de Bernoulli $q\delta_0+p\delta_1$, la loi géométrique de paramètre $p$ est
la loi de la v.a. «premier succès» définie par~:
$$
T(p):=\inf\BRA{n\in\eN^*, X_n=1}.
$$
Elle est donnée par~:
$$
\cG(p):=pq^{-1}\,\sum_{k=1}^{+\infty} q^k\delta_k.
$$
Sa moyenne vaut $1/p$, sa variance $q/p^2$ et sa fonction génératrice est
$sp/(1-sq)$. On préfère parfois numéroter les lancés de pile ou face à partir
de $0$, on a alors la loi géométrique de base $0$~:
$$
p\,\sum_{k=0}^{+\infty} q^k\delta_k,
$$
qui a pour moyenne $q/p$ et pour variance $q/p^2$.
Sous certains aspects, la loi géométrique peut être vue
comme l'analogue discrète de la loi exponentielle. 

%
\subsection{Loi négative-binomiale}\label{ss:loi:negative-binomiale}
%

C'est la loi du nombre de lancés nécessaires à un jeu de pile ou face de
probabilité de gain $p$ pour obtenir exactement $m$ succès.  C'est donc la loi
de la v.a. $T_m(p)$ où $T_1(p)=T(p)$ (de loi géométrique) et $T_i(p)$ ($i\geq 1$) est
défini par récurrence par~:
$$
T_i(p):=\inf\BRA{n>T_{i-1}, X_n=1}.
$$
Il est facile de voir que $T_m(p)$ à la même loi que la somme de $m$ v.a.
i.i.d. de loi géométrique de paramètre $p$. On a donc~:
$$
\cG_m(p)= \sum_{k=m}^{+\infty} C_{n-1}^{m-1}\,p^m q^{k-m} \,\delta_k
= \cG(p)^{*m}.
$$
On retrouve bien la loi géométrique pour $m=1$ : $\cG(p)=\cG_1(p)$. La loi
$\cG_m(p)$ a pour moyenne $m/p$, pour variance $mq/p^2$ et pour fonction
génératrice $\PAR{ps/(1-sq)}^m$. Elle tire son nom du fait que les
coefficients de sa fonction génératrice proviennent d'une sorte de «formule du
binôme inversé».

%
\begin{rem}[Schéma de Bernoulli]\label{ss:loi:schema-bernoulli}
  Le schéma de Bernoulli correspond à un jeu de pile ou face infini, avec
  probabilité $p\in]0,1[$ de succès à chaque lancé (les cas extrêmes sont
  triviaux). On le modélise par la donnée d'une suite $(X_n,n\in\eN^*)$ de v.a.
  i.i.d. de loi de Bernoulli de paramètre $p$ sur $\BRA{0,1}$~: à chaque
  lancé, on code $0$ un échec (probabilité $q:=1-p$) et $1$ un succès
  (probabilité $p$).  Le théorème de Caratheodory permet de définir une tribu
  et une loi de probabilité $\cL$ sur l'ensemble $\BRA{0,1}^{\eN^*}$ des
  suites infinies de $0$ et de $1$ telle que $(X_1,X_2,\ldots)$ soit de loi 
  $\cL$.
  Bien entendu, pour toute suite $s$ dans cet espace, on a
  $\cL\PAR{\BRA{s}}=0$. En revanche, on a pour tout $n\in\eN^*$ et
  $a\in\BRA{0,1}^n$, par indépendance des $X_1,\ldots,X_n$~:
  $\eP(X_1=a_1,\ldots,X_n=a_n)=\eP(X_1=a_1)\cdots\eP(X_n=a_n)$. 
  Cela correspond à l'événement cylindrique 
  $\BRA{a_1}\times\cdots\times\BRA{a_n}\times\BRA{0,1}\times\BRA{0,1}\times\cdots$. La plupart des questions
  que l'on peut se poser sur le jeu de pile ou face reviennent à étudier
  certaines propriétés de la loi $\cL$. Ses marginales sont des lois de 
  Bernoulli $\cB(1,p)$, et la loi de la somme de $k$ termes est binomiale
  $\cB(k,p)$. Sous $\cL$, la loi du rang du premier $1$ dans la
  suite infinie est géométrique $\cG(p)$, et plus généralement la loi du rang
  du $m$\Ieme $1$ est négative-binomiale $\cG_m(p)$.
  Les schémas de Bernoulli sont beaucoup moins triviaux qu'on le pense, et
  fournissent un très bon terrain d'investigation (y compris pour les
  systèmes dynamiques\ldots). La section \ref{ss:lois-fractales} page
  \pageref{ss:lois-fractales} donne une propriété fractale amusante de
  certains schémas de Bernoulli.
\end{rem}

%
\subsection{Loi de Poisson}\label{ss:loi:poisson}
%

La loi de Poisson $\cP(\la)$ de paramètre $\la>0$ est définie par~:
$$
e^{-\la}\,\sum_{n=0}^{+\infty}\frac{\la^n}{n!}\,\delta_n,
$$
C'est la loi du nombre de v.a.r. i.i.d. de loi exponentielle de paramètre
$\la$ qu'il faut additionner pour dépasser le seuil 1. Elle a pour moyenne et
variance $\la$ et pour fonction génératrice $e^{\la(s-1)}$.
La loi de Poisson est en quelque sorte l'analogue discret de la loi gaussienne.
On a par exemple $\cP(\la_1)*\cP(\la_2)=\cP(\la_1+\la_2)$. On dispose même
d'un «théorème central limite poissonien»~: 
$\cB(n,\la/n)$ converge étroitement vers $\cP(\la)$ lorsque $n\to+\infty$,
cf. \cite[th. V.5.6 p. 148]{barbe-ledoux}.

%
\subsection{Loi multinomiale}\label{ss:loi:multinomiale}
%

La loi multinomiale $\cM(n,k,p_1,\ldots,p_k)$ de taille $n\in\eN^*$, de dimension
$k\in\eN^*$ et de paramètre $(p_1,\ldots,p_k)\in\dR_+^k$ 
avec $p_1+\cdots+p_k=1$ est la loi portée par l'ensemble
$$
\BRA{(n_1,\ldots,n_k) \in \eN^k, \text{ t.q. } n_1+\cdots+n_k=n}
$$
et donnée par la formule~:
$$
\cM(n,k,p_1,\ldots,p_k)\PAR{\BRA{n_1,\ldots,n_k}}
:=\frac{n!}{n_1!\cdots n_k!}\,p_1^{n_1}\cdots p_k^{n_k}.
$$
Elle tire son nom de la formule du multinôme~: 
$$
\PAR{a_1+\cdots+a_k}^n=
\!\!\sum_{\SSK{0\leq n_1,\ldots,n_k\leq n\\n_1+\cdots+n_k=n}} 
\frac{n!}{n_1!\cdots n_k!}\,a_1^{n_1}\cdots a_k^{n_k}, 
$$
qui donne~:
$$
\cM(n,k,p_1,\ldots,p_k) = 
\!\!\!\!\sum_{\SSK{0\leq n_1,\ldots,n_k\leq n\\n_1+\cdots+n_k=n}} 
\frac{n!}{n_1!\cdots n_k!}\,p_1^{n_1}\cdots p_k^{n_k} 
\,\delta_{(n_1,\ldots,n_k)} = \PAR{p_1\delta_{e_1}+\cdots+p_k\delta_{e_k}}^{*n},
$$
où $\BRA{e_1,\ldots,e_k}$ est la base canonique de $\dR^k$.
On retrouve la loi binomiale pour $k=1$~: 
$$
\cM(n,1,p)=\cB(n,p).
$$
Si $\PAR{X_1,\ldots,X_n}$ sont des v.a. i.i.d. de loi $(p_1,\ldots,p_k)$ sur 
$\BRA{1,\ldots,k}$, et si 
$N_i:=\#\BRA{j=1,\ldots,n,\text{ t.q. }\, X_j=i}$ 
alors $(N_1,\ldots,N_k)$ suit la loi $\cM(n,k,p_1,\ldots,p_k)$. 
Remarquons que par définition, $N_1+\cdots+N_k=n$. La loi
multinomiale permet par exemple de modéliser les résultats de $n$ lancés
indépendants d'un dé à $k$ faces, $N_i$ représentant alors le nombre de fois
où la face numéro $i$ a été obtenue. On a enfin la convergence étroite
suivante vers une loi normale~:
$$
\PAR{\frac{N_1-np_1}{\sqrt{np_1}},\ldots,\frac{N_k-np_k}{\sqrt{np_k}}}
\limE{n} \cN(0,\Si_{p_1,\ldots,p_k}),
$$
où 
$$
\Si_{p_1,\ldots,p_k}:=\bI_k-\PAR{\sqrt{p_1},\ldots,\sqrt{p_k}}^\top\PAR{\sqrt{p_1},\ldots,\sqrt{p_k}}.
$$
La loi normale $\cN(0,\Si(p_1,\ldots,p_k))$ est la loi de la projection d'un
vecteur aléatoire de loi $\cN(0,\bI_k)$ sur l'hyperplan orthogonal au vecteur
$\PAR{\sqrt{p_1},\ldots,\sqrt{p_k}}^\top$. Sa matrice de covariance est de rang $k-1$,
elle est donc dégénérée (i.e. singulière).

%
\subsection{Loi hypergéométrique}\label{loi:hypergeom}
%

La loi hypergéométrique de paramètres $(N,N_1,n)\in\eN^*\times\eN^*\times\eN^*$
avec $N_1\leq N$ et $n\leq N$ est la loi sur $\BRA{0,\ldots,n}$ donnée par~:
$$
\sum_{k=0}^n \frac{C_{N_1}^kC_{N-N_1}^{n-k}}{C_N^n}\,\delta_k.
$$
Si l'on considère une population de $N$ individus dont $N_1$ possèdent un
caractère particulier, par exemple une maladie, alors la loi hypergéométrique
de paramètre $(N,N_1,n)$ représente la loi du nombre d'individus possédant ce
caractère dans un échantillon de taille $n$ de la population. C'est donc la
loi de $X_1+\cdots+X_n$ où les v.a. $X_i$ sont i.i.d. et ont pour loi
$((N-N_1)/N)\delta_0+(N_1/N)\delta_1$.

Elle a pour moyenne $nN_1/N$ et pour variance
$n(N-n)N_1(N-N_1)(N-1)^{-1}N^{-2}$. Bien sûr, de la même façon que 
la loi multinomiale généralise la loi binomiale, on pourrait définir une
loi hypergéométrique multiple lorsque l'on s'intéresse à un nombre $m\geq 1$ de
caractères dans la population.


%
\section{Transformées de Fourier \& de Laplace}
%

Pour les lois continues, la fonction génératrice est remplacée par la
transformée de Fourier ou de Laplace, qui sont plus puissantes et gardent leur
sens pour les lois discrètes. Soit $\mu$ une mesure de probabilité sur
$\PAR{\Om,\cA}$ où $\Om$ est un espace vectoriel topologique et $\cA$ sa tribu
borélienne. On note $\Om'$ l'espace dual topologique de $\Om$, constitué des
formes linéaires continues sur $\Om$. La transformée de Fourier de $\mu$ est
définie par~:
\begin{align*}
  {\cF}ourier\PAR{\mu}:\Om' & \to\dR \\ f & \mapsto\moyp{\mu}{\exp\PAR{if}}
\end{align*}
Cette fonction est bien définie puisque pour tout $f\in\Om'$, la fonction
$\exp\PAR{if}:\Om\to\dC$ est continue et bornée. Lorsque $\Om$ est un espace
Hilbert $\dH$ ($\dR^n$ par exemple), on identifie $\Om'$ à $\dH$ et on pose~:
\begin{align*}
  {\cF}ourier\PAR{\mu}:\dH & \to\dC \\ s & \mapsto\int_\Om\!\exp\PAR{i<s,x>}\,d\mu(x).
\end{align*}
La transformée de Laplace, quant à elle, est définie lorsque cela a un sens
par~:
$$
{\cL}aplace\PAR{\mu}(u):=\int_\Om\!\exp\PAR{-<u,x>}\,d\mu(x).
$$
Formellement, il suffit de prendre $s=iu$ dans la définition de la transformée
de Fourier pour obtenir la transformée de Laplace, lorsqu'elle existe.

La transformée de Fourier (ou de Laplace) caractérise la loi et
l'indépendance. Ainsi, deux v.a. ont la même loi si et seulement si elles ont
même transformée et $X$ et $Y$ sont indépendantes si et seulement si la
transformée du couple $(X,Y)$ en $(s_1,s_2)$ est égale au produit des
transformées respectives en $s_1$ et $s_2$ pour tout $(s_1,s_2)$. bien
entendu, la transformée en $s$ de la somme de deux v.a. indépendantes est
égale au produit des transformées respectives en $s$ (la réciproque est
fausse).

La transformée de Fourier d'une loi symétrique (i.e. invariante par la
symétrie centrale de centre $0$) est réelle.

La transformée de Fourier de $\delta_a$ avec $a\in\dR^n$ est donnée par
$e^{i<s,a>}$, elle permet de calculer les transformées de Fourier des lois
discrètes (i.e. à support au plus dénombrable sans point d'accumulation).
Ainsi, les lois binomiales $\cB(n,p)$ et de Poisson $\cP(\la)$ ont pour
transformée de Fourier respectives~:
$$
(pe^{is}+q)^n
\text{\quad et \quad}
e^{\la(e^{is}-1)}.
$$
Quant à la loi géométrique $\cG(p)$, sur $\eN^*$, et à la loi
négative-binomiale $\cG_m(p))$, elles ont pour transformée de Fourier
respectives~:
$$
\frac{pe^{is}}{1-qe^{is}}
\text{\quad et \quad}
\frac{p^me^{mis}}{(1-qe^{is})^m}.
$$

\begin{eur}[Transformation de Fourier = analyse en fréquences]
  La transformation de Fourier d'une fonction $f$ exprime les composantes en
  fréquences (on dit aussi spectre), indexées par $s$, de son argument $f$.
  La fonction $x\mapsto e^{isx}$ représente une fonction périodique
  élémentaire, dite \emph{harmonique de fréquence} $2\pi/s$. Il faut beaucoup
  de spectre pour reconstituer une fonction $f$ constante ou plus généralement
  «peu périodique» à partir des harmoniques.  La transformation de Fourier
  change la convolution en un produit.  Pour tronquer le spectre d'un signal
  $f$, il suffit de le convoler avec la transformée de Fourier inverse de la
  fonction indicatrice de troncature.
\end{eur}

%
\section{Lois continues}
%

%
\subsection{Loi uniforme}\label{ss:loi:uniforme}
%

La loi uniforme $\cU(a,b)$ sur l'intervalle compact non vide $[a,b]\subset\dR^n$ a
pour densité par rapport à la mesure de Lebesgue $dx$ sur $\dR$~:
$$
\frac{1}{b-a}\,\rI_{[a,b]}(x).
$$
Elle a pour moyenne $(a+b)/2$ et pour variance $(b-a)^2/12$. Sa transformée
de Fourier est~:
$$
e^{is(a+b)/2}\,\frac{\sin(s(b-a)/2)}{s(b-a)/2}.
$$
Tout ceci se généralise sans difficultés à un pavé $[a_1,b_1]\times\cdots\times[a_n,b_n]$ de
$\dR^n$.

%
\subsection{Loi triangulaire}\label{ss:loi:triangulaire}
%

C'est la loi «uniforme» sur le triangle du plan de base $[-a,a]$ et de sommet
de coordonnées $(0,1)$. Elle a pour densité par rapport à la mesure de
Lebesgue $dx$ sur $\dR$~:
$$
\frac{1}{a}\,\PAR{1-\frac{\ABS{x}}{a}}\,\rI_{[-a,a]}(x),
$$
pour moyenne $0$, pour variance $a^2/6$ et pour transformée de Fourier~:
$$
\frac{2\PAR{1-\cos(as)}}{a^2s^2}.
$$

%
\subsection{Loi gaussienne}\label{ss:loi:gaussienne}
%

On parle aussi de loi normale, de Gauss, ou encore de Maxwell ! En Amérique du
nord, on parle souvent de «bell curve», i.e. de courbe en cloche. Ces
multiples appélations témoignent de l'importance de cette loi. On pourrait
définir les lois gaussiennes sur des espaces très généraux, mais cela nous
mènerait bien trop loin\footnote{Sur un espace préhilbertien $\dH$, les choses
  sont simples : une v.a. à valeurs dans $\dH$ est gaussienne si et seulement
  si pour tout $v$ dans $\dH$, la v.a.r. $\DP{X,v}_\dH$ est gaussienne réelle.
  On retrouve facilement les vecteurs gaussiens usuels en prenant
  $\dH=\dR^n$.}.  La loi gaussienne $\cN(m,\Ga)$, sur $\dR^n$, de moyenne
$m\in\dR^n$ et de matrice de covariance $\Si\in\dS_n^+(\dR)\subset \cM_n(\dR)$, a pour
densité par rapport à la mesure de Lebesgue $dx_1\cdots dx_n$ sur $\dR^n$~:
$$
\PAR{2\pi}^{-n/2}\ABS{\Si}^{-1/2}\,\exp\PAR{-\frac{1}{2}\DP{x-m,\Si (x-m)}}.
$$
Elle a pour transformée de Fourier~:
$$
\exp\PAR{i\DP{s,m}-\frac{1}{2}\DP{\Si\,s,s}}.
$$
Elle a pour propriété de maximiser l'entropie de Shannon définie sur les
lois des vecteurs aléatoires à densité $f$ de covariance fixée $\Si$ par~:
$$
\bH(f):=-\int_{\dR^n}\!f(x)\log f(x)\,dx.
$$

%
\subsection{Loi exponentielle et loi gamma}\label{ss:loi:gamma}
%

La loi gamma $\Ga(a,\la)$ de paramètres $(a,\la)\in\dR_+^*\times\dR_+^*$ a pour
densité sur $\dR$ par rapport à la mesure de Lebesgue $dx$ sur $\dR$~:
$$
\frac{\la^a}{\Ga(a)}\,x^{a-1}\,e^{-\la x}\,\rI_{\dR^+}(x),
$$
où $\Ga(a)$ est la fonction Gamma d'Euler définie par~:
$$
\Ga(a):=\int_0^{+\infty}\!x^{a-1}\,e^{-x}\,dx, \text{\quad en particulier }\Ga(n)=(n-1)!. 
$$
Parfois, on choisit un paramétrage différent de la loi gamma, en posant
$b=1/\la$, et l'on note alors $G(a,b)=\Ga(a,1/b)$. Pour $a=1$, on obtient la
loi exponentielle :
$$
\Ga(1,\la)=G(1,1/\la)=\cE(\la).
$$
La loi exponentielle est l'analogue continu de la loi géométrique, elle
apparaît comme loi du temps inter-sauts du processus de Poisson. La loi
exponentielle est également sans mémoire : si $\cL(X)=\cE(\la)$, alors $\eP(X
\geq t+s\;\vert\;X\geq t)=\exp(-\la s)$ ne dépend que de $s$ et pas de $t$. Cette
propriété la caractérise dans l'ensemble des lois continues, et traduit bien
le comportement de durées de vie en fiabilité, du temps d'arrivée du prochain
client dans une file d'attente, etc. Elle explique également la stationnarité
des accroissements du processus de Poisson (renouvellement).

La loi gamma $\Ga(a,\la)$ a pour moyenne $a/\la$, pour variance $a/\la^2$ et
pour transformée de Fourier $(1-is\la^{-1})^{-a}$. La loi $\Ga(n,\la)$ avec
$n\in\eN^*$ est parfois appelée loi de Erlang. Ces lois sont très importantes
puisqu'elles apparaissent lorsque l'on fait la somme de v.a.r. i.i.d. de loi
exponentielle. La famille des lois gamma est stable par convolution et
constitue donc en quelque sorte l'analogue continu de la famille des lois
négatives-binomiales.  La loi du temps de depassement d'un seuil pour un
processus de Poisson est une loi gamma, car convolution de lois exponentielles.

%
\subsection{Loi double exponentielle}\label{ss:loi:laplace}
%

Également appelée loi de Laplace. Elle a pour densité sur $\dR$ par rapport à
la mesure de Lebesgue $dx$ sur $\dR$~: $\la\exp(-\la\ABS{x})/2$, où $\la$ est
un paramètre dans $\dR_+$. Sa moyenne vaut $0$, sa variance $2/\la^2$ et sa
transformée de Fourier est $1/(1+s^2/\la^2)$.

%
\subsection{Loi de Dirichlet}\label{ss:loi:dirichlet}
%

La loi de Dirichlet de taille $n\in\eN^*$ et de paramètre $\al\in(\dR_+^*)^n$ est
la loi du vecteur aléatoire $(X_1,\ldots,X_n)/(X_1+\cdots+X_n)$ lorsque les variables
aléatoires $X_1,\ldots,X_n$ sont i.i.d. et suivent des lois exponentielles de
paramètres respectifs $\al_1,\ldots,\al_n$, cf. \cite[exercice 8.2.15, page
192]{dacunha-castelle-duflo}. Elle est portée par le simplexe
$\dS(n,1):=\BRA{y\in\dR^n,\,y_i\geq 0,\,y_1+\cdots+y_n=1}$. La densité de
$(Y_1,\cdots,Y_{n-1})$ est donnée par :
$$
\frac{\Ga(\al_1+\cdots+\al_n)}{\Ga(\al_1)\cdots\Ga(\al_n)}
\,\PAR{\prod_{i=1}^{n-1}y_i^{\al_i-1}}\PAR{1-\sum_{i=1}^{n-1}y_i}^{\al_k-1}.
$$
La loi de Dirichlet de taille $n$ et de paramètre $\alpha=(1,\ldots,1)$ n'est rien
d'autre que la loi uniforme sur le simplexe $\dS(n,1)$, cf. section
\ref{se:unif-pspheres} page \pageref{se:unif-pspheres}. Elle permet par
exemple de choisir «uniformément» une loi de probabilité discrète.
%FIXME: moyenne, variance etc.

%
\subsection{Lois du chi-deux}\label{ss:loi:chideux}
%

La loi du $\chi^2(n)$ à $n$ degrès de liberté n'est rien d'autre que la loi de la
somme des carrés de $n$ v.a.r. i.i.d. de loi normale centrées réduites sur
$\dR$. C'est aussi la loi gamma $G(n/2,2)$ de paramètres $(a,b):=(n/2,2)$,
i.e. la loi gamma $\Ga(n/2,1/2)$ de paramètres $(a,\la):=(n/2,1/2)$. La loi du
$\chi^2(n)$ intervient dans le test du même nom (cf. \ref{ss:test-chideux} page
\pageref{ss:test-chideux}).

%
\subsection{Loi exponentielle et loi de Weibull}\label{ss:loi:weibull}
%

La loi de Weibull $W(\alpha,\lambda)$ de paramètres $(\alpha,\lambda)\in\dR_+^*\times\dR_+^*$ est la loi sur
$\dR$ dont la densité par rapport à la mesure de Lebesgue $dx$ sur $\dR$ est~:
$$
\alpha\lambda\,x^{\alpha-1}\,\exp\PAR{-\lambda x^\alpha}\,\rI_{\dR_+}(x).
$$
Elle est plus communément donnée par sa fonction de répartition~:
$$
F_{\alpha,\lambda}(u)=\PAR{1-\exp\PAR{-\lambda x^\al}}\,\rI_{\dR_+}.
$$
Sa moyenne vaut $\lambda^{-1/\alpha}\Ga(1+\alpha^{-1})$ et sa variance
$\lambda^{-2/\alpha}\PAR{\Ga(1+2\alpha^{-1})-\PAR{\Ga(1+\alpha^{-1})}^2}$. Cette loi
intervient en fiabilité des systèmes. Notons que l'on retrouve la loi
exponentielle de paramètre $\lambda$ lorsque $\alpha=1$~:
$$
W(1,\lambda)=\cE(\lambda).
$$
%FIXME: dire que l'expo est sans mémoire ou au moins renvoyer à une page
%FIXLE: sur la fiabilité\ldots
Pour $\alpha=2$, on parle parfois de loi de Rayleigh.

%
\subsection{Loi de Cauchy}\label{ss:loi:cauchy}
%

C'est la loi sur $\dR$ de densité par rapport à la mesure de Lebesgue $dx$ sur
$\dR$~:
$$
\frac{c}{\pi}\,\frac{1}{c^2+x^2},
$$
où $c$ est un paramètre positif. Elle n'a pas de moyenne et donc pas de
variance. Sa transformée de Fourier est $\exp\PAR{-c\ABS{s}^2}$.

%
\subsection{Loi Beta}\label{ss:loi:beta}
%

La loi bêta de paramètres $(a,b)\in\dR_+^*\times\dR_+^*$ est la loi sur $\dR$ de
densité par rapport à la mesure de Lebesgue $dx$ sur $\dR$~:
$$
\frac{1}{B(a,b)}\,x^{a-1}(1-x)^{b-1}\,\rI_{\BRA{0<x<1}}(x),
$$
où $B(a,b)$ est la fonction bêta d'Euler définie par~:
$$
B(a,b):=\int_0^1\!x^{a-1}(1-x)^{b-1}\,dx=\frac{\Ga(a)\Ga(b)}{\Ga(a+b)}.
$$
La loi bêta de paramètres $(a,b)$ a pour moyenne $a/(a+b)$ et pour variance
$ab(a+b)^{-2}(a+b+1)^{-1}$.

%
\subsection{Loi de Pareto}\label{ss:loi:pareto}
%

Si $\cL(X)=\cE(\la)$ et si $r\in\dR$, la v.a. $r\exp\PAR{X}$ suit par définition
une loi de Pareto de paramètres $\la$ et $r$. Sa densité par rapport à la
mesure de Lebesgue sur $\dR$ vaut~:
$$
\frac{\la\,r^\la}{x^{1+\la}}\,\rI_{\BRA{x>r}}(x).
$$
Elle a pour moyenne $\al r /(\al-1)$ si $\al>1$ et n'a pas moyenne sinon.
Si $\al>2$, elle a pour variance $\al r^2(\al-1)^{-2}(\al-2)^{-1}$, et elle
n'a pas de moment d'ordre deux sinon.

%
\subsection{Loi log-normale}\label{ss:loi:log-normale}
%

C'est la loi de l'exponentielle d'une variable aléaroite de loi gaussienne
$\cN(m,\si^2)$. Elle a pour densité par rapport à la mesure de Lebesgue $dx$
sur $\dR$~:
$$
(2\pi\si^2)^{-1/2}\,x^{-1}\,\exp\PAR{-\frac{\PAR{\log(x)-m}^2}{2\si^2}}\,\rI_{\BRA{x>0}}(x),
$$
pour moyenne $\exp\PAR{m+\si^2/2}$ et pour variance
$\exp\PAR{2m+\si^2}\PAR{e^{\si^2}-1}$.

%
\subsection{Loi de Ficher-Snedecor}\label{ss:loi:fisher-snedecor}
%

La loi de Fisher-Snedecor $\cF(n,m)$ à $n$ et $m$ degrés de liberté est la loi
de
$$
\frac{X/n}{Y/m},
$$
où $X$ et $Y$ sont indépendantes et ont pour lois respectives $\chi^2(n)$
et $\chi^2(m)$. Elle a pour densité par rapport à la mesure de Lebesgue $dx$
sur $\dR$~:
$$
\frac{\Ga((n+m)/2) n^{n/2}
  m^{n/2}}{\Ga(n/2)\Ga(m/2)}\,\frac{x^{n/2-1}}{(m+nx)^{(n+m)/2}}.
$$
Pour $m>4$, sa moyenne vaut $m/(m-2)$ et sa variance
$2m^2(m+n-2)n^{-1}(m-4)^{-1}(m-2)^{-2}$.

%
\subsection{Loi de Student}\label{ss:loi:student}
%

La loi de Student $\cT_n$ à $n$ degrés de liberté est la loi de
$$
\frac{\sqrt{n}\,X}{\sqrt{Y}},
$$
où $X$ et et $Y$ sont indépendantes et ont pour lois respectives $\cN(0,1)$
et $\chi^2(n)$. Elle a pour densité par rapport à la mesure de Lebesgue $dx$ sur
$\dR$~:
$$
\frac{\Ga((n+1)/2)}{\Ga(n/2)\sqrt{n\pi}}\,\PAR{1+\frac{x^2}{n}}^{-(n+1)/2}.
$$
Elle est centrée et sa variance vaut $n/(n-2)$ pour $n>2$.

%
\subsection{Loi de Kolmogorov-Smirnov}\label{ss:loi:kolmogorov-smirnov}
%

C'est la loi sur $\dR$ de fonction de répartition~:
$$
\bF(u):=
\begin{cases}
  0 & \text{si } u\leq0,\\
  \ds{1+2 \sum_{k=1}^{+\infty} (-1)^k e^{-2k^2u^2}} & \text{si } u>0.
\end{cases}
$$
Elle intervient dans le test d'adéquation de Kolmogorov-Smirnov (cf.
\ref{ss:test-ks} page \pageref{ss:test-ks}). C'est aussi la loi sur supremum
de la valeur absolue d'un pont brownien sur $[0,1]$ (cf. section
\ref{se:vitesse-tgc} page \pageref{se:vitesse-tgc}).

%
\subsection{Statistique d'ordre, quantiles, médiane}\label{ss:loi:statordre}
%

%FIXME: à compléter.

Soit $\mu$ une loi de probabilité sur $\dR$, de fonction de répartition $F$. On
note $F(x^-)$ sa limite à gauche en $x$. On dit qu'un réel $m$ est une
\emph{médiane} pour $\mu$ lorsque $F(m^-)\leq 1/2 \leq F(m)$. Plus généralement, pour
tout $\al\in\,]0,1[$, on dit qu'un réel $q_\al$ est un \emph{quantile} d'ordre
$\al$ pour $\mu$ lorsque $F(q^-_\al)\leq \al \leq F(q_\al)$. Pour tout ordre $\al$, un
quantile d'ordre $\al$ existe toujours, car la fonction de répartition $F$ est
croissante, et a pour limite $0$ en $-\infty$ et $1$ en $+\infty$. La croissance de $F$
entraîne également que l'ensemble des quantiles d'ordre $\al$ est un
intervalle. Si $q$ est un quantile, l'intervalle des quantiles du même ordre
est réduit à $\BRA{q}$ si et seulement si $\mu\PAR{\BRA{q_\al}}=0$, et alors $F$
est continue en $\al$ (on rappelle qu'une fonction de répartition est toujours
continue à droite). Souvent, on appelle encore quantile d'ordre $\al$ le
milieu de l'intervalle des quantiles d'ordre $\al$, ce qui permet de parler
\emph{du} quantile d'ordre $\al$, même quand il y en a plusieurs. Enfin,
lorsque la loi $\mu$ possède une densité, sa fonction de répartition est
continue et les intervalles quantiles sont tous des singletons.

On parle de \emph{déciles} pour les quantiles d'ordre $1/10$, de
\emph{quartiles} pour ceux d'ordre $1/4$, etc. On parle aussi parfois de
\emph{percentiles} pour les quantiles. Une médiane est un quantile d'ordre
$1/2$. La fonction \ML{} \texttt{median} permet d'obtenir la médiane empirique
d'un échantillon (i.e. la médiane de la fonction de répartition empirique),
alors que la fonction \SB{} \texttt{quantile} permet d'obtenir un quantile
empirique d'ordre quelconque d'un échantillon.

Si $(x_1,\ldots,x_n)$ est un vecteur de $\dR^n$, on note $(x_{(1)},\ldots,x_{(n)})$ le
vecteur de $\dR^n$ obtenu en réordonnant de façon croissante les composantes
de $x$. Si $X:=(X_1,\ldots,X_n)$ est un vecteur aléatoire de $\dR^n$, on appelle
statistique d'ordre de $X$ le vecteur aléatoire
$\tilde{X}:=(X_{(1)},\ldots,X_{(n)})$ obtenu en réordonnant les coordonnées de $X$
à $\om$ fixé. La fonction \ML{} \texttt{sort} permet de trier de façon
croissante un vecteur.

Si $X:=(X_1,\ldots,X_n)$ est un échantillon d'une loi $\mu$ sur $\dR$, alors la
médiane empirique n'est rien d'autre que $X_{((n+1)/2)}$ si $n$ est impair et
$(X_{((n/2)}+X_{((1+n/2)})/2$ si $n$ est pair. De manière générale, si $\al$
n'est pas un multiple de $1/n$, le quantile d'ordre $\al$ empirique vaut
$(X_{([n\al])}+X_{([n\al]+1)})/2$. Enfin, on peut montrer que si $\mu$ a une
densité $f$ par rapport à la mesure de Lebesgue, alors la loi de $X_{(i)}$ a
pour densité :
$$
f_i(x)=\frac{n!}{(i-1)!(n-i)!}F^{i-1}(x)(1-F(x))^{n-i}f(x),
$$
où $F$ est la fonction de répartition de $\mu$. On retrouve bien $f$ pour
$n=1$. Si $x:=(x_1,\ldots,x_n)\in\dR^n$, on appelle \emph{rang} de $x_i$ dans la
suite $x$ la quantité
$$
r_i(x):=\sum_{j=1}^n \rI_{x_j\leq x_i},
$$
qui représente le nombre de composantes de $x$ qui sont inférieures ou
égales à $x_i$. Il peut arriver que $r_i=r_j$, mais on a toujours
$x_{r_i(x)}=x_{(i)}$. Lorsque les composantes de $x$ sont toutes différentes,
l'application $r:i\in\BRA{1,\ldots,n}\mapsto r_i(x)\BRA{1,\ldots,n}$ est une permutation.  Le
vecteur $r(x):=(r_1(x),\ldots,r_n(x))$ est appelé \emph{vecteur rang} de $x$. On
définit naturellement le vecteur aléatoire rang $R(X)$ d'un vecteur aléatoire
$X:=(X_1,\ldots,X_n)$ par $R(X)(\om):=r(X(\om))$. On montre, cf. \cite[thm 4.4.29
page 107]{dacunha-castelle-duflo} que pour un échantillon $X:=(X_1,\ldots,X_n)$ d'une loi
$\mu$ sur $\dR$, continue :
\begin{itemize}
\item le vecteur rang $R(X)$ est presque-sûrement une permutation
\item le vecteur rang $R(X)$ suit la loi uniforme sur l'ensemble des
  permutations de $\{1,\ldots,n\}$
\item la statistique d'ordre $\tilde{X}$ de $X$ et son rang $R(X)$ sont
  indépendants 
\item la statistique d'ordre $\tilde{X}$ a pour loi la loi trace de $n!
  \mu\otimes\cdots\otimes\mu$ sur $\BRA{x\in\dR^n,\,x_1\leq\cdots\leq x_n}$.
\end{itemize}

%
\section{Convolutions \& convergences}
%

On a les propriétés suivantes~:
\begin{enumerate}
\item $\textrm{Bern}(p,\BRA{0,1})^{*n}=\cB(n,p)$.
\item $\cG(p)^{*m} =  \cG_m(p)$.
\item $\cG_{m_1}(p)*\cdots*\cG_{m_n}(p) =  \cG_{m_1+\cdots+m_n}(p)$. 
\item $\cE(\la)^{*n}=\Ga(n,\la)$.
\item $\cN(m_1,\Si_1)*\cdots*\cN(m_n,\Si_n)=\cN(m_1+\cdots+m_n,\Si_1+\cdots+\Si_n)$.
\item $\cP(\la_1)*\cdots*\cP(\la_n)=\cP(\la_1+\cdots+\la_n)$.
\item Si $\cL(X)=\cN(0,\bI_n)$ alors $\cL(X_1^2+\cdots+X_n^2)=G(n/2,2)=\chi^2(n)$.
\item Si $\cL((X,Y))=\Ga(a,1)\otimes\Ga(b,1)$ alors
  $\cL(X/(X+Y))=\textrm{Beta}(a,b)$.
\item Si $\cL(X)=\Ga(1,\la)=\cE(\la)$ alors $\cL(X^{-\alpha})=W(\alpha,\lambda)$.
\item Si $\cL((X,Y))=\chi^2(n)\otimes\chi^2(m)$, alors $\cL((mX)/(nY))=\cF(n,m)$.
\item Si $\cL((X,Y))=\cN(0,1)\otimes\chi^2(n)$, alors $\cL(\sqrt{n}X/\sqrt{Y})=\cT(n)$.
\item Si $\cL((X_n,n\in\eN^*))=\cE(\la)^{\eN^*}$ et
$$
N_t:=\sum_{n=1}^{+\infty}\,\rI_{X_1+\cdots+X_n \leq t}=\inf\BRA{n\in\eN,\,X_1+\cdots+X_n>t},
$$
alors pour tout $t\in\dR_+$, $\cL(N_t)=\cP(\la t)$ (processus de Poisson
simple d'intensité $\la$).
\item $\cB(n,\la/n) \limE{n} \cP(\la)$
\end{enumerate}

\begin{enumerate}
\item $X_n\limP{n}X$
  \begin{enumerate}
  \item ssi $\PAR{\forall\veps>0}\;\;\eP\PAR{\BRA{\ABS{X_n-X}\geq\veps}}\limn{n}0$
  \item ssi $\moyp{}{\ABS{X_n-X}\land 1}\limn{n}0$
  \item ssi $\moyp{}{\ABS{X_n-X}/(1+\ABS{X_n-X})}\limn{n}0$
  \item ssi de toute sous suite $\PAR{X_{n_k},k\in\eN^*}$, on peut
    extraire une sous-suite qui converge p.s. vers $X$
  \end{enumerate}
\item $X_n\limL{n}\mu$ \quad ssi \quad $\cL(X_n)\limE{n}\mu$.
\item $\mu_n\limE{n}\mu$ \quad (avec $\mu_n$ et $\mu$ probas)
  \begin{enumerate}
  \item ssi $\PAR{\forall f\in\cC_b}\;\; \moyp{\mu_n}{f}\limn{n}\moyp{\mu}{f}$
  \item ssi $\PAR{\forall s\in\dR}\;\; 
    \moyp{\mu_n}{e^{is\bullet}}\limn{n}\moyp{\mu}{e^{is\bullet}}$
  \item ssi $\PAR{\forall t\in\mathrm{Cont(F_\mu)}}\;\; F_{\mu_n}(t)\limn{n}F_\mu(t)$
  \end{enumerate}
\item La famille de v.a. $\PAR{X_i,i\in I}\subset\bL^1$ est uniformément intégrable (UI)
  \begin{enumerate}
  \item ssi $\sup_{i{\in}I}\moyp{}{\ABS{X_i}\rI_{\BRA{\ABS{X_i}>c}}}\limn{c}0$
  \item ssi\footnote{Critère «epsilon-delta» ou encore d'équi-intégrabilité.}
    $\sup_{i\in{I}}\moyp{}{\ABS{X_i}}<+\infty$ et $\PAR{\forall\veps>0}\PAR{\exists\delta>0}\PAR{\forall
      A}
    \PAR{\eP(A)\leq \delta \Rightarrow \sup_{i\in I}\moyp{}{\ABS{X_i}\rI_A}\leq\veps}$
  \item ssi\footnote{Critère de Lavallée-Poussin. cf. \cite[p. 10]{borkar}} $\exists
    \Psi:\dR_+\to\dR_+$ telle que $\sup_{i\in{I}}\moyp{}{\Psi\PAR{\ABS{X_i}}}<+\infty$ et
    $\Psi(x)/x\limn{x}+\infty$.
  \end{enumerate}
\item Une famille bornée dans $\bL^1$ est UI.
\item Soit $\PAR{X_n,n\in\eN^*}\subset\bL^1$, il y a équivalence entre~:
  \begin{enumerate}
  \item $X_n\limLeb{n}{1}X$ avec $X\in\bL^1$
  \item $\PAR{X_n,n\in\eN^*}$ est UI et $X_n\limP{n}X$
  \end{enumerate}
\item Si $X_n\limLeb{n}{p}X$ avec $p\geq 1$, alors de toute sous-suite
  $\PAR{X_{n_k},k\in\eN^*}$, on peut extraire une sous-suite qui converge p.s.
  vers $X$
\item Si $X_n\limL{n}\mu$ alors\footnote{Théorème de continuité de Paul Lévy,
    cf. \cite[p. 32]{borkar}.}  $s\mapsto\moyp{}{e^{isX_n}}$ converge vers
  $s\mapsto\moyp{\mu}{e^{is\bullet}}$ uniformément sur tout compact
\item Soit $\PAR{\mu_n,n\in\eN^*}$ des probas. Si
  $s\mapsto\moyp{\mu_n}{e^{is\bullet}}$ converge simplement vers $s\mapsto G(s)$
  continue en $0$ alors\footnote{Théorème de continuité de Paul Lévy, cf.
    \cite[p.  32]{borkar}.} $G$ est la transformée de Fourier d'une loi $\mu$ et
  $\mu_n\limE{n}\mu$.
\item Soit $\PAR{X_n,n\in\eN^*}$ v.a.r. indép. et $S_n:=X_1+\cdots+X_n$. Il y a
  équivalence entre\footnote{Théorème de Paul Lévy, cf. \cite[p.
    83]{borkar}}~:
  \begin{enumerate}
  \item $\PAR{S_n,n\in\eN^*}$ converge p.s.
  \item $\PAR{S_n,n\in\eN^*}$ converge en $\eP$
  \item $\PAR{S_n,n\in\eN^*}$ converge en $\cL$
  \end{enumerate}
  De plus\footnote{Théorème des trois séries de Kolmogorov, cf. \cite[p.
    85]{borkar}}, si $c>0$ et $Y_n:=X_n\rI_{\BRA{\ABS{X_n}\leq c}}$ alors
  $\PAR{S_n,n\in\eN^*}$ converge p.s. ssi on a à la fois~:
 \begin{enumerate}
 \item $\sum_{n=1}^{+\infty} \eP\PAR{\BRA{X_n\neq Y_n}}<+\infty$
 \item $\sum_{n=1}^{+\infty} \moyp{}{Y_n}<+\infty$
 \item $\sum_{n=1}^{+\infty} \varp{}{Y_n}<+\infty$ 
 \end{enumerate}
\item Si $X_n\limPS{n}X$ et $Y_n\limPS{n}Y$ et $(a,b)\in\dR^2$ alors 
  $aX_n+bY_n\limPS{n}aX+bY$ et $X_nY_n\limPS{n}XY$
\item L'espace $\bL^0$ des fonctions mesurables muni de la topologie de la CV
  en $\eP$ associée à la distance $d(X,Y):=\moyp{}{\ABS{X-Y}/(1+\ABS{X-Y})}$
  est un espace de Banach\footnote{Donc un espace vectoriel normé, d'où
    l'additivité des suites convergentes en $\eP$.}.
\item Si $X_n\limP{n}X$ et $Y_n\limP{n}Y$ alors $X_nY_n\limP{n}XY$
\item Si $X_n\limLeb{n}{1}X$ et $Y_n\limP{n}Y$ et $\PAR{Y_n,n\in\eN^*}$ unif.
  bornée alors $X_nY_n\limLeb{n}{1}XY$
\item Si $\PAR{X_n,Y_n}\limL{n}(X,Y)$ alors $X_n+Y_n\limL{n}X+Y$ et
  $X_n\limL{n}X$ et $Y_n\limL{n}Y$
\item Si $X_n\limL{n}X$ et $Y_n\limL{n}Y$ et $\PAR{X_n,Y_n,n\in\eN^*}$ indép.
  alors $X$ et $Y$ indép. et $X_n+Y_n\limL{n}X+Y$
\end{enumerate}

\begin{table}[htbp]
  \begin{center}
    \begin{sideways}
    \begin{tabular}[c]{|l||l|l|l|}\hline
      Loi & Moyenne & Variance & Transformée de Fourier en $s\in\dC$\\\hline\hline
      $\delta_a$ 
      & $a$
      & $0$
      & $e^{ias}$ \\\hline
      Bern. $q\delta_0+p\delta_1$ 
      & $p$
      & $pq$
      & $1+pe^{is}$ \\\hline
      Bern. $q\delta_{-1}+p\delta_1$ 
      & $q-p$
      & $pq$
      & $qe^{-is}+pe^{is}$ \\\hline
      Unif. sur $\BRA{a_1,\ldots,a_n}$
      & $(a_1+\cdots+a_n)/n$
      & $(\sum_ka_k^2)/n-(\sum_k a_k)^2/n^2$
      & $\sum_k e^{ia_ks}/n$\\\hline
      $\cB(n,p)$
      & $np$
      & $npq$
      & $(1+pe^{is})^n$\\\hline
      Géom$(p)$ (sur $\eN$)
      & $q/p$
      & $q/p^2$
      & \\\hline
      $\cG(p)$ (sur $\eN^*$)
      & $1/p$
      & $q/p^2$
      & $pe^{is}\PAR{1-qe^{is}}^{-1}$ \\\hline
      $\cG_m(p)$
      & $m/p$
      & $q/p^2$
      & $p^me^{mis}\PAR{1-qe^{is}}^{-m}$ \\\hline
      $\cP(\la)$
      & $\la$
      & $\la$
      & $\exp\PAR{\la(e^{is}-1)}$\\\hline
      Unif. $\cU(a,b)$
      & $(a+b)/2$
      & $(b-a)^2/12$
      & $2s^{-1}(b-a)^{-1}\exp\PAR{is(a+b)/2}\sin(s(b-a)/2)$ \\\hline
      $\cE(\la)$
      & $1/\la$
      & $1/\la^2$
      & $\PAR{1-is\la^{-1}}^{-1}$ \\\hline
      $\Ga(a,\la)$
      & $a/\la$
      & $a/\la^2$
      & $\PAR{1-is\la^{-1}}^{-a}$\\\hline
      $G(a,b)$
      & $ab$
      & $ab^2$
      & $\PAR{1-ibs}^{-a}$ \\\hline
      $\cN(m,\Si)$
      & $m$
      & $\Si$
      & $\exp\PAR{i<m,s>-<\Si\,s,s>/2}$\\\hline
      $\chi^2(n)$
      & $n$
      & $2n$
      & $\PAR{1-2is}^{-n/2}$ \\\hline
      $W(\al,\la)$
      & $\la^{-1/\al}\Ga(1+\al{-1})$
      & $\la^{-2/\al}\PAR{\Ga(1+2\al^{-1})-\PAR{\Ga(1+\al^{-1})}^2}$
      & \\\hline
      $\cF(n,m)$
      & $m/(m-2)$ si $m>4$
      & $2m^2(m+n-2)n^{-1}(m-4)^{-1}(m-2)^{-2}$
      & \\\hline
      $\cT(n)$      
      & $0$
      & $n/(n-2)$ si $n>2$
      & \\\hline
    \end{tabular}
    \end{sideways}
    \caption{Tableau récapitulatif de quelques lois usuelles}
    \label{tab:lois}
  \end{center}
\end{table}

\begin{table}[htbp]
  \begin{center}
    \begin{tabular}[c]{|l|l|}\hline
      Loi $\mu$ & Fonction de répartition $F_\mu(t):=\mu\PAR{[t,+\infty[}$\\\hline
      Discrète $\sum_{n\geq 0} p_n\delta_{a_n}$ ($a_n<a_{n+1}$)
      & $\sum_{n\geq 0} p_n\rI_{[a_{n},a_{n+1}[}(t)$\\
      Unif. $\cU(a,b)$
      & $(b-a)^{-1}(t-a)\rI_{[a,b]}(t)+\rI_{]b,+\infty[}(t)$\\
      $\cE(\la)$
      & $\PAR{1-\exp\PAR{-\la t}}\rI_{\dR_+}(t)$ \\
      $W(\al,\la)$
      & $\PAR{1-\exp\PAR{-\la t^\al}}\rI_{\dR_+}(t)$ \\
      $\cN(0,1)$
      & $\Phi(t)\sim_{+\infty}1-t^{-1}\exp\PAR{-t^2/2}$\\
      Kolmogorov-Smirnov
      & $\PAR{1+2 \sum_{k=1}^{+\infty} (-1)^k e^{-2k^2u^2}}\rI_{\dR_+^*}(t)$\\ \hline
    \end{tabular}
    \caption{Quelques fonctions de répartition}
    \label{tab:fonctions-de-repartition}
  \end{center}
\end{table}

\begin{figure}[htbp] 
 $$
 \begin{array}[c]{ccccc}
 &&\text{CV }\bL^{p>1}&&\\
 &&\Downarrow&&\\
 &&\text{CV }\bL^1&&\\
 &&\Downarrow&&\\
 \text{CV p.s.}
 &\Rightarrow
 &\text{CV en } \dP
 &\Rightarrow
 &\text{CV en } \cL
 \end{array}
 $$
 $$
 \text{CV } \bL^1 \underset{\text{sous suites}}{\Longrightarrow}\text{CV p.s.}
 $$
 $$
 \text{CV } \eP \underset{\text{sous suites}}{\Longrightarrow}\text{CV p.s.}
 $$
 $$
 \text{CV } \eP \underset{\text{si UI}}{\Longrightarrow}\text{CV } \bL^1
 $$
 \caption{Relations entre les différents types de convergences de v.a.}
 \label{tab:convergences}
\end{figure}

%% Local Variables: 
%% x-symbol-8bits: t
%% x-symbol-coding: iso-8859-1
%% mode: latex
%% TeX-master: "agregation"
%% End: 
