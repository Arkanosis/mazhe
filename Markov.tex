Les chaînes de Markov interviennent pour la description des systèmes dont l'évolution future ne dépend que de l'état présent.

\begin{definition}
    Soit \( E\) un ensemble au plus dénombrable et \( (\Omega,\tribF,P)\) un espace probabilisé. Une \defe{chaîne de Markov}{chaîne de Markov} à valeurs dans \( E\) est une famille \( (X_n)_{n\in\eN}\) de variables aléatoires telles que pour tout \( x_0,\ldots,x_{n+1}\in E\),
    \begin{equation}
        P(X_{n+1}=x_{n=1}|X_n=x_n,\ldots,X_0=x_0)=P(X_{n+1}=x_{n+1}|X_n=x_n).
    \end{equation}
\end{definition}
Pour une chaîne de Markov, il n'est pas important de savoir l'historique pour prédire la futur : \( X_{n+1}\) est seulement déterminé par \( X_n\).

\begin{remark}
    Il existe une théorie des chaînes de Markov à temps continu ou avec \( E\) non dénombrable, mais ce n'est pas au programme.
\end{remark}

Nous notons
\begin{equation}
    p_n(x,y)=P(X_{n+1}=y|X_n=x)
\end{equation}
la \defe{probabilité de transition}{transition!probabilité} de la chaîne à l'instant \( n\). Si cette probabilité ne dépend pas de \( n\), nous disons que la chaîne de Markov est \defe{homogène}{homogène!chaîne de Markov}, et nous notons \( p(x,y)\) au lieu de \( p_n(x,y)\). Nous notons \( Q\) la matrice (éventuellement infinie) de transition\index{matrice!de transition}
\begin{equation}
    Q_{xy}=p(x,y).
\end{equation}
Nous avons
\begin{equation}
    \sum_{y\in E}p(x,y)=1
\end{equation}
parce que c'est la somme de toutes les transitions possibles en partant de \( x\). Notons aussi que \( p(x,y)\geq 0\).

\begin{definition}
    Une matrice dont tous les éléments sont positifs ou nuls et donc la somme de toutes les lignes sont \( 1\) est une \defe{matrice stochastique}{matrice!stochastique}.
\end{definition}

\begin{lemma}
    Si \( U\) est une matrice stochastique, alors il existe une chaîne de Markov dont la matrice de transition soit \( U\).
\end{lemma}

\begin{remark}
    La somme \( \sum_{x\in E}p(x,y)\) ne vaut pas spécialement \( 1\). Si les états \( x_1\) et \( x_2\) arrivent tous les deux en \( y\) de façon certaine, alors nous avons \( \sum_xp(x,y)\geq 2\). Il n'y a donc pas de limites aux sommes des colonnes.
\end{remark}

\begin{example}
    Nous considérons une fourmi qui se déplace dans un appartement à trois pièces \( A\), \( B\), \( C\). Supposons qu'à chaque minute, elle a une probabilité \( 1/3\) de rester dans la pièce et une probabilité \( 2/3\) de se déplacer. Le plan de l'appartement est
    \begin{equation}
        \xymatrix{%
        A \ar[r]      &  B\ar[r]&C
           }
    \end{equation}
    De la pièce \( A\) est est donc uniquement possible d'aller vers la pièce \( B\); de la \( B\) il est possible d'aller en \( A\) et en \( C\) et de la \( C\) il est uniquement possible d'aller en \( B\).

    La matrice de transition de cette chaîne de Markov est 
    \begin{equation}
        Q=\begin{pmatrix}
            1/3    &   2/3    &   0    \\
            1/3    &   1/3    &   1/3    \\
            0    &   2/3    &   1/3
        \end{pmatrix}
    \end{equation}
\end{example}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Marche aléatoire sur \texorpdfstring{$\eZ$}{\( \eZ\)}}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Soit \( (Y_n)\) une suite de variables aléatoires indépendantes et identiquement distribuées valant \( -1\) avec une probabilité \( p\) et \( 1\) avec une probabilité \( (1-p)\). La loi est
\begin{equation}
    Y_n\sim p\delta_{-1}+(1-p)\delta_{1}.
\end{equation}
Nous considérons la variable aléatoire
\begin{equation}
    X_n=X_0+\sum_{i=1}^nY_i
\end{equation}
où \( X_0\) est une variable aléatoire indépendante des \( Y_i\) à valeurs dans \( \eZ\). Nous vérifions à présent que \( X_n\) est une chaîne de Markov avec comme espace d'états \( E=\eZ\). Nous devons montrer que
\begin{equation}        \label{EqAVoirMarkovMAZ}
    P\big( X_{n+1}=x_{n+1}| X_n=x_n,\ldots,X_0=x_0 \big)=P\big( X_{n+1}=x_{n+1}|X_n=x_n \big).
\end{equation}
Étant donné que \( X_{n+1}=X_n+Y_{n+1}\), nous pouvons remplacer \( X_{n+1}=x_{n+1}\) par \( x_n+Y_{n+1}=x_{n+1}\) dans le membre de gauche de \ref{EqAVoirMarkovMAZ}.

L'événement 
\begin{equation}
    \{ X_n=x_n,\ldots,X_1=x_1,X_0=x_0 \}\subset\Omega
\end{equation}
est égal à l'événement
\begin{equation}
    \{ X_0=x_0,Y_1=x_1-x_0,Y_2=x_2-x_1,\ldots,Y_n=x_n-x_{n-1} \}.
\end{equation}
Cet événement est l'ensemble
\begin{equation}
    X_0^{-1}(x_0)\cap Y_1^{-1}(x_1-x_0)\cap\ldots\cap Y_{n}^{-1}(x_n-x_{n-1})
\end{equation}
qui est dans la tribu engendrée par les variables aléatoires \( X_0,(Y_i)_{i=1,\ldots,n}\). Le point délicat du raisonnement est de montrer que les événements \( A\) et \( B\) donnés par
\begin{subequations}
    \begin{align}
        A&=\{ Y_{n+1}=x_{n+1}-x_n \}\\
        B&=\{ X_0=x_0 \}\cap\bigcap_{i=1}^n Y_i=x_i-x_{i-1}
    \end{align}
\end{subequations}
sont indépendants. Nous ne pouvons pas montrer directement que \( P(A\cap B)=P(A)P(B)\) parce que cela est la formule que nous voulons utiliser pour montrer que la chaîne est de Markov. Nous passons donc par les tribus :
\begin{subequations}        \label{subesqqsABtribsYYXzY}
    \begin{align}
        A&\in\sigma(Y_{n+1})\\
        B&\in\sigma(X_0,Y_1,\ldots,Y_n).
    \end{align}
\end{subequations}
Nous utilisons maintenant l'hypothèse d'indépendance des variables aléatoires \( X_0\) et \( Y_i\) pour conclure que les deux tribus des équations \eqref{subesqqsABtribsYYXzY} sont indépendantes. Les événements \( A\) et \( B\) sont par conséquent indépendants. De la même façon, l'événement \( A\) est indépendant de l'événement \( \{ X_n=x_n \}\). Nous avons donc successivement
\begin{subequations}
    \begin{align}
        P(X_{n+1}=x_{n+1}|Y_i=x_i-x_{i-1},X_0=x_0)&=P(Y_{n+1}=x_{n+1}-x_n)\\
        &=P(Y_{n+1}=x_{x+1}-x_n|X_n=x_n)\\
        &=P(Y_{n+1}=x_{n+1}-X_n|X_n=x_n)\\
        &=P(X_{n+1}=x_{n+1}|X_n=x_n).
    \end{align}
\end{subequations}
La chaîne est par conséquent de Markov.

La matrice de transition de cette chaîne de Markov est une matrice infinie «dans tous les sens» :
\begin{equation}
    p(x,y)=\begin{cases}
        p    &   \text{si y=x-1}\\
        (1-p)    &    \text{si y=x+1}\\
        0    &   \text{sinon}.
    \end{cases}
\end{equation}

\begin{proposition}
    Voici quelque propriétés des chaînes de Markov homogènes.
    \begin{enumerate}
        \item
            La probabilité d'une trajectoire donnée est
            \begin{equation}
                P(X_n=x_n,X_{n-1}=x_{n-1},\ldots,X_0=x_0)=p(x_{n-1},x_n)\dots p(x_0,x_1)P(X_0=x_0).
            \end{equation}
        \item
            La probabilité de transition «en \( n\) coups» est donnée par la puissance \( n\)ième de la matrice de transition :
            \begin{equation}
                P(X_n=x_n|X_0=x_0)=Q^n_{x_0,x_n}.
            \end{equation}
        \item
            Si l'espace des états \( E\) est fini, l'espérance d'une fonction bornée \( f\colon E\to \eR\) de l'état est donné par
            \begin{subequations}
                \begin{align}
                    E\big( f(X_{n+1})|X_n=x_n,\ldots,X_0=x_0 \big)&=E\big( f(X_{n+1})|X_n=x_n \big)\\
                    &=\sum_{y\in E}f(y)p(x_n,y).j
                \end{align}
            \end{subequations}
    \end{enumerate}
\end{proposition}

\begin{proof}
    \begin{enumerate}
        \item
            Étant donné que \( P(A\cap B)=P(A|B)P(B)\), nous avons
            \begin{equation}
                P(X_n=x_n,\ldots,X_0=x_0)=P(X_n=x_n|X_{n-1}=x_{n-1},\ldots,X_0=x_0)P(X_{n-1}=x_{n-1},\ldots,X_0=x_0).
            \end{equation}
            Par la propriété de Markov, le premier facteur est
            \begin{equation}
                P(X_n=x_n|X_{n-1}=x_{n-1})=p(x_{n-1},x_n).
            \end{equation}
            Le reste est une récurrence sur \( n\).

        \item
            Montrons avec \( n=2\). En utilisant les divers points du théorème \ref{ThoBayesEtAutres}, nous avons
            \begin{subequations}
                \begin{align}
                    P(X_2=x_2|X_0=x_0)&=\sum_{y\in E}P(X_2=x_2,X_1=y|X_0=x_0)\\
                    &=\sum_{y\in E}P(X_2=x_2|X_1=y,X_0=x_0)P(X_1=y|X_0=x_0)\\
                    &=\sum_{y\in E}P(X_2=x_2|X_1=y)P(X_1=y|X_0=x_0)\\
                    &=\sum_{y\in E}p(x_2,y)p(y,x_0) \label{subEqyExdyyxz}\\
                    &=Q^2_{x_2,x_0}.
                \end{align}
            \end{subequations}
            Bien entendu ici la notion de produit matriciel doit être comprise de façon formelle lorsque \( E\) est infini.
            \begin{remark}
                Nous avons utilisé l'homogénéité de la chaîne de Markov au moment d'écrire l'expression \eqref{subEqyExdyyxz}. En principe nous aurions dû écrire \( p_2(y,x_2)p_1(x_0,y)\).
            \end{remark}
    \end{enumerate}
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Graphe de transition}
%---------------------------------------------------------------------------------------------------------------------------

Le \defe{graphe de transition}{graphe de transition} d'une chaîne de Markov est le graphe dont les sommets sont les éléments de l'espace des états de la chaîne et dont les sommets sont reliés par des arrêtes pondérées par la probabilité de transition correspondante.

\begin{definition}
    Une chaîne de Markov est \defe{irréductible}{irréductible!chaîne de Markov}\index{chaîne de Markov!irréductible} si pour tout \( x,y\in E\), il existe \( n\) tel que \( p^n(x,y)>0\) où 
    \begin{equation}
        p^n(x,y)=P(X_n=y|X_0=x).
    \end{equation}
    Le nombre \( n\) peut dépendre de \( x\) et \( y\).
\end{definition}

\begin{lemma}
    Une chaîne de Markov homogène est irréductible si et seulement si son graphe de transition est connexe.
\end{lemma}

\begin{proof}
    Pour chaque couple \( (x,y)\in E^2\) nous avons
    \begin{equation}
        \begin{aligned}[]
            p^n(x,y)&=\sum_{z_i\in E}P(X_n=y,X_{n-1}=z_{n-1},\ldots,X_1=z_1,X_0=x)\\
            &=\sum_{z_i}p(z_{n-1},y)p(z_{n-2},z_{n-1})\ldots p(z_1,z_2)p(x,z_1).
        \end{aligned}
    \end{equation}
    La positivité d'un des termes de la somme signifie que le graphe est connexe tandis que la positivité de \( p^n(x,y)\) signifie que la chaîne est irréductible.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{chaîne de Markov définie par récurrence}
%---------------------------------------------------------------------------------------------------------------------------

\begin{proposition}
    Soit \( X_0\) une variable aléatoire à valeurs dans $E$, un ensemble au plus dénombrable. Soit \( (Y_n)\) une suite de variables aléatoires réelles indépendantes et identiquement distribuées indépendantes de \( X_0\).

    Soit \( (X_n)\) la suite de variables aléatoires à valeurs dans \( E\) définie par récurrence selon la formule
    \begin{equation}
        X_{n+1}=G(X_n,Y_{n+1})
    \end{equation}
    où \( G\colon E\times \eR\to E\) est une fonction mesurable. Alors \( (X_n)\) est une chaîne de Markov.
\end{proposition}

\begin{proof}
    Soient \( x_0,\ldots, x_{n+1}\) des éléments de \( E\). Nous devons calculer la valeur de
    \begin{equation}
        P(X_{n+1}=x_{n+1}|X_n=x_n,\ldots, X_0=x_0).
    \end{equation}
    
\end{proof}
<++>


%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Classification des états}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Sauf mention expresse du contraire, nous considérons toujours une chaîne de Markov homogène.

\begin{definition}
    Un état \( x\in E\) est \defe{absorbant}{absorbant} pour la chaine \( (X_n)\) si \( p(x,x)=1\).
\end{definition}
Il n'est pas spécialement impossible d'arriver sur un état absorbant, mais il est impossible d'en sortir.

Si \( x\in E\), nous notons
\begin{equation}
    T(x)=\inf\{ k\geq 1\tq X_k=x \},
\end{equation}
le \defe{premier temps d'atteinte}{premier temps d'atteinte} de l'état \( x\). Si \( X_0=x\), alors \( T(x)\) est le \defe{temps de retour}{temps de retour} en \( x\). Si \( p\in \eN\) nous notons
\begin{equation}
    T_p(x)=\inf\{ k\geq 1\tq X_{k+p}=x \}.
\end{equation}
C'est le temps mis pour atteindre \( x\) à partir de l'instant \( p\).

\begin{proposition}
    La loi de la variable aléatoire \( [T_p(x)|X_p=x]\) est la même que celle de la variable aléatoire \( [T(x)|X_0=x]\).
\end{proposition}

\begin{proof}
    Nous devons montrer que 
    \begin{equation}
        P(T_p(x)=k|X_p=x)=P(T(x)=k|X_0=x).
    \end{equation}
    Cela est intuitivement évident du fait qu'une chaîne de Markov soit un processus sans mémoire. Affin de prouver, nous allons sommer sur tous les états intermédiaires possibles :
    \begin{subequations}
        \begin{align}
            P&(T_p(x)=k|X_0=x)=P(X_{p+k}=x,X_{p+k-1}\neq x,\ldots,X_{p+1}\neq x|X_p=x)\\
            &=\sum_{z_i\neq x}P(X_{p+k}=x,X_{p+k-1}=z_{k-1},\ldots,X_{p+1}=z_1|X_p=x)\\
            &=\sum_{z_i}P(X_{p+k}=x,X_{p+k-i}=z_i|X_{p+1}=z_1,X_p=x)\underbrace{P(X_{p+1}=z_1|X_p=x)}_{=p(x,z_1)}\\
            &=\sum_{z_i}P(X_{p+k}=x,X_{p+k-i}=z_i|X_{p+2}=z_2,X_{p+1}=z_1,X_p=x)\\
            &\qquad\underbrace{P(X_{p+2}=z_2|X_{p+1}=z_1,X_p=x)}_{P(X_{p+2}=z_2|X_{p+1}=z_1)=p(z_1,z_2)}p(x,z_1)\\
            &=\ldots\\
            &=\sum_{z_i}p(x,z_1)p(z_1,z_2)\ldots p(z_{k-1},z_{k-1})p(z_{k-1},x).
        \end{align}
    \end{subequations}
    À ce point ci, nous avons éliminé toute référence à \( p\) grâce à l'homogénéité de la chaîne. Nous pouvons refaire le calcul à l'envers pour reconstituer l'expression de départ sans le \( p\) :
    \begin{subequations}
        \begin{align}
         \sum_{z_i}p(x,z_1)p(z_1,z_2)\ldots &p(z_{k-1},z_{k-1})p(z_{k-1},x)\\
         &=P(x_k=x,X_{k-1}\neq x,\ldots,X_1\neq x|X_0=x)\\
         &=P(T(x)=k),
        \end{align}
    \end{subequations}
    ce qu'il fallait obtenir.
\end{proof}

\begin{definition}
    Un état \( x\) est \defe{récurrent}{récurrent!état} si \( P(T(x)=\infty|X_0=x)=0\), c'est à dire si la probabilité de ne jamais retourner en $x$ lorsqu'on y est passé est nulle. L'état \( x\) est \defe{transient}{transient!état} dans le cas contraire.
\end{definition}

Nous introduisons une variable aléatoire qui compte le nombre de fois que la chaîne de Markov passe par l'état \( x\) :
\begin{equation}    \label{EqDefNxmtuXkn}
    N_x=\sum_{k=0}^{\infty}\mtu_{\{ X_k=x\}}.
\end{equation}
C'est une variable aléatoire à valeurs dans \( \eN\cup\{ \infty \}\).

\begin{proposition} \label{PropEquivEPrecuequiv}
    Les deux propriétés suivantes sont équivalentes à dire que \( x\) est récurrent:
    \begin{enumerate}
        \item
            \( P(N_x<\infty|X_0=x)=0\)
        \item
            \( E(N_x|X_0=x)=\infty\).
    \end{enumerate}
    Les deux propriétés suivantes sont équivalentes à dire que \( x\) est transient :
    \begin{enumerate}
        \item
            \( P(N_x<\infty|X_0=x)=1\)
        \item
            \( E(N_x|X_0=x)<\infty\).
    \end{enumerate}
\end{proposition}

\begin{proof}
    En tant que événements, nous avons l'égalité
    \begin{equation}
        N_x<\infty=\bigcup_{n\in\eN}\{\underbrace{ X_n=x,X_{n+k}\neq x\forall k\geq 1}_{F_n} \}.
    \end{equation}
    Nous avons donc 
    \begin{equation}    \label{Eqreprencalculstd}
        P(N_x<\infty|X_0=x)=\sum_{n=0}^{\infty}P(F_n|X_0=x),
    \end{equation}
    et
    \begin{subequations}
        \begin{align}
            P(F_n|X_0=x)&=P(X_{n+k}\neq x, \forall k\geq 1,X_n=x|X_0=x)\\
            &=P(X_{n+k}\neq x,k\geq 1|X_n=x,X_0=x)P(X_n=x|X_0=x)\\
            &=P(X_{n+k}\neq x,k\geq 1|X_n=x)P(X_n=x|X_0=x)  \label{subEqPFnXkneqxii}\\
            &=P(X_k\neq x,k\geq 1|X_0=x)P(X_n=x|X_0=x)  \label{subEqPFnXkneqxi}\\
            &=P(T(x)=\infty|X_0=x)P(X_n=x|X_0=x)    \label{subEqPFnXkneqxiii}
        \end{align}
    \end{subequations}
    Justifications :
    \begin{enumerate}
        \item
            Pour \eqref{subEqPFnXkneqxii}, nous utilisons le fait que la chaîne soit «sans mémoire».
        \item
            Pour \eqref{subEqPFnXkneqxi}, nous utilisons le fait que la chaîne soit homogène.
        \item
            Pour \eqref{subEqPFnXkneqxiii}, l'événement \( X_k\neq x\) pour tout \( k\geq 1\) est exactement l'événement \( T(x)=\infty\).
    \end{enumerate}
    En nous servant de l'exemple \ref{ExempInversSumIntFub} d'application du théorème de Fubini, nous permutons l'espérance et la somme dans l'expression
    \begin{subequations}        \label{EqPEEEntstq}
        \begin{align}
            \sum_{n=0}^{\infty}P(X_n=x|X_0=x)&=\sum_{n=0}^{\infty}E(\mtu_{\{ X_n=x \}}|X_0=x)\\
            &=E\big( \sum_{n=0}^{\infty}\mtu_{\{ X_n=x \}}|X_0=x \big)\\
            &=E(N_x|X_0=x).
        \end{align}
    \end{subequations}
    Voyons ce passage plus en détail. D'abord, en général nous avons
    \begin{subequations}
        \begin{align}
            E(Y|X=x_0)&=\int_{\{ X=x_0 \}}Y(\omega)dP(\omega)\\
            &=\int_{\Omega}\mtu_{\{ X=x_0 \}}(\omega)Y(\omega)dP(\omega).
        \end{align}
    \end{subequations}
    Dans notre cas,
    \begin{equation}
        E\big( \mtu_{\{ X_n=x \}}|X_0=x \big)=\int_{\Omega}\mtu_{X_0=x}(\omega)\mtu_{\{ X_n=x \}}(\omega)dP(\omega).
    \end{equation}
    La fonction qui correspond à l'exemple \ref{ExempInversSumIntFub} est
    \begin{equation}
        f(n,\omega)=f_n(\omega)=\delta_{X_0(\omega),x}\delta_{X_n(\omega),x},
    \end{equation}
    qui est bien une fonction positive et mesurable.

    Nous reprenons à présent le calcul \eqref{Eqreprencalculstd} en remplaçant les éléments par leurs valeurs que nous avons calculées :
    \begin{equation}    \label{EqPnxXzTxarn}
        P(N_x<\infty|X_0=x)=P\big(T(x)=\infty|X_0=x\big)E(N_x|X_0=x).
    \end{equation}
    Si \( x\) est récurrent, nous avons \( P\big( T(x)=\infty|X_0=x \big)=0\), mais la relation \eqref{EqPnxXzTxarn} ne permet pas de conclure que le membre de gauche est nul parce qu'il reste la possibilité que \( E(N_x|X_0=x)=\infty\). Nous devons donc faire un pas en arrière et écrire cette espérance comme la limite des sommes partielles :
    \begin{equation}
        P(N_x<\infty|X_0=x)=\lim_{N\to \infty} \sum_{n=0}^NP\big( T(x)=\infty|X_0=x \big)P(X_n=x|X_0=x)=0
    \end{equation}
    parce que tous les termes de la suite des sommes partielles sont nuls. Nous avons donc bien que \( P(N_x<\infty|X_0=x)=0\). Il s'ensuit immédiatement que \( E(N_x|X_0=x)=1\).

    Nous devons maintenant démontrer l'implication inverse. Supposons que \( P(N_x<\infty|X_0=x)=0\). Dans ce cas nous avons immédiatement \( P(N_x=\infty|X_0=x)=1\) et \( E(N_x|X_0=x)=\infty\). L'équation \eqref{EqPnxXzTxarn} nous indique alors que 
    \begin{equation}
        P\big( T(x)=\infty|X_0=x \big)=0,
    \end{equation}
    c'est à dire que \( x\) est récurrent.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Chaînes irréductibles}
%---------------------------------------------------------------------------------------------------------------------------

\begin{proposition}     \label{Proptoustanstousrecirrsi}
    Soit \( (X_n)\) une chaîne de Markov irréductible.
    \begin{enumerate}
        \item
            Un état \( x\) est récurrent si et seulement si tous les états sont récurrents.
        \item
            Un état \( x\) est transient si et seulement si tous les états sont transients.
    \end{enumerate}
\end{proposition}

\begin{proof}
    Soient \( x\) et \( y\) des états de la chaîne de Markov. Nous devons tester la valeur de \( P(X_n=y|X_0=y)\). Afin d'exploiter l'hypothèse d'irréductibilité, nous considérons \( r,s\in\eN\) tels que
    \begin{subequations}
        \begin{align}
            p^r(x,y)>0\\
            p^s(y,x)>0
        \end{align}
    \end{subequations}
    et nous calculons majorons en passant par quelque intermédiaires :
    \begin{subequations}
        \begin{align}
            P(X_{n+r+s}=y|X_0=y)&\geq P(X_{n+r+s}=y,X_{n+s}=x,X_s=x|X_0=y)\\
            &=P(X_{n+r+s}=y|X_{n+s}=x,X_s=x,X_0=y)\\
            &\qquad P(X_{n+s}=x|X_s=x,X_0=y)P(X_s=x|X_0=y)\nonumber.
        \end{align}
    \end{subequations}
    Les deux premiers facteurs se calculent en utilisant la propriété de Markov et l'homogénéité de la chaîne. Pour le premier,
    \begin{equation}
        P(X_{n+s}=x|X_s=x,X_0=y)=P(X_{n+s}=x|X_s=x)=P(X_n=x|X_0=x).
    \end{equation}
    Nous avons donc
    \begin{equation}
        \sum_{n\in\eN}P(X_{n+r+s}=y|X_0=y)\geq p^r(x,y)p^s(y,x)\sum_{n\in\eN}P(X_n=x|X_0=x).
    \end{equation}
    En réutilisant Fubini comme dans l'équation \eqref{EqPEEEntstq}, nous avons
    \begin{equation}
        \sum_{n\in \eN}P(X_{n+r+s}=y|X_0=y)\geq KE(N_x|X_0=x)
    \end{equation}
    où \( K\) est une constante strictement positive, par hypothèse d'irréductibilité de la chaîne de Markov.

    Si \( x\) est un état récurrent, alors le membre de gauche est infini par la proposition \eqref{PropEquivEPrecuequiv} et donc
    \begin{equation}
        \sum_{n\in\eN}P(X_{n+r+s}=y|X_0=y)=\infty.
    \end{equation}
    Aux \( r+s\) premiers termes près (qui ne changent pas la somme), nous avons 
    \begin{equation}
        \sum_{n\in\eN}P(X_n=y|X_0=y)=\infty,
    \end{equation}
    ce qui signifie que \( y\) est récurrent.
\end{proof}

Nous rappelons que \( T(x)\) est le temps que première atteinte de l'état \( x\). Nous notons\nomenclature[M]{\( \pi(x)\)}{lié au temps de retour}
\begin{equation}
    \pi(x)=\frac{1}{ E\big( T(x)|X_0=x \big) }.
\end{equation}
Étant donné que \( T(x)\) est un entier positif ou nul nous avons \( E\big( T(x)|X_0=x \big)\in\mathopen[ 1 , \infty \mathclose]\) et donc \( \pi(x)\in\mathopen[ 0 , 1 \mathclose]\).

Si \( x\) est un état transient, alors \( T(x)=\infty\) lorsque \( X_0=x\) et donc \( E\big( T(x)|X_0=x \big)=0\) et \( \pi(x)=0\). Si \( x\) est récurent par contre, \( P\big( T(x)<\infty|X_0=x \big)=1\) et il n'y a pas de garanties sur la valeur de \( E\big( T(x)|X_0=x \big)\).

\begin{definition}
    Si \( x\) est un état récurent, et si \( E\big( T(x)|X_0=x \big)<\infty\), alors \( \pi(x)>0\) et nous disons que \( x\) est \defe{récurent positif}{récurent!positif}. Si \( E\big( T(x)|X_0=x \big)=\infty\) alors \( \pi(x)=0\) et l'état \( x\) est \defe{récurrent nul}{récurent!nul}.
\end{definition}

\begin{proposition} \label{PropMrkIrreLoishLCkpjkptXk}
    Soit \( (X_n)\) est une chaîne de Markov irréductible.
    \begin{enumerate}
        \item
            Si \( x\) est un état récurrent, alors \( T(X)<\infty\) presque surement.
        \item
            Nous avons une égalité entre les lois
            \begin{equation}    \label{PropMrkIrreLoishLCkpjkptXkItemii}
                \hL\big( X_{k+T(x)}|T(x)<\infty \big)=\hL(X_k|X_0=x).
            \end{equation}
    \end{enumerate}
\end{proposition}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Nombre de visites}
%---------------------------------------------------------------------------------------------------------------------------

La fonction
\begin{equation}
    \frac{1}{ n }\sum_{k=1}^n\mtu_{\{ X_k=x \}}
\end{equation}
est la \defe{fréquence empirique}{fréquence!empirique} de la chaîne de Markov.

Soit \( x\) un état récurent, c'est à dire que \( P\big( T(x)<\infty|X_0=x \big)=1\). Nous classons les visites de la façon suivante :
\begin{subequations}    \label{SubEqsDefTirectempsretou}
    \begin{align}
        T_1(x)&=T(x)=\inf\{ k\geq 1\tq X_k=x \}\\
        T_2(x)&=\inf\{ k\geq 1\tq X_{T_1(x)+k}=x \}\\
        &\vdots\\
        T_n(x)&=\inf\{ k\geq 1\tq X_{T_{n-1}(x)+k}=x \}
    \end{align}
\end{subequations}
La variable aléatoire \( T_i\) représente le temps entre la visite numéro \( i-1\) et la visite numéro \( i\) (si \( X_0\neq x\), sinon il faut décaler). Nous définissons l'instant la na visite numéro \( n\) :
\begin{equation}
    S_n=\sum_{k=1}^nT_k(x).
\end{equation}

\begin{lemma}
    Les variables aléatoires \( T_i\) sont indépendantes.
\end{lemma}

\begin{proof}
    Nous choisissons \( n\) des \( T_i\) et nous calculons la probabilité
    \begin{equation}
        \spadesuit=P(T_{i_1}=k_1,T_{i_2}=k_2,\ldots,T_{i_n}=k_n)
    \end{equation}
    où nous supposons \( i_1>i_2>\ldots>i_n\). Nous décomposons cette probabilité en sommant sur toute les histoires de la chaîne de Markov compatibles avec les nombres \( k_i\) donnés :
    \begin{equation}
        \spadesuit=\sum_{\substack{\{ z_j \}\\\text{compatibles}}}P(X_j=z_j,j=1,\ldots,N).
    \end{equation}
    Notons qu'ici, le numéro du dernier terme de la somme n'est pas certain parce que tous les \( T_i\) ne sont pas fixés. Nous l'avons noté \( N\), mais en réalité il est différent d'un terme à l'autre de la somme. Il est certain que \( z_N=x\) et \( z_{N-k_1}=x\) et si \( N-k_1<j<N\), alors \( z_j\neq x\). Cela est simplement le fait que nous demandions aux \( z_i\) de respecter les conditions données par les \( k_i\). Nous avons
    \begin{subequations}
        \begin{align}
            \spadesuit&=\sum_{\{ z_j \}} P(X_N=x,X_j=z_j,N-k_1<j<N|X_j=z_j,j\leq N-k_1)P(X_j=z_j,j<N-k_1)\\
            &=\sum_{\{ z_j \}} P(X_N=x,X_j=z_j,N-k_1<j<N|X_{N-k_1}=x)P(X_j=z_j,j<N-k_1)\\
        \end{align}
    \end{subequations}
    Le premier facteur est \( P(T_{i_1}=k_1)\) tandis que le second facteur est précisément \( P(T_{j}=k_j,j>1)\). Nous avons donc montré que
    \begin{equation}
        P(T_{i_1}=k_1,T_{i_2}=k_2,\ldots,T_{i_n}=k_n)=P(T_{i_1}=k_1)P(T_{j}=k_j,j>1),
    \end{equation}
    et donc les \( T_i\) sont indépendants.
\end{proof}

\begin{proposition}
    Si \( (X_n)\) est une chaîne de Markov irréductible et si \( x\in E\) alors
    \begin{equation}        \label{EqPiEndempropropkeu}
        \pi(x)=\lim_{n\to \infty} \frac{1}{ n }\sum_{k=1}^n\mtu_{\{ X_k=x \}}
    \end{equation}
    presque surement.
\end{proposition}

\begin{proof}
    Étant donné que la chaîne est irréductible, les états sont soit tous transient soit tous récurrents par la proposition \ref{Proptoustanstousrecirrsi}. Nous commençons par considérer que \( x\) est transient.

    En comparant la définition \eqref{EqDefNxmtuXkn} de \( N_x\) et le membre de droite de \eqref{EqPiEndempropropkeu}, nous avons pour chaque \( n\) l'inégalité
    \begin{equation}    \label{EqkkueusnfracunENx}
        \frac{1}{ n }\sum_{k=1}^n\mtu_{\{ X_k=x \}}\leq\frac{1}{ n }E(N_x).
    \end{equation}
    Dans le cas d'un élément transient, nous avons \( \pi(x)=0\), donc il serait bon de montrer que \( E(N_x)<\infty\), de telle façon à ce que prendre la limite \( n\to\infty\) dans \eqref{EqkkueusnfracunENx} donne zéro.

    Nous décomposons le calcul en deux morceaux :
    \begin{equation}
        E(N_x)=E\big( N_x|T(x)=\infty \big)P\big( T(x)=\infty \big)+E\big( N_x|T(x)<\infty \big)P\big( T(x)<\infty \big).
    \end{equation}
    Le fait que le premier terme soit fini découle immédiatement du fait que \( T(x)=\infty\) implique \( X_k\neq x\) pour tout \( k\geq 1\). Dans ce cas l'espérance de \( N_x\) est évidemment finie.

    Pour le second terme nous avons
    \begin{subequations}
        \begin{align}
            E\big( N_x|T(x)<\infty \big)&=E\big( \sum_{k=0}^{\infty}\mtu_{\{ X_k=x \}}|T(x)<\infty \big)\\
            &=\sum_{k=1}^{\infty}E\big( \mtu_{\{ X_k=x \}}|T(x)<\infty \big).
        \end{align}
    \end{subequations}
    Pour inverser la somme et l'espérance, nous avons utilisé le théorème de théorème de Fubini-Tonelli qui est encore valable pour des fonctions qui prennent la valeur \( \infty\). Le fait d'inverser ne signifie pas que ni la somme ni l'intégrale soit finie. D'ailleurs c'est exactement ce que nous sommes en train de déterminer.

    Étant donné que nous voulons seulement savoir si cette somme est finie ou non, nous pouvons nous restreindre à la somme depuis \( k=1\) ou oublier le premier terme. D'autre par nous avons
    \begin{equation}
        \sum_{k=1}^{\infty}\mtu_{\{ X_k=x \}}=\sum_{j=0}^{\infty}\mtu_{\{ X_{j+T(x)}=x \}}
    \end{equation}
    parce que les \( T(x)\) premiers termes sont par définition nuls. Nous regardons donc
    \begin{subequations}
        \begin{align}
            \sum_{j=0}^{\infty}E\big( \mtu_{X_{j+T(x)}=x}|T(x)<\infty \big)&=\sum_{j}P\big( X_{j+T(x)}=x|T(x)<\infty \big)\\
            &=\sum_jP(X_j=x|X_0=x)  \label{subeqsumkPXjXzsezii}\\
            &=\sum_jE\big( \mtu_{\{ X_j=x \}}|X_0=x \big)\\
            &=E\big( \sum_j\mtu_{X_j=x}|X_0=x \big)\\
            &=E(N_x|X_0=x)\\
            &<\infty    &\text{parce que \( x\) est transient.}
        \end{align}
    \end{subequations}
    L'équation \eqref{subeqsumkPXjXzsezii} provient de la proposition \ref{PropMrkIrreLoishLCkpjkptXk} et plus précisément de l'égalité entre les lois \eqref{PropMrkIrreLoishLCkpjkptXkItemii}. Nous avons terminé la preuve dans le cas où \( x\) est transient.

    Nous passons maintenant au cas où \( x\) est récurrent, c'est à dire \( P(T(x)<\infty|X_0=x)=1\). Les variables aléatoires \( T_i\) définies en \eqref{SubEqsDefTirectempsretou} pour \( i\geq 2\) sont indépendantes et identiquement distribuées et
    \begin{equation}
        \hL\big( T_k(x) \big)\sim\hL\big( T(X)|X_0=x \big).
    \end{equation}
    La loi des grands nombres nous indique que
    \begin{subequations}        \label{EqlgnMarkdemked}
        \begin{align}
            \frac{ S_n }{ n }=\frac{ T_1(x) }{ n }+\frac{1}{ n }\sum_{k=2}^nT_k(x)\stackrel{p.s.}{\longrightarrow}& E\big( T_2(x) \big)\\
            &=E\big( T(x)|X_0=x \big).
        \end{align}
    \end{subequations}
    \begin{remark}
        La loi des grands nombres est encore vraie sans l'hypothèse de variables aléatoires dans \( L^1\) pourvu qu'elles soient positives. Alors dans la conclusion de la loi nous devons accepter la possibilité que l'espérance soit infinie.
    \end{remark}
    Nous posons pour \( m\in\eN\)
    \begin{equation}    \label{EqDennmsumjmtu}
        n(m)=\sum_{j=1}^m\mtu_{\{ X_j=x \}}
    \end{equation}
    qui est le nombre de visites de \( x\) avant l'instant \( m\). Nous avons évidemment \( n(m)\leq m\). Mais \( S_n\) est l'instant de la \( n\)ième visite, par conséquent \( S_{n(m)}\) est l'instant de la dernière visite avant le moment \( m\). Pour tout \( m\) nous avons les inégalités 
    \begin{equation}
        S_{n(m)}\leq m<S_{n(m)+1}.
    \end{equation}
    Nous divisons par \( n(m)\) et nous effectuons la limite \( m\to\infty\):
    \begin{equation}    \label{EqdrembSnm}
        \frac{ S_n(m) }{ n(m) }\leq \frac{ m }{ n(m) }\leq\frac{ S_{n(m)}+1 }{ n(m) }
    \end{equation}
    En ce qui concerne la limite de \( n(m)\), nous utilisons la définition \eqref{EqDennmsumjmtu} :
    \begin{equation}
        n(m)\to\sum_{j=1}^{\infty}\mtu_{\{ X_j=x \}}=
    \end{equation}
heur\ldots
     \begin{equation}
         \lim_{m\to \infty}  n(m)=\lim_{m\to \infty} \sum_{n=1}^m\mtu_{\{ X_j=x \}}\stackrel{p.s.}{\longrightarrow}\infty
     \end{equation}
     par la proposition \eqref{PropEquivEPrecuequiv}. Plus précisément, la limite vaut \( N_x\) qui vaut presque surement \( \infty\) dans le cas où \( x\) est récurrent. Par ailleurs la loi des grands nombres \eqref{EqlgnMarkdemked} nous enseigne en particulier que
     \begin{equation}
         \frac{ S_{n(m)} }{ n(m) }\stackrel{p.s.}{\longrightarrow} E\big( T(x)|X_0=x \big).
     \end{equation}
     Le terme de droite dans \eqref{EqdrembSnm} se traite de façon usuelle :
     \begin{equation}
         \frac{ S_{n(m)+1} }{ n(m) }=\frac{ S_{n(m)+1} }{ n(m)+1 }\frac{ n(m)+1 }{ n(m) }.
     \end{equation}
     Le dernier facteur tend vers \( 1\) et le tout a pour limite \( E\big( T(x)|X_0=x \big)\). Par conséquent nous avons
     \begin{equation}
         \frac{ m }{ n(m) }\stackrel{p.s.}{\longrightarrow}E\big( T(x)|X_0=x \big)
     \end{equation}
     et 
     \begin{equation}
         \frac{ n(m) }{ n }=\frac{1}{ m }\sum_{j=1}^m\mtu_{\{ X_j=x \}}\to\frac{1}{ E\big( T(x)|X_0=x \big) }=\pi(x).
     \end{equation}
\end{proof}

\begin{proposition}
    Soit \( (x_n)\) une chaîne de Markov irréductible.
    \begin{enumerate}
        \item
            Un état \( x\) est transient si et seulement si tous les états sont transients.
        \item
            Un état est récurrent positif  si et seulement si tous les états sont récurrents positifs.
    \end{enumerate}
\end{proposition}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Simulations en scilab}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Le théorème ergodique dit que
\begin{equation}
    \pi(x)=\lim_{N\to \infty} \frac{1}{ N }\sum_{k=1}^N\mtu_{X_k=x}.
\end{equation}
C'est avec cela qu'on calcule \( \pi(x)\) à partir d'une simulation de chaîne de Markov.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Le théorème central limite pour Markov}
%---------------------------------------------------------------------------------------------------------------------------

\begin{theorem}[Version allégée]
    Si \( (X_n)\) est irréductible et positive récurrente, alors pour toute fonction \( f\),
    \begin{equation}
        \frac{1}{ \sqrt{N} }\left[ \sum_{k=1}^N-N\int fd\pi \right]\stackrel{\hL}{\longrightarrow}\dN(0,\sigma^2)
    \end{equation}
    où \( \sigma^2\) dépend de la fonction \( f\) et de la chaîne de Markov.

   Ici, \( \int fd\pi=\sum_{x\in E}f(x)\pi(x)\).
\end{theorem}

Nous allons simuler la variable aléatoire
\begin{equation}
    Z=\frac{1}{ \sqrt{N} }\left[ \sum f(X_k)-N\sum_{x\in E} f(x)\pi(x) \right]
\end{equation}
et puis on va mettre sa réalisation dans un histogramme. Dans le cas où on prend \( f(i)=\mtu_{i=i_0}\), il y a de la simplification dans l'intégrale qui devient 
\begin{equation}
    Z=\frac{1}{ \sqrt{N} }\left[ \sum_{i=1}^N\mtu_{X_k=i_0}-N\pi(i_0) \right].
\end{equation}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Feuille 5}
%---------------------------------------------------------------------------------------------------------------------------

On pose 
\begin{equation}
    D_n=\sqrt{n}\sup_{x\in\eR}| F_n(x)-F(x) |.
\end{equation}
On en génère un milliers de fois \( D_n\), on note \( D_n^{(k)}\) ces réalisations, et on regarde ce que vaut
\begin{equation}
    \frac{1}{ 1000 }\sum_{k=1}^{1000}\mtu_{D_n^{(k)\geq c}}.
\end{equation}
Cela nous donne une approximation de
\begin{equation}
    P\big( \sqrt{n}\sup_{x\in\eR}| F_n(x)-F(x) |\geq c \big).
\end{equation}

Note que chacun des \( D_n^{(k)}\) demande de créer un nouveau vecteur \( Y_i\) de lois qu'on veut regarder. Par exemple de loi exponentielle.

