References for this chapter are \cite{Wassermann}.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
					\section{Functional, representation and automorphism}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Let $A$ be an algebra and consider a linear functional $\varphi\colon A\to \eC$. That induces a GNS representation $\pi\colon A\to \End(V)$ with
\begin{equation}
  V=\frac{ A }{ \{ b\tq\varphi(ab)=0\,\forall a \}. }
\end{equation}
If $\varphi$ is nondegenerate, the latter ideal reduces to $\{ 0 \}$. Let us assume a sort of Riesz theorem: for every linear functional $\psi\colon A\to \eC$, there exists a $b\in A$ such that $\psi(a)=\varphi(ab)$, $\forall a$. If one fixes $b$, one can see $\varphi(ba)$ as a functional for $a$, and thus define $\sigma(b)$ by
$\varphi(ba)=\varphi\big(a\sigma(b)\big)$.

One can check that this $\sigma$ is an automorphism of $A$.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Commutant}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Let $M\subset\oB(\hH)$ be a collection of bounded operators on $\hH$. The \defe{commutant}{commutant} of $M$ in $\oB(\hH)$ is\nomenclature[O]{$M'$}{The commutant of $M$}
\begin{equation}
M'=\{ S\in\oB(\hH)\tq \text{ $TS=ST$ for every $T\in M$ } \}.
\end{equation}
From now let $M$ be a self-adjoint algebra of operators on an Hilbert space $\hH$ which contains $\mtu$. We have three lemmas.

\begin{lemma}		\label{LemUnVN}
If $v\in\hH$ and if $P$ is the projection onto $\overline{ Mv }\subseteq \hH$, then $P$ commutes with all operators in $M$. 
\end{lemma}

\begin{lemma}		\label{LemDeuxVN}
If $S\in M''$, $v\in \hH$ and $\epsilon >0$, there exists a $T\in M$ such that $\| Sv-Tv \|\leq\epsilon$. Moreover, in the finite dimensional case, there exists a $T\in M$ such that $Sv=Tv$.
\end{lemma}

\begin{proof}
Consider $P$ as in lemma \ref{LemUnVN}, then $P\in M'$, so that $XP=PX$. Now, the fact that $M$ is unital gives $v\in \overline{ Mv }$ from which we deduce $Pv=v$. Thus we have
\[ 
  Xv=XPv=PXv\in\overline{ Mv }
\]
because $Xv=P(Xv)$. The lemma now result from the fact that an element of the closure of $Mv$ is as close as we want from $Mv$.
\end{proof}

\begin{lemma}		\label{LemTroisVN}
If $T\in M''$, $v_1, \ldots v_n\in\hH$, and $\epsilon>0$, there exists a $T\in M$ such that $\| Sv_i-Tv_i \|\leq\epsilon$ for all $i$. Moreover if the finite dimensional case, there exists a $T$ such that $Sv_i=Tv_i$.
\end{lemma}

\begin{proof}
Apply lemma \ref{LemDeuxVN} to the set
\[ 
  N=\{ T\oplus T\oplus\ldots\oplus T\in\oB(\hH\oplus\ldots\oplus\hH)\tq T\in M \}.
\]
\end{proof}

\begin{corollary}
In the finite dimensional case, we have $M''=M$.
\end{corollary}

\begin{proof}
Take a basis of $\hH$ in the lemma \ref{LemTroisVN}.
\end{proof}

\begin{theorem}[Double commutant]		\label{ThoDoubleCommutant}
	Let $M\subset\oB(\hH)$ be a set of bounded operators on the Hilbert space $\hH$. The double commutant $M''$ is the strong closure of $M$, i.e. the set of strong limits of nets.
\end{theorem}

\begin{proof}
A first evidence is that $M\subseteq M''$. Secondly, every commutant is strongly closed, so that $M''$ in particular is strongly closed. So it remains to be proved that for each $S\in M''$ is the limit of some net in $M$ in the strong topology. For that, consider the directed set of finite subsets of $\hH$ and consider the directed set
\[ 
  A=\{ \text{finite subsets of $\hH$} \}\times ]0,\infty[
\]
on which we say $(F,\epsilon)\geq (F',\epsilon')$ if and only if $F'\subseteq F$ and $\epsilon <\epsilon'$.

For each $a=(F,\epsilon)\in A$, we define $T_{(F,\epsilon)}$ as in lemma \ref{LemTroisVN}, so we have, for all $v\in F$,
\[ 
  \| T_{(F,\epsilon)}v-Sv \|\leq\epsilon,
\]
which proves that $T_{(F,\epsilon)}$ converges to $S$ in the strong topology.
\end{proof}

Notice that the operator $S$ is in general \emph{not} a limit of a sequence.

\begin{definition}
A \defe{von Neumann algebra}{von Neumann algebra@von Neumann algebra} is an unital $*$-subalgebra of $\oB(\hH)$ which is equal to its double commutant.
\end{definition}

Let $G$ be a group and $\pi$, an unitary representation of $G$ and $M$ be the commutant of $\pi(G)$. Since $\pi(g)^*=\pi(g)^{-1}=\pi(g^{-1})$, we have that $\pi(G)$ is self-adjoint and $M$ is a von~Neumann algebra.

We say that a von~Neumann algebra is a \defe{factor}{factor} if its center is trivial, i.e. reduces to $\eC\,\id$.

\begin{proposition}	\label{PropprojrepresVN}
Let $\pi$ be a unitary representation of $G$ on $\hH$ and $\hH_1$, an invariant subspace of $\pi(G)$. We have
\begin{itemize}
\item the orthogonal projection on $\hH_1$ belongs to $M$,
\item if $P\in M$ is a projection, then $P\hH$ is a subrepresentation of $\pi$, i.e. the closed subspace $\pi(G)P\hH$.
\end{itemize}
\end{proposition}
So, if $\pi$ is irreducible then $M$ is made of multiples of identity.

The following lemma comes from \cite{Wassermann}.
\begin{lemma}		\label{LeminvarMprime}
Let $\hS$ be a selfadjoint part of $\oB(\hH)$. A closed subspace $\hH_1$ of $\hH$ is $\hS$-invariant if and only if the orthogonal projection on $\hH_1$ belongs to $\hS'$.
\end{lemma}

\begin{proof}
First, suppose that $\hH_1$ is $\hS$-invariant. Thus for every $v\in\hH_1$ and $w\in \hH_1^{\perp}$, we have
\[ 
  0=\langle Sv,w, \rangle =\langle v, S^*w\rangle 
\]
where $S^*\in\hS$ by assumption. We conclude that $S^*w\perp\hH_1$ for every $S\in\hS$. Since $\hS^*=\hS$, we have that $\hH_1^{\perp}$ is $\hS$-invariant. Now if $P$ is the orthogonal projector on $\hH_1$, we decompose $x\in\hH$ as
\begin{equation}		\label{EqDecomxPxSP}
  x=Px\oplus(\id-P)x\in\hH_1\oplus\hH_1^{\perp}.
\end{equation}
since $\hH_1^{\perp}$ is $\hS$-invariant, or every $S\in\hS$, we have $S(\id-P)x\in\hH_1^{\perp}$, so that $PS(\id-P)x=0$. Thus, using the decomposition \eqref{EqDecomxPxSP}, $PSx=PSPx\oplus 0=PSPx$. But $Px\in \hH_1$, then $SPx\in\hH_1$ and $P\big( SPx \big)=SPx$. We have proven that $PS=SP$, it is $P\in\hS'$.

For the second part, assume that $P\in\hS'$, then for every $v\in\hH_1$, we have $v=Pv$ and
\[ 
  Sv=SPv=PSv\in\hH_1,
\]
which proves that $\hH_1$ is $\hS$-invariant.
\end{proof}


\begin{proposition}
If $\hH_1$ and $\hH_2$ are equivalent subrepresentations of $\hH$, then the intertwining operator $W\colon \hH_1\to \hH_2$ determines on $\hH$ a partial isometry such that $P_1=W^*W$ and $P_2=WW^*$.
\end{proposition}

The following decomposition is the \defe{polar decomposition}{polar!decomposition!in von~Neumann algebra}\index{decomposition!polar in von~Neumann algebra}.
\begin{proposition}		\label{PropPolarvNA}
There exists a partial isometry $V\colon \overline{ \Image\big(| T |\big) }\to \overline{ \Image(T^*) }$ such that $T=V| T |$.
\end{proposition}

In other words, any element of a von~Neumann algebra is the product of a positive operator by a projection. A version of this decomposition for operators in Hilbert spaces is given in lemme \ref{LemPolarHilbert}.

\begin{proof}
The operator $V$ must satisfy $V\big( | T |v \big)=Tv$ for every $v\in\hH$. That operator is a partial isometry because
\[ 
  \big\| | T |v \big\|^2=\langle | T |v, | T |v\rangle =\langle | T |^2v, v\rangle =\langle T^*Tv, v\rangle =\| Tv \|^2.
\]
It remains to be proved that $V\in M$.
\end{proof}



\begin{lemma}		\label{LemVNCommunit}
Every von~Neumann algebra is the commutant of an unitary representation.
\end{lemma}

\begin{proof}
Let $M$ be a von~Neumann algebra and consider that group $G=U(M')$, the group of unitary operators on $M'$. Let $T\in M'$, it reads as the sum of self-adjoint operators by
\[ 
  T=\frac{ 1 }{2}(T+T^*)-\frac{ i }{2}(iT-iT^*).
\]
Thus we can restrict ourself to self-adjoint operators. Let $S\in M'$, it can be written as a combination of unitary operators:
\[ 
  S=\frac{ 1 }{2}\left( S+i\sqrt{1-S^2} \right)+\frac{ 1 }{2}\left( S-i\sqrt{1-S^2} \right).
\]
Notice that the square root makes sense because $1-S^2$ is positive. So $M'$ is spanned by $U(M')$ and then $M=M''=\big( U(M') \big)'$.
\end{proof}

%++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Examples of von Neumann algebras}

The very first example of von~Neumann algebra is $\oB(\hH)$ itself which is the commutant of the identity.

%----------------------------------------------------------------------------------------------------------------------------
\subsection{Algebra \texorpdfstring{$L^{\infty}(X)$}{LX}}


 For the second example, consider an $\sigma$-finite measure space $(X,\mu)$, and then define $\hH=L^2(X,\mu)$ and $M=L^{\infty}(X)$, the set of measurable bounded functions on $X$. The algebra $M$ acts on $\hH$ by pointwise multiplication and is therefore a $*$-subalgebra of $\oB(\hH)$. In order to prove that $ L^{\infty}(X)$ is a von~Neumann algebra, we prove that $ L^{\infty}(X)'= L^{\infty}(X)$.

Assume for simplicity that $\mu(X)<\infty$ for simplicity. Now consider $T\in L^{\infty}(X)'$ and $f_)(x)=1\in L^{\infty}(X)$ because the measure is finite. For each $g\in L^{\infty}(X)$, we have
\[ 
  Tg=T(gf_0)=gTf_0=gh
\]
where $h=Tf_0$. So an element of $ L^{\infty}(X)'$ reveals to be a multiplication by a function. We have
\[ 
  \| gh \|_2=\| Tg \|_2\leq \| T \|\cdot \| g \|_2
\]
That proves that $\| h \|_{\infty}\leq \| T \|$ because if $\| h \|_{\infty}=\| T \|+\delta$, then we have a set (of non vanishing measure) on which $h$ is bigger than $\| T \|$. We conclude that $h\in L^{\infty}(X)$.

%----------------------------------------------------------------------------------------------------------------------------
\subsection{Countable direct sum of Hilbert spaces}

Consider $\hH_{\infty}=\hH\oplus\hH\oplus\ldots=\{ f\colon \eN\to \hH\tq \sum \| f(n) \|^2<\infty \}$. One can show that it is an Hilbert space. Let
\[ 
  M=\{ T_{\infty}\tq T\in\oB(\hH) \}
\]
where $(T_{\infty}f)(n)=T\big( f(n) \big)$. One claims that this is a von~Neumann algebra.

Let us see that of a direct sum of two copies of $\hH$. In that case an element of $M$ reads 
$\begin{pmatrix}
T&0\\
0&T
\end{pmatrix}$ with $T\in\oB(\hH)$. An element of $M'$ must be of the form 
$\begin{pmatrix}
A&B\\
C&D
\end{pmatrix}$ with $[A,T]=[B,T]=[C,T]=[D,T]=0$ for every $T\in\oB(\hH)$. Thus we have
\begin{equation}
M'=\left\{ \begin{pmatrix}
A&B\\
C&D
\end{pmatrix}\tq A,B,C,D\in\eC\mtu \right\}.
\end{equation}
In turn, one can see that the commutant of the right hand side is $M$ itself.

Let us now go back with the case of $\hH_{\infty}$. The map $T\mapsto T_{\infty}$ provides an isomorphism $M\simeq\oB(\hH)$ as $*$-algebras. But it is not sufficient to conclude that $M$ is a von~Neumann algebra because the topologies do not correspond. A net $T_{\alpha}$ strongly converges in $M$ when $T_{\alpha}f$ converges for every $f\in M$. But $f$ is an infinite list of vectors in $\hH$, so that the strong topology in $M$ is something like an infinite collection of strong topology on $\oB(\hH)$. Every strongly open set in $\oB(\hH)$ is strongly open in $M$, while the reciprocal is not true.

%----------------------------------------------------------------------------------------------------------------------------
\subsection{Direct limit}

Let us take the example of direct limit of vector spaces given on page \pageref{PgExDirectLimVS}. We are considering the matrix algebras $M_k=\eM_{n_k}(\eC)$, and $A_n=M_1\otimes_{\eC}\ldots\otimes_{\eC} M_n$, together with the maps
\begin{equation}
\begin{aligned}
 \sigma_n\colon A_n&\to A_{n+1} \\ 
   T_1\otimes\ldots\otimes T_n&\mapsto T_1\otimes \ldots\otimes T_n\otimes \mtu. 
\end{aligned}
\end{equation}
We pose $A=\lim_{\rightarrow}A_n$.

\begin{lemma}
If $\pi_1$ and $\pi_2$ are $*$-homomorphisms from $A$ to $\oB(\hH)$, then
\begin{equation}		\label{Eqpiundeuxnirmea}
  \| \pi_1(a) \|=\| \pi_2(a) \|
\end{equation}
for every $a\in A$. In other words, there is an unique way to close $A$ in the norm topology.
\end{lemma}

\begin{probleme}
If one does not ask $\pi_i$ to be faithful, I can take $\pi_1(A)=0$ as counter-example. Thus I think that I have to add the faithful assumption.
\end{probleme}

\begin{proof}
One has $\| \pi_i(a) \|^2=\| \pi_i(a^*a) \|$, so that we only have to prove \eqref{Eqpiundeuxnirmea} in the case of self-adjoint elements of $A$. Using what is said in the proof of proposition \ref{prop:unicitenormcsa}, we have (with obvious notations) $\| \pi_i(b) \|=r_{\oB(\hH)}\big( \pi_i(b) \big)$. Since $b$ belongs to one of the $A_k=\eM_{n_k}(\eC)$ and $\dim A_k <\infty$.

\end{proof}

Now we ask the question of an actual way to represent $A$ on an Hilbert space. First, as matrix algebra, $M_k=\oB(\hH_k)$ for a certain finite dimensional Hilbert space $\hH_k$. We form the Hilbert space
\[ 
  \hH_1\otimes\ldots\otimes\hH_k
\]
with the inner product 
\begin{equation}
\langle v_1\otimes\ldots\otimes v_k, w_1\otimes\ldots\otimes w_k\rangle =\langle v_1, w_1\rangle \ldots\langle v_k, w_k\rangle.
\end{equation}
Now pick unit vectors $v_k\in\hH_k$ and define the maps
\begin{equation}
\begin{aligned}
 \hH_1\otimes\ldots\otimes\hH_{k-1}  &\to \hH_1\otimes\ldots\otimes\hH_k \\ 
   w_1\otimes\ldots\otimes w_{k-1}&\mapsto w_1\otimes\ldots\otimes w_{k-1}\otimes v_\otimes v_kk 
\end{aligned}
\end{equation}
that can be shown to be isometries. Finally, we consider the Hilbert space
\begin{equation}
	H =\bigotimes_1^{\infty}(\hH_k,v_k) = \text{completion of }\lim_{\rightarrow}(\hH_1\otimes\ldots\otimes\hH_k).
\end{equation}
Notice the dependence in the vectors $v_k$. Now we define the map $\pi\colon A\to \oB(H)$ by
\begin{equation}
\pi(T_1\otimes\ldots\otimes T_k)(w_1\otimes w_2\otimes\ldots)=T_1w_1\otimes\ldots\otimes T_kw_k\otimes w_k\otimes w_{k+1}\otimes\ldots
\end{equation}
More intrinsically, $\pi\colon \bigotimes M_k\to \oB\big( \bigotimes(\hH_k,v_k) \big)$,
\begin{equation}
\pi\big( \otimes T_k \big)(\otimes w_k)=\otimes T_kw_k.
\end{equation}
One can show that the strong closure of $\pi(A)$ is $\oB(H)$. The strong topology on $\oB(\hH)$ is generated by the open sets
\[ 
  \mU(S,v,\epsilon)=\{ T\in\oB(H)\tq \| Tv-Sv \|\leq\epsilon \}
\]
with $S\in\oB(\hH)$, $v\in H$ and $\epsilon>0$. The direct limit $\hH=\lim_{\rightarrow}(\hH_1\otimes\ldots\otimes\hH_k)$, is given by a vector space $\hH$ and maps $\varphi_k$ such that
\[ 
  \xymatrix{%
   \hH_1\otimes\ldots\otimes\hH_k \ar[rr]^{\sigma}\ar[dr]_{\varphi}		&	&	\hH_1\otimes\ldots\otimes\hH_{k+1}\ar[ld]^{\varphi_{k+1}}\\
   &	\hH
}
\]
commutes where $\sigma(w_1\otimes\ldots\otimes w_k)=w_1\otimes\ldots\otimes  w_k\otimes v_{k+1}$. The space $\hH$ is the free vector space generated by symbols of the form $w_1\otimes\ldots\otimes w_k\otimes v_{k+1}\otimes\ldots$ and we pose $\varphi_i(w_1\otimes\ldots\otimes w_i)=w_1\otimes\ldots\otimes w_i\otimes v_{i+1}\otimes\ldots$ and the Hilbert space $H$ is the completion of $\hH$.

The definition of $A$ proceeds in the same way: $M_i$ are matrix algebras and we pose $A_n=M_1 \otimes\ldots\otimes  M_n$ with the map $\sigma(T_1\otimes\ldots\otimes  T_n)=T_1\otimes\ldots\otimes  T_n\otimes\mtu$, and
\[ 
  \xymatrix{%
   A_n \ar[rr]^{\sigma}\ar[dr]_{\varphi_n}		&	&	A_{k+1}\ar[ld]^{\varphi_{k+1}}\\
   &							A
}
\]
with $\varphi_i(T_1\otimes\ldots\otimes  T_i)=T_1\otimes\ldots\otimes  T_i\otimes\mtu \otimes\ldots$, the space $A$ being the free vector space generated by the symbols $T_1\otimes\ldots\otimes  T_j\otimes\mtu\otimes\ldots$ 

Now an element of $H$ reads
\[ 
  \sum_{i=1}^{\infty}w_1^i\otimes\ldots\otimes  w_{k_i}^i\otimes v_{k_i+1}^i\otimes\ldots
\]
with $w_l^i\in\hH_l$, and we act on it by an element of $A$ by
\begin{equation}
\begin{split}
\pi(T_1\otimes\ldots\otimes T_k\otimes\cun\otimes\ldots)\big( \sum_{i=1}^{\infty} w_1^i\otimes&\ldots\otimes w_{k_i}^i\otimes v_{k_i+1}^i\otimes\ldots \big)\\
		&=	\sum_{i=1}^{\infty}T_1w_1^i\otimes\ldots\otimes T_{k_i}w_{k_i}^i\otimes v_{k_i+1}^i\otimes\ldots
\end{split}
\end{equation}
where some of the $T_j$ are subject to actually be $\mtu$. We are now going to prove that the strong closure of $\pi(A)$ is $\oB(H)$. Let $E$ be the set of finites sets of elements of the form $w_1\otimes\ldots\otimes  w_k\otimes v_{k+1}\otimes\ldots$ and the directed set $I=E\times ]0,\infty[$.

\begin{probleme}
I'm not sure of the next affirmation.
\end{probleme}

Let $T\in\oB(H)$. For each $(F,\epsilon)\in E$, there is a $T_{(F,\epsilon)}\in\pi(A)$
\begin{equation}
\| T_{(F,\epsilon)}X_k-TX_k \|<\epsilon
\end{equation}
for all $X_k\in F$. In that case, the limit of the net $(F,\epsilon)\to T_{(F,\epsilon)}$ is $T$, which shows that the strong closure of $\pi(A)$ is $\oB(H)$.

So that example does not provide new example of von~Neumann algebra.
\begin{proposition}
Let $V_k=\eC^{n_k}$ endowed with the standard representation of $\eM_{n_k}(\eC)$. Then the representation $\pi\colon \bigotimes_k \eM_{n_k}\to \oB\big( \bigotimes_k(V_k,v_k) \big)$ fulfils 
\[ 
  \big( \pi(M) \big)''=\oB\big( \bigotimes_k(V_k,v_k) \big)
\]
where $M=\bigotimes_k\eM_{n_k}$.
\end{proposition}

\begin{proof}
No proof.
\end{proof}

Notice that $\bigotimes_{1}^{\infty}\eM_{n_k}$ can differ from $\bigotimes_{1}^{\infty}\eM_{n'_k}$ when the $n_k$ and $n'_k$ do not agree. In fact, we have
\[ 
\bigotimes_{1}^{\infty}\eM_{n_k} =\bigotimes_{1}^{\infty}\eM_{n'_k}
\]
if and only if $\prod_k n_k=\prod_k n'_k$ in the sense of generalised products: each prime factor arise the same number of time in both side. For example, $\eM_2\otimes\eM_2\otimes\ldots=\eM_4\otimes\eM_4\otimes\ldots\neq \eM_3\otimes\eM_3\otimes\ldots$.

Take for example $V_k=\eC^2$ for every $k$ and then $v_k=v$, $v'_k=v'$. In this case, the representations $\pi$ and $\pi'$ are equivalent if and only if $v=\lambda v'$. This provides an Hilbert sphere of inequivalent irreducible representations.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Continuous dimensions}

Let $\cA$ be a $*$-algebra with a faithful state $\varphi$ defining the inner product $\langle a, b\rangle =\varphi(a^*b)$. We define a representation $\rho$ of $A$ on itself by $\rho(a)b=ab$.

Let us take the situation and the notations of proposition \ref{Propstaretattraces}, and for $n=2$, consider the choice 
\[ 
  s_{\lambda}=
\begin{pmatrix}
\lambda/(1+\lambda)\\
		&		1/(1+\lambda)
\end{pmatrix}
\]
with $0\leq\lambda\leq 1$.

Let $M=\bigotimes_1^{\infty}\eM_2(\eC)$ and consider the positive continuous form $\varphi_{\lambda}$ on $M$ defined by
\begin{equation}
\varphi_{\lambda}(a_1\otimes a_2\otimes\ldots\otimes a_k\otimes\mtu\otimes\ldots)=\varphi_{\lambda}(a_1)\varphi_{\lambda}(a_2)\ldots=\tr(a_1s_{\lambda})\tr(a_2s_{\lambda})
\end{equation}
Notice that the product is finite because from a certain point, $a_i=\mtu$. It is on the other hand not difficult to see that the $\varphi_{\lambda}(a)=0$ only if $a_i=0$ for every $i$. The purpose now is to follow the GNS construction of proposition \ref{PropGNSanother}. The remark we just made says that there is no ideal to quotient with in order to have the Hilbert space of representation.

The representation of $\cA$ we get is the simple $\rho(a)b=ab$ of $\cA$ on its completion. Let $M_{\lambda}$ be the double commutant in this representation. 

\begin{theorem}[Powers]
The von~Neumann algebra $M_{\lambda}$ are all distinct for different values of $0\leq\lambda\leq 1$.
\end{theorem}
\begin{proof}
No proof.
\end{proof}

Let us see an example of that result. When $\lambda=0$, we get the standard representation of matrices on $\eC^n$, so that $M_0=\oB(\hH)$. When $\lambda=1$, we can show that 
\[ 
  \tr(T)=\langle V, TV\rangle 
\]
where $V=v\otimes v\otimes\ldots\otimes v\otimes\ldots$ is a trace on $M_1$ while there does not exist any trace on $\oB(\hH)$. We conclude that $M_1\neq M_0$.

%++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Cantor}

Let $M=\bigoplus_{k=1}^{\infty}M_k$ with $M_k=\eM_{n_k}(\eC)$ that can be seen as $\Span\{ T_1\otimes\ldots \}$ with $T_k=\mtu$ for sufficiently large $k$. Now take the case $n_k=2$ for all $k$. The algebra $M$ naturally acts on the space of locally constant functions on the Cantor set.

More generally, for arbitrary $n_k$, one can think of $M$ as an algebra of endomorphisms of the space of locally constant functions on $\prod\eZ_{n_k}$.
\begin{probleme}
Still to be developed.
\end{probleme}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
					\section{More general state}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Let $\varphi_i$ be state on $M_i$. We define 
\begin{equation}
\begin{aligned}
 \varphi\colon M&\to \eC \\ 
   T_1\otimes T_2\otimes\ldots&\mapsto \varphi_1(T_1)\varphi_2(T_2)\ldots 
\end{aligned}
\end{equation}
where the product is finite because $T_k=\mtu$ for sufficiently large $k$. One can prove that $\varphi$ fulfills
\begin{enumerate}
\item $\varphi(\mtu)=1$,
\item $\varphi(T^*T)\geq 0$,
\item\label{enuitemvarpsdex} $\varphi(T^*S^*ST)=\| S \|^2\varphi(T^*T)$,
\end{enumerate}
so that $\varphi$ is in particular a state on $M$. The norm $\| S \|$ is the following. We know that $S\in\bigotimes_1^NM_k\subseteq M$ but, by construction, $\bigotimes_1^NM_k=\End(\eC^{n_1}\otimes\ldots\otimes \eC^{n_N})$. The norm of $S$ is taken as the operator norm in the sense of that endomorphism space.

The property \ref{enuitemvarpsdex} shows that the multiplication by $S$ is a bounded operator. We can build the GNS representation and define $M_{\varphi}$ to be $M''$ is that representation.

\begin{definition}
A \defe{factor of type $II_1$}{factor!of type $II_1$} is an infinite dimensional factor $M$ which accepts a non vanishing linear functional $\tr\colon M\to \eC$ such that
\begin{itemize}
\item $\tr(ST)=\tr(TS)$,
\item $\tr(T^*T)\geq 0$,
\item the function $\tr$ is continuous for the ultraweak topology.
\end{itemize}
\end{definition}


%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
					\section{Group measure space construction}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Let $(X,\mu)$ be a measured space that we assume to be $\sigma$-finite, and $G$, a discrete countable group acting on $X$ in such a way that for every $g\in G$,
\begin{enumerate}
\item if $E\subset X$ is measurable then $gE$ is measurable,
\item if $\mu(E)=0$, then $\mu(gE)=0$.
\end{enumerate}
We do not impose the action to preserve the measure. As an example we take $G\subset\SL(2,\eR)=\left\{ \frac{ ax+b }{ cx+d } \right\}$ acting on $\eR\cup\{ \infty\}=\eR P^1$.

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{First attempt}
%---------------------------------------------------------------------------------------------------------------------------

Take $L^2(X,\mu)$ as Hilbert space and, to $f\in  L^{\infty}(X,\mu)$, we associate the pointwise multiplication operator $M_f\colon  L^2(X,\mu)\to  L^2 (X,\mu)$. We also introduce the new measure $g\mu$ by
\begin{equation}
		(g\mu)(E)=\mu(g^{-1}E),
\end{equation}
and the action of $G$ on the functions by
\begin{equation}
		(gf)(x)=f(g^{-1}x).
\end{equation}
So we have
\begin{equation}
		\int_X (gf)(x)d(g\mu)(x)=\int_X f(x)d\mu(x).
\end{equation}

Notice that if $f\in L^{\infty}(X,\mu)$, we have $gf\in L^{\infty}(X,\mu)$, but when $f\in  L^2$, there are no guarantee that $gf\in  L^2$.

Let $\mu_1$ and $\mu_2$ be two measures on the set $X$. One says that $\mu_2$ is \defe{absolutely continuous}{absolutely continuous} with respect to $\mu_1$ if every $\mu_1$ null set is $\mu_2$ null.

\begin{theorem}[\href{http://en.wikipedia.org/wiki/Radon-Nikodym_theorem}{Radon-Nikod\'ym}]		\label{ThoRadonNikodym}\index{Radon-Nikod\`ym theorem}
Let $\mu_1$ and $\mu_2$ be two $\sigma$-finite measures on $X$. The measure $\mu_2$ is absolutely continuous with respect to $\mu_1$ if and only if there exists a measurable positive function $f$ such that $\mu_2=f\mu_1$.
\end{theorem}

The useful statement in our case is:
\begin{proposition}
There exists an unique function 
\[ 
	\frac{ d f\mu }{ d \mu }\colon X\to ]0,\infty[
\]
such that
\begin{equation}	\label{EqDefRadonNiko}
		\int (gf)(x)\left( \frac{ d g\mu }{ d \mu } \right)(x)d\mu(x)=\int (gf)(x)d(g\mu)(x)=\int f(x)d\mu(x).
\end{equation}
\end{proposition}
Applying $g^{-1}$ to the function $(gf)(x)\left( \frac{ d g\mu }{ d \mu } \right)(x)$ and applying the theorem, we see that for every function $f$, we have
\[ 
  \int f(x)\left( \frac{ d g\mu }{ d \mu } \right)(gx)\left( \frac{ d g^{-1}\mu }{ d \mu } \right)(x)=\int f(f)d\mu(x),
\]
so that
\begin{equation}
  \left( \frac{ d g\mu }{ d \mu } \right)(gx)\left( \frac{ d g^{-1}\mu }{ d \mu } \right)(x)=1.
\end{equation}

Using the function provided by that theorem, we define
\begin{equation}
\mU_gf=(gf)\cdot\left( \frac{ d g\mu }{ d \mu } \right)^{\frac{ 1 }{2}},
\end{equation}
so that $\| \mU_gf \|_{ L^2(X,\mu)}=\| f \|_{ L^2(X,\mu)}$. Moreover we have the following two important relations
\begin{enumerate}
\item $\mU_g\mU_h=\mU_{gh}$,
\item $\mU_g M_f \mU_g^{-1}=M_{gf}$
\end{enumerate}
where $M_f$ stands for the operator of pointwise product with $f$. The second relation implies $\mU_g M_f=M_{gf}\mU_g$, thus we have
\begin{equation}
M:=\{ M_f,\mU_g \}''=\{ \sum_{i=1}^n M_{f_i}\mU_{g_i} \}
\end{equation}
(because the double commutant is the strong closure) which is a $*$-algebra of operators. Notice that $\mU_g\mU_g^*=1$ because $\mU_g$ is an isometry.

We say that an action $G\times M\to M$ is \defe{ergodic}{ergodic} when $gf=f$ for every $g\in G$ implies that $f$ is constant almost everywhere.

\begin{lemma}		\label{LemergoBLCmu}
If the action $G\times X\to X$ is ergodic, then $M=\oB\big(  L^2(X,\mu) \big)$.
\end{lemma}

\begin{proof}
Let us first study the commutant $\{ M_f,\mU_g \}'$ which is of course contained in $\{ M_f \}'$. But we know that the commutant of $ L^{\infty}(X,\mu)$ is $ L^{\infty}(X,\mu)$, so that
\[ 
  \{ M_f \}'=\{ M_f\tq f\in L^{\infty}(X,\mu) \}.
\]
Is there an element in $ L^{\infty}(X,\mu)$ which commutes with all the elements of the form $\mU_g$, or in other words, is there a $f\in  L^{\infty}(X,\mu)$ such that $M_f=\mU_g M_f\mU_g^*=M_{gf}$ ? The only element $f$ such that $M_f=M_{gf}$ for every $g\in G$ is $f=1$, since the action is ergodic.
\end{proof}

That lemma shows that we didn't construct any interesting von~Neumann algebras in the ergodic case.

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Second attempt}
%---------------------------------------------------------------------------------------------------------------------------

Let $H= L^2(X\times G,\mu)$. Notice that $G\times X$ is nothing else than a countable number of copies of $X$, on which each of them we consider the measure $\mu$. The multiplication operator is now replaced by
\begin{equation}
\begin{aligned}
 M_f\colon H&\to H \\ 
   (M_f\varphi)(x,h)&=f(x)\varphi(x,h),
\end{aligned}
\end{equation}
and the unitary operator $\mU_g$ is replaced by
\begin{equation}
\begin{aligned}
 \mU_g\colon H&\to H \\ 
   (\mU_g\varphi)(x,h)&=\varphi(g^{-1}x,g^{-1} h)\left( \frac{ d g\mu }{ d \mu } \right)^{\frac{ 1 }{2}}(x)
\end{aligned}
\end{equation}
The introduction of the Radon-Nikod\'ym function serves to preserve the norm. The so defined operators have the following properties:
\begin{enumerate}
\item $\mU_g M_f\mU_g^*=M_{gf}$,
\item $\mU_g\mU_h=\mU_{gh}$,
\item $\mU_g^{-1}=\mU_{g^{-1}}=\mU_g^*$.
\end{enumerate}
Now we define
\begin{equation}
   M(G,X)=\{ \mU_g,M_f \}''=\{ \sum_{i=1}^nM_{f_i}\mU_{g_i} \},
\end{equation}
 and we will show (later) that
\begin{theorem}
If the action is ergodic, then $M(G,X)$ is a factor.
\end{theorem}
\begin{proof}
No proof up to now.
\end{proof}
We emphasize the progress: lemma \ref{LemergoBLCmu} says that the commutant is trivial while now the center only is trivial.

As an example, take $X=S^1\subset \eC$ and $G=\eZ$, the action being $g\cdot z= e^{2\pi i\theta g}z$ for some irrational $\theta$. One can prove, using Fourier transform, that this equation is ergodic.

Let us now define
\begin{equation}
\begin{aligned}
  \varphi\colon M(G,X)&\to \eC \\ 
   T&\mapsto \langle f_0, Tf_0\rangle  
\end{aligned}
\end{equation}
where $f_0\in  L^2(X\times G,\mu)$ is defined as follows
\[ 
  f_0(g,x)=
\begin{cases}
\mu(X)^{-2}		&\text{if $g=e$}\\
0			&\text{otherwise.}
\end{cases}
\]
We show that the so defined $\varphi$ is a trace over $M(G,X)$, i.e. it satisfies $\varphi(TS)=\varphi(ST)$ for every $S$, $T\in M(G,X)$. We know that $M(G,X)$ is generated by expressions of the form $L_f\mU_g$. When $g\neq e$, the functions $f_0$ and $\mU_gf_0$ have disjoint support, so that $\varphi(M_f\mU_g)=0$. If $g=e$, the computation is easy and we finally find
\begin{equation}
  \varphi(M_f\mU_g)=
\begin{cases}
\frac{1}{ \mu(X) }\int_X f(x)d\mu(x)		&\text{if $g=e$}\\
0						&\text{if $g\neq e$}.
\end{cases}
\end{equation}
It is easy to check that this expression is a trace on $\{ \sum_iM_{f_i}\mU_{g_i} \}$. Since $\oB(H)$ has no trace, we know that $M(G,X)$ is a non trivial von~Neumann algebra. Stated in a different way, what we just proved is that, provided that $\mu$ is a $G$-invariant \defe{probability measure}{probability!measure} (i.e. $\mu(X)=1$), the formula
\begin{equation} 		\label{Eqvpmupickid}
  \varphi_{\mu}\big( \sum_{h\in G} M_{f_h}\mU_h \big)=\int_X f_e(x)d\mu(x).
\end{equation}
extends to a trace state on $M(G,X)$.

\begin{proposition}
If $\mu$ is not invariant (but still $\mu(X)=1$), then $\varphi_{\mu}$ is still a state, but no more a trace.
\end{proposition}

\begin{proof}
By definition, $\varphi_{\mu}(T)=\langle f_0, Tf_0\rangle $ where $f_0(e)=1$ and $f_0(g)=0$ otherwise. We have
\begin{align*}
\varphi_{\mu}\Big( \big( \sum M_{f_h}\mU_h \big)^*\big( \sum M_{f_h}\mU_h \big) \Big)&=\varphi_{\mu}\Big( \sum_{h_1,h_2}\mU_{h_1}^*M_{f_{h_1}}^*M_{f_{h_2}} \mU_{h_2} \Big)\\
		&=\varphi_{\mu}\Big( \sum_{h_1,h_2}  M_{f_{h_1}}^*M_{f_{h_2}}\mU_{h_1^{-1}}\mU_{h_2} \Big)
\end{align*}
because $\mU_g^*=\mU_g^{-1}=\mU_{g^{-1}}$ commutes with the $M_f$. Now, according to the expression \eqref{Eqvpmupickid}, the function $\varphi_{\mu}$ pick up the identity component and integrates. So we have
\begin{align*}
\varphi_{\mu}\Big( \big( \sum M_{f_h}\mU_h \big)^*\big( \sum M_{f_h}\mU_h \big) \Big)&=\sum_{h}\int_X h^{-1}(f^*_hf_h)d\mu\\
							&=\sum+h\int_X| f_h |^2(h^{-1}x)d\mu(x)\geq0.
\end{align*}

\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{First generalisation}
%---------------------------------------------------------------------------------------------------------------------------

Let us replace the space $ L^{\infty}(X,\mu)$ by any von~Neumann algebra $N$ of operators on the Hilbert space $\hH$. As Hilbert $H$ space we take the completion of $\hH\times l^2(G)$ and we assume to have an action of $G$ over $N$. We know that the metric of a $C^*$-algebra is determined by its algebra structure, so that the action must be isometric. We assume the action to be \emph{via} strongly continuous automorphisms. We have $H\otimes l^2(G)=l^2(G,H)$. For $t\in N$, we define 
\[ 
  (M_T\varphi)(g)=g^{-1}(T)\varphi(g)
\]
where $\varphi\in l^2(GmH)$. We also define
\[ 
  (\mU_h\varphi)(g)=\varphi(h^{-1}g).
\]
Notice that the group does not act on $H$ while in the previous constructions, it did act on $X$. We still have the relation
\begin{equation}
\mU_hM_T\mU_h^*=M_{hT}.
\end{equation}
Now, we form the von~Neumann algebra
\begin{equation}
M(G,N)=\{ \mU_h,M_T \}''.
\end{equation}

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Second generalisation}
%---------------------------------------------------------------------------------------------------------------------------

Now we replace the discrete group $G$ by a second countable locally compact topological group. Typical examples are $(\eR,+)$ or the group ``$ax+b$'' generated by matrices of the form $\begin{pmatrix}
a&b\\0&1
\end{pmatrix}$ with $a>0$ and $b\in \eR$, acting on the real line by affine transformations. Each such group has an unique (up to constant multiple) Borel measure $m$ such that each compact set has finite measure and which is in the same time the Haar measure: for every compactly supported functions on $G$,
\[ 
  \int_G f(hg)dm(g)=\int_G f(g)dm(g).
\]
The measure on ``$ax+b$'' is $dm=\frac{1}{ a^2 }da\,db$.

We consider on $G\times N$ the product topology and we assume the action $G\times N\to N$ to be strongly continuous. Now, we proceed as before: we take the Hilbert space $H$ the completion of
\[ 
  \hH\otimes  L^2(G,m)=L^2(G,\hH),
\]
and $M_T$ is defined by the same formulas as before. The von~Neumann algebra that we obtain is denoted by $M(G,N)$.

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{One particular case}
%---------------------------------------------------------------------------------------------------------------------------
\label{sssOnePartCaseMG}

Take a discrete group $G$, so that $M(G)$ is generated by the operators $\mU_g\in\oB\big( l^2(G) \big)$ who are defined by
\begin{equation}
		(\mU_h\varphi)(g)=\varphi(h^{-1}g).
\end{equation}
Consider the function
\begin{equation}
		f_e(g)=
\begin{cases}
1		&\text{if $g=e$}\\
0		&\text{otherwise.}
\end{cases}
\end{equation}
We have 
\[ 
  (\mU_hf_e)(g):=f_h(g)=
\begin{cases}
1		&\text{if $g=h$}\\
0		&\text{otherwise,}
\end{cases}
\]
so that $\{ f_h \}$ is an orthonormal basis of $l^2(G)$ and $\mU_{h_1}f_{h_2}=f_{h_1h_2}$. We conclude that $\mU_h$ is a permutation of the basis vectors. 

\begin{proposition}		\label{ProplDeuxGFGP}
The module $l^2(G)$ over $M(G)$ is projective and finitely generated.
\end{proposition}

\begin{proof}
The fact that $l^2(G)$ as module over $M(G)$ is finitely generated comes from the fact that $f_e$ by itself generates the basis $\{ f_h \}$ as we just said. 

In order to prove that the module is projective, we will prove the condition \ref{ItemTroisCarecterisationProjectif} of proposition \ref{PropEquivProjModule}. Let $\modM$ be a $M(G)$-module and $\rho\colon \modM\to l^2(G)$ be a surjective module map. Consider any $\xi\in\modM$ such that $\rho(\xi)=f_e$, define $s(f_e)=\xi$ and extend by linearity and action of $M(G)$. The so defined map $s$ obviously fulfils $\rho\circ s=\id|_{l^2(G)}$.
\end{proof}

\begin{probleme}
That statement and the proof are correct uhm ? I use them on page \pageref{PglDeuxGFGPutiliseIci}.
\end{probleme}

For each $S\in M(G)'$, we define $f_S=S(f_e)\in l^2(G)$. Now if $S\in M(G)\cap M(G)'$, we have
\begin{enumerate}
\item $S\mU_h=\mU_hS$,
\item $S\mU_hf_e=\mU_hS f_e$.
\end{enumerate}
The operators $W_k$ defined by
\[ 
  (W_kf)(g)=f(gk)
\]
commute with $\mU_h$. So they commute with $M(G)$ and with $S$. Therefore we have
\[ 
  W_kSf_h=SW_kf_h=Sf_{hk^{-1}},
\]
and taking $h=k$, we find
\begin{equation}
  f_S(hg)=f_S(gh)
\end{equation}
for every $g$, $h\in G$. That means that $f_S$ is constant on the conjugacy classes because $g$ and $hgh^{-1}$ are two elements of the form $g_1g_2$ and $g_2g_1$ with $g_1=h$ and $g_2=gh^{-1}$.

If $G$ has no finite conjugacy class (except $\{ e \}$), then $f_S$ has to be a multiple of $f_e$ because its norm would contains infinitely many constant non zero terms. But when $S_1$ and $S_2$ belongs to $M'(G)$ with $f_{S_1}=f_{S_2}$, then $S_1=S_2$ because $S_1f_h=S_1\mU_hf_e=\mU_1S_1f_e=\mU_hf_{S_1}$, while the same computation with $S_2$ gives $S_2 f_h=\mU_hf_{S_2}$. So $S_1$ and $S_2$ agree on a basis.

For this reason, if we assume that $G$ has infinite conjugacy class, we have $M(G)'\cap M(G)=\eC\mtu$. The most famous example of such a group is $G=F_k$, the group of formal words of $1\ldots k$ with $k>1$.

Now fix an element of finite order $h\in G$, and the natural homomorphism $\eZ\to G$ given by $n\mapsto h^n$. The group $G$ has a natural equivalence relation $g_1\sim g_2$ if and only if there exists a $n\in\eZ$ such that $g_1=g_2^n$. We denote by $G/\eZ$ the quotient of $G$ by this relation. One class of this space is
\[ 
  \eZ_{g}=\{ g^n\tq n\in\eZ \},
\]
and we have
\begin{equation}
l^2(G)=\bigoplus_{g\in G/\eZ}l^2(\eZ_g).
\end{equation}
The operator $\mU_g$ acts on $l^3(\eZ_g)$ by translation: $\mU_gg^n=g^{n+1}$. Now we fix a $g\in G$ and we make the identifications
\begin{equation}
l^2(\eZ_g)\simeq l^2(\eZ)\simeq L^2(S^1),
\end{equation}
the latter identification being given by the Fourier series of a function on the circle (seen as a periodic function on $\eR$). In that framework, $\mU_g$ acts by translation of $1$ on $l^2(\eZ)$:
\[ 
  \mU_g(x_i)_{i\in\eN}=(x_i+1)_{i\in\eN}.
\]
A function $f\in C(S^1)$ is bounded (since $S^1$ is compact), to that if $s\in L^2(S^1)$, the product function $(fs)$ still belongs to $L^1(S^1)$ and then corresponds to an element of $l^2(S^1)$. Thus we have a map
\[ 
  C(S^1)\to\oB\big( l^2(\eZ_g) \big).
\]
If one acts separately on each of the ``fixed'' $g$, we obtain an action
\[ 
  C(S^1)\to\oB\big( \bigoplus_{g\in G/\eZ}l^2(\eZ_g) \big).
\]
We define the operator $\mU\in \bigoplus_{g\in G/\eZ}l^2(\eZ_g)  $ as acting on $l^2(\eZ_g)$ with $\mU_g$. That allows us to consider
\begin{equation}
\begin{aligned}
 C(S^1)&\to M(G) \\ 
   z^n&\mapsto \mU^n 
\end{aligned}
\end{equation}
that can be composed with the trace $\varphi$ to give
\[ 
  f\mapsto\int_{S^1} f(z)dm(z)
\]
for each $f\in C(S^1)$.


%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
					\section{More about projections}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Let $M$ be a von~Neumann algebra and $p$, $q$, two projections in $\oB(\hH)$. We define\nomenclature[O]{$p\vee q$}{The smallest projection bigger than $p$ and $q$}\nomenclature[O]{$p\wedge q$}{The biggest projection smaller than $p$ and $q$}
\begin{align}
p\vee q		&=\text{projection onto $\overline{ \Image(p)+\Image(q) }$}\\
p\wedge q	&=\text{projection onto $\Image(p)\cap\Image(q)$}
\end{align}
A projection is determined by the closed space of its range, so one can order the projection by ordering the closed subspace of $\hH$.

\begin{lemma}		\label{LemDimSupDeuxProjs}
We have
\begin{equation}
	\dim(R_1\vee R_2)=\dim R_1+\dim R_2-\dim(R_1\wedge R_2)
\end{equation}
for any two projections $R_1$ and $R_2$ in $M$.
\end{lemma}

\begin{proof}
Left as an exercise. 
\end{proof}

For two projections $p$ and $q$, we write that $p\preceq q$\nomenclature[C]{$p\preceq q$}{A partial ordering notion over the projections of a von~Neumann algebra} if there exists a partial isometry $V$ such that
\begin{enumerate}
\item $V^*V=p$,
\item $VV^*\leq q$.
\end{enumerate}
One proves that this determines a partial ordering on the projections.

\begin{proposition}
If $p$ and $q$ belong to $M$, then the projections $p\vee q$ and $p\wedge q$ belong to $M$ too.
\end{proposition}

\begin{proof}
There exists an unitary representation $\pi\colon G\to \End(\hH)$ whose $M$ is the commutant: $M=\pi(G)'$ by lemma \ref{LemVNCommunit}. Since $p$ is a projection, proposition \ref{PropprojrepresVN} says that $p\hH$ is an invariant subspace of $\pi(G)$. The same being true for $q$, we have that the spaces $\overline{ \Image(p)+\Image(q) }$ and $\Image(p)\cap\Image(q)$ are invariant too. Now the proposition \ref{PropprojrepresVN} assures that the corresponding projections (namely $p\vee q$ and $p\wedge q$) are part of $M$.
\end{proof}

Before to define the infinite case $p_1\vee p_2\vee\ldots$, we need a lemma.

\begin{lemma}
If $\{ T_{\alpha} \}$ is a net of selfadjoint bounded operators such that
\begin{enumerate}
\item $\sup_{\alpha}\| T_{\alpha} \|<\infty$,
\item if $\alpha >\beta$, then $\langle v, T_{\alpha} v\rangle >\langle t, T_{\beta} v\rangle $ for every $v\in\hH$.
\end{enumerate}
Then $\{ T_{\alpha} \}$ strongly converges to an operator $T$, see condition \eqref{EqDEflimforte}.
\end{lemma}

\begin{proof}
We want the limit $T$ to fulfil $\langle v, Tv\rangle =\lim_{\alpha\to\infty}\langle v, T_{\alpha} v\rangle$. From weak-compactness of the unit ball, that formula defines the quadratic form $Q(v)=\lim_{\alpha\to\infty}\langle v, T_{\alpha} v\rangle $ with $\| v \|=1$. The form $Q$ is then defined on the whole space $\hH$ by homogeneity: $Q(\lambda v)=\lambda^2 Q(v)$. The polarization identity\index{polarization!identity}
\[ 
  4\Reel\langle v, T_{\alpha} w\rangle =\langle (v+w), T_{\alpha}(v+w)\rangle -\langle (v-w), T_{\alpha}(v-w)\rangle 
\]
defines $Q(v,w)$ and then defines the value of $\langle v, Tw\rangle $ for every $v$ and $w$. This is the candidate to be the strong limit of $T_{\alpha}$. The question is now to know if this is an actual strong limit.

Since the net is increasing, we have $\langle v, (T-T_{\alpha})v\rangle \geq0$, so that $T-T_{\alpha}$ is positive which implies that $(T-T_{\alpha})^{1/2}$ is well defined. We have
\[ 
  \| (T-T_{\alpha})^{1/2}v \|=\langle v, (T-T_{\alpha})v\rangle \to 0,
\]
so that the strong limit of $(T-T_{\alpha})^{1/2}$ is zero. 

It is not true in general that, in the strong topology, $a_{\alpha}\to a$ and $b_{\alpha}\to b$ imply $a_{\alpha} b_{\alpha}\to ab$. But it is true when $a_{\alpha}$ and $b_{\alpha}$ are contained in a ball. Since $\sup \| T-T_{\alpha} \|^{1/2}<\infty$, we can thus make
\[ 
  \slim(T-T_{\alpha})=\slim\big( (T-T_{\alpha})^{1/2} \big)^2=0.\quad \slim_{a\to 0}f(a)
\]
\end{proof}
In short, that lemma claims that $M$ contains the limits of all bounded increasing nets of selfadjoint operators. In particular, for a net of projections $P_{\alpha}\in M$ with $\alpha\in X$,
\begin{align*}
	\bigvee_{\alpha}P_{\alpha}&\in M,&
	\Wedge_{\alpha}P_{\alpha}&\in M.
\end{align*}

\begin{proposition}
Let $\{ P_{\alpha} \}$ and $\{ Q_{\alpha} \}$ to be two nets of projectors on the same directed set, and suppose that we have operators $T_{\alpha}\colon \Image(P_{\alpha})\to \Image(Q_{\alpha})$ such that
\begin{enumerate}
\item $\sup_{\alpha}\| T_{\alpha} \|<\infty$,
\item $\left.T_{\alpha}\right|_{\Image(P_{\beta})}=T_{\beta}$,
\end{enumerate}
then there exists an operator $T\colon \Image\big(\bigvee_{\alpha} P_{\alpha}\big)\to \Image\big(\bigvee_{\alpha}Q_{\alpha}\big)$  with
\[ 
  T|_{\Image(P_{\alpha})}=T_{\alpha}.
\]
If moreover $P_{\alpha}$, $Q_{\alpha}$ and $T_{\alpha}$ belong to $M$, then $T\in M$.
\end{proposition}

\begin{proof}
No proof.
\end{proof}

\begin{probleme}
I think that $p_1\vee p_2\vee \ldots$ is now well defined when $p_i$ are projections. Indeed, the projections $P_k=p_1\vee \ldots p_k$ form a net and, by the proposition, the limit belongs to $M$. More generally, if $A$ is a set of projections, for $\bigvee_{p\in A}p$, one considers the set of parts of $A$ (which is partially ordered) and then the net $p_{\alpha}=\bigvee_{p\in\alpha}p$ where $\alpha$ is a part of $A$.

Now, one has to understand why the result is still a projection.
\end{probleme}


\begin{lemma}		\label{LemPTQnnzero}
Let $M$ be a factor. If $P$ and $Q$ are nonzero projections in $M$, then there is a $T\in M$ such that $PTQ\neq 0$.
\end{lemma}

\begin{proof}
Let $U(M)$ be the unitary group of $M$. We saw that if $T$ commutes with $U(M)$, then it commutes with all $M$. Assume that $PTQ=0$ for every $T\in M$, then in particular it holds for $T=U\in U(M)$ and we have $UPU^*Q=0$.

Consider the operator $R=\bigvee_{U\in U(M)}UPU^*$ which is a projection in $M$. Since the set $\{ UPU^*\tq U\in U(M) \}$ is invariant under the adjoint action of $U(M)$, we have $URU^*=R$, or $UR=RU$ for every $U\in U(M)$. That proves that $R\in M'$. So $R\in M\cap M'$ and is thus a multiple of identity by the fact that $M$ is a factor: $R=\id$ (the multiple has to be $1$ because $R$ is a projection).

We said, on the other hand, that $UPU^*Q=0$, which means that the range of $UPU^*$ is orthogonal to the one of $Q$ for every $U\in U(M)$, so that the range of $R$ has to be orthogonal too. That contradicts the fact that $R$ is a multiple of identity.
\end{proof}

\begin{lemma}		\label{LemVVPVVQfactreu}
Let $M$ be a factor and $P$, $Q$ two nonzero projections in $M$, then there exists a nonzero partial isometry $V\in M$ such that $V^*V\leq P$ and $VV^*\leq Q$.
\end{lemma}

\begin{proof}
Let $T$ be such that $PTQ\neq 0$ (by lemma \ref{LemPTQnnzero}), and $V$ be the partial isometry part of $QTP$. The image of $V^*V$ is at most the one of $QTP$ which is smaller (or equal) to the image of $Q$, so $V^*V\leq Q$. For the same reason, the image of $VV^*$ is contained in $P^*T^*Q^*\hH=PY^*Q\hH\subseteq\Image(P)$. Then $VV^*\leq P$.
\end{proof}

\begin{proposition}
Let $M$ be a factor and $P$, $Q$ two nonzero projections in $M$, then there exists a nonzero partial isometry $V\in M$ such that 
\begin{enumerate}
\item $V^*V\leq P$,
\item $VV^*\leq Q$
\end{enumerate}
and either $V^*V=P$, or $VV^*=Q$ or both.
\end{proposition}

\begin{proof}
Let $X$ be the set of partial isometries $V$ such that $V^*V\leq P$ and $VV^*\leq Q$. We write $P_V=V^*V$ and $Q_V=VV^*$. We define a partial ordering on $X$ by $V_1\leq V_2$ if $P_{V_1}\leq P_{V_2}$, $Q_{V_1}\leq Q_{V_2}$ and $V_2P_{V_1}=V_1$. In that case, $V_2$ is some kind of extension of $V_1$.

If one considers an increasing sequence $V_1\leq V_2\leq\ldots$, the Zorn's lemma assures the existence of a $V$ bigger than all the elements of the sequence. We claim that this $V$ is the solution of the proposition. Indeed, suppose $V^*V\neq P$ and $VV^*\neq Q$. Then the operators $P'=P-V^*V$ and $Q'=Q-VV^*$ are nonzero projections. Now, lemma \ref{LemVVPVVQfactreu} provides a partial isometry which contradicts maximality of $V$.
\end{proof}

The \defe{dimension}{dimension!of a von~Neumann algebra} of the von~Neumann algebra $M$ is the set of equivalence class of projections in $M$. This is a linearly ordered set.

Let $M=M(G)$ where $G$ is a group with only infinite conjugacy classes (but the one of identity). We saw that there is a trace $\tau\colon M\to \eC$, and that $\forall t\in[0,1]$, there exists a projection whose trace is $t$.

\begin{proposition}
If $T\geq 0$ is an element of $M$ such that $\tau(T)=0$, then $T=0$.
\end{proposition}

\begin{proof}
We know the injection $M\to l^2(G)$ defined by $T\mapsto f_T=Tf_e$. Since the right translation commutes with every $T_1$ (because $T_1(gf_e)=g(T_1f_e)$), we have $T_1f_g=0$ for every $g$ if $T_1f_e=0$. On the other hand,
\[ 
  \tau(T_1^*T_1):=\langle f_e, T_1^*T_1f_e\rangle =\| Tf_e \|^2
\]
which is positive. So if $\tau(T_1^*T_1)=0$, then $T_1f_e=0$, and so $T_1f_g=0$ which proves that $T_1=0$. This concludes the proof that $T\geq 0$ and $\tau(T)=0$ imply $T=0$ because every positive element reads as a product $T_1^*T_1$. 
\end{proof}

Now let define $\tau'\colon \dim M\to [0,1]$ by
\begin{equation}
	\tau'\big( [P] \big)=\tau(P).
\end{equation}
It is well defined because if $P\sim Q$, then we have a $u$ such that $P=uu^*$ and $Q=u^*u$, so that $\tau(P)=\tau(uu^*)=\tau(u^*u)=\tau(Q)$ by cyclic invariance of the trace. The map $\tau'$ preserves the order because $P-Q$ is positive when $P\geq Q$.

\begin{proposition}
The map $\tau'$ is a bijection
\end{proposition}

\begin{proof}
What we have to prove is that $P\sim Q$ if $\tau(P)=\tau(Q)$. Let $V^*V=P$ and $VV^*\leq Q$ and compute
\[ 
  \tau(Q-VV^*)=\tau(Q)-\tau(VV^*)=\tau(Q)-\tau(V^*V)=\tau(Q)-\tau(P)=0.
\]
The fact that $\tau(Q-VV^*)=0$ implies $Q-VV^*=0$, which in turn proves that $V$ implements the equivalence $P\sim Q$.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Comparison of projections}
%---------------------------------------------------------------------------------------------------------------------------

In this section we follow \cite{Wassermann}. Let $M$ be a von~Neumann algebra and $p$, $q$, two projectors. \defe{Equivalence of projectors}{equivalence of projectors}\label{PgEaivVNMurray}  is given by $p\sim q$\nomenclature[C]{$p\sim q$}{Equivalence of projectors} if there exists a partial isometry $u\in M$ such that $u^*u=p$ and $uu^*=q$. If $p$ is equivalent to a subprojection of $q$, we write $p\prec q$.

\begin{proposition}
If $p=\oplus_i p_i$ and $q=\oplus_iq_i$ are orthogonal sums of projectors with $p_i\sim q_i$, then $p\sim q_i$. If moreover $p_i\prec q_i$ for every $i$, then $p\prec q$.
\end{proposition}
\begin{proof}
No proof.
\end{proof}

Let $T\in\oB(\hH)$. The closed spaces $\overline{ \Image(T) }$ and $\overline{ \Image(T^*) }$ are the \defe{left support}{left!support} and \defe{right support}{right!support} of $T$.

\begin{theorem}
Let $T$ be an invertible operator, then it reads under the form
\[ 
  T=| T |U
\]
where $U$ is unitary. This decomposition is the unique one of the form $T=SU$ with $S$ positive and $U$ unitary.
\end{theorem}

\begin{proof}
Let $T=PU$, then $TT^*=PUU^*P=P^2$, then $P=\sqrt{TT^*}$ and then $U=P^{-1}T$. That proves unicity of the decomposition. For existence, we pose $U=(TT^*)^{-1/2}T$ and $P=(TT^*)^{1/2}$. Then we check
\begin{equation}
	UU^*=(TT^*)^{-1/2}TT^*(TT^*)^{-1/2}=\mtu.
\end{equation}
 Now, the operator $U$ is the product of two invertible operators, so that it is invertible. Thus the fact that $UU^*=\mtu$ forces $U^*U=\mtu$.
\end{proof}

When $T$ is not invertible, we have a weaker result of decomposition.
\begin{proposition}		\label{PropdecmbTbV}
Every $T\in\oB(M)$ can be written under the form
\[ 
  	T=| T |V
\]
 where $V\colon \overline{ \Image(T^*) }\to \overline{ \Image(| T |) }$ is a partial isometry whose final projection is the support of $| T |=\sqrt{TT^*}$.
\end{proposition}

\begin{proposition}
The left and right support of any operator in $\oB(\hH)$ are equivalent projections.
\end{proposition}

\begin{proof}
Let $T=| T |V$ be the decomposition of $T$ by proposition \ref{PropdecmbTbV}. By definition, $e=V^*V$ is a projection and we have $(1-e)V^*V(1-e)=0$ as can be checked by developing the expression and using $e^2=e$. Since $e=e^*$, the latter equation rewrites
\[ 
  \big( V(1-e) \big)^*\big( V(1-e) \big)=0,
\]
so that $V(1-e)=0$ and $Ve=V$ (we used lemma \ref{LemTTzepoT}). Now look at $f=VV^*$, we have
\[ 
  fV=VV^*V=Ve=V,
\]
so $f$ is a projection such that $fV=V$. We deduce that $V\colon e\hH\to f\hH$ is an isometry. The projectors $e$ and $f$ are the \defe{initial}{initial projection} and \defe{final}{final projection} \defe{projections}{projection!initial and final} of $V$.
\end{proof}
\begin{probleme}
This proof is not finished.
\end{probleme}

Using lemma \ref{LemkerTkersqrtT}, we have in particular
\begin{equation}
\overline{ \Image(T^*) }=(\ker T)^{\perp}=\big( \ker(T^*T)^{1/2} \big)^{\perp}=\Image(T^*T)^{1/2}.
\end{equation}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
					\section{Type I factor and factorization}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{lemma}		\label{LemPMPPMPprime}
Let $M$ be a von~Neumann algebra and $P\in M$, a projection. Then
\begin{equation}
(PM'P)'=PMP,
\end{equation}
and 
\begin{equation}		\label{EqLemPMPPMPprimedeux}
(PMP)'=PM'P
\end{equation}
where we see $PMP$ as an algebra of operators on $P\hH\subseteq\hH$. 
\end{lemma}

Let us give an intuitive argument with matrices before to give a proof. For the first claim, consider $M$ as the set of two by two matrices 
$
\begin{pmatrix}
a&b\\
c&d
\end{pmatrix}
$, and $P=
\begin{pmatrix}
1&0\\
0&1
\end{pmatrix}$. In that case, $PMP=\begin{pmatrix}
a&0\\
0&0
\end{pmatrix}$ while $M'=\{ \begin{pmatrix}
\alpha&0\\
0&\beta
\end{pmatrix}\}$ with $[\alpha,a]=0$. Thus we have $PM'P=\begin{pmatrix}
\alpha&0\\
)&0
\end{pmatrix}$.

For the second claim, suppose $Q\in(PNP)'$. We are looking for a $R\in M'$ such that $Q=PRP$. Notice that $Q$ itself does not belong to $M'$ in general. Take for example
\begin{align*}
M&=\begin{pmatrix}
\star&0&\star\\
0&\star&0\\
\star&0&\star\\
\end{pmatrix},		
&
P&=\begin{pmatrix}
1\\
&1\\
&&1
\end{pmatrix},
&
Q&=\begin{pmatrix}
1\\
&0\\
&&0
\end{pmatrix}.
\end{align*}
we have $M'=\begin{pmatrix}
a\\
&b\\
&&a
\end{pmatrix}$, so that $Q$ does not lie in $M'$, but
\[ 
  Q=P\begin{pmatrix}
1\\
&0\\
&&1
\end{pmatrix}P
\]
anyway. We see on that example that the matrix $R$ to be chosen is bigger than $Q$.
	
\begin{proof}[Proof of lemma \ref{LemPMPPMPprime}]
Let $Q\in (PMP)'$ and $R$ be the projection onto the closure of $MQ\hH$. The latter space being invariant under $M$, the projection $R$ belong to $M'$ by lemma \ref{LeminvarMprime}. We are now going to prove that $Q=PRP$. Since $P=P^2$ commutes with $R$, the operator $PRP$ is the projection onto the intersection of the target spaces of $R$ and $P$, because $PRP=PR=RP$. Therefore $Q$ is smaller than $P$, so that $MQ\hH=MPQ\hH$. That proves that $PRP$ is the projection on
\[ 
  PMQ\hH=PMPQ\hH=QPMP\hH=QP\hH=Q\hH
\]
where we used the fact that $Q\in(PMP)'$. That concludes the proof that $Q=PRP$.
\end{proof}

\begin{lemma}		\label{LemMapipsomPMmP}
If $M$ is a factor and $P$, a nonzero projection in $M$, then the map
\begin{equation}
\begin{aligned}
 M'&\to PM'P \\ 
   S&\mapsto PSP 
\end{aligned}
\end{equation}
is a $*$-algebra isomorphism.
\end{lemma}
 
\begin{proof}
The fact that the map is multiplicative and surjective is clear. The only point to prove is injectivity. So we will prove that $S=0$ under the assumption $SP=0$. We have $0=MSP=SMP$, so that $S$ vanishes on $MP\hH$.

The latter subspace is obviously invariant under $M$, but also under $M'$ because for every $S_1\in M'$, we have $S_1MP\hH=MPS_1\hH\subseteq MP\hH$. We conclude that the projection onto $MP\hH$ lies in $M'\cap M$. Hence that projection must be a multiple of the identity or zero. Since that space contains at least $P\hH$, the zero possibility is ruled out. Thus the projection onto $MP\hH$ is the identity and $MP\hH=\hH$. Now, $SMP=0$ implies $S=0$ which concludes the proof of the lemma.
\end{proof}

A projection $P\in M$ is a \defe{minimal projection}{minimal!projection}\index{projection!minimal} $P$ if if $0<Q\leq P$ implies $Q=P$. In other words, the projection $P$ is minimal if $PMP=\eC P$ because the projection onto $PMP$ is of course smaller or equal to $P$. A minimal projection is always finite, indeed, a projection $Q$ such that $Q\sim P$ and $Q\leq P$ (which exists when $P$ is infinite) contradicts minimality of $P$. 

\begin{definition}
Let $M$ be a factor. It is
\begin{itemize}
\item of \defe{type $I$}{type $I$ factor}\index{factor!of type $I$} if $M$ contains a non vanishing minimal projection,
\item of \defe{type $II$}{type $II$ factor}\index{factor!of  type $II$} if $M$ contains a non vanishing finite projection (and is not of type I)
\item of \defe{type $III$}{type $III$ factor}\index{factor!of type $III$} if no projection in $M$ is finite (but the vanishing one).
\end{itemize}
\end{definition}

A type $II$ factor is of \defe{type $II_1$}{factor!of type $II_1$} if it is finite and of \defe{type $II_{\infty}$}{factor!of type $II_{\infty}$} if it is not finite.

Let us now examine what are the type I factors.\label{PgtypeIonavu} Suppose that $M$ is a factor of type I and $P\in M$ is a minimal projection. Then $\eC P=PMP\subseteq\oB(P\hH)$, and formula \eqref{EqLemPMPPMPprimedeux} in lemma \ref{LemPMPPMPprime} makes $(PMP)'=PM'P=\oB(P\hH)$. Now the map of lemma \ref{LemMapipsomPMmP} is an isomorphism, then
\[ 
  M'\simeq\oB(P\hH)
\]
as $*$-algebra. Thus $M'$ is a factor. This factor is moreover of type I because $\oB(P\hH)$ has minimal projections, namely projections on one dimensional spaces. 

If we repeat the same argument with $M'$ instead of $M$, we obtain that 
\begin{equation}		\label{EqMPHtypeIBh}
		M\simeq\oB(P'\hH)
\end{equation}
where $P'$ is a minimal projection in $M'$.

What we proved is
\begin{proposition}
If $M$ is a factor of type $I$, there exists a separable Hilbert space $\hH$ such that
\begin{equation}
	M=\oB(\hH).
\end{equation}
\end{proposition}

When $M=\oB(\hH)$ is of type $I$ says that $M$ is of \defe{type $I_n$}{factor!of Type $I_n$} if $\dim\hH=n$ where $1\leq n \leq\infty$.

\begin{proposition}
If $M$ is of type $I_n$ with $1\leq n <\infty$, then $M\simeq \eM_n(\eC)$ and the unique trace is the ususal matrix trace up to renormalization:
\begin{equation}
	\tr(T)=\frac{1}{ n }\sum_{i=1}^nT_{ii}.
\end{equation}
\end{proposition}
\begin{proof}
No proof.
\end{proof}



In particular we have that the composition of the two minimal projection $PP'=P'P$ is a rank one projection in $\oB(\hH)$. Now consider $Q=PP'$ and $v$ be the unital vector in the target space of $Q$, i.e. $Qv=v$ and $\| v \|=1$.

\begin{proposition}
Let $M$ be a factor of type I and $P$, a minimal projection. In the same way, let $P'$ be a minimal projection in $M'$. Let $Q=PP'$ and $v\in Q\hH$ such that $\| v \|=1$. Then
\begin{equation}
\begin{aligned}
 M'Q&\to P\hH \\ 
   SQ&\mapsto Sv 
\end{aligned}
\end{equation}
is an isomorphism.
\end{proposition}

\begin{proof}
Since $Q$ projects on the space spanned by $v$, the fact that $S_1v=S_2v$ implies $S_1=S_2$ and the injectivity is proved. For surjectivity, we know that, $M$ being a factor of type I and $P$ a minimal projection, we have $\eC P=PMP\subseteq\oB(\hH)$ where the last equality has to be understood in the sense of that $T\in PMP$ restricts to an operator on $P\hH$, and that this restrictions completely defines $T$. But as operators on $P\hH$, we have $(PMP)'=PM'P$ (lemma \ref{LemPMPPMPprime}), while lemma \ref{LemMapipsomPMmP} assures that the latter algebra is $M'$. Thus $M'=\oB(P\hH)$ and $M'v=P\pH$.
\end{proof}

\begin{proposition}
In the same way, we have that
\begin{equation}
\begin{aligned}
  MQ&\to P'\hH \\ 
   TQ&\mapsto Tv 
\end{aligned}
\end{equation}
is an isomorphism
\end{proposition}

\begin{proof}
No proof.
\end{proof}

\begin{proposition}
Let $M$ be a factor $S\in M$ and $T\in M'$, then if $ST=0$, then $S=0$ or $T=0$.
\end{proposition}

\begin{proof}
Let $P$ be the projection on the right support of $S$, i.e. onto $\Image(S^*)=(\ker S)^{\perp}$. This operator is equal to the limit\quext{To be proven.}
\[ 
  P=\lim_{n\to\infty}(S^*S)^{1/n}.
\]
So $P$ is a strong limit, and then belongs to $M$. Since, by assumption, $ST=0$, we have $S^*ST=0$, and then $PT=0$. Since $M$ is a factor, it implies that $P=0$ or $T=0$.
\end{proof}

\begin{proposition}
Let $M\subseteq\oB(\hH)$ be a factor. Then the map
\begin{equation}
\begin{aligned}
 M\otimes_{\eC}M'&\to \oB(\hH) \\ 
   S\otimes T&\mapsto ST 
\end{aligned}
\end{equation}
is an injective $*$-homomorphism. Its image is strongly dense in $\oB(\hH)$.
\end{proposition}

\begin{proof}
First, as $M$ is a factor, we have
\[ 
  \{ ST\tq S\in M\text{ and }T\in M' \}'=\eC\id,
\]
so that $\{ ST \}''=\oB(\hH)$, which proves that $\{ ST \}$ is strongly dense in $\oB(\hH)$.

We have elements $S_i\in M$ and $T_i\in M'$ ($i=1,\ldots,n$) such that 
\begin{equation}		\label{EqDecSTiMMprime}
	\sum_{i=1}^nS_iT_i=0,
\end{equation}
and we are going to prove that the set $\{ S_i \}$ is not linearly independent, so that all the $S_i$, or all the $T_i$ vanish. An element of $M\otimes M'$ can be decomposed under the form \eqref{EqDecSTiMMprime} in several ways.

Let $Q$ be the projection on the closure of the space
\begin{equation}	\label{EqEspaceTTHHnv}
	\big\{    
		(TT_1v,\ldots TT_nv)\in\hH\oplus\ldots\oplus\hH\tq T\in M', v\in\hH
	\big\}.
\end{equation}
This space is invariant under the algebra
\begin{equation}
	M'^{(n)}=\Big\{ 
\begin{pmatrix}
T&&0\\
&\ddots\\
0&&T
\end{pmatrix}
\tq T\in M' \Big\},
\end{equation}
so that $Q\in\Big( M'^{(n)} \Big)'$. Since $\{ T_1Tv\tq v\in\hH, T\in M \}=\{ T_1TSv\tq v\in \hH,T\in M,S\in M' \}$ the space \eqref{EqEspaceTTHHnv} is also invariant under
\begin{equation}		\label{EqSSSinvMBig}
	\Big\{ 
\begin{pmatrix}
S&&0\\
&\ddots\\
0&&S
\end{pmatrix}
\tq S\in M \Big\},
\end{equation}
On the other hand, the operators which commute with all $M'^{(n)}$ are element of $\eM_n(M)$, then
\[ 
  Q\in\Big( M'^{(n)} \Big)'=\eM_n(n),
\]
and for the same reason, the operators which commute with all \eqref{EqSSSinvMBig} are elements of $\eM_n(M')$, so that
\[ 
  Q\in\eM_n(M\cap M')=\eM_n(\eC).
\]
consider now the operator
\[ 
  R=
\begin{pmatrix}
S_1&\ldots & S_n\\
0&\ldots & 0 \\
\vdots  &&\vdots\\
0&\ldots & 0 \\
\end{pmatrix}.
\]
We havea
\[ 
\begin{pmatrix}
S_1&\ldots & S_n\\
0&\ldots & 0 \\
\vdots  &&\vdots\\
0&\ldots & 0 \\
\end{pmatrix}\cdot
  \begin{pmatrix}
TT_1 v\\
TT_2 v\\
\vdots\\
TT_nv
\end{pmatrix}
=
\begin{pmatrix}
S_1TT_1v+\ldots+S_nTT_nv\\
0\\
\vdots\\
0
\end{pmatrix}.
\]
The first component is
\[ 
  T\big( \sum_i S_iT_iv \big)
\]
which vanishes by assumption, so that $RQ=0$. Let us write $Q=(q_{ij}\id)$ as element of $\eM_n(\eC)$. The relation $RQ=0$ says that
\begin{equation}
		\sum_{i=1}^n S_iq_{ij}=0
\end{equation}
for every $j$. Since $Q$ is a non vanishing projector, at least one of these relations is nontrivial. That nontrivial relation shos that the $S_i$'s are vanishing. If not, we have $Q=0$, which means that $T_i=0$.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Tensor product of von~Neumann algebras}
%---------------------------------------------------------------------------------------------------------------------------

Let $M_1\subseteq\oB(\hH_1)$ and $M_2\subseteq\oB(\hH_2)$ be two von~Neumann algebras. We define\nomenclature[C]{$M_1\bar\otimes M_2$}{tensor product of von~Neumann algebras} the \defe{tensor product}{tensor product!of von~Neumann algebras}
\begin{equation}
	M_1\bar\otimes M_2=\{ S_1\otimes S_2\tq S_i\in M_i \}''\subseteq\oB(\hH_1\otimes\hH_2)
\end{equation}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
					\section{Dimensions}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Finite and infinite projections}
%---------------------------------------------------------------------------------------------------------------------------

A projection in a factor is \defe{infinite}{infinite!projection}\index{projection!finite or infinite} if it is equivalent to a proper subprojection; it is \defe{finite}{finite!projection} is it is not infinite. The notion of finite and infinite projections descents to the equivalence classes. A factor is \defe{finite}{finite!factor} when the identity is finite.

\begin{proposition}
If $P$ and $Q$ are projections with $P\leq Q$ and $Q$ is finite, then $P$ is finite.
\end{proposition}

\begin{proof}
Assume that $P$ is infinite, that is there exists a projection $P'<P$ with $P\sim P'$. So we have $P'<P\leq Q$ and there exists a $v\in\hH$ such that $Qv=v$, $Pv=v$ and $P'v=0$. Thus we have
\[ 
	Q=P+(Q-P)\sim P'+(Q-P)<Q,
\]
the last inequality being assured by the vector $v$. What we proved is that $Q$ is equivalent to a subprojection of itself, which contradicts the fact that $Q$ is finite.
\end{proof}

\begin{corollary}
Let $\alpha$, $\beta\in\dim M$. If $\alpha$ is finite and $\beta$ infinite, then $\alpha\leq\beta$.
\end{corollary}

If $\alpha=[P]$ and $\beta=[Q]$ with $PQ=0$, we define $\alpha+\beta=[P+Q]$. We denote by $n\alpha$ the sum
\begin{equation}
	n\alpha=\underbrace{\alpha+\ldots+\alpha}_{\text{$n$ times}},
\end{equation}
$n\in\eN$. If $n\alpha$ exists for every positive integer $n$, we write
\[ 
  \infty\alpha=\bigvee_{n=1}^{\infty}n\alpha.
\]

\begin{proposition}
The sum $\alpha+\beta$ fulfils
\begin{enumerate}
\item If $\alpha+\beta$ exists, then it is independent of the representative $P$ and $Q$ in $\alpha$ and $\beta$,
\item It is commutative and associative: $\alpha+\beta=\beta+\alpha$ and $\alpha+(\beta+\gamma)=(\alpha+\beta)+\gamma$,
\item zero is the neutral: $\alpha+[0]=\alpha$.
\end{enumerate}
\end{proposition}

\begin{proof}
No proof.
\end{proof}

\begin{lemma}
If $\alpha$ and $\beta$ are finite, then $\alpha+\beta$ is finite when it exists.
\end{lemma}
\begin{proof}
No proof.
\end{proof}

\begin{lemma}
If $\alpha$ is finite and $\beta$ is infinite, then
\begin{enumerate}
\item $\infty\alpha$ exists,
\item $\infty\alpha=\beta$.
\end{enumerate}
In particular, all the infinite projections are equivalent each other.
\end{lemma}

\begin{proof}
Since $\beta$ is infinite and $\alpha$ is finite, the projection $\beta$ contains a subprojection equivalent to $\alpha$. What remains in $\beta$ is still an infinite projection, and thus still contains a subprojection equivalent to $\alpha$. Let $\alpha=[P]$ and $\beta=[Q]$. We have
\[ 
  Q=\big( \sum_nP_n \big)+R
\]
where for each $n$, the projection $P_n$ is equivalent to $P$, and $R$ is a finite projection which does not contain a subprojection equivalent to $P$. Thus $P$ contains a subprojection equivalent to $R$.

Notice that $\beta$ can only contain a countable number of copies of $\alpha$ because one only has a countable number of basis vectors in a separable Hilbert space.

Let us consider the projection
\begin{equation}
	\beta'=[Q-R]=[\sum P_n]=\infty\alpha.
\end{equation}
One can construct a partial isometry implementing an equivalence between $\beta$ and $\beta'$ using an Hilbert hotel argument.
\begin{probleme}
This proof has to be finished.
\end{probleme}
\end{proof}

\begin{lemma}	\label{LemVstarVPP}
If $P$ is a projection and if $V^*V=P$, then $V$ vanishes on the target space of $P^{\perp}$.
\end{lemma}

\begin{proof}
It is evident that $V^*$ does not vanish on the range of $V$ (apart on zero) because
\[ 
  \langle v, V^*Vv\rangle =\langle Vv, Vv\rangle \neq 0.
\]
Thus, in order $V^*V$ to vanish on the range of $P^{\perp}$, one requires $V$ to vanish on $\Image(P^{\perp})$.
\end{proof}

\begin{lemma}		\label{LemfinifactisemVUP}
Let $M$ be a finite factor, the every partial isometry $V$ reads
\begin{equation}
	V=UP
\end{equation}
where $U$ is unitary and $P$ is a projection.
\end{lemma}

\begin{proof}
Consider the equivalent projections $P=V^*V$ and $Q=VV^*$ and their complement $P^{\perp}$, $Q^{\perp}$. First, we remark that $P^{\perp}$ and $Q^{\perp}$ are equivalent. Indeed, if they are not equivalent let say that $Q^{\perp}$ is equivalent to a subprojection of $P^{\perp}$, in this case, the identity $\mtu=P+P^{\perp}=Q+Q^{\perp}$ provides an equivalence between $\mtu$ and a subprojection of $\mtu$, which is in contradiction with the assumption that $M$ is a finite factor.

Thus $P^{\perp}\sim Q^{\perp}$ and wet set $W^*W=P^{\perp}$ and $WW^*=Q^{\perp}$ and then $U=V+W$ is the answer because
\[ 
  (V+W)P=VP+WP,
\]
but $P$ is the projection on the target space of $V$, so $VP=V$ and, by lemma \ref{LemVstarVPP}, we have $WP=0$.
\end{proof}

Notice that the decomposition $V=UP$ is a special feature of the finite factor case. In the general infinite case, we have for example the operator which shifts the basis vectors
\[ 
  S=
\begin{pmatrix}
0	&0	&0	&0	&\ldots\\
1	&0	&0	&0	&\ldots\\
0	&1	&0	&0	&\ldots\\
0	&0	&1	&0	&\ldots\\
\vdots	&\vdots	&\vdots	&\vdots	&\ddots
\end{pmatrix}
\]
It has $S^*S=\mtu$ while $SS^*\neq\mtu$.

\begin{proposition}		\label{PropDecoTUTabsfinifacteur}
Every element $T$ of a finite factor reads
\begin{equation}	\label{EqDecoTUTabsfinifacteur}
	T=U| T |
\end{equation}
with $U$ unitary.
\end{proposition}

\begin{proof}
One guess the form of $U$ by the decomposition \eqref{EqDecoTUTabsfinifacteur}: $U=T(T^*T)^{-1/2}$. One checks that $U^*U=\mtu$. Since we are in a finite factor, the unit cannot be equivalent to something else than itself, so $UU^*=\mtu$ is forced, and $U$ is thus unitary.
\end{proof}

\begin{proposition}	
If $N$ is a finite factor, then so is $\eM_2(N)$.
\end{proposition}

\begin{proof}
Let us suppose that we have a partial isometry $V\in\eM_2(N)$ such that $VV^*=\mtu_2$. We have to prove that $V^*V=\mtu_2$; if not, the identity would be equivalent to a subprojection. In other words, we have to prove that $V$ is invertible. It will be done by constructing an invertible operator $W$ such that $V^*W$ is invertible. In that case, $V^*$ is invertible and so is $V$.

If we set $V=
\begin{pmatrix}
a&b\\
c&d
\end{pmatrix}$, with $a$, $b$, $c$, $d\in N$, the relation $V^*V=\mtu_2$ imposes among others relations
\begin{subequations}	\label{SubEassEqaaccunVV}
\begin{align}
a^*a+c^*c&=\id		\label{ssEqaaccunVV}\\
b^*a+d^*c&=0		\label{ssEqbadczVV}
\end{align}
\end{subequations}
Relation \eqref{ssEqaaccunVV} says that $| a |^2+| c |^2=1$, so that in the sense of the continuous functional calculus, we have $| a |=\sqrt{1-| c |^2}$. We deduce that $| a |$ is a limit of polynomials in $1-| c |^2$ and that $\big[ | a |,| c | \big]=0$.

Since $a$ and $c$ belong to a finite factor, proposition \ref{PropDecoTUTabsfinifacteur} provide unitary elements $u$ and $v$ of $N$ such that $a=u| a |$ and $c=v| c |$. Now we consider the unitary element
\[ 
  W=
\begin{pmatrix}
u&0\\
0&v
\end{pmatrix}
\begin{pmatrix}
| a |&-| c |\\
| c |&| a |
\end{pmatrix}
\]
Using relations \eqref{SubEassEqaaccunVV}, we find
\[ 
  V^*W=
\begin{pmatrix}
1	&	-a^*u| c |+c^*v| a |\\
0	&	x
\end{pmatrix},
\]
but $a^*u| c |=| a |u^*u| c |=| a | | c |=| c | |a |$, so that the upper-right element is actually zero. We are left with
\[ 
  V^*W=
\begin{pmatrix}
1	&0\\
0	&x
\end{pmatrix}
\]
in which we want to prove that $x$ is invertible. Using the fact that $W$ is unitary, we have $(V^*W)(V^*W)^*=V^*V=\mtu$, then
\[ 
  \begin{pmatrix}
1	&	0\\
0	&	x
\end{pmatrix}
  \begin{pmatrix}
1	&	0\\
0	&	x^*
\end{pmatrix}
  \begin{pmatrix}
1	&	0\\
0	&	xx^*
\end{pmatrix}
=
  \begin{pmatrix}
1	&	0\\
0	&	1
\end{pmatrix}.
\]
Thus we have $xx^*=\mtu$ in $N$, which in turn imposes $x^*u=\mtu$ because $N$ is a finite factor. We have finished to prove that $V^*W$ is invertible.
\end{proof}

% Si je déplace ce lemme, il faut déplacer la proposition qui suit en même temps parce qu'elle vient naturellement.
\begin{lemma}
If $P$ and $Q$ are projections with $PQ=0$, then $P$ is equivalent to a subprojection of $Q$, or $Q$ is equivalent to a subprojection of $P$.
\end{lemma}
\begin{proof}
No proof.
\end{proof}

\begin{proposition}			\label{PropnnminSTperpssR}
If $R$ is not a minimal projection, then there exist subprojections $S$, $T$ of $R$ such that $S\sim T$ and $S\perp T$.
\end{proposition}

\begin{proof}
Since $R$ is not minimal, we have a non vanishing projection $S<R$. Let consider $S_1=R-S$. One checks that $SS_1=0$. Now $S$ or $S_1$ is equivalent to a subprojection of the other. Let $S\sim T\leq S_1$. Now, we have $S\sim T$ and $ST=0$ which means $S\perp T$.
\end{proof}


Let $P$ and $Q$ be two projection in $M$ such that $PQ=0$. In $\eM_2(M)$, we have
\[ 
  \begin{pmatrix}
P+Q&0\\
0&0
\end{pmatrix}
\sim
  \begin{pmatrix}
P&0\\
0&R
\end{pmatrix}
\]
where $R$ is a subprojection of $P$ which is equivalent to $Q$. Define the partial isometry $V$ by $V^*V=Q$ and $VV^*=R$. We have
\[ 
 \begin{pmatrix}
  P	&	V^*	\\ 
  0	&	0	
\end{pmatrix}
\begin{pmatrix}
  P	&	0	\\ 
  V	&	0	
\end{pmatrix}
=
\begin{pmatrix}
  P+Q	&	0	\\ 
  0	&	0	
\end{pmatrix}, 
\]
and
\[ 
  \begin{pmatrix}
  P	&	0	\\ 
  V	&	0	
\end{pmatrix}
\begin{pmatrix}
  P^*	&	V^*	\\ 
  0	&	0	
\end{pmatrix}
=
\begin{pmatrix}
  P	&	PV^*	\\ 
  VP^*	&	R	
\end{pmatrix}
=
\begin{pmatrix}
  P	&	0	\\ 
  0	&	R	
\end{pmatrix}
\]
because $\Image(V^*)=\Image(Q)$ implies $PV^*=VP^*=VP=0$. Now, 
$
\begin{pmatrix}
  P	&	0	\\ 
  0	&	0	
\end{pmatrix}
$ is  a subprojection of 
$
\begin{pmatrix}
  P	&	0	\\ 
  0	&	P	
\end{pmatrix}
$
because $R$ is a subprojection of $P$. Thus we have
\begin{equation}
\begin{pmatrix}
  P+Q	&	0	\\ 
  0	&	0	
\end{pmatrix}
\sim
\begin{pmatrix}
  P	&	0	\\ 
  0	&	E	
\end{pmatrix}
\leq
\begin{pmatrix}
  P	&	0	\\ 
  0	&	P	
\end{pmatrix}
=\text{finite}.
\end{equation}
So we deduce that $P+Q$ is finite.

A factor is \defe{semifinite}{semifinite!factor}\index{factor!semifinite} if there are projections $P_{\alpha}$ such that $\bigvee P_{\alpha}=\id$. Notice that if $\{ P_1,\ldots, P_n \}$ is a finite set of finite projections, then $\bigvee P_i$ is a finite projection. A factor is \defe{purely infinite}{purely infinite}\index{factor!purely infinite} if $0$ is the only finite projection.

\begin{proposition}
If $P$ is any finite projection, one can find a sequence of equivalent projections $\{ P_i \}$ such that $\mtu=\sum P_i$.
\end{proposition}
\begin{proof}
No proof.
\end{proof}
A consequence of that proposition is that any factor is semifinite or purely infinite, while a finite factor is always semifinite.

\begin{remark}
A factor of type I is semifinite because a minimal projection is finite. Indeed, when $P$ is infinite, the projection $Q$ such that $Q\sim P$ and $Q\leq P$ contradicts minimality of $P$. 
\end{remark}

\begin{proposition}
A factor is semifinite if and only if it reads $(\text{finite})\bar\otimes (\text{type I})$.
\end{proposition}

\begin{proof}
If a factor reads $(\text{finite})\bar\otimes (\text{type I})$, the type I part is a $\oB(\hH)$ in which one can take as approximation of the identity the sequence of projections $P_i$ given by 
\begin{equation}
P_ie_j=
\begin{cases}
e_j	&\text{if $j\leq i$}\\
0	&\text{otherwise}\\
\end{cases}
\end{equation}
where $\{ e_i \}$ is an orthonormal basis of $\hH$.

Now if $M$ is semifinite, let $P_i$ be a sequence of finite projections with $P_iP_j=0$ and $P_i\sim P_j$ such that $VP_i=\id$. Then we have $\hH=\oplus_iP_i\hH$, but each of the $P_i$ is equivalent to $P_1\hH$, so that $\hH=\oplus_iP_i\hH=\oplus P_1\hH=P_1\hH\otimes l^2(\eN)$.

Under that isomorphism, an operator $T\in M$ acts on $P_1\hH$ by $P_1TP_1$, so that
\begin{equation}
M=P_1MP_1\bar\otimes \oB\big( l^2(\eN) \big).
\end{equation}

\end{proof}
Thus, in order to understand the semifinite factors, it is sufficient to understand the finite factors.

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Finite factor}
%-----------------------------------------------------------------------------------------------------------------------------

\begin{lemma}		\label{LemfassminPPperp}
Every factor without minimal projection contains a projection $P$ such that $P\sim P^{\perp}$.
\end{lemma}

\begin{proof}
Consider the set
\[ 
\begin{split}
  Z=\Big\{ 
(P,Q,V)\text{ where $P$ and $Q$ are projections,}&\text{with $P\perp Q$,}\\
						&\text{$V$ is a partial isometry,}\\
						 &\text{and $V^*V=P$, $VV^*=Q$}
 \Big\}.
\end{split}
\]
The set $Z$ is endowed with a partial order given by $(P_1,Q_1,V_1)\leq (P_2,Q_2,V_2)$ when $P_1\leq P_2$, $Q_1\leq Q_2$ and $V_2P_1=V_1$. The Zorn's lemma provides a maximal element that we denote by $(P,Q,V)$. Let us suppose that $P+Q<\mtu$ (strictly). Then we write $R=\mtu-P-Q$ and by proposition \ref{PropnnminSTperpssR} we have subprojection $S$ and $T$ of $R$ such that $S\sim T$ and $S\perp T$. 

We put $W^*W=S$ and $WW^*=T$, then $(P+S,Q+T,V+W)$ contradicts maximality of $(P,Q,V)$, and $P+Q=\id$ with $P\perp Q$ and $P\sim Q$.
\end{proof}

\begin{lemma}		\label{LemfinfacPPQQPsimQ}
Let $M$ be a finite factor. If $P\sim P^{\perp}$ and $Q\sim Q^{\perp}$, then $P\sim Q$.
\end{lemma}

This lemma means that there is only one way tu cut $\hH$ in two equal subspaces.

\begin{proof}
Let us suppose that $P$ is not equivalent to $Q$, thus it is equivalent to a subprojection of $Q$.

\begin{probleme}
What is the exact statement which says that a projection is equivalent to a subprojection of the other, or the contrary ?
\end{probleme}

Since $P\sim sub\, Q$, we have $P^{\perp}\sim sub\, Q^{\perp}$ and $P+P^{\perp}\sim sub(Q+Q^{\perp})$. That means that $\id$ is equivalent to a subprojection of itself, which is impossible because of the assumption of finite factor. We deduce that $P\sim Q$.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Rational and real dimensions}
%---------------------------------------------------------------------------------------------------------------------------
\label{SubSecRationalRealDim}

We consider a factor of finite type $M$ without minimal projection. Lemma \ref{LemfassminPPperp} ensures the existence of a projection $P$ such that $P\sim P^{\perp}$ while lemma \ref{LemfinfacPPQQPsimQ} says that every such projection lie in the class $[P]$. We define $\frac{ 1 }{2}\in\dim M$ by
\begin{equation}
\frac{ 1 }{2}=[P]\in\dim M
\end{equation}
where $P\sim P^{\perp}$. Now we look at the algebra $PMP$, which posses its own $\frac{ 1 }{2}$ that is called $\frac{1}{ 4 }$ in $M$. So we set the definition
\begin{equation}
	\frac{1}{ 4 }=[Q]\in\dim M
\end{equation}
where $Q\leq P$ and $Q\sim P-Q$. Notice that $P-Q=Q^{\perp}$ in $P\hH$. In the same way, we define $\frac{ 3 }{ 4 }$ by
\begin{equation}
	\frac{ 3 }{ 4 }=[P+R]\in\dim M
\end{equation}
with $R\leq R^{\perp}$ and $R\sim P^{\perp}-R$. Continuing the process, we can define
\[ 
	\frac{ r }{ 2^n }\text{ for } r\in\{ 0,\ldots, 2^n \},
\]
and we define $\tau\colon \dim M\to [0,1]$ by
\begin{equation}
	\tau(P)=\sup\Big\{ \frac{ r }{ 2^n }\tq \frac{ r }{ 2^n }\leq [P] \Big\}\in [0,1].
\end{equation}

\begin{theorem}		\label{ThobijzudimM}
The map $\tau\colon \dim M\to [0,1]$ is a bijection for every finite factor without minimal projection.
\end{theorem}

\begin{proof}
No proof.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Summary}
%---------------------------------------------------------------------------------------------------------------------------

When $M$ is a finite factor, it has two possibilities: it contains or not a minimal projection.

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
					\subsubsection{Finite factor with minimal projection}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

We saw at page \pageref{PgtypeIonavu}, and more precisely on equation \eqref{EqMPHtypeIBh} that if $P'$ is the minimal projection of $M'$, then $M\simeq\oB(\hH)$, so that the possible dimensions are
\begin{equation}
	\dim M=\{ 0,1,\ldots,N \}
\end{equation}
where $N$ can eventually take the value $\infty$, as shows the example $M=\eC\id$.

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
					\subsubsection{Finite factor without minimal projection}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

In the case of finite factor without minimal projection, we saw by theorem \ref{ThobijzudimM} that 
\begin{equation}
	\dim M=[0,1].
\end{equation}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
					\subsubsection{Semifinite factor}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

If the factor is not finite, there are two possibilities: it is semifinite or purely infinite. In the semifinite case

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Purely infinite factor}
%---------------------------------------------------------------------------------------------------------------------------

One still has to see what are the dimensions for a purely infinite factor.

\begin{lemma}		\label{LemORSneqzeroini}
Let $P$ be an infinite projection in a factor and $P=R\oplus S$ (orthogonal sum) with $R\sim P$ and $S\neq 0$. Then $[P]=\infty [S]$.
\end{lemma}

\begin{proof}
Let $R\sim P$ and $P=R+S$ with $S\neq 0$. Since $R\sim P$, we can decompose $R$ in the same way as $P$ is decomposed, namely
\[ 
	R=R_1+S_1
\]
with $R_1\sim R\sim P$ and $S_1\sim S$. Explicitly, if $V^*V=P$ and $VV^*=R$, we put $R_1=VRV^*$ and $S_1=VSV^*$. Proceeding, we decompose $R_1=R_2+S_2$, $R_2=R_3+S_3$, and so on. Since $R\perp S$, we have $S_1\perp R_1$, and $S_2$ being a subprojection of $R_1$ which is orthonormal to $S_1$, we have $S_1\perp S_2$.

What we get is finally is a set $\mS=\{ S,S_i \}_{i\in \eN}$ of projections two by two orthogonal and equivalent. Let $\mZ$ be the set of sets of projections two by two orthogonal and equivalent which contains $\mS$. This is the set of extensions of $\mS$. The Zorn's lemma provides a maximal element in $\mZ$ that we name $\mQ=\{ Q_n \}$. By very definition, $\mS\subseteq\mQ$.

We want to prove that $\sum_nQ_n=P$, so that $P\leq\infty[S]$ because $\infty[S]\leq\sum_nQ_n$. Let $E=P-\sum_nQ_n$. By maximality, it does not contain a subprojection equivalent to $S$, so we have $E\preceq S$. We are going to prove that $E+\sum_nQ_n\sim \sum Q_n$. The argument is once again an Hilbert hotel construction.

Let $Q_i=A_i+E_i$ with $A_i\sim A_j$ and $E_i\sim E$. That decomposition is nothing else that the fact that $E$ is equivalent to a subprojection of $Q_i$. Now consider the following equivalences:
\begin{align*}
	E&\sim E_1\\
	A_1&\sim A_1\\
	E_1&\sim E_2\\
	A_2&\sim A_2\\
	E_2&\sim E_3\\
	&\vdots
\end{align*}
On the left hand side we have $E+\sum_n Q_n$ while on the right hand side we have $\sum_nQ_n$. Thus we have $E+\sum_nQ_n\sim\sum_nQ_n$ and then $P\sim\sum_nQ_n$.
\end{proof}

\begin{corollary}
If $M$ is a purely infinite factor, then $\dim M=\{ 0,\infty \}$
\end{corollary}

\begin{proof}
In a purely infinite factor, zero is the only finite projection, thus any projection reads $P=R+S$ with $P\sim R$ and $S\neq 0$. The aim is to prove that $[P]=\id$, in such a way that there exists only one infinite.

We have $\id=Q+S$ for a certain $Q\sim \id$. The $S$ here can be chosen the same as the $S$ of $P$. Indeed $\id=P^{\perp}+P=P^{\perp}+R+S$. Using the equivalences $P^{\perp}\sim P^{\perp}$ and $P\sim R$, we see that $\id=P^{\perp}+P\sim P^{\perp}+R$, so that $\id=Q+S$ with $Q=P^{\perp}+R$. Using lemma \ref{LemORSneqzeroini}, we have $[P]=\infty[S]$, and then using the lemma again on $[P]$, we get $[P]=\infty[S]$, which proves that $[P]=[\id]$.
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
					\section{Tracial functional}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\label{SecTracevonNeuman}

References: \cite{TrioloSemifinite,DixmierTrace}. This section is related to section \ref{SecTraceCstar} about trace on $C^*$-algebra.

A linear functional $\tau\colon M\to \eC$ is
\begin{description}
	\item[a state] when $\tau(A^*A)\geq0$ and $\tau(1)=1$;
	\item[tracial]\index{tracial functional!on von Neumann algebra} when $\tau(A^*A)=\tau(AA^*)$;
	\item[faithful]\index{faithful!functional} when $\tau(A^*A)=0$ if and only if $A=0$;
	\item[normal]\index{normal!functional} when if $A=\sum_n A_n$ exists for a sequence $\{ A_n \}$ of positive operators, then $\tau(A)=\sum_n\tau(A_n)$;
	\item[semifinite]\index{semifinite!functional on von Neumann algebra} if for every non zero $A\in M^+$ majorizes some non zero $B\geq 0$ with $\tau(B)<\infty$.
\end{description}

\begin{lemma}
A linear tracial functional on a von~Neumann algebra is a trace.
\end{lemma}

\begin{proof}
Let $U$ be unitary, using the tracial property we find $\tau(U^*A^*AU)=\tau(AA^*)$, so that
\begin{equation}	\label{EqtauUBUtauBpos}
	\tau(U^*BU)=\tau(B)
\end{equation}
for every positive $B$. Since any element of $M$ reads as composition of four positive, the relation \eqref{EqtauUBUtauBpos} holds in fact for every $B$ in $M$. Since every element $C\in M$ can be written as $C=U^*B$, we have
\[ 
	\tau(CU)=\tau(U^*BU)=\tau(B)=\tau(UC),
\]
and we have $\tau(CU)=\tau(UC)$ for every $C$ and $U$ unitary. Now, every element is a combination of four unitary, so that $\tau(CD)=\tau(DC)$ for every $C$ and $D$, which means that $\tau$ is a trace.
\end{proof}

Notice that the existence of a faithful normal trace on $M$ implies that $M$ is finite because if $V^*V=1$,
\[ 
	\tau(1-VV^*)=1-\tau(VV^*)=1-\tau(V^*V)=1-\tau(1)=0,
\]
which, from faithfulness, implies that $VV^*=1$.

Let $\epsilon>0$, an \defe{$\epsilon$-trace}{$\epsilon$-trace}\index{trace!$\epsilon$-trace} is a normal state $\varphi\colon M\to \eC$ such that
\begin{equation}
	\varphi(A^*A)\leq (1+\epsilon)\varphi(AA^*).
\end{equation}

\begin{lemma}
A normal state on a finite factor is an $\epsilon$-state if and only if $P\sim Q$ implies $\varphi(P)\leq (1+\epsilon)\varphi(Q)$.
\end{lemma}

\begin{proof}
No proof.
\end{proof}

\begin{lemma}
If $\varphi$ is an $\epsilon$-trace, then we have
\begin{equation}
	\frac{1}{ (1+\epsilon) }\varphi(P)\leq\frac{ \dim(P) }{ \dim(\mtu) }\leq (1+\epsilon)\varphi(P)
\end{equation}
for every projection $P$.
\end{lemma}

\begin{proof}
Let us first suppose that 
\begin{equation}		\label{EqdimPsimunmtun}
	\dim (P)=\dim(\mtu)/n,
\end{equation}
 and decompose $\mtu=P_1+\ldots+P_n$ with $P_iP_j=0$ ($i\neq j$) and $P_i\sim P_j$ for every $i$. So we have $V_i^*V_i=P$ and $V_iV_i^*=P_i$. In that case
\begin{equation}
\begin{split}
	n\varphi(P)=\varphi(V_1^*V_1+\ldots+V_n^*V_n)&\leq(1+\epsilon)\varphi(V_1V_1^*+\ldots+V_nV_n^*)\\
							&=(1+\epsilon)\varphi(1)=1+\epsilon,
\end{split}
\end{equation}
thus
\begin{equation}
	\varphi(P)\leq\frac{ 1+\epsilon }{ n }=(1+\epsilon)\frac{ \dim(P) }{ \dim(\mtu) }.
\end{equation}
The other sense is obtained by the same computation:
\[ 
	1=\varphi(V_1V_1^*+\ldots+V_nV_n^*)\leq (1+\epsilon)\varphi(V_1^*V_1+\ldots+V_n^*V_n)=(1+\epsilon)n\varphi(P).
\]
The lemma is now proved with the assumption \eqref{EqdimPsimunmtun}. If that assumption does not hold, we can build projections $P_i$ with $P_iP_j=0$, $\dim(P_i)= \dim(\mtu)/ n_i $ and $P=\sum_iP_i$. Then we can use the fact that $\varphi$ is normal and carry on the same computation as before.
\end{proof}

\begin{corollary}
If $\varphi_1$ is an $\epsilon_1$-trace and $\varphi_2$ is an $\epsilon_2$-trace, then
\[ 
	\| \varphi_1-\varphi_2 \|\to 0
\]
when $\epsilon_1,\epsilon_2\to 0$.
\end{corollary}
\begin{proof}
No proof.
\end{proof}

The interest of this lemma resides in the fact that if $\varphi_k$ is an $\epsilon_k$-trace with $\epsilon_k\to 0$, we have a Cauchy sequence, so that $\lim_{k\to\infty}\varphi_k$ is an actual trace. We are thus not obliged to build traces, but $\epsilon$-trace are sufficient.

\begin{lemma}	\label{LemPMPnormalfaithstate}
Let $\varphi$ be a faithful normal state. If $\epsilon>0$, there exists a non vanishing projection $P\in M$ such that
\[ 
	\varphi(A^*A)\leq(1+\epsilon)\varphi(AA^*)
\]
if $A\in PMP$. In other words, $\varphi$ is an $\epsilon$-trace on $PMP$.
\end{lemma}

\begin{proof}
Let $Q=\sum_{\alpha}Q_{\alpha}$ and $Q'=\sum_{\alpha}Q'_{\alpha}$ where $\{ (Q_{\alpha},Q'_{\alpha}) \}$ is a maximal set of projections pairs such that
\begin{enumerate}
\item $Q_{\alpha}\perp Q_{\beta}$ and $Q'_{\alpha}\perp Q'_{\beta}$ if $\alpha\neq\beta$,
\item $Q_{\alpha}\sim Q_{\alpha}'$,
\item $\varphi(Q_{\alpha})<\varphi(Q'_{\alpha})$.
\end{enumerate}
From normality of $\varphi$, the third condition implies that $\varphi(Q)=\varphi(Q')$. Since $Q\neq\mtu$, we have $\varphi(Q')\leq 1$ and thus
\[ 
	\varphi(Q)<\varphi(Q')\leq 1.
\]
Let us now choose a pair $(R,R')$ such that $R\perp Q$, $R'\perp Q'$ and $R\sim R'$. By maximality, that pair cannot fulfil the third condition of $\{ Q_{\alpha},Q'_{\alpha} \}$:
\[ 
	\varphi(R)\geq \varphi(R').
\]
Now we consider the number
\begin{equation}
	m=\min\{ k\tq\, k\varphi(R)\geq\varphi(R')\text{ for every $(R,R')$ satisfying the two conditions} \}.
\end{equation}
We just saw that $1$ belongs to the set, so $m\leq 1$. Let us suppose that $m=0$. One typical projection orthogonal to $R$ is $\mtu-R$, but $\varphi(\mtu-R)\neq 0$ because $\varphi$ is faithful and $\mtu-R\neq\mtu$. So we conclude that $m$ cannot be zero and
\[ 
	m\in]0,1].
\]
Now, take $\epsilon>0$ and choose a pair $(R,R')$ which fulfils the two conditions and such that
\begin{equation}		\label{EqcondpaireRRprime}
	m\varphi(R)<(1+\epsilon)\varphi(R').
\end{equation}
Existence of such a pair is ensured by minimality of $m$.

We build the projections $S=\sum_{\alpha}S_{\alpha}$ and $S'=\sum_{\alpha}S'_{\alpha}$ where $\{ S_{\alpha},S'_{\alpha} \}$ is maximal for the properties
\begin{enumerate}
\item $S_{\alpha}\leq R$ and $S'_{\alpha}\leq R'$,
\item $S_{\alpha}\perp S_{\beta}$, $S'_{\alpha}\perp S'_{\beta}$ if $\alpha\neq\beta$,
\item $S_{\alpha}\sim S'_{\alpha}$,
\item $m\varphi(S_{\alpha})\geq (1+\epsilon)\varphi(S'_{\alpha})$.
\end{enumerate}
Using normality, the last condition sums to 
\begin{equation}
	m\varphi(S)\geq (1+\epsilon)\varphi(S').
\end{equation}
We also have $S\sim S'$ and $S\neq R$. Indeed, suppose that $S=R$. Then $S\sim R$, but $S\sim S'$, so $R\sim R'$. Since $S'_{\alpha}\leq R$ for every $\alpha$, we have $S'\leq R'$. We conclude that $S'=R'$ because $M$ is a finite factor: in this case, $S'\leq R'$ and $S'\sim R'$ imply $S'=R'$. Now the fourth condition over $S_{\alpha}$ becomes $m\varphi(R)\geq (1+\epsilon)\varphi(R')$ which contradicts the condition \eqref{EqcondpaireRRprime} that we made on the pair $(R,R')$. Thus we conclude that $S\neq R$.

Let take $P=R-S$ and choose projections $E$ and $E'$ such that $E\leq P$, $E'\leq P'$ with $E\sim E'$. In this case we have 
\[ 
	m\varphi(E)<(1+\epsilon)\varphi(E'),
\]
if not $(E,E')$ contradicts maximality of $\{ S_{\alpha},S'_{\alpha} \}$. On the other hand, minimality of $m$ provides $m\varphi(E)\geq \varphi(E')$, so that we are left with
\begin{equation}
	\varphi(E')\leq m\varphi(E)<(1+\epsilon)\varphi(E'),
\end{equation}
which shows that $\varphi$ is an $\epsilon$-trace and that $P'$ is the answer to the lemma.

\end{proof}

An example of faithful normal state is
\begin{equation}
	\varphi(T)=\sum_n2^{-n}\langle v_n, Tv_n\rangle 
\end{equation}
where $\{ v_i \}$ is an orthonormal basis of $\hH$.

\begin{proposition}
There is an $\epsilon$-trace on $M$.
\end{proposition}

\begin{proof}
We just saw that normal states do exist, so we apply lemma \ref{LemPMPnormalfaithstate} and we find a projection $P$ for which we suppose $\dim(P)=1/n$, and we choose $P_1,\ldots P_n$ such that $P_iP_j=0$ ($i\neq j$) and $P_i\sim P$. We define the partial isometries $V_i$ by
\begin{align*}
	V_i^*V_i&=P,&V_iV_i^*&=P_i.
\end{align*}
Now we define 
\[ 
	\psi(A)=\sum_i\varphi(V_i^*AV_i)
\]
where $\varphi$ is the normal faithful state on $PMP$. Thus we have
\[ 
	\psi(A)=\sum\varphi(V_i^*AV_i)=\sum\psi(V_i^*AV_i)=\sum\psi(AV_iV_i^*)=\sum\psi(AP_i),
\]
and we find
\begin{equation}
\begin{split}
	\psi(A^*A)	&=\sum_i\varphi(V_i^*A^*AV_i)\\
			&=\sum_{ij}\varphi(\underbrace{V_i^*A^*V_j}_{\in PMP}\underbrace{V_j^*AV_i}_{\in PMP})\\
			&\leq(1+\epsilon)\sum_{ij}\varphi(V_j^*AV_iV_i^*A^*V_j)\\
			&\leq (1+\epsilon)\psi(AA^*),
\end{split}
\end{equation}
which means that $\psi$ is a trace.
\end{proof}

\begin{proposition}		\label{PropExistenceTrace}\index{factor!finite}\index{trace!over finite factor}
Every finite factor accepts an unique faithful, normal and tracial state. Moreover, if $P$ and $Q$ are projections and $\tau$ is the trace, then
\begin{equation}
	P\sim Q\Leftrightarrow \tau(P)=\tau(Q).
\end{equation}
\end{proposition}

\begin{proposition}	\label{PropFactIIunttedim}						\index{factor!of type $II_1$}
If $M$ is a factor of type $II_1$, then
\begin{equation}
	\{ \tau(P)\tq P\in \oP(M) \}=[0,1].	
\end{equation}
where $\tau$ is the trace given by proposition \ref{PropExistenceTrace}.
\end{proposition}

\begin{proof}
No proof.
\end{proof}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
					\section{Modules over von~Neumann algebras}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\label{SecOverModVNalgDim}

Let $X$ be a topological space and denote by $\pi$ the group $\pi_1(X)$. We denote by $\tilde X$ the universal covering of $X$, and the group $\pi$ acts on $\tilde X$ by the monodromy action defined in subsection \ref{sssMonodromyact}. We denote by $C_p(X)$ the space of $p$-chains over $X$ and $C_p(\tilde X)$ the one of $\tilde X$ from which we build the complexes
\[ 
  \xymatrix{%
   \ldots \ar[r]^b	&	C_p(X)\ar[r]^{b}	&C_{p-1}(X)\ar[r]^{b}	&\ldots	
}
\]
and
\[ 
  \xymatrix{%
   \ldots \ar[r]^b	&	C_p(\tilde X)\ar[r]^{b}	&C_{p-1}(\tilde X)\ar[r]^{b}	&\ldots	
}
\]
with $b\circ b=0$. The chain space $C_p(\tilde X)$ is not only a group, but a module over $\eZ[\pi]$.

We are now going to look at the tensor product von~Neumann algebra
\begin{equation}
	M_p(\tilde X)=M(\pi)\otimes_{\eZ[\pi]}C_p(\tilde X).
\end{equation}
In the right hand side, $M(\pi)$ is the von~Neumann algebra described in subsection \ref{sssOnePartCaseMG}, which is generated by the operators $\mU_g\in\oB\big( l^2(\pi) \big)$ defined by $\mU_g(\varphi)(g)=\varphi(h^{-1}g)$, and the tensor product is the one defined in equation \eqref{EqdefAtensRB}.

We can then look at the complex of $M(\pi)$-modules
\[ 
  \xymatrix{%
   \ldots \ar[r]^b	&	M_{p+1}(\tilde X)\ar[r]^{b}	&M_p(\tilde X) \ar[r]^{b}	&M_{p-1}(\tilde X)\ar[r]^{b}	&\ldots	
}
\]
and look at the corresponding Betty numbers which are integers numbers associated with any topological space.


%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Modular conjugation and factor of type \texorpdfstring{$II_1$}{II1}}
%---------------------------------------------------------------------------------------------------------------------------

The results presented here partially come from \cite{Wassermann}, section 9 and \cite{JonesSunder}, proposition 2.2.6.

A \defe{module}{module!over a von~Neumann algebra} over a von~Neumann algebra $M$ is an Hilbert space\footnote{Hilbert space are generally denoted by $\hH$, while modules are denoted by $\modE$ or $\modF$. Here, the notation will depend on what aspect we are focusing on.} $\modE$ for which there exists a weakly continuous map $\pi_r\colon M\to \oB(\modE)$ such that $\pi_r(T)=\big( \pi_r(T) \big)^*$ and $\pi_r(ST)=\pi_r(S)\pi_r(T)$. If $\modE$ and $\modF$ are two modules over $M$, a map $a\colon \modE\to \modF$ is \defe{linear}{linear map between modules} if 
\begin{equation}
	a(S\xi)=Sa(\xi)
\end{equation}
for every $S\in M$ and $\xi\in\modE$. We denote by\footnote{This is what \cite{JonesSunder} denote by $_M\mathcal{L}(\hH)$} $\oL_M(\modE,\modF)$\nomenclature[A]{$\oL_M(\modE,\modF)$}{Space of linear maps between the modules $\modE$ and $\modF$} the set of $M$-linear maps from $\modE$ to $\modF$. When $\modE=\modF$, we write $\oL_M(\modE)$. By definition of linearity, we have $\oL_M(\modE)=\pi(M)'$. The same notion exists for linearity at right, and in the general case, we denote by $\oL_{M,N}(\modE,\modF)$, the set of $M$-left-linear and $N$-right-linear maps from $\modE$ to $\modF$.



 We say that the modules $\modE$ and $\modF$ are \defe{isomorphic}{isomorphism!of modules} if there exists an unitary $M$-linear map between them.

When $M$ is a type $II_1$ factor, we denote $\hH_1=L^2(M)$ and $\hH_{\infty}=\hH_1\otimes l^2$.
\begin{proposition}			\label{PropTypeIIProjhHinfty}\index{factor!of type $II_1$}
Let $M$ be a type $II_1$-factor and $\modE$ be a separable $M$-module. There exists a projection $P\in \eM_{\infty}(M)$ such that $\modE\simeq \hH_{\infty}P$. All such projections are Murray-von Neumann equivalent.
\end{proposition}
\begin{proof}
No proof, explanations can be found in \cite{JonesSunder}, theorem 2.2.2.
\end{proof}

When $\modE$ is a separable $M$-module ($M$ is a type $II_1$ factor), we define
\begin{equation}
	\dim_M\modE=\tr p
\end{equation}
where $p\in\oP\big( \eM_{\infty}(M) \big)$ is the projection such that $\big( L^2(M)\otimes l^2 \big)p\simeq \modE$ and whose existence is given by proposition \ref{PropTypeIIProjhHinfty}.

Let $M$ be a factor of type $II_1$ with the unique trace $\tau$ given by proposition \ref{PropExistenceTrace}. We denote by $L^2(M,\tau)$ the Hilbert space of its GNS representation, and $\pi_{\tau}$ the representation. Since $\tau$ is unique, we will simply denote them by $L^2(M)$ and $\pi$. We denote by $\Omega\in L^2(M)$ a cyclic vector. If $\pi(T)=0$, we have
\[ 
	\tau(T^*T)=\| \pi(T)\Omega \|^2=0,
\]
so that $T=0$ and the representation is faithful. We can thus identify $T\in M$ with $\pi(T)\in \oB\big( L^2(M) \big)$ and we have $M\subset\oB\big( L^2(M) \big)$. The basics properties of the GNS construction say also that $\overline{ M\Omega }=L^2(M)$ and $\tau(T)=\langle T\Omega, \Omega\rangle $ for every $T$ in $M$. 

If $T\Omega=0$, then $0=\| T\Omega \|^2=\tau(T^*T)$, so that $T=0$. That means that $\Omega$ is separating for~$M$.

\begin{lemma}
If $M\subseteq\oB(\hH)$ is a von~Neumann algebra, a vector in $\hH$ is cyclic for $M$ if and only if it is separating for $M'$.
\end{lemma}
\begin{proof}
A proof is given in \cite{JonesSunder}.
\end{proof}

Now, for every $\xi\in L^2(M)$, we define the operators $\pi_l$ and $\pi_r$ by
\begin{subequations}
\begin{align}
	\pi_l(\xi)(T'\Omega)&= T'\xi\\
	\pi_r(\xi)(T\Omega) &= T\xi
\end{align}
\end{subequations}
for $T'\in M'$ and $T\in M$. The domains are $\dom\big( \pi_l(\xi) \big)=M'\Omega$ and $\dom\big( \pi_r(\xi) \big)=M\Omega$. These operations are well defined because $\Omega$ is cyclic and separating for $M$ and $M'$.

If $\pi_l(\xi)$ extends to a bounded operator on $L^2(M)$, one says that $\xi$ is \defe{left bounded}{left!bounded vector}\index{right!bounded vector}., and the (necessarily unique) extension is still denoted by $\pi_l(\xi)$. We do the same for $\pi_r$. Let now the map
\begin{equation}
\begin{aligned}
 J\colon M\Omega&\to M\Omega \\ 
   T\Omega&\mapsto T^*\Omega, 
\end{aligned}
\end{equation}
this is a conjugate linear isometry, so that it extends to an anti-unitary involution.
\begin{equation}
	J\colon L^2(M)\to L^2(M)
\end{equation}
That map $J$ is the \defe{modular conjugation}{modular!conjugation} operator for the factor $M$ of type $II_1$.

The algebra $JMJ$ acts on $L^2(M)$ as well as on $L^2(JMJ)$. If $\xi\in L^2(M)$, the action is
\begin{equation}		\label{EqActJMJLdM}
	(JSJ)\xi=\xi S^*.
\end{equation}
That one is inspired by the fact that $JSJT=J(ST^*)=TS^*$. Since $J^2=1$, the action of $JMJ$ on $L^2(JMJ)$ is given by
\begin{equation}		\label{EqActJMJLdJMJ}
	(JSJ)(JTJ)=J(ST)J.
\end{equation}

Let $M$ be a type $II_1$ factor. We denote $\hH_1(M)=L^2(M)$\nomenclature[C]{$\hH_1=L^2(M)$}{A completion of a von~Neumann algebra}, or simply by $\hH_1$ when no confusion is possible, and $\hH_{\infty}=L^2(M)\otimes l^2$\nomenclature[C]{$\hH_{\infty}$}{$\hH_1\otimes l^2$}. The algebra $M$ acts on $\hH_1$ by
\begin{equation}
	\pi_1(S)\xi=S\xi,
\end{equation}
and $M$ acts on $\hH_{\infty}$ by
\begin{equation}
	\pi_{\infty}(S)=\pi_1(s)\otimes\id_{l^2}.
\end{equation}
We also note $\eM_{\infty}(M)=M\otimes\oB(l^2)$, that has to be understood as infinite matrices with elements in $M$. It is a type $II_{\infty}$ factor, and the trace is a follows. If $p\in\eM_{\infty}(M)=(p_{ij})$, then
\begin{equation}					\label{EqTraceMinfinuM}
	\tr(p)=\sum_{i=1}^{\infty}\tr_M(p_{ii}).
\end{equation}
With that formula, when $q\in\oP(l^2)$ has rank $1$, then $\tr(1_m\otimes q)=1$. Let $q\in\eM_n(M)$ and consider the element of $\eM_{\infty}(M)$ given by the following:
\begin{equation}
	\begin{pmatrix}
  q	&	0	\\ 
  0	&	0	
\end{pmatrix}.
\end{equation}
It's trace, in $\eM_{\infty}(M)$, is $\sum_{i=1}^n\tr(q_{ii})$, but the trace of $q$ in $\eM_n(M)$ is $\frac{1}{ n }\sum_{i-1}^n\tr(q_{ii})$. The normalization is not the same in $\eM_n(M)$ and in $\eM_{\infty}(M)$.

We denote by $e_{11}$, the element of $\eM_n(M)$ given by
\begin{equation}
	e_{11}=
\begin{pmatrix}
  1	&		\\ 
  	&	0	
\end{pmatrix}.
\end{equation}
We have $\tr(e_{11})=1/n$, and $\pi_e(e_{11})\in\oP\Big( \pi_r\big( \eM_n(M) \big) \Big)$.

\begin{lemma}
	The $\oL_M\big( L^2(M) \big)$-modules $\oL_M\big(L^2(M)\big)$ and $L^2(M)$ are isomorphic.
\end{lemma}

\begin{proof}
	The result comes from the fact that an element of $\oL_M\big(L^2(M)\big)$ is uniquely defined by its value at $1\in M$.
\end{proof}
As a consequence of that lemma, we have
\begin{equation}
	\dim_{\oL_M\big( L^2(M) \big)}L^2(M)=1,
\end{equation}
because
\begin{equation}
	\Big( \oL_M\big( L^2(M) \big)\otimes l^2 \Big)p=L^2(M)
\end{equation}
when $p=\id\otimes e_{11}$, whose trace is\footnote{it is not $1/n$ or anything like that because of the remark we did bellow the definition \eqref{EqTraceMinfinuM}.} $1$.

\begin{lemma}		\label{LemLJMJequalLM}
	We have the isomorphism
	\begin{equation}
		L^2(JMJ)\simeq L^2(M)
	\end{equation}
as $JMJ$-module.
\end{lemma}

\begin{proof}
	Let us prove that the map which extend the following is an isomorphism:
	\begin{equation}
		\begin{aligned}
		 \psi\colon L^2(JMJ)&\to L^2(M) \\ 
		   JSJ&\mapsto S^* 
		\end{aligned}
	\end{equation}
	So we have to prove that for every $a\in JMJ$ and $\xi\in L^2(JMJ)$, we have $\psi(a\xi)=a\psi(\xi)$. Using the actions \eqref{EqActJMJLdM} and \eqref{EqActJMJLdJMJ}, if $a=JSJ$ and $\xi=JTJ$, we find
	\begin{equation}
		\psi(a\xi)=\psi(JSJJTJ)=\psi(JSTJ)=T^*S^*, 
	\end{equation}
	while
	\begin{equation}
		a\psi(\xi)=(JSJ)\psi(JTJ)=(JSJ)T^*=T^*S^*.
	\end{equation}
	That prove that $L^2(M)\simeq L^2(JMJ)$ as $JMJ$-modules.
\end{proof}

\begin{lemma}
	We have
	\begin{equation}		\label{EqoLLdpireununmodE}
		\oL_M\big( L^2(M) \big)=\oL_{M,\pi_r(e_{11})}(\modE_n)
	\end{equation}
	where $\modE_n=L^2(M)\oplus \cdots\oplus L^2(M)$ ($n$ terms).
\end{lemma}

\begin{proof}
An element in the right hand side of \eqref{EqoLLdpireununmodE} is a right-linear map with respect to $\pi_r(e_{11})$, i.e. a map $f\colon \modE\to \modE$,
\begin{equation}
	f\big( (\xi_1,\ldots,\xi_n)\pi_r(e_{11}) \big)=f(\xi_1,\ldots,\xi_n)\pi_r(e_{11}).
\end{equation}
Since the left hand side only depends on $\xi_1$, the right hand side  shows that $f(\xi_1,\cdots,\xi_n)$ only depends on $\xi_1$. Now, the right hand side takes its values in $L^2(M)$, so that the left hand side shows that $f$ takes its values in $L^2(M)$.
\end{proof}

The following is the proposition 2.2.6 in \cite{JonesSunder}.
\begin{proposition}	\label{PropDimIIun}
	Let $\hH$ be a separable Hilbert space and $M\subseteq\oB(\hH)$, a factor of type $II_1$. We have
	\begin{enumerate}

		\item\label{ItemiPropDimIIun} for every $d\in[0,1]$, there exists a $M$-module $\modE_d$ such that $\dim_M\modE_d=d$.
		
		\item\label{ItemiiPropDimIIun} There exists an unique $d\in[0,\infty]$ such that $\hH\simeq\modE_d$ as $M$-module.

		\item\label{ItemiiiPropDimIIun} The algebra $M'$ is a factor of type $II_1$ if and only if $\dim_M\hH<\infty$.

		\item\label{ItemivPropDimIIun} $\dim_M L^2(M)=1$.
 
		\item\label{ItemvPropDimIIun} If $\{ \modF_n \}_{n\in\eN}$ is a set of separable $M$-modules, then
			\begin{equation}
				\dim_M\big( \oplus_n\modF_n \big)=\sum_M\dim_M\modF_n.
			\end{equation}
		\item\label{ItemviPropDimIIun} If $\dim_M\hH<\infty$ and if $P'\in\oP(M')$, then 
			\begin{equation}
				\dim_{PMP}(P\hH)=\big( \tr_M(P) \big)^{-1}\dim_M\hH.				
			\end{equation}
	
		\item\label{ItemviiPropDimIIun} If $P$ is a projection in $M$, then 
			\begin{equation}
				\dim_{PMP}(P\hH)=\big( \tr_M(P) \big)^{-1}\dim_M\hH.
			\end{equation}

		\item\label{ItemviiiPropDimIIun}  We have
		\begin{equation}				\label{EqDimMMprimeprodun}
			\dim_{M'}\hH=(\dim_M\hH)^{-1}
		\end{equation}
		if $M'$ is a factor of type $II_1$
	\end{enumerate}
\end{proposition}

\begin{proof}

	For \ref{ItemiPropDimIIun}, let begin with $d=n\in \eN$, and define
	\begin{equation}
		\modE_n=\underbrace{  L^2(M)\oplus\ldots\oplus L^2(M)   }_{\text{$n$ times}}
	\end{equation}
	which can be seen as an element of $\eM_{1\times n}\big( L^2(M) \big)$. This is a $M$-$\eM_n(M)$-bimodule, for the matrix multiplication. What we have is to compute $\dim_{M}\hH_n=\tr p$ where $p\in\oP\big( \eM_{\infty}(M) \big)$ is the projection such that $\big( L^2(M)\otimes l^2 \big)P=\hH_n$. 
	
	Intuitively, $P$ is the projection onto the first $n$ component of the space of infinite vertical matrices. Indeed, the picture is that $\hH_n=\eM_{1\times n}\big( L^2(M) \big)$ while $\hH_{\infty}=\eM_{1\times \infty}\big( L^2(M) \big)$. We are searching for $p\in\oP(\eM_{\infty}(M))$ such that 
	\begin{equation}
		\big( L^2(M)\otimes l^2 \big)p=L^2(M)\oplus\ldots\oplus L^2(M).
	\end{equation}
	The answer is $p=\id_{M}\otimes \pr_n$ where $\pr_n$ stands for the projection onto the first $n$ components. Using formula \eqref{EqTraceMinfinuM}, we conclude that $\dim_M\modE_n=n$. 

	Let us now consider $d\in[0,\infty[$, and an integer $n\geq d$. Since $\eM_n(M)$ is a factor of type $II_1$, proposition \ref{PropFactIIunttedim} provides a projection $q\in\oP\big( \eM_m(M) \big)$ such that $\tr_{\eM_n(M)}(q)=d/n$. Now we look at
	\begin{equation}
		\modE_d=\modE_nq.
	\end{equation}
	In order to compute $\dim_M(\modE_d)$, we have to find $r\in\oP\big( \eM_{\infty}(M) \big)$ such that
	\begin{equation}
		\big( L^2(M)\otimes l^2 \big)r\simeq \big( L^2(M)\oplus\ldots\oplus L^2(M) \big)q.
	\end{equation}
	The answer is
	\begin{equation}
		r=
	\begin{pmatrix}
	  q	&	0	\\ 
	  0	&	0	
	\end{pmatrix}
	\end{equation}
	whose trace is 
	\begin{equation}
		\tr_{\eM_{\infty}(M)}(r)=\sum_{i=1}^{\infty}\tr_M(r_{ii})=\sum_{i=1}^n\tr_M(q_{ii})=n\tr_{\eM_n(M)}(q),
	\end{equation}
	because of the discussion bellow the definition \eqref{EqTraceMinfinuM}. This concludes the proof of \ref{ItemiPropDimIIun}.
	
	We pass to the proof of \ref{ItemviiiPropDimIIun}. Since $\dim_M\hH<\infty$, we know that $\hH$ is a factor of type $II_1$ by \ref{ItemiiiPropDimIIun}. We can thus suppose that $\hH=\modE_d$ for some $d$. One knows that $M'=JMJ$, so that $\dim_{M'}\modE_d=\dim_{JMJ}\modE_d$. 
	
	Let us first work with $d=1$. In order to compute $\dim_{JMJ}\big( L^2(M) \big)$, we are searching for $p\in\oP\big(\eM_{\infty}(JMJ))$ such that $\big( L^2(JMJ)\otimes l^2 \big)p\simeq L^2(M)$ as $JMJ$-modules. From lemma \ref{LemLJMJequalLM}, $P=e_{11}$ works.
	
	Let us now study the case $d=n\in\eN$.
	
\end{proof}

\begin{corollary}
	When $M$ is a factor of type $II_1$, two $M$-modules are isomorphic if and only if they have same dimension.
\end{corollary}
This is a direct consequence of point \ref{ItemiiPropDimIIun} in proposition \ref{PropDimIIun}.


%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Dimension}
%---------------------------------------------------------------------------------------------------------------------------

We are going to associate any $M=M(\pi)$-module with a dimension in $[0,1]$ such that for every projection $P\in M$, the dimension of the submodule $M(\pi)P$ is equal to $\dim\big( M(\pi)P \big)=\tr(P)$. We will in fact give a dimension to every module over a von~Neumann algebra accepting a trace. For that, we use theory developed in section \ref{SecModUnitalAnneau}.

\begin{theorem}			\label{ThofgsurMFSubEEClSplits}
If $M$ is a finite von~Neumann algebra and if $E$ is a finitely generated module over $M$, and if $F$ is any submodule, then the quotient map $E\to E/\Cl_E(F)$ splits and furthermore the quotient space $E/\bar E$ is projective and finitely generated.
\end{theorem}

\begin{probleme}
Has one to add the assumption that $F$ is projective ?
\end{probleme}
\begin{proof}
Later.
\end{proof}

As consequence of the this theorem, $F\simeq \bar E\oplus(\text{finite projective module})$. In particular,
\begin{equation}
	F\simeq \Cl_F(0)\oplus  (\text{finitely generated projective module})
\end{equation}

\begin{theorem}		\label{ThoPropDimiM}
Let $M$ be a finite von~Neumann algebra with a normal faithful tracial state $\varphi$. There is an unique function 
\[ 
	\dim_{\varphi}\colon \{ \text{$M$-modules} \}\to [0,\infty]
\]
such that
\begin{enumerate}
\item $F_1\simeq F_2$ implies $\dim_{\varphi}F_1=\dim_{\varphi}F_2$,
\item (normalisation) if $F$ is a finitely generated projective module, then the value of $\dim_{\varphi}(F)$ coincides with the definition \eqref{DefDimFunctModule}, in particular when $E\simeq M^nP$ is finitely generated and projective, we have $\dim E=\sum_i\varphi(P_{ii})$,
\item (continuity) if $E$ is any submodule on a finitely generated module $F$, then $\dim_{\varphi}(E)=\dim_{\varphi}\big( \Cl_F(E) \big)$\footnote{From an analytic point of view, that condition is not usual, as can be seen on the example $\dim\eQ=0$ while $\dim\eR=1$.},
\item\label{ItemCofinalitySuiteExact} (cofinality) given an exact sequence
\[ 
	\xymatrix{%
   0\ar[r] 	&F_1\ar[r]	&F\ar[r]	&F_2 \ar[r]	&0,
}
\]
then $\dim_{\varphi}(F)=\dim_{\varphi}(F_1)+\dim_{\varphi}(F_2)$.
\end{enumerate}
\end{theorem}

\begin{proof}
later.
\end{proof}

Notice that, since $P=P^*P$ for every projection, we have $\dim E\geq 0$.

We will prove the following
\begin{proposition}			\label{PropDimClEgalDim}
If $E$ is a finitely generated projective module over $M$, we have
\begin{equation}
	\Dim(F)=\Dim\big( \Cl_E(F) \big)
\end{equation}
if $F$ is any submodule of $E$.
\end{proposition}

\begin{probleme}
One has to check that is it actually proved somewhere in the next pages.
\end{probleme}

We will not often explicitly write the trace $\varphi$ and simply write $\dim(E)$. However, we will sometimes precise the ring over which we consider the module and denote by $\dim_M(E)$\nomenclature[C]{$\dim_M(E)$}{The dimension of $E$ as module over $M$} the dimension of $E$ as module over $M$.

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
					\subsubsection{Examples}		\label{subsubsecExemDimMMMod}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Let $M$ be a von~Neumann algebra with a normal faithful tracial state $\varphi$, and let us give some examples of modules over $M$.

First, $M$ itself is a free module of dimension $1$\footnote{In fact that dimension is $\tr(\mtu)$ which is usually normalised at $1$, see definition \eqref{EqPreDefDimModuleRA} and bellow.} over $M$. If $P$ is a projection, then $MP$ is a projective module\label{PgMPprojModule} and $\dim_{\varphi}(MP)=\varphi(P)$. The fact that $MP$ is a projective module comes from the direct sum decomposition $M=MP\oplus M(\mtu-P)$ and the third characterisation if projective module in proposition \ref{PropEquivProjModule}. Notice that $M$ is a free module over $M$ because $M=M\mtu$.

\begin{proposition}		\label{PropMTprojpourtoutT}
For every element $T\in M$, the set $MT$ is a projective $M$-module.
\end{proposition}

\begin{proof}
Let $P$ be the projection onto $\overline{ \Image(T) }$, so that $P=\lim_{n\to\infty}(TT^*)^{1/n}$ as already seen. We are going to prove that $MT\simeq MP$ as $M$-module. For we define $\Phi\colon MT\to MP$ by $\Phi(ST)=SP$. In order to see that this is a good definition, suppose $S_1T=S_2T$, then $(S_1-S_2)T=0$. But we have
\begin{align}
	ST&=0&\Rightarrow &&S|_{\Image(T)}&=0&\Rightarrow &&S|_{\overline{ \Image(T) }}&=0&\Rightarrow	&&S|_{\Image(P)}&=0,
\end{align}
so that $SP=0$. It shows that $\Phi$ is a well defined $M$-module isomorphism between $MT$ and $MP$.
\end{proof}

By polar decomposition, we have $MT=M| T |$, so we can suppose $T\geq 0$ without loss of generality. We have the exact sequence
\[ 
	\xymatrix{%
   0\ar[r] 	&MT\ar[r]^{\Phi}	&MP\ar[r]	&MP/MT \ar[r]	&0,	
}
\]
so that by property \ref{ItemCofinalitySuiteExact} of theorem \ref{ThoPropDimiM}, we have $\dim_{\varphi}(MT)=\dim_{\varphi}(MP)+\dim_{\varphi}(MP/MT)$. Since the modules $MP$ and $MT$ are isomorphic, that means that 
\[ 
	\dim_{\varphi}(MP/MT)=0.
\]

As another example, take projections $P_m$ with $\varphi(P_m)=2^{-m}$, and let $F$ be the infinite algebraic direct sum $MP_1\oplus MP_2\oplus\ldots$. By cofinality, it has at least the dimension of each of its submodule. In other words, we have
\[ 
	\dim F=\sup_n\dim(MP_1\oplus\ldots\oplus MP_n)=1.
\]

Since we can embed $F$ into $M$, we also get $\dim(M/F)=0$.

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
					\subsubsection{Summary}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

We want to define, for each module, a dimension such that
\begin{itemize}
\item if $E$ is a projective left module with $E\simeq M^nP$ (see proposition \ref{PropFGPRkP}) and $P=P^2\in\eM_n(M)$,
\[ 
	\dim(E)=\sum \varphi(P_{ii}),
\]
and does not depend on the choices.
\item If $E$ is not a finitely generated projective module, then
\begin{equation}		\label{DefDimAvecGrandD}
	\Dim(E)=\sup\big\{  \dim(F)\text{ with $F$ finite projective submodule of $E$} \big\}.
\end{equation}
\end{itemize}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
					\section{Position of submodules}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{proposition}
Let $M$ be a von~Neumann algebra (not specially with trace). Every finitely generated submodule of a finite generated projective module is projective.
\end{proposition}

\begin{proof}
Passing to the matrix algebra (lemmas \ref{LemEprojEEEfproj} and \ref{LemFGenEEEsingleGen}), one can assume that the module and the submodule are in fact singly generated.

A singly generated module over $ M$ has the form $E=MT\subseteq M$ for some element $T\in M$. We saw during the proof of proposition \ref{PropMTprojpourtoutT} that $MT\simeq MP$ where $P$ is the projection onto $\overline{ \Image(T) }$. The fact that $MP$ is a projective module was already argued on page \pageref{PgMPprojModule}.
\end{proof}

\begin{proposition}			\label{PropEfgpFssmodQuotProj}
If $E$ is a finite projective module over $M$ and $F$ is a submodule of $E$, then $E/\Cl_E(F)$ is projective.
\end{proposition}

\begin{proof}
Once again, using the matrix trick, one can suppose that $E$ is singly generated by an element $e$. A left module map $\varphi\colon E\to M$ such that $\varphi(F)=0$ is determined by the value of $\varphi(e)\in M$. The element $\varphi(e)$ is an operator on $\hH$ and we define $P_{\varphi}$ as the projection onto $\overline{ \Image\big( \varphi(e) \big) }$.

Now we define the module map
\begin{equation}
\begin{aligned}
\tilde{\varphi} \colon E&\to M \\ 
   \tilde{\varphi}(Te)&\mapsto TP_{\varphi}. 
\end{aligned}
\end{equation}
This is well defined. Indeed if $Se=0$, then $\varphi(Se)=S\varphi(e)=0$, which implies that $SP_{\varphi}=0$. For the same reason, $\ker(\varphi)=\ker(\tilde{\varphi})$. We define 
\begin{equation}
	Q=\bigvee_{\varphi}P_{\varphi},
\end{equation}
and 
\begin{equation}
\begin{aligned}
 \psi\colon E&\to M \\ 
   \psi(Te)&\mapsto TQ 
\end{aligned}
\end{equation}
which is well defined because $TQ=0$ if and only if $TP\varphi =0$ for every $\varphi$, since the operator $T$ is bounded\footnote{If $T$ is not bounded, it can get bigger and bigger on the range of $\varphi_k$ when $k$ goes to infinity, so that the limit of $T\bigvee_{\varphi\in\alpha}$ is not zero when $\alpha$ gets bigger.}.
\begin{probleme}
The explanation in the footnote is unclear; it has to be expressed in terms of nets.
\end{probleme}
By construction, $\ker(\psi)=\Cl_E(F)$, while $\Image(\psi)=MQ$, so that
\begin{equation}
	E/\ker(\psi)\simeq MQ,
\end{equation}
while the latter is projective.
\end{proof}

\begin{corollary}		\label{CorEfgpFssIsom}
When $E$ is a finite projective module and $F$ a submodule, we have an isomorphism
\[ 
	E=\Cl_E(F)\oplus E/\Cl_E(F)
\]
as direct sum of modules.
\end{corollary}

\begin{proof}
If $\xi\in E$, the class of $\xi$ in $E/\Cl_E(F)$ is
\begin{equation}
	[\xi]=\{ \xi+\eta\tq \eta\in\Cl_E(F) \}.
\end{equation}
Let us choose a representative $[\xi]_0$ in each of the classes\quext{This uses the famous axiom; it would be possible to do otherwise, isn't ?}. The following is the module isomorphism we are searching for
\begin{equation}
\begin{aligned}
 \psi\colon E&\to \Cl_E(F)\oplus E/\Cl_E(F) \\ 
   \xi&\mapsto  \eta\oplus [\xi]_0 
\end{aligned}
\end{equation}
where $\eta$ is the unique element of $\Cl_E(F)$ such that $[\xi]_0+\eta=\xi$.
\end{proof}

When $E$ is a finite projective module over $M$, we say that $\Cl_E(0)$ is the \defe{torsion submodule}{torsion!submodule} of $E$.

Let us see an example. Let 
\begin{equation}
	E=M/MT 
\end{equation}
with $T\geq 0$ and $\overline{ \Image(T) }=\hH$. We claim that the torsion submodule of $E$ is $E$ itself. A module map $\varphi\colon E\to M$ is a module map $M\to M$ composed with a projection, or in other words a module map $\varphi\colon M\to M$ such that $\varphi(T)=0$. Since $\varphi$ is a module map, its fulfils
\begin{equation}
	\varphi(S)=\varphi(S\mtu)=S\varphi(\mtu)=SX
\end{equation}
for a certain $X\in M$ such that $TX=0$. Thus we have $\overline{ \Image(X) }\subset\ker(T)$, but since $T\geq 0$ (in particular $T$ is self-adjoint) and $\overline{ \Image(T) }=\hH$, we have $\ker(T)=0$, and we conclude that $X=0$, so that $\varphi=0$. The question is to know if $E=M/MT$ has a finitely generated submodule or not. Let $P$ be a projective submodule of $M/MT$; by the lifting property \eqref{EqLiftPropProjModules} we have a map $\tilde \lambda$ such that the following commutes
\begin{equation}
\xymatrix{%
 									&  M \ar@{->>}[d]^{\displaystyle\lambda}\\
   P \ar[r]\ar@{.>}[ru]							& M/MT
}
\end{equation}
where the arrow from $P$ to $M/MT$ is injective. The image of $P$ by $\tilde\lambda$ is a submodule $MX$ that has to be injectively\quext{How to say the fact to be injective in English ? Does the word \emph{injectively} exist ?} projected in $M/MT$, so that $MX\cap MT=\emptyset$. Notice that it is not possible when $\hH$ is finite dimensional because $T$ is invertible (from the fact that the closure of its image is the whole space), so that $MT=M$.

Now we suppose that $X$ is positive. This is done without loss of generality because from polar decomposition, for every $X\in M$, there exists a positive $Y$ such that $MX=MY$.

Since $T$ is positive, we can consider the spectral theorem \ref{ThoSpectralTho} and the isomorphism
\begin{equation}
\begin{aligned}
 \theta\colon C^*(T,\cun)&\to C\big( \Spec(T) \big). 
\end{aligned}
\end{equation}
We define the following function on $\Spec(T)$
\begin{equation}
	f_{\epsilon}=
			\begin{cases}
					0				&\text{if $x<\epsilon$}\\
					\frac{ 1 }{ (\theta T)(x) }	&\text{if $x\geq\epsilon$,}
			\end{cases}
\end{equation}
and then one defines the operator $S_{\epsilon}=\theta^{-1}(f_{\epsilon})\in C^*(T,\cun)$. Let us prove that $P_{\epsilon}=S\epsilon T$ is a projection. We have $P_{\epsilon}^2=S_{\epsilon} TS_{\epsilon}T$. Take an orthonormal basis of $\hH$ of eigenvectors of $T$ and let's call $\lambda_i$ the eigenvalues: $Te_i=\lambda_ie_i$. If $\lambda_k<\epsilon$, then $S_{\epsilon}e_i=0$ and of course $S_{\epsilon}TS_{\epsilon}e_i=S_{\epsilon}e_i$. Otherwise, we have
\begin{equation}
	S_{\epsilon}TS_{\epsilon}e_i=\frac{1}{ \lambda_i }S_{\epsilon}T e_i =S_{\epsilon}e_i.
\end{equation}
That proves that $P_{\epsilon}^2=P_{\epsilon}$, and so that this is a projection. We obviously also have $P_{\epsilon}\to \mtu$ in $MT$.

Similarly one can define $Q$, the projection onto $\overline{ \Image(X) }$ and we have projections $Q_{\epsilon}\to Q$ with $Q_{\epsilon}=Y_{\epsilon} X$ for some $Y\epsilon\in M$ and $Q_{\epsilon}\in MX$. Now take $\epsilon_1$ and $\epsilon_2$ and look at the projection
\begin{equation}
	Q_{\epsilon_1}\vee P_{\epsilon_2}
\end{equation}
onto $\Image(Q_{\epsilon_1})\cap\Image(P_{\epsilon_2})$. The latter intersection is in fact $0$ because $A_{\epsilon_1}\vee P_{\epsilon_2}\in MQ_{\epsilon_1}\cap MP_{\epsilon_2}=MX\cap MT=0$. Using lemma \ref{LemDimSupDeuxProjs}, we get
\begin{equation}
	\dim\mtu\geq \dim(Q_{\epsilon_1}\vee P_{\epsilon_2})=\dim(Q_{\epsilon_1})+\dim(P_{\epsilon_2}).
\end{equation}
Recall that the trace used to define the dimension has to be normal, so that the dimension function is continuous in such a way that taking the limit $\epsilon_1\to 0$ and $\epsilon_2\to 0$ provides the expected result
\begin{equation}
	\dim(\mtu)\geq \dim(Q)+\dim(\mtu),
\end{equation}
from which one deduce that $\dim Q=0$ and therefore $X=0$. This finish the proof that the module $E=M/MT$ with a positive $T$ and $\overline{ \Image(T) }=\hH$ has no projective submodules.

\begin{proposition}
If $E$ is a finitely generated module over $M$, then the torsion submodule does not contains non zero projective finite submodules.
\end{proposition}

\begin{proof}
Later.
\end{proof}


\begin{lemma}			\label{LemFClosEF}
If $E$ is a finitely generated submodule of a finitely generated projective module $E$, then $F$ is projective and $F\simeq \Cl_E(F)$.
\end{lemma}

\begin{proof}
We assume as usual that $E$ and $F$ are singly generated. The singly generated projective module $E$ reads $E=MP$ while the general form of a singly generated submodule is $F=MT$ for a positive $T$ which vanishes on $P^{\perp}\hH$ and $\Image(T)\subseteq\Image(P)$. We already proved that $MT\simeq MQ$ where $Q$ is the projection over $\Image(T)$.

We have $\Cl_{MP}(MT)=MQ$ because of the direct sum decomposition $MP=MQ\oplus M(P-Q)$ from which we can build an homomorphism $MP\to M$ which vanishes on $MT$, namely the projection  because $MT\subseteq MQ$.
\begin{probleme}
I do not understand one single word about the latter justification $:($
\end{probleme}
\end{proof}

\begin{corollary}		\label{Corfgfgdilleqdim}
If $F$ is a finitely generated submodule of a finitely generated projective module $E$, then $\dim(F)\leq\dim(E)$.
\end{corollary}

\begin{proof}
By lemma \ref{LemFClosEF}, we have $\dim(F)\simeq\dim\big( \Cl_E(F) \big)$ while we know that $E=\Cl_E(F)\oplus E/\Cl_E(F)$. The latter makes that $\dim E$ is given by the trace of two projections:
\begin{equation}
	\dim E=\tr P_{\Cl_E(F)}+\tr P_{E/\Cl_E(F)}.
\end{equation}
\end{proof}

\begin{corollary}
If $E$ is a finitely projective module over a von~Neumann algebra with a trace, then $\dim(E)=\Dim(E)$. 
\end{corollary}

\begin{proof}
By very definition, $\Dim(E)\geq\dim(E)$ because $E$ itself belongs to the set on which the supremum is taken in the definition \eqref{DefDimAvecGrandD} of $\Dim$. The corollary \ref{Corfgfgdilleqdim} provides the opposite inequality.
\end{proof}

\begin{proposition}		\label{PropProjFiniDimCldim}
If $E$ is projective finitely generated and if $F\subseteq E$, then $\dim\big( \Cl_E(F) \big)=\Dim(F)$.
\end{proposition}

\begin{proof}
The case where $F$ is finitely generated is already done by lemma \ref{LemFClosEF}. For the general case, suppose that the proposition does not hold. In this case, the lemma \ref{LemFClosEF} yields
\begin{equation}
	\sup\{ \dim\big( \Cl_E(H) \big)\tq \text{$H$ is finite projective} \}<\dim\big( \Cl_E(F) \big).
\end{equation}
On the one hand, by corollary \ref{CorEfgpFssIsom}, the module $\Cl_E(H)$ is a direct summand of $\Cl_E(F)$ which is itself (by the same result) a direct summand of $E$. On the other hand, being a finitely generated module, it reads $E=M^nP$ for some projection $P$ by proposition \ref{PropFGPRkP}. Combining both, we have a projection $P_H\leq P$ such that $\Cl_E(H)=M^nP_H$.

Now the finitely generated projective submodules of $F$ form a directed system. For every finitely generated projective submodules $H_1$ and $H_2$ of $F$, there exists at least $H_3=H_1\oplus H_2$ which contains $H_1$ and $H_2$. Thus the set of $P_H$ is directed too and one can look at $\bigvee_HP_H$, the smalest projection whose range contains the range of all of the $P_H$.

We have $\bigvee_HP_H<P$ because if not, using normality of the trace,
\begin{equation}
	\dim\big( \bigvee_HP_H \big)=\sup_H\dim(P_H)<P.
\end{equation}
Now let $Q=P-\bigvee_HP_H$. If $F$ is some sunmodule of $E$, one has
\begin{equation}
\begin{split}
	F&=\bigcup\{ H\subseteq F\tq \text{$H$ is finitely generated} \}\\
	&=\bigcup\{ H\subseteq F\tq \text{$H$ is finitely generated and projective} \}
\end{split}
\end{equation}
because $H\subseteq F\subseteq E$ which is finitely generated projective. Such a $H$ has the form $M^nP_H$, sp $F\subseteq M^n\big( \bigvee_HP_H \big)$. Notice that this $F$ lies in the kernel of the non zero map
\begin{equation}
\begin{aligned}
 \Cl_E(F)=M^nP&\to M^nQ \\ 
   V&\mapsto VQ. 
\end{aligned}
\end{equation}
Indeed, since $\bigvee_HP_H<P$, we have $\big( \bigvee_HP_H \big)P=\bigvee_HP_H$, so that for every $T\in M^n$ we have $T\bigvee_HP_H\big( P-\bigvee_HP_H \big)=0$. By looking at the complement of $VQ$, one has a nonzero homomorphism $ \Cl_E(F)\to M$ which vanishes on $F$. That contradicts the definition of the closure.

\end{proof}

The three point in this demonstration that use the von~Neumann algebra blackground (and not only general module theory) are the following.
\begin{itemize}
\item First we used normality of the trace to commute the dimension with the suppremum,
\item and second, we used continuity of $\bigvee$ with respect to the dimension.
\end{itemize}

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Summary}
%---------------------------------------------------------------------------------------------------------------------------

We have two dimension functions $\dim$ and $\Dim$ such that
\begin{enumerate}
\item $\dim E=\Dim E$ whenever $E$ is a finitely generated projective module,
\item for every finitely generated module $E$ and every submodule $F$, the module $E/\Cl_E(F)$ is finitely generated and projective,
\begin{probleme}
Check if one does not need the assumption that $E$ is projective too.
\end{probleme}
\item If $F\subseteq E$ and if $E$ is a finitely generated projective module, then $\Dim(F)=\Dim\big( \Cl_E(F) \big)$.
\end{enumerate}
From now we do no more use the ``von~Neumann algebra'' assumption. Instead we suppose to have a ring $R$ and two dimensions functions satisfying these three properties.

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Properties of the dimension function}
%---------------------------------------------------------------------------------------------------------------------------

\begin{proposition}
If $E$ is the union of a directed system of submodules $E_{\alpha}$, then $\Dim(E)=\sup \Dim E_{\alpha}$.
\end{proposition}

\begin{proof}
A finitely generated projective submodule in $E$ is generated by $n$ elements, each of them being contained in some $E_{\alpha_1}$, $E_{\alpha_2},\ldots$ By definition of a directed set, the union of all the so defined $E_{\alpha_i}$ is contained in a $E_{\beta}$. Thus every finitely generated projective submodule in $E$ is of the form $E_{\beta}$.
\end{proof}

\begin{lemma}			\label{LemHinjectifHdimdim}
If one has a projective module map $\rho\colon H_1\to H_2$, then $\Dim(H_1)\geq\Dim(H_2)$.
\end{lemma}

\begin{proof}
Let $F$ be any projective module for which there exists an inclusion $\iota\colon F\to H_2$. That map can be lifted because $F$ is projective. So among all the submodules of $H_1$, there is the one which is the image of $F$ be the lifted map. That one of course contains $H_2$ itself. Thus $H_2$ is a submodule of $H_1$ and the supremum defining the dimension in $H_1$ is automatically bigger or equal to the one defining the dimension of $H_2$.
\end{proof}

\begin{proposition}
If
\begin{equation}
	\xymatrix{%
   0\ar[r] 	&E_0\ar[r]^{}	&E_1\ar[r]^{p}	&E_2 \ar[r]	&0	
}
\end{equation}
is a short exact sequence of modules, then $\dim(E_1)=\dim(E_0)+\dim(E_2)$.
\end{proposition}

\begin{proof}
Using last proposition, we can assume that all of $E_0$, $E_1$ and $E_2$ are finitely generated. Indeed when a module is not finitely generated, it is still the union of the directed system of all its finitely generated submodules.

Let $F$ be a finitely generated projective submodule of $E_2$, we have the exact sequence
\begin{equation}
	\xymatrix{%
   0\ar[r] 	&E_0\ar[r]	&p^{-1}(F)\ar[r]	&F \ar[r]	&0.
}
\end{equation}
The module $F$ being projective, we have $p^{-1}(F)\simeq F\oplus E_0$. We do not know if the dimension function is additive with respect to direct sum, but by definition of a supremum, we have the inequality $\Dim(E_0)+\Dim(F)\leq \Dim\big( p^{-1}(F) \big)$, and the chain
\begin{equation}
	\Dim(E_0)+\Dim(F)\leq \Dim\big( p^{-1}(F) \big)\leq\Dim(E_1)
\end{equation}
which in turn provides the inequalities
\begin{equation}
	\Dim(E_0)+\Dim(E_2)\leq\Dim(E_1).
\end{equation}
For the reverse inequality, let $F$ be a finitely generated projective submodule of $E_1$, and consider the following exact sequence of finitely generated projective module
\begin{equation}
	\xymatrix{%
   0\ar[r] 	&\Cl_F(F\cap E_0)\ar[r]	&F\ar[r]	&F/\Cl_F(F\cap E_0) \ar[r]	&0	
}
\end{equation}
The fact that $F/\Cl_F(F\cap E_0)$ is projective is proposition \ref{PropEfgpFssmodQuotProj}. Since $F/\Cl_F(F\cap E_0)$ is at most a subset of $F$ which is finitely generated, it has to be finitely generated too. We also know by corollary \ref{CorEfgpFssIsom} that $F$ splits into
\begin{equation}
	F\simeq \Cl_F(F\cap E_0)\oplus F/\Cl_F(F\cap E_0)
\end{equation}
which is a direct sum of finitely generated projective module, so that we can use the definition of dimension with traces (which sums up over direct sum) instead of the one with supremum. Thus we have
\begin{equation}
	\dim(E)=\dim\big( \Cl_F(F\cap E_0) \big)+\dim\big( F/\Cl_F(F\cap E_0) \big).
\end{equation}
The module $F$ being projective and finitely generated, proposition \ref{PropProjFiniDimCldim} allows us to replace $\dim\big( \Cl_F(F\cap E_0) \big)$ by $\Dim(F\cap E_0)$ and write
\begin{equation}
	\dim(E)=\Dim(F\cap E_0)+\Dim\big( F/\Cl_F(F\cap E_0) \big)\leq \Dim(E_0)+\Dim(F/(F\cap E_0))
\end{equation}
where we also used lemma \ref{LemHinjectifHdimdim}. Since $F/(F\cap E_0)$ is a quotient of $E_2$, we have $\Dim(F/(F\cap E_0))\leq\Dim(E_2)$, and taking the supremum over all suitable $F$, we find the result
\begin{equation}
	\dim(E_1)\leq \Dim(E_0)+\Dim(E_2).
\end{equation}
\end{proof}

\begin{proposition}
If $E$ is a finitely generated module and $F\subseteq E$, then $\Dim(F)=\Dim\big(\Cl_E(F)\big)$.
\end{proposition}
\begin{proof}
Hint: by the proposition, one can assume that $E$ is actually projective.
\end{proof}
\begin{probleme}
 That has to be completed.
\end{probleme}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
					\section{Decomposition of operators and representations}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Motivation}
%---------------------------------------------------------------------------------------------------------------------------

Let $G$ be a compact topological group and consider the space $L^2(G)$ (with respect to the Haar measure), and $M$ be the von~Neumann algebra generated by the left regular representation
\begin{equation}
	M=\{ U_g\tq g\in G \}''
\end{equation}
with $(U_gf)(f)=g(g^{-1} h)$. Each $U_g$ is an unitary operator in $H$. In this case, the commutant $M'$ turns out to be the von~Neumann algebra generated by the regular right representation.

\begin{probleme}
	The operator $R$ given by 
	\begin{equation}
		\big(R(f)\big)(x)=\frac{ f(x) }{ 2 }
	\end{equation}
	commutes with all the regular left representation, but is not part of the regular right representation. Do we impose unitarity conditions ?
\end{probleme}

When $\sigma\colon G\to \End(V)$ is a finite dimensional irreducible representation of the group $G$, the \defe{character}{character!of a representation} of $\sigma$ is the function $\chi_{\sigma}\colon G\to \eC$ defined by the formula
\begin{equation}
	\chi_{\sigma}(g)=\tr\big( \sigma(g) \big).
\end{equation}
The representation $\sigma$ thus defines the operator $P_{\sigma}$ on $H=L^2(G)$,
\begin{equation}
	(P_{\sigma})(f)=\frac{ \dim(\sigma) }{ \volume(G) }\int \chi_{\sigma}(g^{-1})(U_gf)\,dg.
\end{equation}

\begin{theorem}[Peter-Weyl]			\label{ThoPeterWeyl}\index{Peter-Weyl theorem}
	The operator $P_{\sigma}$ is a projection which belongs to $M\cap M'$ and for which the following hold
	\begin{enumerate}
		\item\label{ItemPeterWeyli} If $\sigma_1\nsimeq \sigma_2$, then $P_{\sigma_1}P_{\sigma_2}=0$,
		\item \label{ItemPeterWeylii} in the strong topology, $\sum_{\sigma}P_{\sigma}=\mtu$,
		\item the algebra $M\cap M'$ is generated by $\{ P_{\sigma} \}$ and each of the $P_{\sigma}$ is minimal in the center,
		\item $P_{\sigma}MP_{\sigma}$ is a factor on $H_{\sigma}$ and we have $(P_{\sigma}MP_{\sigma})'=P_{\sigma}M'P_{\sigma}$,
		\item $P_{\sigma}MP_{\sigma}$ is finite dimensional.
	\end{enumerate}
\end{theorem}

Notice that, because of point \ref{ItemPeterWeyli} and \ref{ItemPeterWeylii}, if $H_{\sigma}$ denotes the range of $P_{\sigma}$, then
\begin{equation}
	H=\bigoplus_{\sigma}H_{\sigma}.
\end{equation}

\begin{proof}
No proof.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Conventions and definitions}
%---------------------------------------------------------------------------------------------------------------------------

From now, all Hilbert space will be separable and measure spaces $(X,\mu)$ will be as follows. The topological space $X$ will be an Hausdorff, secondly countable metrisable space and $\mu$ will be the completion of a Borel measure which is finite on compact sets on $X$. By \defe{completion}{completion!of a measure}, we mean that all subset of a null set are measurable of measure zero.

Now let $X$ be a set. A \defe{field of Hilbert space}{field!of Hilbert space} over $X$ is a set of Hilbert spaces $H_x$ for each $x\in X$. A \defe{section}{section!of field of Hilbert space} of the field is a function $V\colon C\to \bigsqcup_{x\in X}H_x$ such that $V(x)\in H_x$. We often write $V_x$ instead of $V(x)$. The set of sections is denoted by $\Gamma\{ H_x \}$.

Let $H$ be a (separable) Hilbert space. A \defe{direct integral decomposition}{direct!integral decomposition} of $H$ is
\begin{itemize}
	\item a measure space $(X,\mu)$,
	\item a field of Hilbert spaces over $X$,
	\item a function from $H$ to the space of sections of the field that we denote by $v_x$, the value at $x$ of the section associated with $v\in H$
\end{itemize}
such that
\begin{enumerate}
	\item for every $v$ and $w$ in $H$, the function $x\mapsto\langle v_x, w_x\rangle $ is integrable and
	\begin{equation}
		\int_X\langle v_x, w_x\rangle d\mu(x)=\langle v, w\rangle ,
	\end{equation}
	\item if $u$ is any section of the field such that $x\mapsto\langle u_x, w_x\rangle $ is integrable for all $w\in H$, then $u$ is almost everywhere equal to the section associated with a vector of $H$,
	\item the set of all decompositions of vectors in $H$ is maximal.
\end{enumerate}

\begin{probleme}
I do not understand the precise signification if the maximality, cf problem \ref{ProbMaximvE}.
\end{probleme}

Notice that the set of sections that are equal almost everywhere to sections obtained by decomposition of vectors in $H$ form a module over $L^{\infty}(X,\mu)$.


An technical fact that will be used in much of proofs is the following. 

\begin{lemma}		\label{LemdensHdensHx}
If $\{ v_1,v_2,\ldots \}\subseteq H$ has a dense span in $H$, then for almost every $x\in X$, the set $\Span\{ v_{1x},v_{2x},\ldots \}$ is dense in $H_x$.
\end{lemma}

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Examples}
%---------------------------------------------------------------------------------------------------------------------------

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
					\subsubsection{First example}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////



Let $H_x$ with $x\in X$ be a field of Hilbert space over a countable set $X$. Then define $H=\bigoplus_{x\in X}H_x$. That Hilbert space decomposes by $(X,\mu)$ with $\mu$ being the counting measure, and to $v\in H$ corresponds a component $v_x$ in each $H_x$ that are taken as the section associated to the vector $v$.

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
					\subsubsection{Second example}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////


Let $(X,\mu)$ be the counting measure over the countable set $X$, and consider the Hilbert space $H=L^2(X,\mu)$. A decomposition of that Hilbert space is given as follows: first pose $H_x=\eC$ for each $x\in X$. Then, for each vector $v\in H$, we associate some choice of function $f$ in the equivalence class that defines $v$. Then we define the section associated with $v$ is $v_x=f(x)$.

Let us check that this construction fulfils the axioms of a direct integral decomposition of Hilbert space. First the function $x\mapsto \langle v_x, w_x\rangle $ has to be integrable. If $f$ is the function associated with $v$ and $g$ the one associated with $w$, we have $\langle v_x, w_x\rangle =f(x)\overline{ g(x) }$ which is integrable by Cauchy-Schwartz, and by the definition of the product in $L^2$, we have
\begin{equation}
	\langle v, w\rangle =\int_X f(x)\overline{ g(x) }\,d\mu(x).
\end{equation}
Second, suppose that $u$ is a section such that the map $x\mapsto u_x\overline{ f(x) }$ is integrable for every $f$ associated with a vector in $H$. The measured space $(X,\mu)$ being countable, $X$ is a union of finite measure sets $\{ X_i \}$ on each of them one can consider the characteristic function $1_i$. Then for every $i$, the function $x\mapsto u_x 1_i$ is measurable on $X_i$. That proves that $u$ is measurable. We conclude that it is square integrable and thus defines a function which is almost everywhere equal to the section associated with a vector $v\in L^2(X,\mu)$, namely the element of $L^2(X,\mu)$ which is the class of $u$.

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
					\subsubsection{Third example}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Let $H=L^2(X,\mu_1)\oplus L^2(X,\mu_2)$ and $\mu=\mu_1+\mu_2$ which is still a complete measure. By Radon-Nikod\'ym theorem \ref{ThoRadonNikodym}, there exists positive measurable functions $f_1$ and $f_2$ such that $\mu_i=f_i\mu$. We can decompose $H$ as the direct integral
\begin{equation}
	H_x=l^2\Big(    \{ x \}\cap\{ f_1>0 \}\sqcup \{ x \}\cap\{ f_2>0 \}  \Big).
\end{equation}
Depending on the $x$, the set $\{ x \}\cap\{ f_1>0 \}\sqcup \{ x \}\cap\{ f_2>0 \}$ has zero, one or two elements. Now if $v=(v_1,v_2)\in H$ with $v_!=[g_1]$ and $v_2=[g_2]$, we define the section associated with $v$ as
\begin{equation}
	v_x=\big( f_1(x)^{1/2}g_1(x),f_2(x)^{1/2}g_2(x) \big).
\end{equation}
As notation, if $f_1(x)=0$, we identify this with the element $f_2(x)^{1/2}g_2(x)$ instead of with $(0,f_2(x)^{1/2}g_2(x))$.

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Decompositions of operators}
%---------------------------------------------------------------------------------------------------------------------------



Suppose that the separable Hilbert space $H$ is provided with a decomposition over $(X,\mu)$. A \defe{decomposition}{decomposition!of operator} of the operator $T\in \oB(H)$ is a family of bounded operators $T_x\colon H_x\to H_x$ such that for every $v\in H$, the condition
\begin{equation}		\label{EqCondTvDecompOps}
	(Tv)_x=T_xv_x
\end{equation}
holds for almost every $x\in X$. 

\begin{remark}
The conditions \ref{EqCondTvDecompOps} are in fact uncountably many conditions (one for each $v\in H$) each of them having the possibility to be wrong on a null set. One has thus to be prudent because an uncountable union of null set \emph{might} be a set of non zero measure.
\end{remark}


\begin{lemma}
The set of decomposable operators is a $*$-algebra.
\end{lemma}

\begin{proof}
If the operator $T$ is decomposable, the rule $(T^*)_x=(T_x)^*$ provides a decomposition of $T^*$.
\end{proof}

\begin{lemma}
Let $T$ be a decomposable operator. We have $T\geq 0$ if and only if $T_x\geq 0$ almost everywhere.
\end{lemma}

\begin{proof}
	In order to prove that $T$ is positive, we have to evaluate $\langle Tv, v\rangle $ from the decomposition of $T$ and $v$. We suppose that $T_x\geq 0$ for almost every $X\in X$ and we compute
	\begin{equation}
		\langle Tv, v\rangle =\int_X\langle (Tv)_x, v_x\rangle d\mu(x)=\int_X\langle T_xv_x, v_x\rangle d\mu(x)\geq 0.
	\end{equation}
	where we were allowed to change $(Tv)_x$ by $T_xv_x$ because the equality holds almost everywhere.

	For proving the contrary, let pick a dense, countable and rational vector subspace $H_0\subseteq H$, and assume that $T\geq 0$. If $v\in H$ and if $E\subseteq X$ is measurable, then by maximality of the Hilbert space decomposition there is some vector $v_E\in H$ such that
	\begin{equation}		\label{EqCondvEvx}
		(v_E)_x=
	\begin{cases}
		v_x&\text{if $x\in E$}\\
		0&\text{otherwise.}
	\end{cases}
	\end{equation}

	\begin{probleme}		\label{ProbMaximvE}
	I do not see why to use the maximality. Indeed, one considers the section 
	\begin{equation}		
		s_x=
	\begin{cases}
		v_x&\text{if $x\in E$}\\
		0&\text{otherwise.}
	\end{cases}
	\end{equation}
	By definition of decomposition of $v$, the integral
	\begin{equation}		\label{EqProbIntX}
		\int_X\langle v_x, w_x\rangle d\mu(x)
	\end{equation}
	exists for every $w\in H$. Now we have that
	\begin{equation}		\label{EqProbIntE}
		\int_X\langle s_x, w_x\rangle d\mu(x)= \int_E\langle v_x, w_x\rangle d\mu(x)
	\end{equation}
	whose existence is assured by existence of \eqref{EqProbIntX}, isn't ? 

	Existence of integral \eqref{EqProbIntE} assures the existence of a vector $v_E\in H$ such that $(v_E)_x=s_x$ almost everywhere. So we have the $v_E$ without maximality axiom. Do we really want the condition \eqref{EqCondvEvx} to hold everywhere and not only almost everywhere ? Since we only use it in integrals, I think that one does not care about a violation of condition \eqref{EqCondvEvx} on a null set.
	\end{probleme}

	We have that
	\begin{equation}
		\int_E\langle T_xv_x, v_x\rangle d\mu(x)=\int_X\langle T_xv_{Ex}, v_{Ex}\rangle =\langle Tv_E, v_E\rangle \geq 0
	\end{equation}
	because $T\geq 0$ by assumption. So we proved that $x\mapsto\langle T_xv_x, v_x\rangle $ is an integrable function on $X$ for which the integral over any subset is a positive real number. Then the function is real positive almost everywhere. Thus we have
	\begin{equation}
		\langle T_xv_x, v_x\rangle \geq 0
	\end{equation}
	almost everywhere. Therefore there exists a null set $N\subseteq X$ such that $\langle T_xv_x, v_x\rangle \geq 0$ for every $v\in H_0$ whenever $x\in X\setminus N$. If $x\in X\setminus N$, then $\Span\{ v_x\tq v\in H_0 \}$ is dense in $H_x$ because of lemma \ref{LemdensHdensHx}. Notice that $H_0$ is countable and there is one null set for each element of $H_0$ on which we are unsure of the sign of $\langle T_xv_x, v_x\rangle $.

	By enlarging the set $N$ we can assume that 
	\begin{equation}
		(a_1v_1+a_2v_2)=a_1(v_1)_x+a_2(v_2)_x
	\end{equation}
	for every $x\in X\setminus N$ and $a_i\in\eQ[i]$. Indeed the equalities are an equation for each $a_i\in\eQ[i]$ and $v_i\in H_0$. That is thus a countable set of equations; thus the set where the equations are not satisfied is a countable union of null sets.

	What we have now is that every vector in $H_x$ (with $xin X\setminus N$) can be written as a limit if vectors in $H_0$, and then $\langle T_xv_x, v\rangle \geq 0$, so that $T_x\geq 0$.

\end{proof}

\begin{lemma}
We have
\begin{equation} 
	\| T \|=\esssup\| T_x \|=\min\{ c\tq \| T_x \|\leq c\text{ almost everywhere} \}.
\end{equation}
\end{lemma}

\begin{proof}
	The inequality $\| T \|\leq\esssup\| T_x \|$ comes from the fact that
	\begin{equation}
		\| Tv \|=\int_X\langle T_xv_x, T_xv_x\rangle d\mu(x)
	\end{equation}
	which gives the bound. For the inverse inequality, remark that $\| T \|^2=\| T^*T \|$ and $(T^*T)_x=(T_x)^*T_x$ almost everywhere, so that one can replace $T$ by $T^*T$, or more simply we can assume that $T\geq 0$. Now consider the positive and self-adjoint operator $\| T \|\mtu-T$. The ``component'' operator is positive almost everywhere: $\| T \|\mtu=T_x\geq 0$ for almost every $x\in X$. We know that the maximum of the spectrum of $T_x$ is $\| T_x \|$, so that the number $\| TY \|-\| T_x \|$ is almost everywhere positive because it is an element of the spectrum of $\| T \|\mtu-T_x$ which is positive.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Diagonal and decomposable operators}
%---------------------------------------------------------------------------------------------------------------------------



An operator $S$ is \defe{diagonal}{diagonal operator} if it is decomposable and if $S_x$ is multiple of identity for almost every $x\in X$.

As motivation, consider the example $H=\eC^{n_1+n_2}=\eC^{n_1}\oplus\eC^{n_2}$, the measure space being two points with the counting measure. A diagonal operator looks like
\begin{equation}
	\begin{pmatrix}
	  \lambda_1\mtu	&		\\ 
		&	\lambda_2\mtu	
	\end{pmatrix},
\end{equation}
while decomposable operators are
\begin{equation}
	\begin{pmatrix}
	 		 T_1	&		\\ 
			&	T_2	
	\end{pmatrix}.
\end{equation}
One sees that these two sets are mutually commutant. We will see in theorem \ref{ThoDecopDiagCommE} that this is a general fact that decomposable operators and diagonal operators are mutually commutant.

\begin{theorem}[Kaplansky density theorem]\index{Kaplansky density theorem}		\label{ThoKaplanskyDensity}
	If $A$ is a $*$-algebra of operators on $H$, then every strong limit of net in $A$ is a strong limit of a bounded net of elements in $A$. In other words, if $T=\lim_{\rightarrow}T_{\alpha}$, then there exist a net $S_{\beta}$ with $\| S_{\beta} \|\leq M$ (fixed $M$) such that $T=\lim_{\rightarrow}T_{\beta}$.
\end{theorem}

A complete proof is given in \cite{JonesVN}.

\begin{proof}[Sketch of proof]
	First, a convex subset of $\oB(\hH)$ is strongly closed if and only if it is weakly closed. So, using what is said on page \pageref{PgStarWeakRespecte} about the fact that weak topology is compatible with the involution, we know that if $T$ lies in the strong closure of $A$, and if $T=T^*$, then $T$ is the limit of a net of self-adjoint elements in $A$. That allows us to focus the proof of the theorem on self-adjoint elements of $A$.

	\begin{probleme}
	For me, the fact that this reasoning actually allows to restrict ourself to self-adjoint elements. But I suppose that it would become more clear when one understands the link between the statement here and the statement of Kaplansky's theorem in \cite{JonesVN}, page 32.
	\end{probleme}

	Consider the function $f(x)=2x/(1+x^2)$ that provides an homeomorphism from $[-1,1]$ to $[-1,1]$. Thus by continuous functional calculus, if $T=T^*$ and $\| T \|\leq 1$, we have $T=f(S)$ where $S=S^*$ and $S$ belongs to the norm closure of the algebra generated by $T$.

	Now if $T$ is the strong limit of the net $T_{\alpha}$ of self-adjoint operators, then $S$ is the strong limit of $S_{\alpha}$ with $S_{\alpha}\in A$ and $S^*_{\alpha}=S_{\alpha}$. Indeed one can prove that $S_{\alpha}\to S$ implies\footnote{In the weak topology, that implication is the continuous functional calculus, but in the strong topology (the one we are considering here), the validity of this assertion relies on the particular form of $f$.} $f(S_{\alpha})\to f(S)$.

	Since $\| f(S_{\alpha}) \|\leq 1$, thus $\| T \|\leq 1$.
\end{proof}



\begin{theorem}		\label{ThoDecopDiagCommE}
The algebra of decomposable and diagonal operators are mutually commutant.
\end{theorem}

\begin{proof}
	The fact that decomposable operators are in the commutant of diagonal operators and vice versa. The strategy to prove the theorem will be to first prove that decomposable and diagonal operators are von~Neumann algebras, and then show that every operator in the commutant of diagonal operators is decomposable. From there, the conclusion yields from the double commutant theorem.

	Suppose that $T$ is a strong limit of decomposable operators, i.e
	\begin{equation}
		T=\slim T_{\alpha}
	\end{equation}
	where $T_{\alpha}$ is decomposable and $\sup\{ | T_{\alpha} | \}<\infty$.
	 We want to show that $T$ is decomposable. For, let $H_0$ be a dense countable rational subspace of $H$. If $T$ is limit of a uniformly bounded \emph{net}, the fact that $H_0$ is countable makes that there is a \emph{sequence} of uniformly bounded decomposable operators $T_n$ such that $T_nv\to Tv$ for every $v\in H_0$.

	We have
	\begin{equation}
		\lim_{n\to\infty}\int_X \| T_{nx}v_x - (Tv)_x \|^2d\mu(x)=0
	\end{equation}
	for almost every $v\in H_0$. A general fact about $L^2$ spaces is that when a sequence goes to zero, then the functions (representative of the elements of $L^2$) themselves goes to zero on a subsequence. So for every given $v\in H_0$ there is a subsequence $\{ n_j \}$ such that
	\begin{equation}
		\| T_{n_jx}v_x-(Tv)_x \|\to 0
	\end{equation}
	for almost every $x\in X$. The subsequence might depends on the $v$, bu a diagonal argument provides a subsequence $\{ n_k \}$ of $\{ n_j \}$ such that for every $v\in H_0$,
	\begin{equation}
		\| T_{n_kx}v_x-(Tv)_x \|\to 0
	\end{equation}
	for almost every $x\in X$. These relations are a countable number of convergence almost everywhere. Then there exists a null set $N\subseteq X$ such that
	\begin{equation}		\label{EqTnkxTvxHorsN}
		\| T_{n_kx}v_x-(Tv)_x \|\to 0
	\end{equation}
	for every $v\in H_0$ and $x\in X\setminus N$. 

	By enlarging again the null set $N$, we define
	\begin{equation}
		H_{0x}=\{ v_x\tq v\in H_0 \}
	\end{equation}
	for $x\in X\setminus N$. This is a dense subspace of $H_x$ by lemma \ref{LemdensHdensHx}. Since the essential supremum of $\| T_{nx} \|$ is the norm of $T_n$, we have a ``double uniformly bounded'' relation
	\begin{equation}
		\sup_n\sup_x\| T_{nx} \|<\infty.
	\end{equation}
	Now for $x\in X\setminus N$ we define $T_x$ on $H_{0x}$ by
	\begin{equation}
		T_xv_x=\lim_{k\to\infty} T_{n_kx}v_x
	\end{equation}
	for each $v\in H_0$. That limit exists by construction. 

	\begin{probleme}
		I suppose that this definition together with property \eqref{EqTnkxTvxHorsN} means that for every $w\in H_0$ and every $x\in X\setminus N$,
		\begin{equation}			\label{EqSurHzeroTwTxwx}
			(Tw)_x-T_xw_x=0.
		\end{equation}
	\end{probleme}

	It extends by continuity from $H_{0x}$ to $H_x$. The resulting operator is bounded because the sequence $T_{n_kx}$ is uniformly bounded.
	 
	Now we enlarge once again the set $N$ by the null set appearing in the definition of the essential supremum we find that $T_x$ is bounded for every $x\in X\setminus N$. All the work make $\{ T_x \}_{x\in X}$ a candidate decomposition of $T$. 

	In order to check that this actually is a decomposition of $T$, we have to prove that $(Tv)_x=T_xv_v$ for every $v\in H$ and almost every $x\in X$. We will prove that property by proving that the integral
	\begin{equation}
		\int_X\| (Tv)_x-T_xv_x \|\,d\mu(x)
	\end{equation}
	vanishes. For that, we choose $w\in H_0$ such that $\| w-v \|\leq\epsilon$ and, by virtue of \eqref{EqSurHzeroTwTxwx}, we add $T_xw_x-(Tw)_w$ in the integrand:
	\begin{equation}
		\begin{split}
			\int_X\| (Tv)_x-T_xv_x \|^2\,d\mu(x)	&= \int_X\| (Tv)_x -(Tw)_x+T_xw_x -T_xv_x \|^2\,d\mu(x)\\
								&\leq 2\int_X\| (Tv)_x-(Tw)_x\|^2\,d\mu(x)+\int_X\| T_xw_x-T_xv_x\|^2\,d\mu(x)\\
								&=2\| T(v-w) \|^2+2\| \tilde T(v-w) \|^2\\
								&=2\| T \|\,\| v-w \|^2 + 2\| \tilde T \|\,\| v-w \|^2\\
								&\leq \text{constant}\cdot \epsilon
		\end{split}
	\end{equation}
	where the operator $\tilde T$ is defined by $(\tilde Tw)_x=T_xw_x$.


	Thus the set of decomposable operators is strongly closed, so that it is a von~Neumann algebra. The same argument holds to prove that diagonal operators form a von~Neumann algebra too. We want now to prove that the commutant of diagonal operators is the set of decomposable. For that, it is sufficient to prove that every operator in the commutant of diagonals is decomposable. Since a von~Neumann algebra is generated by its projections , we have only to prove that every projection in the commutant of the diagonal is decomposable.

	Let $P$ be such a projection and enlarge $H_0$ in order to have $PH_0\subset H_0$. That remains a countable set because such an enlargement is $H'_0=H_0+PH_0$ for example. We choose a null set $N\subseteq X$ such that if $x\in X\setminus N$ then
	\begin{equation}
		(a_1v_1+a_2v_2)_x=a_1v_{1x}+a_2v_{2x}
	\end{equation}
	for every $v_1$ and $v_2$ in $H_0$ and $a_i\in\eQ[i]$. The set $H_{0x}=\{ v_x\tq v\in H_0 \}$ is dense in $H_x$. For $f\in L^{\infty}(X,\mu)$, we define the multiplication operator
	\begin{equation}
		(M_fv)_x=f(x)v_x,
	\end{equation}
	which is, by definition, a diagonal operator. Let $v\in PH_0$ and $w\in P^{\perp}H_0$, we have
	\begin{equation}
		\int_Xf(x)\langle v_x, w_x\rangle \,d\mu(x)= \int_X\langle f(x) v_x, w_x\rangle \,d\mu(x)=\langle M_fv, w\rangle .
	\end{equation}
	Since $P$ is in the commutant of diagonals, it commutes with $M_f$, so that $M_fv\in PH$ while $w\in P^{\perp}H_0$ and the latter product is thus zero: $\langle M_fv, w\rangle =0$. That proves that $x\mapsto\langle v_x, w_x\rangle $ is a function that integrates to zero when multiplicated\quext{My spelling corrector does not know that word. Bad word or bad corrector ?} by any $L^{\infty}$ function. That means in turn that $\langle v_x, w_x\rangle =0$ almost everywhere. We enlarge $N$ in such a way that
	\begin{equation}		\label{EqPerpPHPperpH}
		\{ v_x\tq v\in PH_0 \}\perp\{ w_x\tq w\in P^{\perp}H_0 \}
	\end{equation}
	for every $x\in X\setminus N$. Of course, $PH_0\oplus P^{\perp}H_0=H_0$, so that the direct sum of the two spaces of \eqref{EqPerpPHPperpH} is $H_{0x}$. Taking the strong closure,
	\begin{equation}
		\overline{ \overline{ \{ v_x\tq v\in PH_0 \} } }\oplus\overline{ \overline{ \{w_x\tq w\in P^{\perp}H_0 \}} }=H_x
	\end{equation}
	where the double bar denotes the strong closure.
	%
	%	If someone knows ho to produce a double bar in a more intrinsically way that double \overline{  }, I am open to learn.
	% 
	Now, for $x\in C\setminus N$, define $P_x\colon H_x\to H_x$, the projection onto $\overline{ \overline{ \{ v_x\tq v\in PH_0 \} } }$. By the same reasoning as for $T$ before, we prove that $\{ P_x \}$ decomposes $P$.
\end{proof}

\begin{lemma}		\label{LemMabelAstrDense}
If $M$ is an abelian von~Neumann algebra on a separable Hilbert space $H$, then $M$ has a strongly dense $C^*$-algebra $A$
\end{lemma}

\begin{proof}
No proof.
\end{proof}

\begin{theorem}		\label{ThoVNableHDiag}
If $M$ is an abelian von~Neumann algebra on a (as usual separable) Hilbert space $H$, then there is a decompositon of $H$ such that $M$ is the set of diagonal operators.
\end{theorem}

\begin{proof}
	Pick a $A\subseteq M$ as in the lemma \ref{LemMabelAstrDense}, and add an unit is needed. Then we have $A\simeq C(X)$ for some metrisable compact space $X$ by the
	\href{http://en.wikipedia.org/wiki/Gelfand_isomorphism}{Gelfand theorem} (see \cite{Landsman}). We can write 
	\begin{equation}
		H=\bigoplus_{k=1}^{\infty}H_k
	\end{equation}
	where $H_k$ is invariant under the action of $A$ and has a cyclic vector. Indeed, pick a vector $v_1$ in $H$ and define $H_1=Av_1$, then pick $v_2$ in the complement and continue. We have an isomorphism $H_k\simeq L^2(X,\mu_k)$ where $\mu_k$ is some probability measure by $v_k\mapsto 1$ and $Tv_k\mapsto\hat T$ where the hat denotes the Gelfand isomorphism.

	\begin{probleme}
		That gives an element of $L^2(X,\mu_k)$ for each vector inside $H_k$. But I do not see the isomorphism. For example a simple step function belongs to $L^2(X,\mu_k)$ and corresponds to which element of $H_k$ ?

		The map
		\begin{equation}
			\begin{aligned}
			 \psi\colon Av_1&\to L^2(X,\mu) \\ 
			   Tv_1&\mapsto \hat T 
			\end{aligned}
			\end{equation}
		(whose image is included in $L^2(X,\mu)$ because $X$ is compact, so that every continuous function is square integrable with respect to a probability measure) is injective because two different continuous functions cannot belong to the same class in $L^2(X,\mu)$. 

		For me, surjectivity is not clear (and even wrong) because there exists many elements in $L^2(X,\mu)$ who have no continuous representative. Do we have to game with limits and exploit the fact that $A$ is strongly closed ?

		\end{probleme}
	So we can assume that $A=C(X)$ and $H=\bigoplus_kL^2(X,\mu)$. Let 
	\begin{equation}
		\mu=\sum_{k=1}^{\infty}2^{-k}\mu_k
	\end{equation}
	which is still a probability measure, and define $H_x=l^2(\eN,\mu_x)$ where $\mu_x$ is the measure on $\eN$ defined by
	\begin{equation}
		\mu_x\big( \{ k \} \big)=\frac{ d\mu_k }{ d\mu }(x)
	\end{equation}
	by the Radon-Niked\'ym theorem. For recall, $d\mu_k/d\mu$ is the function on $X$ defined by the fact that $d\mu_k=(d\mu_k/d\mu)d\mu$ in the sense that
	\begin{equation}
		\int_Xfd\mu_k=\int_Xf\frac{ d\mu_k }{ d\mu }d\mu
	\end{equation}
	for every functions $f$ on $X$. Now for each $\varphi=(\varphi_1,\varphi_2,\ldots)\in H$, we define $\varphi_x\in H_x$ by
	\begin{equation}
	\begin{aligned}
	 \varphi_x\colon \eN&\to \eC \\ 
	   k&\mapsto \varphi_k(x). 
	\end{aligned}
	\end{equation}
	One has to show that the so defined $\varphi_x$ is actually an element of $l^2(\eN,\mu_x)$, that is 
	\begin{equation}		\label{EqSumVpNK}
		\sum_k| \varphi_k(x) |^2\frac{ d\mu_k }{ d\mu }(x)
	\end{equation}
	has to be finite. For, we have the computation
	\begin{equation}		\label{EqIntXsumnormVarPhi}
	\begin{split}
		\int_X\sum_k| \varphi_k(x) |^2\frac{ d\mu_k }{ d\mu }(x)\,d\mu(x)	
			&=\sum_k\int_X| \varphi_k(x) |^2\frac{ d\mu_k }{ d\mu }(x)\,d\mu(x)\\
			& = \sum_k\int_X| \varphi_k |^2\,d\mu_k(x)\\
			& = \sum_k\| \varphi_j \|^2\\
			& = \| \varphi \|^2.		
	\end{split}
	\end{equation}
	where, in the first line we permuted the sum and the integral using the monotone convergence theorem. The fact that integral \eqref{EqIntXsumnormVarPhi} is finite proves that the function \eqref{EqSumVpNK} has finite values almost everywhere, or 
	\begin{equation}
		\| \varphi_x \|^2_{l^2(\eN,\mu_x)}<\infty
	\end{equation}
	almost everywhere. Let us redefine $\varphi_x$ as zero for the $x$ where the former definition gives $\| \varphi_x \|^2_{l^2(\eN,\mu_x)}$. This is a redefinition over a null set.

	One can check that this construction provides a decomposition of $H$ for which $M$ is the algebra of diagonal operators.

	\begin{probleme}
	To be done\ldots 
	\end{probleme}
\end{proof}

Let $M$ be an abelian von~Neumann algebra of operators on $H$ and suppose that there are two decompositions $\{ H_x \}$ and $\{ H_y \}$ of $H$ using $M$ by theorem \ref{ThoVNableHDiag}. Let now 
\begin{equation}
	M_2=
\left\{ 
\begin{pmatrix}
  T	&		\\ 
  	&	T	
\end{pmatrix}
 \right\}\tq T\in M
\end{equation}
That von~Neumann algebra decomposes $H\oplus H$ into $\{ H_x \}\oplus\{ H_y \}$. The matrix
\begin{equation}
	S=
\begin{pmatrix}
  0	&	1	\\ 
  1	&	0	
\end{pmatrix}
\end{equation}
is decomposable because it belongs to the commutant of $M_2$. Thus it provides an unitary isomorphism of $H$ that applies $H_x$ on $H_y$.

\begin{proposition}		\label{PropNprimexxNprime}
	If $N$ lies in the commutant of $M$, there are von~Neumann algebras $N_x\subseteq\oB(H_x)$ for almost every $x$ such that
	\begin{enumerate}
		\item $N_x=\{ T_x\tq T\in N \}''$,
		\item $(N_x)'=(N')_x$ almost everywhere.
	\end{enumerate}
\end{proposition}

\begin{proof}
No proof.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Decompositions of representations}
%---------------------------------------------------------------------------------------------------------------------------



Let $A$ be a separable $C^*$-algebra and $\pi\colon A\to \oB(H)$ be a representation of $A$ on a separable Hilbert space. We do not assume that $\pi$ is faithful.

\begin{lemma}		\label{LemHDecPipixxpi}
If $H$ is provided with a decomposition $\{ H_x \}$ and if $\pi(A)$ consists of decomposable operators, then there are representations $\pi_x\colon A\to \oB(H_x)$ such that $\pi(a)_x=\pi_x(a)$.
\end{lemma}

\begin{proof}
No proof.
\end{proof}

\begin{theorem}		\label{ThoRepDecSepIrrep}
	If $\pi\colon A\to \oB(H)$ is any representation of a separable $C^*$-algebra, then there is a decomposition of $H$ such that $\pi(A)$ consists of decomposable operators. There also exists a decomposition $\{ \pi_x \}$ of $\pi$ such that each $\pi_x$ is irreducible.
\end{theorem}

That theorem says that every representation decomposes into irreducible.

\begin{proof}

	We do not prove the first part, and suppose then that $\{ \pi_x \}$ is a decomposition given by lemma \ref{LemHDecPipixxpi}, so that $\pi_x(a)=\pi(a)_x$.

	Let $M$ be a maximal (Zorn's lemma) abelian von~Neumann subalgebra of $\big( \pi(A) \big)'$, and decompose $H$ so that $M$ is the algebra of diagonal operators. Now we consider $N$, the von~Neumann algebra generated by $M$ and $\pi(A)$. An element in $N'$ belongs to $\pi(A)'$ and commutes with $M$ which is maximal. Thus $N'=M$. 

	By the property of the decomposition $\pi_x$, an element of $\pi_x(A)'$ has to commute with all $M$, so that
	\begin{equation}
		\pi_x(A)'=(N_x)'=(N')_x=M_x=\eC\mtu,
	\end{equation}
	and by Schur's lemma, the representation $\pi_x$ is irreducible almost everywhere.
\end{proof}

As an example, take $A=C^*(F_2)$ where $F_2$ is the free group with two generators and $A$ is formed by taking all the linear combination and then the closure as $C^*$-algebra. One can show that
\begin{enumerate}
	\item There are two decompositions of the regular representation $\pi$ of $A$ on $H=l^2(F_2)$ that we denote by $\{ H_x \}$ and $\{ H_y \}$. These decompositions are \emph{a priori} built on different measured spaces.
	\item All the representations in $\{ \pi_x \}\sqcup\{ \pi'_y \}$ are irreducible and mutually inequivalent.
\end{enumerate}
So the decomposition in irreducible representations is not unique at all, in contrast to the group representation case. The point is that the regular representation of $C^*(F_2)$ is a factor, while the following theorem only assures unicity of decomposition into factors.

\begin{theorem}
	Let $\pi\colon A\to \oB(H)$ be a representation of the $C^*$-algebra $A$. There is an essentially unique decomposition of $H$ such that 
	\begin{enumerate}
		\item the representation $\pi(A)$ consists of decomposable operators,
		\item the representations $\pi_x$ are factors representations for almost every $x$.

		By ``essentially unique'', one means that if 
		\begin{align}
			\big( X,\mu,\{ H_x \}, H\to\Gamma\{ H_x \} \big)&\text{and}&\big( X',\mu',\{ H'_x \}, H\to\Gamma\{ H'_x \} \big)
		\end{align}
		are two decompositions, there exists a map $X\to X'$ which is almost everywhere an equivalence of measurable spaces. That is it maps $\mu$ to a measure which is mutually absolutely continuous with $\mu'$, and an unitary isomorphism $H_x\to H'_x$ defined for almost every $X$ which maps $v_x$ to $v'_x$ where $v'_x$ is the decomposition of $v$ with respect to the decomposition $\{ H'_x \}$.
	\end{enumerate}
\end{theorem}

\begin{proof}
	Let us prove the existence part of the theorem For we proceed as in the proof of theorem \ref{ThoRepDecSepIrrep}, but we take $M=\pi(A)''\cap\pi(A)'$, this is the center of the von~Neumann algebra generated by $\pi(A)$. Using proposition \ref{PropNprimexxNprime}, we find
	\begin{equation}
		\pi_x(A)''\cap\pi_x(A)'=\big( \pi(A)''\cap\pi(A)' \big)_x=\eC\mtu.
	\end{equation}
	That shows that $\pi_x(A)$ is a factor.
\end{proof}

A $C^*$-algebra is \defe{liminal}{liminal $C^*$-algebra } if for every irreducible representation $\pi\colon A\to \oB(H)$, we have $\pi(A)=\oK(H)$, the space of compact operators on $H$.

\begin{theorem}
If $G$ is a semisimple Lie group, then $C^*(G)$ is liminal.
\end{theorem}
\begin{proof}
No proof.
\end{proof}

\begin{theorem}
If $A$ is a liminal $C^*$-algebra, then every factor representation is of type I.
\end{theorem}

\begin{theorem}
	If $\pi$ is any representation of a liminal $C^*$-algebra on a separable Hilbert space, then there is a decomposition of $H$ such that 
	\begin{enumerate}
		\item the space $H_x$ carries a representation which is a factor of type I,
		\item $H_x=H_{\pi_x}\otimes L_x$ where $H_{\pi_x}$ is an irreducible representation of $A$, all mutually inequivalent and $L_x$ is some Hilbert space which says the ``multiplicity'' of the representation $\pi_x$ inside $\pi$.
	\end{enumerate}
	That decomposition is essentially unique.
\end{theorem}

\begin{proof}
No proof.
\end{proof}

\begin{lemma}
Every irreducible representation of $A_1\otimes A_2$ with both $A_i$ being liminal is a tensor product of irreducible representations of $A_1$ and $A_2$.
\end{lemma}

Now take an unimodular group $G$ such that $C^*(G)$ is liminal. One knows that the von~Neumann algebras generated by the left and right regular representations are mutually commutant. We consider the bi-regular representation $G\times G$ on $L^2(G)$. The commutant of that representation is equal to the center of the von~Neumann algebra generated by the two regular representation and is in particular abelian.

Using the lemma, the space $ L^2(G)$ decomposes into representations $H_{\pi\tau}=H_{\pi}\otimes H_{\tau}$ of $G\times G$ where $\pi$ and $\tau$ are irreducible representations. From the unimodular assumption, the symmetry $f(g)\to f(g^{-1})$ is an isometry that intertwines left and right regular representations. Notice that a function can be seen as a vector on $L^2(G)$ as well as as an operator over $L^2(G)$ by the convolution. Thus we turn $H_{\pi\tau}$ into a $*$-algebra by the multiplication $H_{\pi\tau}\otimes H_{\pi\tau}\tau H_{\pi\tau}$.

We denote by $\hat G$\nomenclature{$\hat G$}{Set of irreducible representations of the group $G$} the set of irreducible representations of $G$

\begin{theorem}
	Let $G$ be an unimodular locally compact liminal group. There is an unique measure on $\hat G$, the \defe{Plancherel measure}{plancherel measure}, denoted by $\mu$ such that for every $f\in L^1(G)\cap L^2(G)$ (as vector in $L^2(G)$ or as operator by involution),
	\begin{equation}
		\| f \|^2_{L^2(G)}=\int_{\hat G}\| \pi(f) \|^2_{HS}\,d\mu(\pi)
	\end{equation}
	where $\| . \|_{HS}$ denotes the Hilbert-Schmidt operator norm. Moreover we have
	\begin{equation}
		\pi(f)=\int_G f(g)\pi(g)\,dg.
	\end{equation}
\end{theorem}

That theorem has to be compared to the Fourier theory for abelian groups like $\eR$ or $S^1$, in particular the \href{http://en.wikipedia.org/wiki/Parseval's_identity}{Parseval equality}. This has also to be compared with the following theorem.

\begin{theorem}[Peter-Weyl]
If $G$ is a compact group, then
\begin{equation}
	\| f \|_{L^2(G)}^2=\sum_{\hat G}\frac{ \dim(\pi) }{ \volume(G) }\| \pi(f) \|^2_{HS}
\end{equation}
where the ration $\dim(\pi)/\volume(G)$ is the Plancherel measure made explicit in the compact case.
\end{theorem}


%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
					\section{Index theory}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


One speaks about index and subfactors in \cite{JonesVN,ConnesNCG,JonesSunder}.

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Introduction}
%---------------------------------------------------------------------------------------------------------------------------



Let $M$ be a type $II_1$ factor, which, thus, possesses an unique normal, tracial, normalized faithful state. We can assign a dimension to every modules over $M$ by theorem \ref{ThoPropDimiM}. In particular, $M$ being an algebra of operators on the Hilbert space $\hH$, the space $\hH$ is a $M$-module and we can consider the number
\begin{equation}
	\dim_M(\hH).
\end{equation}
Following the cases, that can be any number in $]0,\infty[$. Indeed, taking any $v\in\hH$, we have the $M$-module map 
\begin{equation}
\begin{aligned}
 \rho\colon M&\to \hH \\ 
   T&\mapsto Tv ,
\end{aligned}
\end{equation}
so that by lemma \ref{LemHinjectifHdimdim}, we have
\begin{equation}
	\dim_M(\hH)\geq\dim_MM.
\end{equation}
But we saw on page \pageref{subsubsecExemDimMMMod} that $\dim_MM=\tr(\mtu)$, see definition \eqref{EqPreDefDimModuleRA} and bellow. We deduce that $\dim_M\hH\geq \tr(\mtu)$, which can be any non vanishing positive real number.

Let $N\subseteq M\subseteq \oB(\hH)$ be a subfactor, i.e. that $N$ is a factor in $\oB(\hH)$ and $N\subseteq M$. For the same reason as before, $\dim_N(\hH)\in]0,\infty[$. We consider the ratio
\begin{equation}
	[M:N]=\frac{ \dim_N(\hH) }{ \dim_M(\hH) }
\end{equation}
that is called the \defe{index}{index}\nomenclature{$[M:N]$}{The index of two modules}.

The theorem that we are intend to prove is the following.
\begin{theorem}[Jones]
If $[M:N]<4$, then $[M:N]=4\cos^2(\pi/n)$ for some $n<2$.
\end{theorem}

\begin{proof}
No proof.
\end{proof}

\begin{center}
\begin{tabular}{ccr}
	$n$		&	$4\cos^2(\pi/n)$\\
\hline
	$2$		&	$0$\\
	$3$		&	$1$\\
	$4$		&	$2$\\
	$5$		&	$2.618$		& the golden ratio\\
	$6$		&	$3$\\
	\vdots		&	\vdots	
\end{tabular}
\end{center}
In the dots, we have an increasing sequence of numbers bigger than $3$ that converges to $4$.

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Example}
%---------------------------------------------------------------------------------------------------------------------------


Let $G$ be a discrete group with infinite conjugacy classes and $H$, a subgroup which has infinite conjugacy classes for its own right. Consider $M=M(G)\subseteq\oB\big(l^2(G))$ and $N=M(H)\subseteq\oB\big( l^2(H) \big)$. By simple inclusion of $H$ in $G$, we have $M(H)\subseteq\oB\big( l^2(G) \big)$ too.

As defined in subsection \ref{sssOnePartCaseMG}, the von~Neumann algebra $M(H)$ is generated by the operators $\mU_h$ with $h\in H$. We already proved in proposition \ref{ProplDeuxGFGP}\label{PglDeuxGFGPutiliseIci} that $l^2(G)$ is a finitely generated projective module over $M(G)$, so that one can address the question of $\dim_{M(G)}\big( l^2(G) \big)$ using the decomposition given by corollary \ref{CorEfgpFssIsom}:
\begin{equation}
	l^2(G)=\Cl_{l^2(G)}\big( M(G) \big)\oplus l^2(G)/M(G).
\end{equation}
On the one hand, by proposition \ref{PropDimClEgalDim}, we have $\dim\Big( \Cl_{l^2(G)}\big( M(G) \big) \Big)=\dim\big( M(G) \big)$, and on the other hand, one can prove that $l^2(G)/M(G)$ is a torsion, so that
\begin{equation}		\label{EqdimmGlDeuxGbig}
	\dim_{M(G)}\big( l^2(G) \big)=\dim_{M(G)}\big( M(G) \big)=1
\end{equation}
when a correct choice of normalisation is done.

\begin{probleme}
Is it correct that the latter dimension is in fact the trace of $\mtu$ on $M(G)$ which has to be normalised ?
\end{probleme}

Let us now consider $g_1,\ldots,g_n$ be representatives of the classes of $G/H$ and look at the decomposition
\begin{equation}
	l^2(G)=l^2(Hg_1)\oplus\ldots\oplus l^2(Hg_n).
\end{equation}
Since $l^2(Hg_i)$ is a submodule of $l^2(H)$, each of $\dim_n\big( l^2(G) \big)$ lies in the same case as equation \eqref{EqdimmGlDeuxGbig}, so that
\begin{equation}
	\dim_N\big( l^2(G) \big)=n.
\end{equation}
Thus $[M:N]=n$.

One can explicitly construct examples of index for every real bigger than $4$. 

Let $M\subseteq\oB(\hH)$ be a von~Neumann algebra and form $M^{(\infty)}\subseteq\oB(\hH\oplus\ldots\oplus\hH\oplus\ldots)$,
\begin{equation}
	M^{(\infty)}=\big\{  (T,T,\ldots)\tq T\in M  \big\}.
\end{equation}
Since $M^{(\infty)}$ does not contains more information than $M$ itself, we want to be able to say that they are the same von~Neumann algebra. The interest of ultraweak topology described in subsection \ref{subSecUltraWtopol} is that if we consider both $M$ and $M^{(\infty)}$ with the ultraweak topology, then they are homeomorphic in a natural way. 


%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Isomorphisms of abstract von~Neumann algebras}
%---------------------------------------------------------------------------------------------------------------------------

If $M\subseteq\oB(\hH)$ is an ultraweakly closed subspace (what a von~Neumann algebra always is), then the Hahn-Banach theorem applies and in particular, every von~Neumann algebra is the dual of a space.

A positive linear map $\Phi$ between von~Neumann algebras is \defe{normal}{normal!map between von~Neumann algebras} if
\begin{equation}
	\Phi(\bigvee_{\alpha}P_{\alpha})=\bigvee_{\alpha}\Phi(P_{\alpha})
\end{equation}
for every increasing net of projections. A net of projections being said \defe{increasing}{increasing!net of projections} when $\alpha>\beta$ implies $P_{\alpha}>P_{\beta}$. An example of a normal map is the trace of a type $II_1$ factor.

\begin{theorem}		\label{ThoDixLinVNanormifffuwc}
A positive linear functional on a von~Neumann algebra is normal if and only if it us ultraweakly continuous.
\end{theorem}
A proof can be found in \cite{DixDecompBk}.

\begin{probleme}
It is the right citationm, isn't ?
\end{probleme}

\begin{theorem}				\label{ThoPhiEquivuwcvna}
Let $\Phi\colon M\to \oB(\hH)$ be a $*$-homomorphism from a von~Neumann algebra into $\oB(\hH)$. The the following are equivalent:
\begin{enumerate}
\item\label{ItemPhiEquivuwcvnai} $\Phi$ is ultraweakly continuous,
\item\label{ItemPhiEquivuwcvnaii}  $\Phi$ is normal,
\item\label{ItemPhiEquivuwcvnaiii}  $\Phi(M)$ is a von~Neumann algebra.
\end{enumerate}
\end{theorem}
Notice that we do not suppose $M$ to be a von~Neumann algebra acting on the Hilbert space $\hH$.

\begin{proof}
The implication \ref{ItemPhiEquivuwcvnaiii} $\Rightarrow$ \ref{ItemPhiEquivuwcvnaii} is proved by using the theorem \ref{ThoDixLinVNanormifffuwc}. The implication \ref{ItemPhiEquivuwcvnaii} $\Rightarrow$ \ref{ItemPhiEquivuwcvnai} is only the fact that ultraweak continuity is defined in terms of linear functionals.

The difficult part is to prove that \ref{ItemPhiEquivuwcvnai} implies \ref{ItemPhiEquivuwcvnaiii}. Since $\Phi(M)$ is a $*$-algebra, proving that it is strongly closed proves that it is a von~Neumann algebra. So, let us suppose $T$ to be in the strong closure of $\Phi(M)$. By Kaplansky density theorem \ref{ThoKaplanskyDensity}, there exists a net $T_{\alpha}\in\Phi(M)$ with $\sup\| T_{\alpha} \|<\infty$ and
\begin{equation}
	T=\slim T_{\alpha}=\slim \Phi(S_{\alpha})
\end{equation}
for some $S_{\alpha}$. Since $\Phi$ is isometric, the set $\{ S_{\alpha} \}$ is uniformly bounded: $\| S_{\alpha} \|<\infty$. Thus, using the Banach-Alaogu theorem \ref{ThoBanachAlaoglu}, and taking a subnet, we can assume that there is a $S\in M$ such that
\begin{equation}
	S=\uwlim S_{\alpha}.
\end{equation}
Since $\Phi$ is ultraweakly continuous by assumption, we have $\Phi(S)=\uwlim\Phi(S_{\alpha})$. Since the limit $T=\slim T_{\alpha}$ exists, the same exists in the weak topology (and is equal), thus $T=\Phi(S)$, which proves that $\Phi(M)$ is strongly closed.
\end{proof}

So if a von~Neumann algebra is algebraically realised as two different algebras of operators on two different Hilbert spaces, the two realisations are homeomorphic. For short, we say that $*$-isomorphisms of von~Neumann algebras correspond to weakly continuous maps between realisations of them.

Remark that a map $\Phi$ which fulfils the theorem \ref{ThoPhiEquivuwcvna} is automatically isometric because $\| T \|$ is the spectral radius of $| T |$ while the spectral radius (which is a purely algebraic notion) does not change when we consider $T$ as an operator acting on one Hilbert space or an other. So, the map $\Phi$ preserves the $C^*$-algebra structure.

Let $M$ be a finite factor. We denote by $L^2(M)$\nomenclature{$L^2(M)$}{Hilbert space of the standard form for a finite factor}\label{PgLdM} the completion of $M$ in the norm derived  from the inner product
\begin{equation}
	\langle T_1, T_2\rangle =\tau(T_1T_2^*).
\end{equation}
This is the GNS construction applied to the tracial state $\tau$. The \defe{standard form}{standard!form of a von~Neumann algebra} of the finite factor $M$ is the realisation of $M$ as left multiplication operators on $L^2(M)$. The image is a von~Neumann algebra because the representation is normal and faithful. 


%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Index of finite subfactors}
%---------------------------------------------------------------------------------------------------------------------------

We say that the vector $v\in L^2(M)$ is \defe{bounded}{bounded!element of $L^2(M)$} by the positive real $K$ if for every projection $P\in M$, the condition
\begin{equation}
	\| Pv \|^2_{L^2(M)}\leq K\tau(P).
\end{equation}

\begin{lemma}
An element $v\in L^2(M)$ belongs to $M$ if and only if it is bounded.
\end{lemma}
\begin{proof}
No proof.
\end{proof}

We consider the map
\begin{equation}
\begin{aligned}
 J\colon L^2(M)&\to L^2(M) \\ 
   T&\mapsto T^*. 
\end{aligned}
\end{equation}
\emph{A priori}, that is only defined on $M$, but it is an isometry because
\begin{equation}
	\| T \|=\tr(TT^*)=\tr(T^*T)=\| T^* \|.
\end{equation}
So it extends to the completion $L^2(M)$.

\begin{lemma}
We have
\begin{equation}
	M'=JMJ
\end{equation}
in the standard form.
\end{lemma}
Notice that operators in $JMJ$ are operators of right multiplication on $M$ because $(JTJ)S=JT(S^*)=J(TS^*)=ST^*$ while the elements of $M$ are left multiplications, so that it is clear that $JMJ\subseteq M'$.

\begin{proof}
No proof.
\end{proof}

Let $M_0$ be a subfactor of a finite factor $M_1$. We define the \defe{index}{index}\nomenclature{$[M_1:M_0]$}{Index of a subfactor.}
\begin{equation}
	[M_1:M_0]=\dim_{M_0}\big( L^2(M_1) \big).
\end{equation}

\begin{theorem}
One has
\begin{equation}
	[M_1:M_0]=\dim_{M_0}(M_1).
\end{equation}
and moreover
\begin{equation}
	[M_1:M_0]=\frac{ \dim_{M_0}(\hH) }{   \dim_{M_1}(\hH) }
\end{equation}
 if $M_1$ is represented on the Hilbert space $\hH$.
\end{theorem}
\begin{proof}
No proof.
\end{proof}

Suppose given $M_1$ and a finite subfactor $M_0$ and suppose $[M_1:M_0]<\infty$. Since $M_0$ is a subfactor of $M_1$, we can see $M_0'$ as subset of $\oB\big( L^2(M_1) \big)$. If $M_1'$ is not finite, then there is a part of $L^2(M_1)$ which is identified with $L^2(M_1)$ as $M_0$-module. That part has obviously the same dimension as the whole $L^2(M_1)$ (because the module structure is the same). Thus in this case, $L^2(M_1)$ contains infinitely many submodules with all the same dimension, so that $\dim_{M_0}\big( L^2(M_1) \big)=\infty$, which contradicts the assumption. We deduce that
\begin{equation}
	M_0'\subseteq\oB\big( L^2(M_1) \big)
\end{equation}
is a finite von~Neumann algebra. We consider 
\begin{equation}
	P_1\colon L^2(M_1)\to L^2(M_1)
\end{equation}
be the orthogonal projection onto $L^2(M_0)\subseteq L^2(M_1)$. 


\begin{lemma}		\label{LemTMunPTTPiffTMzero}
If $T\in M_1$, then $TP_1=P_1T$ if and only if $T\in M_0$.
\end{lemma}

\begin{proof}
It $T\in M_0$, we have
\begin{equation}		\label{EqTPPTPTProj}
	TP_1=P_1TP_1.
\end{equation}
Taking the adjoint of that equation, $P_1T^*=P_1T^*P_1$, and using the relation \eqref{EqTPPTPTProj} for $T^*$, we find $P_1T^*=T^*P_1$ which holds for every $T\in M_0$. Thus we have
\begin{equation}
	TP_1=P_1T
\end{equation}
for every $T\in M_0$.

For the reverse sense, equality $TP_1=P_1T$ is an equality of operators on $M_1$. Let us apply it to $\mtu\in M_1$. Since $\mtu$ belongs to $M_0$ too (every von~Neumann algebra contains the unit), $P_1(\mtu)=\mtu$ and we stay with $T=P_1T$, so that $T\in M_0$. 
\end{proof}

Let now $M_2$ be a von~Neumann algebra generated by $M_1$ and $P_1$
\begin{equation}
	M_2=\{ M_1,P_1 \}''.
\end{equation}
The properties of $M_1$, $P_1$ and $M_2$ are summarized in the following theorem.
\begin{theorem}
	If $[M_1:M_0]<\infty$, then
\begin{enumerate}
\item $M_2$ is a finite factor, in particular it has a unique normal faithful trace $\tau$,
\item $[M_2:M_1]=[M_1:M_0]$,
\item $\tau(P_1)=[M_1:M_0]^{-1}$.
\end{enumerate}
\end{theorem}
\begin{proof}
No proof.
\end{proof}

The von~Neumann algebra $M_2$ was created from $M_0$ and $M_1$, while the theorem shows that $M_1$ has the same properties in $M_2$ than $M_0$ in $M_1$, so that one can redo the construction starting from $M_2$ and $M_1$ instead of $M_0$ and $M_1$ to build $M_3$ and $P_2$. The index does not change and the projection $P_2$ still has the same trace.

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Subfactors}
%---------------------------------------------------------------------------------------------------------------------------

\begin{probleme}
Je pense qu'à partir d'ici, j'ai inversé $M_0$ et $M_1$ partout jusqu'à la subsection \ref{SubSecPropSeqMO}.
\end{probleme}

Let $M_1\subseteq M_0$ be a subfactor of the finite factor $M_0$, and $P\colon L^2(M_0)\to L^2(M_0)$ be the projection onto $L^2(M_1)$. Notice that $L^2(M_1)\subseteq L^2(M_0)$ because the trace on $M_1$ is the restriction to the one of $M_0$ from unicity. Now we consider $\langle M_0, P\rangle $\nomenclature{$\langle M_0, P\rangle $}{The von~Neumann algebra generated by $M_0$ and $P$}, the von~Neumann algebra generated by $M_0$ and $P$.

\begin{lemma}		\label{LemPMNinclu}
We have $P(M_0)\subseteq M_1$.
\end{lemma}
\begin{proof}
No proof.
\end{proof}

\begin{proposition}		\label{PropPropMappMN}
The map
\begin{equation}
\begin{aligned}
p \colon M_0&\to M_1 \\ 
   T&\mapsto P(T). 
\end{aligned}
\end{equation}
satisfies
\begin{enumerate}
\item\label{ItemPropMappMNi} $p(T^*)=p(T)^*$,
\item\label{ItemPropMappMNii}$p(T^*T)\geq 0$,
\item\label{ItemPropMappMNiii} $p(T^*T)=0$ if and only if $T=0$,
\item\label{ItemPropMappMNiv} $p(S_1TS_2)=S_1p(T)S_2$ for every $S_1$ and $S_2$ in $M_1$.
\end{enumerate}
for every $T\in M_0$.
\end{proposition}

\begin{proof}
The point \ref{ItemPropMappMNi} is the fact that $M_1$ is closed under the involution. The point \ref{ItemPropMappMNii} comes form lemma \ref{LemPMNinclu} and the positivity property in $M_1$. For the point \ref{ItemPropMappMNiii}, remark that $\tr\big( p(T) \big)=\tr(T)$ because $p(\mtu)=\mtu$, while by unicity up to normalisation, the trace is determined by its value on~$\mtu$.
\end{proof}
 
A basic implication if \ref{ItemPropMappMNi} is that 
\begin{equation}
	PJ=JP.
\end{equation}


\begin{lemma}		\label{LemPTPpTPopLdeux}
If $T\in M_0$, then 
\begin{equation}
	PTP=p(T)P
\end{equation}
as operators on $L^2(M_0)$.
\end{lemma}

\begin{proof}
No proof.
\end{proof}

\begin{lemma}		\label{LemNMpPNcup}
If $M_1\subseteq M_0$ is a subfactor of the finite factor $M_0$ and if $P$ is the projection onto $L^2(M_1)$ (as operator in $L^2(M_0)$), then
\begin{equation}
	M_1=\{ M_0'\cup P \}',
\end{equation}
and
\begin{equation}
	M_1'=\{ M_0'\cup P \}''
\end{equation}
as consequence.
\end{lemma}

\begin{proof}
First, every element of $\{ M_0'\cup P \}'$ has to commute with $M_0'$ and then to belongs to $M_0''=M_0$. But we proved in lemma \ref{LemTMunPTTPiffTMzero} that when $T\in M_0$ and $TP=PT$, then $T\in M_1$. That proves that $\{ M_0'\cup P \}'=M_1$.
\end{proof}

As other consequence of lemma \ref{LemTMunPTTPiffTMzero}, we have that, when $T\in M_1$, the operator $PT\colon S\mapsto P(TS)\in L^2(M_0)$ is equal to the operator $S\colon \mapsto TP(S)$, in other words,
\begin{equation}		\label{EqPTSeqalTPS}
	P(TS)=TP(S)
\end{equation}
for every $T\in M_1$ and $S\in M_0$.

\begin{lemma}		\label{LemMOJNJequal}
We have
\begin{equation}		\label{EqLemMPJNJequal}
	\langle M_0, P\rangle =JM_1'J,
\end{equation}
and as consequence, $\langle M_0, P\rangle $ is a finite factor.
\end{lemma}

\begin{proof}
First note that the commutant of a factor is a factor, so that $M_1'$ is a factor and $JM_1'J$ is a factor because it is algebraically isomorphic to the factor $M_1'$. Thus the lemma proves that the left hand side of \eqref{EqLemMPJNJequal} is in particular a finite factor.

Let us now prove the equality \eqref{EqLemMPJNJequal}. One needs to show that $J\langle M_0, P\rangle J=M_1'$. The commutant of the left multiplication action is the right one, while the left action of $JTJ$ is the right action of $T$, so one has $JM_0J=M_0'$. Since $JPJ=P$, it is sufficient to show that
\begin{equation}
	\langle M_0', P\rangle =M_1'.
\end{equation}
The von~Neumann algebra generated by $M_0'$ and $P$ is $\{ M_0',P \}''$ that is equal to $M_1'$ by lemma \ref{LemNMpPNcup}.
\end{proof}
So $\langle M_0, P\rangle $ is a factor and it is finite when $M_1'$ is finite, which happens when $[M_0:M_1]<\infty$. Assuming that finiteness, we thus have a trace $\tr\colon \langle M_0, P\rangle \to \eC$ which extends the trace on $M_0$ (by uniqueness).

Notice that, as particular case of equation \eqref{EqLemMPJNJequal} when $M_1=M_0$, we have $P=\id$ and 
\begin{equation}
	M_0=JM_0'J.
\end{equation}
That gives us an action of $M_0'$ on $L^2(M_0)$ by
\begin{equation}		\label{EqScdotTTSJT}
	S\cdot T=(JSJ)T
\end{equation}
when $S\in M_0'$ and $T\in M_0$. 

\begin{proposition}		\label{PropdimMQhHQDIMMhH}
If $M_0$ is any finite factor acting on $\hH$ and if $Q\in M_0'$, then $Q\hH$ is invariant by $M_0$, and
\begin{equation}
	\dim_{M_0}(Q\hH)=\tr(Q)\dim_{M_0}(\hH)
\end{equation}
where $Q\hH$ is seen as module over $M_0$ (because of its invariance).
\end{proposition}

\begin{proof}
First, notice that a finite factor always has an unique trace. If $Q=0$ or $Q=\mtu$, the claim is obvious. Suppose now that $\tr(Q)=r/s$, that is a rational number.

In that case, we have
\begin{equation}		 \label{EqQhQhHHHeqMmod}
	\underbrace{Q\hH\oplus\ldots\oplus Q\hH}_{\text{$s$ times}} =\underbrace{\hH\oplus\ldots\oplus \hH}_{\text{$r$ times}} 
\end{equation}
\begin{probleme}
I can understad that in the setting of the fractional dimensions as described in subsection \ref{SubSecRationalRealDim}, but there, we have the assumption of no minimal projection.
\end{probleme}
First, notice that the trace of the identity over $Q\hH$ is the trace of $Q$ on $\hH$. Indeed, let $\{ v_i \}$ be an Hilbertian basis of $Q\hH$ and $\{ w_k \}$ be a one of $Q^{\perp}\hH$. Then
\begin{equation}	
	\tr(Q)=\sum_i\langle v_i, Qv_i\rangle +\sum_k\langle w_k, Qw_k\rangle =\sum_i\langle v_i, v_i\rangle =\tr(\mtu_{Q\hH}).
\end{equation}
Thus, by additivity, 
\begin{equation}
	\tr(\mtu_{Q\hH\oplus\ldots\oplus Q\hH})=s\tr(Q)=r.
\end{equation}
On the other hand, $\tr(\mtu_{\hH\oplus\ldots\oplus\hH})=r\tr(\mtu_{\hH})=r$. So the identity over these two $M_0$-modules are the same.
\begin{probleme}
Is that enough to deduce that these are isomorphic as $M_0$-modules ?
\end{probleme}
Taking the dimension of both sides of \eqref{EqQhQhHHHeqMmod}, we find $s\dim_{M_0}(Q\hH)=r\dim_{M_0}(\hH)$, which proves the statement in the case of $\tr(Q)\in\eQ$.

Now, the functions $\dim_{M_0}(Q\hH)$ and $\tr(Q)\dim_{M_0}(\hH)$ are increasing functions of $\tr(Q)$ that coincide on $\eQ$. Thus they are equal on $\eR$.

\end{proof}



\begin{proposition}		\label{ProptrPTMNtrT}
We have the formula
\begin{equation}		\label{EqClaimLemPTfracMNtrT}
	\tr(PT)=\frac{1}{ [M_0:M_1] }\tr(T)
\end{equation}
for every $T\in M_0$.
\end{proposition}


\begin{proof}
We have $\tr(PT)=\tr(PPT)=\tr(PTP)=\tr\big( p(T)P \big)$ because of lemma \ref{LemPTPpTPopLdeux}. It is sufficient to prove the claim \eqref{EqClaimLemPTfracMNtrT} for $T\in M_1$ because when $S\in M_0$, we would have $\tr(PS)=\tr\big( p(S)P \big)=\tr(S)/[M_0:M_1]$ because $p(S)\in M_1$. Let thus $T\in M_1$ and consider the map
\begin{equation}
	T\mapsto \tr(PT)
\end{equation}
where $PT$ is considered as operator on $L^2(M_0)$. Thanks to \eqref{EqPTSeqalTPS}, this is a (normal faithful) trace on $M_0$. So that must be a multiple of the trace on $M_0$, namely there exists a $\tau\in\eC$ such that $\tr(PT)=\tau\tr(T)$. Taking that equality with $T=\mtu$ shows that $\tau=\tr(P)$. Using proposition \ref{PropdimMQhHQDIMMhH}, we have thus
\begin{equation}
	\dim_{M_1}\big( P\cdot L^2(M_0) \big)=\tr(P)\dim_{M_0}\big( L^2(M_0) \big),
\end{equation}
but, as $M_0$-module, we have $P\cdot L^2(M_0)=L^2(M_1)$ by definition of $P$, so we have
\begin{equation}
	1=\tr(P)\cdot \dim_{M_1}\big( L^2(M_0) \big).
\end{equation}

\end{proof}


The set of expressions 
\begin{equation}
	T_0+\sum_{j=1}^nT_{j_1}PT_{j_2}
\end{equation}
with $T_0$, $T_{j_1}$ and $T_{j_2}$ in $M_0$ is a $*$-algebra. Indeed, in the multiplication of two such expressions, we get monomials of the form
\begin{equation}
	T_1\underbrace{PT_2 P}_{=p(T_2)P}T_3=\underbrace{T_1p(T_2)}_{\in M_0}PT_3.
\end{equation}
By the double commutant theorem, the von~Neumann algebra $\langle M_0, P\rangle $ is the strong closure of such expressions, and
\begin{equation}
	\tr(T_1PT_2)=\tr(PT_2T_1)=\frac{1}{ [M_0:M_1] }\tr(T_1T_2)
\end{equation}
by proposition \ref{ProptrPTMNtrT}. Thus we have an explicit formula for the trace on $\langle M_0, P\rangle $ from the trace over $M_0$.

\begin{lemma}		\label{lemPhHPNPfrac}
If $P\in M_1$, then we have
\begin{equation}
	\dim_{PM_1P}( P\hH)=\frac{1}{ \tr(P) }\dim_{M_1}(\hH),
\end{equation}
but $P\hH$ is no more a $M_1$-module.
\end{lemma}

\begin{proof}
Let $\modE$ be any $M_1$-module. Since $P\modE$ is a $PM_1P$-module, we can define $\dim^{(P)}(\modE)$ by
\begin{equation}
	\dim^{(P)}(\modE)=\dim_{PM_1P}(P\modE).
\end{equation}
That defines a dimension function on the $M_1$-modules, which is thus a multiple of the standard one. We know that, as $M_1$-module, $M_1P$ as dimension $\tr(P)$, so that the proportionality factor can be fixed on $M_1P$.

\begin{probleme}
	That proof is not complete.
\end{probleme}
\end{proof}

Let take $M_1=\eM_3(\eC)$ and $\hH=\eC^3$ as example. Each column of $a\in M_1$ is an element of $\eC^3$, so $M_1$ is three copies of $\hH$ and, as left module, we have $\hH\oplus\hH\oplus\hH=N$, and $\dim_{M_1}(\hH)=1/3$. Let
\[ 
	P=
\begin{pmatrix}
  1	&		&	\\ 
  	&	0	&	\\ 
 	&		& 0	  
\end{pmatrix}.
\]
We have $P\hH\simeq \eC$, and $PM_1P=\eC$ (the upper left element of the matrix). Thus if we have $\tr(P)=1/3$, we conclude by the lemma \ref{lemPhHPNPfrac} that $\dim_{PM_1P}(P\hH)=1$.

\begin{lemma}
We have
\begin{equation}
	\dim_{M_1}(\hH)\dim_{M_1'}(\hH)=1
\end{equation}
if $M_1$ and $M_1'$ are finite factors.
\end{lemma}

\begin{proof}
Let us first check for $\hH=L^2(M_1)$. The action of $M_1'$ on $L^2(M_1)$ is given by \eqref{EqScdotTTSJT}, so we have $\dim_{M_1'}\big( L^2(M_1) \big)=\dim_{JM_1J}\big( L^2(M_1) \big)$, so that the action of $M_1'$ on $L^2(M_1)$ is conjugate of the one of $M_1$. That proves the lemma in the case where $\hH=L^2(M_0)$.

\begin{probleme}
Pourquoi ? Cela est fait dans la proposition \ref{PropDimIIun}. Et je crois que du côté de cette proposition, on trouve pas mal de réponses à pas mal de questions ici.
\end{probleme}

\end{proof}

\begin{corollary}
We have
\begin{equation}
	[M_0:M_1]=[M_1':M_0']
\end{equation}
when $M_0\in\oB(\hH)$ is a factor of type $II_1$ and $M_1$ is a subfactor of $M_0$.
\end{corollary}
\begin{proof}
No proof.
\end{proof}

\begin{theorem}
We have
\begin{equation}
	[ \langle M_0, P\rangle :M_0 ]=[M_0:M_1]
\end{equation}
under the same assumptions.
\end{theorem}

\begin{proof}
If $\modE$ is any representation of $\langle M_0, P\rangle $, we have the formula
\begin{equation}	\label{EqlangleMOmodEME}
	[\langle M_0, P\rangle :M_0]=\frac{ \dim_{M_0}\modE }{ \dim_{\langle M_0, P\rangle }\modE }.
\end{equation}
We know by formula \eqref{EqDimMMprimeprodun} that 
\begin{equation}
	\Big( \dim_{\langle M_0, P\rangle }\modE \Big)\cdot \Big(  \dim_{\langle M_0, P\rangle '}\modE\Big)=1.
\end{equation}
On the other hand, since $\langle M_0, P\rangle =JM_1'J$ (lemma \ref{LemMOJNJequal}), we have
\begin{equation}
	\dim_{\langle M_0, P\rangle '}\modE=\dim_{JM_1J}\modE=\dim_{M_1}\modE=[M_0:M_1].
\end{equation}
Since formula \eqref{EqlangleMOmodEME} holds for every choice of $\modE$, we compute the right hand side in the case where $\modE=L^2(M_0)$. In that particular case, $\dim_{M_0}\modE=1$, and the claim follows.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Example of index bigger than \texorpdfstring{$4$}{4}}
%---------------------------------------------------------------------------------------------------------------------------

Consider $R$, the hyperfinite factor of type $II_1$ given by\footnote{Recall that one needs a functional in order to define the infinite tensor product.}
\begin{equation}
	R=\bigotimes_1^{\infty}\big( \eM_2(\eC),\tr \big)
\end{equation}
It turns out that, for that factor, we have $R\simeq PRP$ for every projection $P\in R$. Choose isomorphism $\alpha\colon R\to PRP$ and $\beta\colon R\to P^{\perp}RP^{\perp}$, and form the algebra
\begin{equation}
	S=\{ \alpha(T)+\beta(T)\tq T\in R \}.
\end{equation}
That algebra is algebraically isomorphic to $R$, and the isomorphism is ultraweakly continuous, so that $S$ is a von~Neumann algebra. The index of $S$ in $R$ is given by
\begin{equation}
	[R:S]=\tr(P)^{-1}+\tr(P^{\perp})^{-1}
\end{equation}
where $\tr(P)$ can take any value between $0$ and $1$, and $\tr(P^{\perp})=1-\tr(P)$. The possible values of the index are then given by the range of the function
\begin{equation}
	f(x)=\frac{1}{ x }+\frac{1}{ 1-x }
\end{equation}
when $x$ runs over $[0,1]$. One easily checks that that range is $[4,\infty]$.


%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Properties of the sequence of \texorpdfstring{$M_i$}{Mi}, \texorpdfstring{$P_i$}{Pi}}		\label{SubSecPropSeqMO}
%---------------------------------------------------------------------------------------------------------------------------

Let $M_0$ be a subfactor of $M_1$. We define $[M_1:M_0]=\dim_{M_0}\big( L^2(M_1) \big)$. We define $P_1\colon  L^2(M_1)\to L^2(M_1)$, the projection onto $L^2(M_0)$. Then we consider the new factor
\begin{equation}
	M_2=\langle M_1, P_1\rangle.
\end{equation}
For that definition, we see $M_1$ as subalgebra of $\oB\big( L^2(M_1) \big)$. Now, $M_2$ is also a subalgebra of $\oB\big( L^2(M_2) \big)$, so that, defining $P_2\colon L^2(M_2)\to L^2(M_2)$ as the projection onto $L^2(M_1)$, allows to define 
\begin{equation}
	M_3=\langle M_2, P_2\rangle \subseteq\oB\big( L^2(M_2) \big).
\end{equation}
Using that construction again and again, we get a sequence
\begin{equation}
	M_0\subseteq M_1\subseteq M_2\subseteq\ldots
\end{equation}
of factors defined by $M_{n+1}=\langle M_n, P_n\rangle $ where $P_n\colon L^2(M_n)\to L^2(M_n)$ is the orthogonal projection onto $L^2(M_{n-1})$. One can prove that
\begin{equation}
	P_n(M_n)\subseteq M_{n-1}.
\end{equation}
We thus consider the maps
\begin{equation}
\begin{aligned}
 p_n\colon M_n&\to M_{n-1} \\ 
   p_n(T_n)&\mapsto P_n(T_n),
\end{aligned}
\end{equation}
and we have the sequence
\begin{equation}
\xymatrix{%
   P_{n-1}\in M_n \ar[r]^{p_n}	&	M_{n-1}\ar[r]^{p_{n-1}}	& M_{n-2}.
}	
\end{equation}

The following is the proposition 3.3.2 in \cite{JonesSunder}.

\begin{proposition}		\label{ProppropsindexMarkov}
We have
\begin{enumerate}
\item $[M_n:M_{n+1}]=\lambda^{-1}$ does not depend on $n$,
\item $\tr(P_n)=\lambda$,
\item $\tr(P_nT_n)=\lambda\tr(T_n)$ for every $T_n\in M_n$.
\end{enumerate}
\end{proposition}

The last property is the \defe{Markov property}{Markov property}.

\begin{proof}
No proof.
\end{proof}

\begin{lemma}		\label{LemPnPllamcun}
We have 
\begin{equation}
	p_n(P_{n-1})=\lambda\cun
\end{equation}
where $\lambda=\tr(P_n)$ does not depends on $n$ by the proposition \ref{ProppropsindexMarkov}.
\end{lemma}

\begin{proof}
Since the map $(S,T)\mapsto\tr(ST)$ is a nondegenerate bilinear functional on $M_{n-1}$, it is sufficient to prove that $\tr\big( Sp_n(P_{n-1}) \big)=\lambda\tr(S)$ for every $S\in M_{n-1}$. Using point \ref{ItemPropMappMNiv} of proposition \ref{PropPropMappMN}, we have $Sp_n(P_{n-1})=p_n(SP_{n-1})$, so that
\begin{equation}
	\tr\big( Sp_n(P_{n-1}) \big)=\tr(SP_{n-1})=\lambda\tr(S),
\end{equation}
where the last equality is the Markov property.
\end{proof}

\begin{proposition}		\label{PropAlgPPPKoi}
	The projections $P_i$ fulfil the algebra
	\begin{subequations}		\label{SubeqPnPalgPPI}
	\begin{align}
		P_nP_{n+1}P_n&=\lambda P_n		\label{EqLoiPPun}		\\
		P_nP_{n-1}P_n&=\lambda P_n		\label{EqLoiPPdeux}		\\
		P_nP_m&=P_mP_n				\label{EqLoiPPtrois}
	\end{align}
	\end{subequations}
	when $| n-m |\geq 2$.
\end{proposition}

\begin{proof}
	Let us prove the second one. Using lemma \ref{LemPnPllamcun}, we find
	\begin{equation}
		P_nP_{n-1}P_n=p_n(P_{n-1})P_n = \lambda P_n,
	\end{equation}
	which is the claim.
\end{proof}

\begin{corollary}
	The algebra generated by
	\begin{equation}
		\{ \mtu,P_1,\ldots, P_n\}
	\end{equation}
	is a finite dimensional $C^*$-algebra in which there exists an unique tracial state such that for every~$k$,
	\begin{equation}
		\tr(P_kT)=\lambda \tr(T)
	\end{equation}
	whenever $T$ belongs to the algebra generated by $\mS_{k-1}=\{ \mtu,P_1,\ldots,P_{k-1} \}$.
\end{corollary}

\begin{proof}[Sketch of the proof]
Let a \emph{reduced word} in $P_1$, \ldots, $P_k$ be a word which is as small as possible using the three rules \eqref{SubeqPnPalgPPI}. We prove by induction that such a reduced word contains $P_k$ at most once. For beginning, the only reduced word in $P_1$ is $P_1$ itself. 

Now, let a word containing twice $P_k$. What is between two successive occurrences of $P_k$ is a word of $\mS_{k-1}$. That word is reduced, and thus contains $P_{k-1}$ only once by induction hypothesis. From rule \eqref{EqLoiPPtrois}, the operator $P_k$ commutes with $\mS_{k-2}$, and then the rule \eqref{EqLoiPPdeux} reduces the word (because $P_{k-1}$ appears only once).


Now, a general reduced word of $\mS_k$ has only one $P_k$ and thus has the form $m_1 P_k m_2$ where $m_1$ and $m_2$ are reduces words of $\mS_{k-1}$. Of course, $m_1$ them self decomposes in $n_{1} P_{k-1} n_2$ where $n_i$ are reduces words of $\mS_{k-2}$, and the process continues.

Every reduced word in $\mS_9$ look like
\begin{equation}
	(P_5P_4P_3)(P_8P_7P_6P_5P_4)(P_9P_8P_7P_6).
\end{equation}
Some comments
\begin{itemize}
\item The sub words are made of consecutive projections. For example the sub word $(P_5P_3)$ can be rearranged as the two sub words $(P_3)(P_5)$ by rule \eqref{EqLoiPPtrois}.
\item The sub words begin by $P_5$, $P_8$ and $P_9$. Notice that $5<8<9$. It will always be like that. If not, a rearrangement is possible.
\end{itemize}
Now fix a $n$ and consider the set of all the reduced words of $\mS_n$; there are only finitely many of them which will be labelled as $W_i$. We look at the matrix whose element $ij$ is given by
\begin{equation}		\label{EqMtrWWtr}
	\tr(W_i^*W_j).
\end{equation}
Each of $W_i^*W_j$ is a long string of elements of $\mS_n$ and the cyclic property of the trace allows us to do
\begin{equation}
	\tr\big( (\ldots)(\ldots)(P_nP_{n-1}\ldots) \big)=\tr\big( (P_nP_{n-1}\ldots)(\ldots)(\ldots)  \big).
\end{equation}
Then, using the Markov property of proposition \ref{ProppropsindexMarkov}, we can extract $P_n$. That matrix is positive semidefinite because it is formed of scalar products. If not, that would means that the assumption $M_0\subseteq M_1$ is wrong.

\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Some interesting functions}
%---------------------------------------------------------------------------------------------------------------------------

Consider the polynomials defined by the induction
\begin{subequations}
\begin{align}
	f_0(x)&=0	\\
	f_1(x)&=1	\\
	f_n(x)&=f_{n-1}(x)-xf_{n-2}(x).	
\end{align}
\end{subequations}
Since $f_n(0)=f_{n-1}(0)$, all these polynomials pass by the point $(0,1)$. By induction, one can see that
\begin{equation}
	f_n\left( \frac{1}{ 4\cos^2\theta } \right)=\frac{\sin(n\theta)}{2^{n-1}\cos^{n-1}(\theta)\sin(\theta)},
\end{equation}
so that	the smallest positive root of $f_n$ is 
\begin{equation}
	\frac{1}{ 4\cos^2\left( \frac{ \pi }{ n } \right) },
\end{equation}
and $f_n$ is negative on the interval between $1/4\cos^2(\pi/n)$ and $1/4\cos^2(\pi/(n-1))$.

Suppose $\lambda^{-1}=[M:M_0]$ and $\lambda>1/4$. Now, assume that 
\begin{equation}
	\lambda\neq \frac{1}{ 4\cos^{2}(\pi/n) }
\end{equation}
for any value of $n\in\eN$. In this case, we will found a negative diagonal entry of the matrix \eqref{EqMtrWWtr}, which is impossible because a semipositive definite matrix has no negative diagonal element.

Let 
\begin{equation}
	Q_k=\mtu-P_1\vee\ldots\vee P_k.
\end{equation}
From lemma \ref{LemFiniCSestVNa}, the operator $Q_k$ is in fact a projection in a finite dimensional algebra, and is thus a polynomial in the $P_i$'s.

\begin{lemma}
	We have
\begin{equation}		\label{EqQPQffQPQ}
	(Q_{k-1}P_kQ_{k-1})^2=\frac{ f_k(\lambda) }{ f_{k+1}(\lambda) }Q_{k-1}P+kQ_{k-1},
\end{equation}
and 
\begin{equation}
	Q_{k+1}=Q_k-\frac{ f_{k+1}(\lambda) }{ f_k(\lambda) }Q_{k-1}Q_{k-1},
\end{equation}
if $f_{k+1}(\lambda)$, \ldots, $f_1(\lambda)\neq0$.
\end{lemma}
Notice in particular that, up to a factor, the operator of equation \eqref{EqQPQffQPQ} is a projection.

\begin{proof}
No proof.
\end{proof}

\begin{corollary}
The operators $Q_{k-1}$, $P_k$ and $Q_{k+1}$ are projection, and the product is a positive operator.
\end{corollary}

That corollary shows that
\begin{equation}
	\frac{ f_k(\lambda) }{ f_{k+1}(\lambda) }>0.
\end{equation}
But a simple study of the polynomials shows that this ratio is in fact negative. We conclude that operator satisfying the algebra of proposition \eqref{PropAlgPPPKoi} are only possible when $\lambda=1/4\cos(\pi/n)$.





%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
					\section{Modular theory}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Modular isometry}
%---------------------------------------------------------------------------------------------------------------------------

Let $M$ be a von~Neumann algebra provided with $\varphi$, a faithful normal state. We consider $L_{\varphi}^2(M)$\nomenclature{$L_{\varphi}^2(M)$}{A completion of the von~Neumann algebra $M$}, the completion of $M$ for the norm associated with the inner product
\begin{equation}
	\langle T_1, T_2\rangle =\varphi(T^*_1T_2).
\end{equation}
That product is conjugate-linear in his first argument and linear in the second. The algebra $M$ acts at left by multiplication on $L_{\varphi}^2(M)$, by extending
\begin{equation}
	T\cdot S = TS.
\end{equation}
The space $L_{\varphi}^2(M)$ has a distinguished vector: the one represented by $\mtu\in M$ that we call $v$. It is a cyclic vector for $M$, i.e. the space $Mv$ is dense in $ L_{\varphi}^2(M)$. It is also separating, because $Tv=0$ with $T\in M$ implies $T=0$.

Conversely, if $\hH$ is an Hilbert space and $v\in\hH$ is cyclic and separating for a von~Neumann algebra, then the expression
\begin{equation}
	\varphi(T)=\langle v, Tv\rangle 
\end{equation}
defines a faithful (because separating) normal state on the von~Neumann algebra. Thus, in fact $\hH\simeq  L_{\varphi}^2(M)$ via an unitary isomorphism compatible with $M$. 

A natural question arising is to know the commutant of $M$ acting by left multiplication on $ L_{\varphi}^2(M)$. Let us suppose that $\varphi$ is also a trace, so we drot the index and we write $ L^2(M)$ instead of $ L_{\varphi}^2(M)$. We define
\begin{equation}
\begin{aligned}
 J\colon  L^2(M)&\to  L^2(M) \\ 
   Tv&\mapsto T^*v. 
\end{aligned}
\end{equation}
That definition is correct because $\{ Tv\tq T\in M \}$ is dense in $L^2(M)$. Notice that $T_1v=T_2v$ implies $T_1=T_2$, so that, when $\xi\in L^2(M)$ can be represented as $Tv$, that $T\in M$ is unique. 

The following lemma provides the main properties of $J$.
\begin{lemma}			\label{LemPropJ}
	The map $J$ has the following properties.
	\begin{enumerate}
		\item $J$ is conjugate-linear.
		\item\label{ItemPropJii} It is an isometry in the sense of conjugate linear operators.
		\item $J^2=\mtu$.
		\item\label{ItemPropJiv} $JMJ\subseteq M'$.
		\item\label{ItemPropJv}  $\langle Sv, JTv\rangle = \langle JS^*v, T^*v\rangle  $ for every $S$ and $T$ in $M$.
	\end{enumerate}
\end{lemma}

\begin{proof}
	The proof of \ref{ItemPropJii} is a computation using the definition of $J$, the definition of the inner product and the fact that $\varphi$ is a state:
	\begin{equation}
		\langle JT_1v, JT_2v\rangle =\langle T_1^*v, T_2^*v\rangle\varphi(T_1T^*_2)=\overline{ \varphi(T_2T_1^*) }=\overline{ \varphi(T_1^*T_2) }=\overline{ \langle T_1v, T_2v\rangle  }.
	\end{equation}
	For \ref{ItemPropJiv}, remark that
	\begin{equation}
		(JTJ)(Sv)=JT(S^*v)+J(TS^*v)=ST^*v.
	\end{equation}
\end{proof}

\begin{definition}
	A \defe{modular isometry}{modular!isometry} for $M$ with respect to the cyclic vector $v$ is a map $J\colon L^2(M)\to L^2(M)$ which satisfies 
	\begin{enumerate}
		\item $Jv=v$.,
		\item $J$ is a conjugate linear isometry,
		\item $J^2=1$,
		\item $JMJ\subseteq M'$,
		\item $\langle JSv, Tv\rangle =\langle S^*v, JT^*v\rangle $ for every $S$, $T\in M'$.
	\end{enumerate}
	Notice the difference between the claim \ref{ItemPropJv} of lemma \ref{LemPropJ}.
\end{definition}

\begin{lemma}
	If $v$ is cyclic for $M$, then it is separating for $M'$, and if it is separating for $M$, then it is cyclic for $M'$.
\end{lemma}


\begin{proposition}
	If $J$ is a modular isometry, then $JMJ=M'$. In particular, $M$ and $M'$ are of same type.
\end{proposition}

\begin{proof}
	We have to prove that $T\in JMJ$ whenever $T\in M'$. Let $S$ and $T$ be in $M'$, and let us prove that $JSJ$ and $T$ commute. For that, we are going to prove that
	\begin{equation}
		\langle JSJTv, v\rangle =\langle TJSJv, v\rangle,
	\end{equation}
	which is sufficient because the product is nondegenerate. For all $S$ and $T$ in $M'$, one successively has
	\begin{equation}
	\begin{aligned}[]
		\langle JSJTv, v\rangle =\langle JSJTv, J^2v\rangle	&=\langle Jv, SJTv\rangle =\langle v, SJTv\rangle\\
									& =\langle S^*v, JTv\rangle =\langle JSv, T^*v\rangle=\langle TJSJv, v\rangle,
	\end{aligned}
\end{equation}
	where we used the extra property $Jv=v$ which defines a modular isometry.

	Now we repeat the same with $S_1=A^*S$ and $T_1=TB$ where $A\in JMJ\subseteq M'$ and $B\in JMJ$. The operators $S_1$ and $T_1$ belong to $M'$ because $S$ and $T$ belong to $M'$. We find
	\begin{equation}
		\langle JSJT(Bv), (JAv)\rangle =\langle TSJS(Bv), (JAv)\rangle.
	\end{equation}
	Using the fact that $v$ is cyclic, the vectors $Bv$ and $JAv$ separately span dense subspaces, so that, as operators, $TSJT=TJSJ$ because they are equal on a dense subspace.
\end{proof}


\begin{proposition}
	If $J$ is a modular isometry for $M$ (with respect to $v$), then it is a modular isometry for $M'$ (with respect to $v$) too.
\end{proposition}

\begin{proof}
	The fact that $JM'J=M$ is obtained by application of $J$ at left and right of both sides of $JMJ=M'$. For the last one, compute
	\begin{equation}
		\langle Sw, Tw\rangle =\langle w, S^*Tw\rangle =\langle w, TS^*w\rangle =\langle T^*w, S^*\rangle 
	\end{equation}
	for every $S\in M$ and $T\in M'$.
\end{proof}

\begin{proposition}
If $\varphi(T)=\langle v, Tv\rangle $ is a trace, then $JSv=S^*v$ for every $S\in M'$.
\end{proposition}

\begin{proof}
When $T$ runs over $M$, the element $Tv$ spans a dense space, and we have, for $T\in M$ and $S\in M'$:
\begin{equation}
	\langle JSv, Tv\rangle =\langle JTv, Sv\rangle =\langle T^*v, Sv\rangle =\langle v, TSv\rangle =\langle v, STv\rangle =\langle S^*v, Tv\rangle .
\end{equation}
So the inner product of $JSv$ and $S^*v$ on any $Tv$ are the same. That proves that $JSv=S^*v$.
\end{proof}

\begin{theorem}
For every von~Neumann algebra $M$ and every cyclic and separating vector $v$, there exists a modular isometry.
\end{theorem}

\begin{proof}
No proof.
\end{proof}

\begin{corollary}
The algebras $M$ and $M'$ are always algebraically isomorphic.
\end{corollary}

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Example}
%---------------------------------------------------------------------------------------------------------------------------

Let $M(G)$ where $G$ is a non unimodular locally compact group. Thus $M(G)=C_c(G)''$. A function $f\in C_c(G)$ defines an operator on $L^2(G)$ by
\begin{equation}
	(f\xi)(g)=\int_{G}f(h)\xi(h^{-1} g)\,d\mu(h)
\end{equation}
where $\mu$ is a left Haar measure. We consider the functional $\varphi$ on $M(G)$
\begin{equation}
	\varphi(f)=f(e).
\end{equation}
If $G$ was unimodular, this would be a tracial weight, but in the non unimodular case, $\varphi$ is not even a trace on $C_c(G)$. 

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Other example}
%---------------------------------------------------------------------------------------------------------------------------

Let $G$ be a discrete group with counting measure. Suppose that $G_0$ is an \defe{almost normal}{almost!normal subgroup}\index{normal!(almost) subgroup} of $G$, that means that each double coset $G_0gG_0$ is a finite union of left cosets\footnote{In the case of a normal subgroup, the double cosets are made of only one left coset.}. We define
\begin{equation}
	A=\eC[G,G_0]=\{ f\colon G_0\backslash G/G_0\to \eC\text{ such that $f$ is finitely supported} \},
\end{equation}
and we introduce the product
\begin{equation}
	(f_1\star f_2)(g)=\sum_{h\in G_0/G}f_1(gh^{-1})f_2(h),
\end{equation}
and the involution $f^*(g)=\overline{ f(g^{-1}) }$.  The map
\begin{equation}
\begin{aligned}
 \varphi\colon \eC[G,G_0]&\to \eC \\ 
   f&\mapsto f(e) 
\end{aligned}
\end{equation}
is not a trace in the general case. Since $\varphi(f^*f)\geq0$ and $\varphi(f^*f)=0$ implies $f=0$, we conclude that $\varphi$ is a state.

In the case where $G_0$ is a normal subgroup, however, it is a trace. We define
\begin{equation}
\begin{aligned}
 \sigma_z\colon \eC[G,G_0]&\to \eC[G,G_0] \\ 
   \big( \sigma_z(f) \big)(g)& = \Delta(g)^zf(g) 
\end{aligned}
\end{equation}
where $\Delta(g)=L(g)/R(g)$ where $L(g)$ is the number of left cosets in $G_0gG_0$ and $R(g)$ is the number of left cosets in $G_0gG_0$.

\begin{lemma}
	We have
	\begin{equation}
		\varphi(f_1f_2)=\varphi\big( f_2\sigma(f_1) \big)
	\end{equation}
	where $\sigma=\sigma_1$. The map $\sigma_z$ is, moreover, an automorphism.
\end{lemma}
That lemma says that the non triviality of $\sigma$ measures at what extend $\varphi$ is not a trace.

\begin{proof}
No proof.
\end{proof}
If $\varphi$ is a trace, then the class of identity in $\eC[G,G_0]$ is cyclic and one can make a GNS construction. Notice that $\sigma_z$ is not a $*$-automorphism because
\begin{equation}
	\sigma_z(f^*)=\sigma_{-\bar z}(f)^*.
\end{equation}
If $z$ is purely imaginary, $\sigma_z$ is a $*$-automorphism.

Let $\hH$ be the completion of $A$ with respect to the inner product defined by the state $\varphi$. The algebra $A$ acts on $\hH$ by bounded operators of left multiplication\footnote{Since $A$ is not a $C^*$-algebra, we cannot invoke a GNS construction here.}. Let $v\in\hH$ be defined by
\begin{equation}
	v(g)=
\begin{cases}
	1&\text{if $g\in G_0$}\\
	0&\text{else},
\end{cases}
\end{equation}
and let $\hH_0=A\cdot v\subseteq\hH$.


\begin{lemma}
	We have
	\begin{equation}
		\| \sigma_{1/2}(f)^*v \|=\| fv \|,
	\end{equation}
	in other words, $f\mapsto \sigma_{1/2}(f^*)$ is a conjugate linear isometry.
\end{lemma}

\begin{proof}
	First, notice that for every $h\in A$ and $z\in \eC$,
	\begin{equation}		\label{Eqsigmazvarhih}
		\varphi\big( \sigma_z(h) \big)=\varphi(h).
	\end{equation}
	We have 
	\begin{equation}
		\| \sigma_{1/2}(f^*)v \|^2=\varphi\big( \sigma_{1/2}(f^*)^*\sigma_{1/2}(f^*) \big)=\varphi\big( \sigma_{-1/2}(f)\sigma_{1/2}(f^*) \big).
	\end{equation}
	Now we apply the relation \eqref{Eqsigmazvarhih} with $z=-1/2$, and we find that the latter line is equal to
	\begin{equation}
		\varphi\big( \sigma_{-1}(f)\sigma_0(f^*) \big)=\varphi\big( \sigma_{-1}(f)f^* \big)=\varphi\Big( f^*\sigma_1\big( \sigma_{-1}(f) \big) \Big)=\varphi(f^*f)=\| fv \|^2.
	\end{equation}
\end{proof}

Let $M\subseteq\oB(\hH)$ be the von~Neumann algebra generated by $A$.
\begin{proposition}
	The formula
	\begin{equation}
		J(fv)=\sigma_{1/2}(f^*)v
	\end{equation}
	defines a modular isometry for $M$ with respect to $v$.
\end{proposition}

\begin{proof}
No proof.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Still an other example}
%---------------------------------------------------------------------------------------------------------------------------

Let $A=\eM_n(\eC)$ and
\begin{equation}
	\varphi\colon S\mapsto \tr(ST)
\end{equation}
where $T$ is invertible and chosen in such a way that $T\geq0$, $\tr(T)=1$, so that $\varphi$ is a positive faithful state. Let now $\hH$ be the GNS Hilbert space and consider the map
\begin{equation}
	\sigma_z=T^zST^{-z}.
\end{equation}
We have
\begin{equation}
	\varphi(S_1S_2)=\tr(S_1S_2T)=\tr(S_2TS_1)=\tr(S_2TS_1T^{-1}T)=\tr\big( S_2\sigma(S_1)T \big)=\varphi\big( S_2\sigma(S_1) \big),
\end{equation}
thus $\sigma_1$ has the same property as before to measure the lack of tracial property of $\varphi$.

Once again, we pick $v$, the vacuum of the GNS representation, i.e. the representative of the identity. The map
\begin{equation}
	J\colon Sv\mapsto \sigma_{1/2}(S^*)v
\end{equation}
is a modular isometry for $M$ with respect to $v$.


%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Tomita's theorem}
%---------------------------------------------------------------------------------------------------------------------------

\begin{lemma}
	The map
	\begin{equation}	\label{EqApplQuiDoitEtreIsom}
		T\xi\mapsto T^*\xi
	\end{equation}
	is isometric if and only if $\xi$ is a trace vector.
\end{lemma}

\begin{proof}
	The fact for the map \eqref{EqApplQuiDoitEtreIsom} to be an isometry means that $\langle T\xi, T\xi\rangle =\langle T^*\xi, T^*\xi\rangle $. This is equivalent to
	\begin{equation}
		\langle \xi, T^*T\xi\rangle =\langle \xi, TT^*\xi\rangle ,
	\end{equation}
	which means that $\xi$ is a trace vector.
\end{proof}

\begin{theorem}
	If $v$ is a cyclic and separating vector for $M\subseteq\oB(\hH)$, and if
	\begin{equation}
		\varphi(T)=\langle v, Tv\rangle ,
	\end{equation}
	then there is a strongly dense $*$-subalgebra $A\subseteq M$ and a one parameter group of automorphisms $\sigma_z\colon A\to A$ ($z\in\eC$) such that
	\begin{enumerate}
	\item The map $z\mapsto \sigma_z(S)$ is holomorphic as map from $\eC$ into $\oB(\hH)$ in the sense that it accepts a power expansion $\sigma_z=T_0+zT_1+z^2T_2+\ldots$
	\item\label{ItemTomitaii} If $z\in i\eR$, then $\sigma_z$ extends to a strongly continuous one parameter group of automorphisms on $M$ which only depends on $\varphi$ when the other conditions are satisfied.
	\item The maps $\varphi$ and $\sigma$ are related by
	\begin{equation}
		\varphi(ST)=\varphi\big( T\sigma(S) \big)
	\end{equation}
	for every $S$, $T\in A$, where $\sigma=\sigma_1$.
	\end{enumerate}
	Moreover the formula
	\begin{equation}
		J\colon Sv\mapsto \sigma_{1/2}(S^*)v
	\end{equation}
	defines a modular isometry for $M$ with respect to $v$.
\end{theorem}
Notice that the point \ref{ItemTomitaii} does not depend on $A$.

\begin{proof}[Idea of the proof]
We ignore the analytical issues.  We define
\begin{equation}	
	\begin{aligned}
		\mS\colon \hH&\to \hH \\
		Tv&\mapsto T^*v. 
	\end{aligned}
\end{equation}
For a general $v$, this is not an isometry (this is even unbounded), but we can try to have in idea of what is $\mS^*$. Since $\mS$ is conjugate linear, the equation to solve is
\begin{equation}
	\langle \mS T_1v, T_2v\rangle =\langle \mS^*T_2v, T_1v\rangle .
\end{equation}
We have $\langle T_1^*v, T_2v\rangle =\langle \mS^*T_2v, T_1v\rangle $. Since the Hilbert space $\hH$ is build from a GNS construction, the inner product is in fact given in terms of $\varphi$:
\begin{equation}
	\langle T_1^*v, T_2v\rangle =\varphi(T_1T_2)=\varphi\big( T_2\sigma(T_1) \big)=\varphi\big( \sigma_{-1}(T_2)T_1 \big)=\langle \sigma_{-1}(T_2)^*v, T_1v\rangle =\langle \sigma(T_2^*)v, T_1c\rangle,
\end{equation}
so that
\begin{equation}
	\mS^*(Tv)=\sigma(T^*)v,
\end{equation}
which is an equation for $\mS^*$ in the same time as for $\sigma$. After computations, one shows that
\begin{equation}
	\mS^*\mS(Tv)=\sigma_{-1}(T)v.
\end{equation}
Conclusion: the automorphism $\sigma_{-1}$ (which is the inverse of $\sigma_1$) can be deduced from $\mS$. Moreover, one can prove that $\mS^*\mS$ is a linear (no more conjugate linear) positive, selfadjoint operator and
\begin{equation}		\label{eqMsstarMssigmaz}
	(\mS^*\mS)^zSv=\sigma_z(S).
\end{equation}
Thus, in fact, the whole set $\{ \sigma_z \}_{z\in\eC}$ can be recovered from $\mS$ and thus from $\varphi$.

Notice that equation \eqref{eqMsstarMssigmaz} makes no sense in the infinite dimensional case. More analytic work is needed to be right.

\end{proof}

Two one parameter families of automorphisms $\alpha_t,\beta_t\colon M\to M$ ($\in \eR$) are \defe{outer equivalent}{outer!equivalent automorphism} if there is a one parameter family of automorphisms $\gamma_t\colon \eM_2(M)\to \eM_2(M)$ such that
\begin{equation}
		\gamma_t
	\begin{pmatrix}
	  S	&	0	\\ 
	  0	&	T	
	\end{pmatrix}
	=
	\begin{pmatrix}
	  \alpha_t(S)	&	0	\\ 
	  0	&	\beta_t(T)	
	\end{pmatrix}.
\end{equation}
This is an equivalence relation.

Since $
\begin{pmatrix}
  0	&	\mtu	\\ 
  0	&	0	
\end{pmatrix}
$ is a partial isometry, the automorphism $\gamma_t$ has to send it to another partial isometry, i.e.
\begin{equation}
		\gamma_t
	\begin{pmatrix}
	  0	&	\mtu	\\ 
	  0	&		
	\end{pmatrix}
	=
	\begin{pmatrix}
	  0	&	\mU_t	\\ 
	  0	&	0	
	\end{pmatrix}
\end{equation}
where $\mU_t$ is unitary. I we apply $\gamma_t$ to the equality
\begin{equation}
	\begin{pmatrix}
	  0	&	0	\\ 
	  \mtu	&	0	
	\end{pmatrix}
	\begin{pmatrix}
	  S	&	0	\\ 
	  0	&	0	
	\end{pmatrix}
	\begin{pmatrix}
	  0	&	\mtu	\\ 
	  0	&	0	
	\end{pmatrix}
	=
	\begin{pmatrix}
	  0	&	0	\\ 
	  0	&	S	
	\end{pmatrix},
\end{equation}
we find
\begin{equation}
	\gamma_t
	\begin{pmatrix}
		0	&	0	\\ 
		\mtu	&	0	
	\end{pmatrix}
	=
	\begin{pmatrix}
		0	&	0	\\ 
		\mU_t^*	&	0	
	\end{pmatrix},
\end{equation}
so that
\begin{equation}
	\mU_t^*\alpha_t(S)\mU_t=\beta_t(S).
\end{equation}
The conclusion is that $\alpha_t$ and $\beta_t$ only differ by an inner automorphism.

When $M=\oB(\hH)$, all automorphisms are inner and all the one parameter families of automorphisms are equivalent to the identity.

If $\alpha$ and $\beta$ are outer equivalent, they define the same homomorphism
\begin{equation}
	\eR\to\Out(M)=\frac{ \Aut(M) }{ \Inn(M) }.
\end{equation}

We recall that if $M$ is a von~Neumann algebra of operators of the Hilbert space $\hH$, a vector $\xi$ is \defe{cyclic}{cyclic!vector} if $\hH=\overline{ M\xi }$ and it is \defe{separating}{separating vector} for $M$ is $T\xi=0$ if and only if $T=0$.

\begin{theorem}[Connes' theorem]
The modular group of different cyclic and separating vectors are all outer equivalent.
\end{theorem}

\begin{proof}
	Given two states $\varphi_1$ and $\varphi_2$, we define
	\begin{equation}	
		\begin{aligned}
			\varphi\colon \eM_2(M)&\to \eC \\
			\begin{pmatrix}
				T_{11}&	T_{12}	\\ 
				T_{21}	&	T_{22}	
			\end{pmatrix}
			&\mapsto \frac{ 1 }{2}\big( \varphi_1(T_{11})+\varphi_2(T_{22}) \big), 
		\end{aligned}
	\end{equation}
	which is a faithful normal state. Then apply Tomita's theorem.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Modular group}
%---------------------------------------------------------------------------------------------------------------------------
This subsection is based on \cite{CirpianiDirichlet}.

If $\xi$ is cyclic and separating and if $T\mapsto T^*$ is an isometric involution on $M$, the antilinear map $T\xi\mapsto T^*\xi$ is densely defined on $M\xi\subset\hH$. We denote by
\begin{equation}
	S_{\xi}\colon \hH\to \hH
\end{equation}
the closure. Thus everywhere it makes sense we have $S_{\xi}(T\xi)=T^*\xi$. The operator $S_{\xi}$ has the polar decomposition
\begin{equation}
	S_{\xi}=J_{\xi}\Delta^{1/2}_{\xi}.
\end{equation}
The antilinear part $J_{\xi}$ is said the \defe{modular conjugation}{modular!conjugation} while the operator $\Delta^{1/2}_{\xi}$ is the \defe{modular operator}{modular!operator} associated with the pair $(M,\xi)$. We have $\Delta_{\xi}=S_{\xi}^*S_{\xi}$.

Now, instead of referring to the cyclic separating vector, we can consider a faithful normal state $\omega$ and think about its associated cyclic separating vector in the GNS cyclic representation $(\pi_{\omega},\hH_{\omega},\xi_{\omega})$. In this setting, the \defe{modular group of automorphism}{modular!group of automorphisms} of the pair $(M,\omega)$ is $\sigma^{\omega}$ defined by
\begin{equation}
	\sigma_t^{\omega}(T)=\pi_{\omega}^{-1}\big( \Delta_{\omega}^{it}\pi_{\omega}(T)\Delta_{\omega}^{-it} \big)
\end{equation}
for $T\in M$ and $t\in\eR$. Here $\Delta_{\omega}$ is the modular operator associated with the pair $\big( \pi_{\omega}(M),\xi_{\omega} \big)$.

\begin{theorem}
	The modular group $\sigma^{\omega}\colon \eR\to \Aut(M)$ associated with the pair $(M,\omega)$ satisfies the following conditions (the \defe{modular condition}{modular!condition}) :
	\begin{enumerate}
		\item
			$\omega$ is $\sigma^{\omega}$-invariant, that means that $\omega=\omega\circ\sigma_t^{\omega}$.
		\item
			for every $x,y\in M$, there exists a bounded function $F_{xy}$ on the strip
			\begin{equation}
				\bar D=\{ z\in\eC\tq 0\leq\Imag(z)\leq 1 \}
			\end{equation}
			which is holomorphic on the interior of $\bar D$ and such that
			\begin{subequations}
				\begin{align}
					F_{xy}(t)=\omega\big( \sigma^{\omega}_t(x)y \big)\\
					F_{xy}(t+i)=\omega\big(y \sigma^{\omega}_t(x) \big).
				\end{align}
			\end{subequations}
			
	\end{enumerate}
	Moreover, the map $\sigma^{\omega}$ is defined in an unique way by these two properties.
\end{theorem}

Let $\hH$ be an Hilbert space and an acting von~Neumann algebra $M$ of compact operators on $\hH$. Let $\xi$ be a cyclic separating vector. We define
\begin{equation}
	\begin{aligned}
		j_{\xi}\colon M&\to M' \\
		x&\mapsto J_{\xi}xJ_{\xi} 
	\end{aligned}
\end{equation}
Tomita's theorem shows that this map is well defined and that it takes values in $M'$.

If $\xi$ is a trace vector (definition \ref{DefVecteurTrace}), the map $j_{\xi}$ is the involution:
\begin{equation}
	j_{\xi}(x)=x^*
\end{equation}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Standard positive cone}
%---------------------------------------------------------------------------------------------------------------------------

The \defe{standard positive cone}{positive!cone!standard} $\hH_{\xi}^+$ associated wit the pair $(M,\xi)$ is the set
\begin{equation}
	\overline{ \{ xj_{\xi}(x)\xi\in\hH\tq x\in M \} }.
\end{equation}
A \defe{standard form}{standard!form!of a von~Neumann algebra} of a von~Neumann algebra $M$ acting on $\hH$ is a self dual cone $\hH^+$ and an antilinear involution $J$ such that $(M,\hH,\hH^+,J)$ satisfies
\begin{enumerate}
	\item
		$JMJ=M'$;
	\item
		$JxJ=x^*$ for every $x\in M\cap M'$;
	\item
		$J\eta=\eta$ for every $\eta\in\hH^+$;
	\item
		$(xJxJ)\hH^+\subset\hH^+$ for every $x\in M$.
\end{enumerate}


\label{LaFin}
