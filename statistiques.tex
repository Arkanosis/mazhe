%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Notations et hypothèses}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Nous notons \( X\) le caractère à étudier, et \( \Omega\) l'ensemble des individus. Le caractère à étudier est vu comme une fonction sur \( \Omega\) :
\begin{equation}
    X\colon \Omega\to \eR,\eN,\{ 0,1 \},\ldots
\end{equation}
Les \defe{statistiques descriptives}{statistiques!descriptives} sont les techniques pour présenter et résumer les données : diagrammes, graphiques, indicateurs numériques : moyenne, écart-type, médiane, \ldots

Nous faisons les hypothèses suivantes :
\begin{enumerate}
    \item
        Chaque observation \( x_i\) est la réalisation de la variable aléatoire \( X\) qui sera de loi inconnue \( \mu\).
    \item
        Le \( n\)-uple \( (x_1,\ldots,x_n)\) est la réalisation de \( (X_1,\ldots,X_n)\) qui est l'échantillon de taille \( n\).
    \item
        Les variables aléatoires \( X_i\) sont indépendantes et identiquement distribuées, de loi commune \( \mu\). La loi \( \mu\) est la \defe{loi parente}{loi!parente} de l'échantillon.
\end{enumerate}

\begin{example}
    Un échantillon de taille \( 1\) consisterait à tirer au sort une personne dans une population et mesurer sa taille.
\end{example}

\begin{example}
    Une échantillon de taille \( n\) consisterait à tirer au sort \( n\) personnes dans une population et de mesurer leurs tailles.
\end{example}

L'\defe{inférence statistique}{inférence statistique} est l'art de dégager des informations sur la population à partir d'informations partielles : intervalles de confiance, estimateurs, test d'hypothèses, \ldots

En théorie des probabilités, nous connaissons la loi de la variable aléatoire \( X\) et nous en déduisons des informations sur le réalisations de \( X\) : valeur la plus probable, moyenne, intervalle dans lequel \( X(\omega)\) a le plus de chance d'appartenir. En statistique, au contraire, la loi est inconnues et nous cherchons des informations sur la loi à partir d'un échantillon de données numériques observées.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Modèle statistique}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Une \defe{modèle statistique}{modèle statistique} est un triplet
\begin{equation}
    \statS=\Big[ (\Omega,\tribF,P),(X_{\theta})_{\theta\in\Theta},(\mu_{\theta})_{\theta\in\Theta} \Big]
\end{equation}
où \( (\Omega,\tribF,P)\) est un espace probabilisé, \( (X_{\theta})\) est une famille de variables aléatoires définies sur \( \Omega\) et telles que pour tout \( \theta\in\Theta\), la variable aléatoire \( X_{\theta}\) suive la loi \( \mu_{\theta}\). Les $\mu_{\theta}$ sont des mesures sur les boréliens de \( \eR\) et pour tout \( B\in\Borelien(\eR)\) nous avons
\begin{equation}
    P(X_{\theta}\in B)=\mu_{\theta}(B).
\end{equation}
\begin{remark}
    D'une certaine manière, l'introduction de \( \mu_{\theta}\) dans la définition est redondante parce que ces mesures sont déjà contenues dans la données des variables aléatoires \( X_{\theta}\).
\end{remark}

\begin{example}[Modèle statistique gaussien]
    Si nous savons que les variables aléatoires \( X_i\) suivent une loi gaussienne, alors nous considérons \( \Theta=\eR\times\eR^+\) et \( \theta=(m,\sigma^2j)\). Dans ce cas, \( \mu_{\theta}=\dN(m,\sigma^2)\) et le but de la statistique est de déterminer la valeur de \( \theta\) qui correspond à une population en partant de l'observation d'un échantillon.
\end{example}

\begin{definition}
    Si \( \Theta\subset\eR^k\), nous disons que le modèle statistique est un modèle \defe{paramétrique}{modèle!paramétrique}.
\end{definition}
Le modèle gaussien est un modèle paramétrique : dès que \( m\) et \( \sigma^2\) sont déterminés, la loi du phénomène \( X\) est connue.

\begin{definition}
    Pour chaque \( \theta\in\theta\), un \defe{échantillon}{échantillon} de taille \( n\) associé à un modèle statistique \( \big[ (\Omega,\tribF,P),(X_{\theta}),(\mu_{\theta}) \big]\) est un vecteur \( \big( X_{\theta,1},\ldots,X_{\theta,n} \big)\) de taille \( n\) de variables aléatoires indépendantes et identiquement distribuées de la même loi que la variable aléatoire \( X_{\theta}\). La loi \( \mu_{\theta}\) est la \defe{loi parente}{loi!parente} de l'échantillon.
\end{definition}

\begin{definition}
    Un \defe{modèle d'échantillonnage}{modèle!échantillonnage} sur le modèle statistique \( \statS\) est une famille \( (X_{\theta,1},\ldots, X_{\theta,n})_{\theta\in\Theta}\) d'échantillons de taille \( n\geq 1\).
\end{definition}

Nous noterons souvent \( (X_1,\ldots,X_n)\) à la place de \( (X_{\theta,1},\ldots,X_{\theta,n})\) un échantillon, mais il faut se souvenir que les \( X_i\) suivent toujours la même loi donnée par \( \theta\). La loi du vecteur \( (X_1,\ldots,X_n)\) est \( \mu_{\theta}\otimes\ldots\otimes\mu_{\theta}\) et est définie sur l'espace \( (\Omega^n,\tribF\otimes\ldots\otimes\tribF,P^{\otimes n})\).

\begin{remark}
    Le travail du statisticien est de proposer un modèle statistique \( \statS\) a priori. Si nous étudions la taille d'une population, nous allons choisir un modèle gaussien. Plus le modèle est précis, plus l'espace \( \Theta\) est petit mais plus il y a de risques que le vérité soit hors de l'ensemble considéré.
\end{remark}

\begin{example}
    Soit \( X\) une variable aléatoire de carré intégrable que l'on sait simuler. Affin d'évaluer la moyenne \( \mu\) de \( X\), nous pouvons considérer la moyenne empirique des simulations : \( \bar X_n=\frac{1}{ n }\sum_{i=1}^nX_i\) où les variables aléatoires \( X_i\) sont indépendantes, identiquement distribuées et de même loi que \( X\). 

    La loi des grands nombres nous enseigne que \( \bar X_n\to\mu\). De plus,
    \begin{equation}
        \lim_{n\to \infty} P\left( \mu\in\left[ \bar X_n-\frac{ a\sigma }{ \sqrt{n} },\bar X_n+\frac{ a\sigma }{ \sqrt{n} } \right] \right)=\int_{-a}^a e^{-x^2/2}\frac{ dx }{ \sqrt{2\pi} }.
    \end{equation}
    En effet, la condition sur \( \mu\) est équivalente à
    \begin{equation}
        -a\leq \frac{ \bar X_n-\mu }{ \sigma/\sqrt{n} }\leq a,
    \end{equation}
    tandis que le théorème central limite nous enseigne que la variable aléatoire \( \frac{ \bar X_n-\mu }{ \sigma/\sqrt{n} }\) se comporte comme \( \dN(0,1)\) lorsque \( n\) est grand. Dans ce cas, nous avons que
    \begin{equation}
        P\left( \frac{ \bar X_n-\mu }{ \sigma/\sqrt{n} }\in\mathopen[ -a , a \mathclose] \right)=\frac{1}{ \sqrt{2\pi} }\int_{-a}^a e^{-x^2/2}dx.
    \end{equation}
    Notons que dans ce calcul nous avons utilisé le fait que \( \mu=E(X_1)\).

    Montrons que la suite
    \begin{equation}
        \sigma_n^2=\frac{1}{ n }\sum_{i=1}^nX_i^2-\left( \frac{1}{ n }\sum_{i=1}^nX_i \right)^2
    \end{equation}
    converge presque sûrement vers \( \sigma^2\). Le théorème central limite implique que
    \begin{equation}
        \frac{1}{ n }\sum_{i=1}^nX_i^2\stackrel{p.s.}{\longrightarrow} E(X_1^2)
    \end{equation}
    et que
    \begin{equation}
        \left( \frac{1}{ n }\sum_{i=1}^nX_i \right)^2\stackrel{p.s.}{\longrightarrow}E(X_1)^2.
    \end{equation}
    La différence converge donc presque sûrement vers \( \sigma^2\) en vertu de la proposition \ref{PrropVarAlterfrom}.

    Nous avons également \( E(\sigma_n^2)=\sigma^2\). En effet, sachant que \( E(X_i)=E(X_1)=\mu\) et que \( E(X_i^2)=E(X_1^2)=\mu^2+\sigma^2\),
    \begin{subequations}
        \begin{align}
            E(\sigma_n^2)&=\frac{1}{ n }\sum_{i=1}^nE(X_i^2)-\frac{1}{ n^2 }\left( \sum_{i=1}^nE(X_i^2) \right)+\sum_{i\neq j}E(X_iX_j))\\
            &=\sigma^2+\mu^2-\frac{1}{ n^2 }\big( n(\sigma^2+\mu^2)+(n^2-n)\mu^2 \big)\\
            &=\sigma^2-\frac{1}{ n }\sigma^2,
        \end{align}
    \end{subequations}
    dont la limite \( n\to\infty\) donne bien \( \sigma^2\).

    Nous voudrions à présent montrer que 
    \begin{equation}
        \frac{ \bar X_n-\mu }{ \sigma/\sqrt{n} }\stackrel{\hL}{\longrightarrow}\dN(0,1).
    \end{equation}
    Vu que le théorème central limite donne une convergence en loi, nous pouvons utiliser le lemme de Slutsky pour montrer que
    \begin{equation}
        \left( \frac{ \bar X_n-\mu }{ 1/\sqrt{n} },\sigma_n^2 \right)\stackrel{\hL}{\longrightarrow}(\sigma Z,\sigma^2)
    \end{equation}
    où \( Z\sim\dN(0,1)\). En vertu de la proposition \ref{PropcvLsousfonc} appliqué à la fonction \( f\colon \eR^2\to \eR\),
    \begin{equation}
        f(x,y)=\begin{cases}
            \frac{ x }{ \sqrt{y} }    &   \text{si \( y\neq 0\)}\\
            0    &    \text{sinon}
        \end{cases}
    \end{equation}
    nous avons la convergence en loi
    \begin{equation}
        f\left( \frac{ \bar X_n-\mu }{ 1/\sqrt{n} },\sigma_n^2 \right)\stackrel{\hL}{\longrightarrow}f(\sigma Z,\sigma^2),
    \end{equation}
    c'est à dire 
    \begin{equation}
        \frac{ \bar X_n-\mu }{ \sigma_n/\sqrt{n} }\stackrel{\hL}{\longrightarrow}Z.
    \end{equation}
    Affin d'être complet, précisons que 
    \begin{equation}
        P\big( (\sigma Z,\sigma)\in\eR\times \{ 0 \} \big)=0.
    \end{equation}
\end{example}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Statistiques descriptives}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Modèles d'échantillonnages}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Soit \( X\), une variable aléatoire sur \( (\Omega,\tribF,P)\). Un \defe{échantillon}{échantillon} de taille \( n\) pour \( X\) est une suite de \( n\) variables aléatoires \( (X_1,\ldots,X_n)\) définies sur \( (\Omega,\tribF,P)\) indépendantes et de même loi que \( X\). Nous disons que la loi de \( X\) est la \defe{loi parente}{loi!parente d'un échantillon} de la suite \( X_i\).

\begin{definition}
    Soit
    \begin{equation}
        \statS=\Big[ (\Omega,\tribF,P),(X_{\theta}),(\mu_{\theta}) \Big]_{\theta\in\Theta},
    \end{equation}
    un modèle statistique. Un \defe{modèle d'échantillonnage}{modèle!échantillonnage} de taille \( n\) associée au modèle statistique \( \statS\) est la donnée d'une famille de \( n\)-échantillons \( (X_{\theta,1}),\ldots,X_{\theta,n}\) telle que pour tout \( \theta\in\Theta\), l'échantillon \( (X_{\theta,i})\) soit de variable parente \( X_{\theta}\).
\end{definition}

La \defe{moyenne empirique}{moyenne!empirique d'un échantillon} du \( n\)-échantillon \( (X_i)\) est la variable aléatoire
\begin{equation}
    \bar X_n=\frac{1}{ n }\sum_{i=1}^{n}X_i.
\end{equation}

La proposition suivante signifie que la moyenne empirique est une «bonne» façon d'approcher la variable aléatoire.
\begin{proposition}
    Soit \( X\), une variable aléatoire dans \( L^2(\Omega)\) (c'est à dire \( E(X^2)<\infty\)) d'espérance \( m\) et de variance \( \sigma^2\). Alors
    \begin{enumerate}
        \item
            \( E(\bar X_n)=m\) et \( \Var(\bar X_n)=\frac{ \sigma^2 }{ n }\).
        \item
            Nous avons les convergences
            \begin{subequations}
                \begin{align}
                    \bar X_n&\stackrel{p.s.}{\longrightarrow} m\\
                    \frac{ \bar X_n-m }{ \sigma/\sqrt{n} }&\stackrel{\hL}{\longrightarrow} Z\sim\dN(0,1).
                \end{align}
            \end{subequations}
        \item
            Si \( X\) est de loi \( \dN(m,\sigma^2)\), alors \( \bar X_n\sim\dN(m,\frac{ \sigma^2 }{ n })\), c'est à dire
            \begin{equation}
                \frac{ \bar X_n -m}{ \sigma/\sqrt{n} }\sim\dN(0,1).
            \end{equation}
            
            
    \end{enumerate}
    
\end{proposition}
L'intérêt de prendre la moyenne \( \bar x_n\) des données expérimentales en statistiques descriptives est que \( \bar X_n\to m\).

La \defe{variance empirique}{variance!empirique} d'un échantillon est la variable aléatoire
\begin{equation}
    V_n^2=\frac{1}{ n }\sum_{i=1}^n(X_i-\bar X_n)^2.
\end{equation}
La \defe{variance empirique corrigée}{variance!empirique corrigée} est la variable aléatoire 
\begin{equation}
    S_n^2=\frac{1}{ n-1 }\sum_{i=1}^n(X_i-\bar X_n)^2.
\end{equation}

\begin{lemma}

    La variance corrigée et la variance empirique ont comme espérances :
    \begin{subequations}
        \begin{align}
            E(V_n^2)&=\frac{ n-1 }{ n }\sigma^2\\
            E(S_n^2)&=\sigma^2.
        \end{align}
    \end{subequations}
\end{lemma}

\begin{proof}
    Nous commençons par calculer l'espérance de la variance non corrigée. La première étape est de la récrire sous la forme
    \begin{equation}
        \begin{aligned}[]
            V_n^2&=\frac{1}{ n }\sum_k(X_k^2-2X_k\bar X_n+\bar X_n^2)\\
            &=\frac{1}{ n }\sum_kX_k^2-2\bar X_n\underbrace{\sum_kX_k}_{=n\bar X_n}+\bar X_n^2\\
            &=\frac{1}{ n }\sum_k X_k-\bar X_n^2.
        \end{aligned}
    \end{equation}
    Nous calculons séparément l'espérance de ces deux termes. Si \( X\) est la loi parente des \( X_i\), en utilisant l'indépendance des \( X_i\) nous trouvons
    \begin{equation}
        \begin{aligned}[]
            E\left( \frac{1}{ n }\sum_kX_k^2 \right)&=\frac{1}{ n }\sum_{k=1}^nE(X_k^2)\\
            &=E(X^2)\\
            &=E(X)^2-\Var(X).
        \end{aligned}
    \end{equation}
    Nous devons à présent calculer l'espérance de \( \bar X_n^2\):
    \begin{equation}
        E(\bar X_n^2)=E(\bar X_n)^2+\Var(\bar X_n).
    \end{equation}
    En utilisant le lemme \ref{LemVarXpYsmindep},
    \begin{subequations}
        \begin{align}
            \Var(\bar X_n)&=\Var\left( \frac{1}{ n }\sum_kX_k \right)\\
            &=\frac{1}{ n^2 }\sum_k\Var(X_k)\\
            &=\frac{1}{ n }\Var(X).
        \end{align}
    \end{subequations}
    Par conséquent
    \begin{equation}
        E(V_n^2)=\Var(X)\left( 1-\frac{1}{ n } \right)=\frac{ n-1 }{ n }\Var(X).
    \end{equation}

    En ce qui concerne la variance corrigée,
    \begin{equation}
        S_n^2=\frac{1}{ n-1 }\sum_k(X_k-\bar X_n)^2=\frac{ n }{ n-1 }V_n^2,
    \end{equation}
    par conséquent \( E(S_n^2)=\frac{ n }{ n-1 }E(V_n^2)=\Var(X)\).
\end{proof}

\begin{proposition}
    Soit \( X\) une variable aléatoire de variance \( \Var(X)=\sigma\). Si \( E(X^4)<\infty\), alors
    \begin{enumerate}
        \item
            \( S_n^2\stackrel{p.s.}{\longrightarrow}\sigma^2\).
        \item
            \begin{equation}
                \frac{ S_n^2-\sigma^2 }{ \sqrt{\frac{ \mu^4-\sigma^4 }{ n }} }\stackrel{\hL}{\longrightarrow}Z\sim\dN(0,1)
            \end{equation}
            où \( \mu^4=E(X^4)\) est le moment d'ordre \( 4\) de \( X\).
    \end{enumerate}
\end{proposition}

\begin{theorem}
    Si \( (X_1,\ldots,X_n)\) est un \( n\)-échantillon de loi parente \( \dN(m,\sigma^2)\), alors
    \begin{enumerate}
        \item
            Les variables aléatoires 
            \begin{equation}
                \begin{aligned}[]
                    \frac{ \bar X_n-m }{ \sigma/\sqrt{n} }&\text{et}&(n-1)\frac{ S_n^2 }{ \sigma^2 }
                \end{aligned}
            \end{equation}
            sont indépendantes.
        \item
            La loi de \( (n-1)\frac{ S_n^2 }{ \sigma^2 }\) est \( \chi^2(n-1)\).
    \end{enumerate}
    Si un échantillon vérifie ces deux propriétés, alors les \( X_i\) sont de loi \( \dN(m,\sigma^2)\).
\end{theorem}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Estimation ponctuelle}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Nous considérons un modèle statistique 
\begin{equation}
    \statS=\big[ (\Omega,\tribF,P),(X_{\theta}),(\mu_{\theta}) \big]_{\theta\in\Theta}
\end{equation}
et pour tout \( \theta\) nous notons \( X=(X_{\theta,1},\ldots,X_{\theta,n})\) un échantillon de loi parente \( \mu_{\theta}\). Tant que nous travaillerons avec un \( \theta\) fixé, nous écrirons \( X=(X_1,\ldots,X_n)\) sans expliciter la paramètre \( \theta\). Nous noterons 
\begin{equation}
    E_{\theta}\big( \varphi(X_1,\ldots,X_n) \big)=\int_{\eR^n}\varphi(x_1,\ldots,x_n)d\mu_{\theta}^{\otimes n}(x_1,\ldots,x_n).
\end{equation}
Dans cette notation nous plaçons le \( \theta\) sur l'espérance, tandis qu'en réalité le \( \theta\) devrait être sur chaque \( X_1\). Tant qu'aucune confusion n'est possible nous ferons toujours cet abus d'écriture.

Le but de la théorie de l'estimation est de déduire la valeur de \( \theta\) (et donc la loi \( \mu_{\theta}\)) à partir d'un échantillon de loi parente \( \theta\). 

Nous posons les hypothèses suivantes.
\begin{enumerate}
    \item
        Le modèle statistique \( \statS\) est paramétré, c'est à dire que \( \Theta\subset\eR^d\) avec le plus souvent \( d=1,2\). Typiquement les paramètres seront la moyenne et la variance.
    \item
        Le modèle statistique est \defe{identifiable}{identifiable}, c'est à dire que pour tout couple \( (\theta_1,\theta_2)\in\Theta^2\), si \( \theta_1\neq\theta_2\), alors \( \mu_{\theta_1}\neq\mu_{\theta_2}\).
    \item
        Le modèle \( \statS\) est \defe{dominé}{dominé!modèle statistique} par la mesure de Lebesgue si les lois \( \mu_{\theta}\) sont continues et par la mesure de comptage si les lois \( \mu_{\theta}\) sont discrètes.
\end{enumerate}

\begin{example}
    La famille des lois exponentielles \( \big( \dE(\lambda) \big)_{\lambda>0}\) est identifiable. Les lois gaussiennes \( \big( \dN(m,\sigma^2) \big)_{m\in\eR,\sigma^2>0}\) sont également identifiables.

    En réalité il est assez compliqué de trouver un exemple de modèle non identifiable à moins de la faire exprès. Par exemple en paramétrant les lois exponentielles de la façon suivante : \( \big( \dE(\sin(\lambda)) \big)_{\lambda\in\eR}\). Cette famille n'est pas identifiable.
\end{example}

Le corollaire \ref{CorDomDens} ainsi que l'hypothèse de modèle dominé implique que les lois ont des densités. Si la loi \( \mu_{\theta}\) est discrète, nous notons 
\begin{equation}
    p(x,\theta)=\mu_{\theta}(\{ x \})
\end{equation}
la densité de \( \mu_{\theta}\) par rapport à la mesure de comptage. Si La loi \( \mu_{\theta}\) est continue, nous notons
\begin{equation}
    p(x,\theta)=f_{\theta}(x)
\end{equation}
la densité par rapport à la mesure de Lebesgue.

Si \( \mu_{\theta}\) est une loi discrète et si \( (X_1,\ldots,X_n)\) est un échantillon de taille \( n\), alors pour tout \( (x_1,\ldots,x_n)\in\eR^n\) nous avons
\begin{equation}
    p_n(x_1,\ldots,x_n;\theta)=\mu_{\theta}^{\otimes n}\big( \{ x_1,\ldots,x_n \} \big)=\mu_{\theta}(\{ x_1 \})\ldots\mu_{\theta}(\{ x_n \})=p(x_1,\theta)\ldots p(x_n,\theta).
\end{equation}
La première et la dernière égalité sont des notations; la seconde est une conséquence de l'indépendance des \( X_i\) contenues dans l'échantillon. Pour une loi continues, nous adoptons la même notation. Le vecteur aléatoire \( (X_1,\ldots,X_n)\) admet la densité
\begin{equation}
    (x_1,\ldots,x_n)\mapsto p_n(x_1,\ldots,x_n;\theta)=f_{\theta}(x_1)\ldots f_{\theta}(x_n)=p(x_1,\theta)\ldots p(x_n,\theta).
\end{equation}

\begin{example}
    Soit \( (X_1,\ldots,X_n)\) un \( n\)-échantillon de loi \( \dB(1,\theta)\) avec \( \theta\in\mathopen] 0 , 1 \mathclose[\). C'est une loi discrète portée par l'ensemble \( \{ 0,1 \}\). Nous avons
    \begin{equation}
        p(x,\theta)=\begin{cases}
            0    &   \text{si \( 0\neq x\neq 1\)}\\
            1-\theta    &   \text{si \( x=0\)}\\
            \theta    &    \text{si \( x=1\).}
        \end{cases}
    \end{equation}
    De façon plus condensée nous pouvons écrire 
    \begin{equation}
        p(x,\theta)=\theta^x(1-\theta)^{1-x}\mtu_{\{ 0,1 \}}(x).
    \end{equation}
    Pour tout \( (x_1,\ldots,x_n)\in\eR^p\), la densité du \( n\)-échantillon est donnée par
    \begin{equation}
        p_n(x_1,\ldots,x_n;\theta)=\theta^{x_1+\ldots+x_n}(1-p)^{1-\sum_i(1-x_i)}\mtu_{\{ 0,1 \}^n}(x_1,\ldots,x_n).
    \end{equation}
\end{example}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Statistiques et estimateurs}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{definition}
    Une \defe{statistique}{statistique} sur un modèle d'échantillonnage est une variable aléatoire fonction de l'échantillon \( (X_1,\ldots,X_n)\) ne dépendant pas de \( \theta\). C'est à dire une application borélienne \( T\colon \eR^n\to \eR\) ne dépendant pas de \( \theta\). La statistique associée à cette application est $S=T(X_1,\ldots,X_n)$.
\end{definition}

Les fonctions \( T(X_1,\ldots,X_n)\) données par \( \sum_iX_i\), \(  e^{\sum X_i}\) sont des statistiques. La constante \( \frac{ 1 }{2}\) est également une statistique (mais elle est moins intéressante).

Un \defe{estimateur}{estimateur} est une statistique qui prend ses valeurs dans \( \Theta\). Nous la noterons
\begin{equation}
    \hat\theta_n=\theta(X_1,\ldots,X_n).
\end{equation}
La fonction \( \hat\theta_n\) est borélienne à valeurs dans \( \Theta\).

\begin{example}
    Soit un \( n\)-échantillon de loi \( \dB(1,\theta)_{\theta\in\mathopen[ 0 , 1 \mathclose]}\). Les fonctions \( \hat\theta_n=\frac{1}{ n }\sum_{i=1}^nX_i\) et \( \hat\varphi_n=\frac{ 1 }{2}\) sont des estimateurs. Cependant nous devinons que la première va être plus intéressante que la seconde.
\end{example}
Pour la suite, nous travaillerons avec des estimateurs de carré intégrable, c'est à dire que
\begin{equation}
    E_{\theta}\big( | \hat\theta_n(X_1,\ldots,X_n) |^2 \big)<\infty
\end{equation}
pour tout \( \theta\in\Theta\).

\begin{definition}
    Une estimateur est \defe{convergent}{convergent!estimateur} si pour tout \( \theta\in\Theta\), la suite de variables aléatoires \( \hat\theta_n(X_1,\ldots,X_n)\) converge en probabilité vers \( \theta\).
\end{definition}
En d'autres termes, l'estimateur \( \hat\theta_n\) est convergent si pour tout \( \theta\in\Theta\) et pour tout \( \eta>0\),
\begin{equation}
    \lim_{n\to \infty} P\big( | \hat\theta_n(X_1,\ldots,X_n)-\theta |>\eta \big)=0.
\end{equation}
La probabilité dans le membre de gauche est donnée par
\begin{equation}
    \mu^{\otimes n}_{\theta}\Big( \big\{ (x_1,\ldots,x_n)\in\eR^n\tq| \hat\theta_n(x_1,\ldots,x_n)-\theta |>\eta \big\} \Big).
\end{equation}

Nous allons maintenant étudier quelque manières de construire des estimateurs convergents. Il vont évidemment s'appuyer sur la loi des grands nombres.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Méthode des moments}
%---------------------------------------------------------------------------------------------------------------------------

Sans surprises, un bon estimateur pour la moyenne est
\begin{equation}
    \hat\theta_n(X_1,\ldots,X_n)=\frac{1}{ n }\sum_{i=1}^nX_i.
\end{equation}

Plus généralement, nous supposons qu'il existe une fonction borélienne \( M\colon \eR\to \eR\) telle que
\begin{equation}
    E_{\theta}\big( | M(X) | \big)<\infty
\end{equation}
où \( X\) est la loi parente de l'échantillon. Supposons également que la fonction 
\begin{equation}
    h(\theta)=E_{\theta}\big( M(X) \big)
\end{equation}
soit inversible et continue sur \( \Theta\). Dans ce cas, pour estimer le paramètre \( \theta\), nous considérons l'estimateur
\begin{equation}
    \hat\theta_n=h^{-1}\left( \frac{1}{ n }\sum_{i=1}^nM(X_i) \right).
\end{equation}
Cela est un estimateur convergent. En effet, la loi des grands nombres dit que
\begin{equation}
    \frac{1}{ n }\sum_iM(X_i)\stackrel{p.s.}{\longrightarrow}E_{\theta}\big( M(X) \big).
\end{equation}
En composant avec la fonction \( h\), nous avons
\begin{equation}
    \hat\theta_n\stackrel{p.s.}{\longrightarrow}h^{-1}\Big( E_{\theta}\big( M(X) \big) \Big)=\theta.
\end{equation}
Dans cette construction, \( M(X)\) est le moment de \( X\) que l'on souhaite déterminer.

\begin{example}
    Soit \( (X_1,\ldots,X_n)\) un échantillon de loi \( \dE(\lambda)\). Construire \( \hat\lambda_n\). Pour une loi exponentielle,
    \begin{equation}
        E(X)=\frac{1}{ \lambda }.
    \end{equation}
    Nous devons donc déterminer le moment d'ordre \( 1\) de \( X\) (c'est à dire sa moyenne). Nous considérons donc la fonction \( M(x)=x\); par conséquent
    \begin{equation}
        h(\lambda)=E(X)=\frac{1}{ \lambda }
    \end{equation}
    et \( h^{-1}(\theta)=1/\theta\). L'estimateur que nous considérons pour \( \lambda\) est finalement
    \begin{equation}
        \hat\theta_n=\frac{1}{ \frac{1}{ n }\sum_{i=1}^nX_i }.
    \end{equation}
    
\end{example}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Méthode de substitution}
%---------------------------------------------------------------------------------------------------------------------------

Supposons que nous connaissions un estimateur convergent \( \hat\theta_n\to\theta\). Si \( g\colon \eR^d\to \eR\) est une fonction continue, alors
\begin{equation}
    g(\hat\theta_n)\to g(\theta).
\end{equation}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Méthode du maximum de vraisemblance}
%---------------------------------------------------------------------------------------------------------------------------

\begin{example}
    Nous désirons contrôler la qualité d'une chaîne de production; pour cela nous prélevons un échantillon de \( 10\) pièces, et nous en trouvons \( 3\) défectueuses. Que dire de la proportion de pièces défectueuses ?

    Évidemment, le plus probable est que la proportion de pièces défectueuses soit de \( 1/3\). Analysons en détail comment nous arrivons à ce résultat. Nous considérons que le fait de tirer \( 10\) pièces revient à une expérience binomiale de paramètres \( 10\) et de probabilité \( p\) inconnue. Dans ce cas, la probabilité d'observer exactement \( 3\) pièces défectueuses est de 
    \begin{equation}
        L(p)=P(X=3)={10\choose 3}p^3(1-p)^{7}.
    \end{equation}
    Affin de trouver le \( p\) qui réalise le maximum de \( P(X=3)\), nous annulons la dérivée et nous trouvons \( p=3/10\).

The result is on figure \ref{LabelFigMaxVraissLp}.
\newcommand{\CaptionFigMaxVraissLp}{<+Type your caption here+>}
\input{Fig_MaxVraissLp.pstricks}

\end{example}
<++>
