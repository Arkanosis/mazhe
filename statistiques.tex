%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Notations et hypothèses}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Nous notons \( X\) le caractère à étudier, et \( \Omega\) l'ensemble des individus. Le caractère à étudier est vu comme une fonction sur \( \Omega\) :
\begin{equation}
    X\colon \Omega\to \eR,\eN,\{ 0,1 \},\ldots
\end{equation}
Les \defe{statistiques descriptives}{statistiques!descriptives} sont les techniques pour présenter et résumer les données : diagrammes, graphiques, indicateurs numériques : moyenne, écart-type, médiane, \ldots

Nous faisons les hypothèses suivantes :
\begin{enumerate}
    \item
        Chaque observation \( x_i\) est la réalisation de la variable aléatoire \( X\) qui sera de loi inconnue \( \mu\).
    \item
        Le \( n\)-uple \( (x_1,\ldots,x_n)\) est la réalisation de \( (X_1,\ldots,X_n)\) qui est l'échantillon de taille \( n\).
    \item
        Les variables aléatoires \( X_i\) sont indépendantes et identiquement distribuées, de loi commune \( \mu\). La loi \( \mu\) est la \defe{loi parente}{loi!parente} de l'échantillon.
\end{enumerate}

\begin{example}
    Un échantillon de taille \( 1\) consisterait à tirer au sort une personne dans une population et mesurer sa taille.
\end{example}

\begin{example}
    Une échantillon de taille \( n\) consisterait à tirer au sort \( n\) personnes dans une population et de mesurer leurs tailles.
\end{example}

L'\defe{inférence statistique}{inférence statistique} est l'art de dégager des informations sur la population à partir d'informations partielles : intervalles de confiance, estimateurs, test d'hypothèses, \ldots

En théorie des probabilités, nous connaissons la loi de la variable aléatoire \( X\) et nous en déduisons des informations sur le réalisations de \( X\) : valeur la plus probable, moyenne, intervalle dans lequel \( X(\omega)\) a le plus de chance d'appartenir. En statistique, au contraire, la loi est inconnues et nous cherchons des informations sur la loi à partir d'un échantillon de données numériques observées.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Modèle statistique}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Une \defe{modèle statistique}{modèle!statistique} est un triplet
\begin{equation}
    \statS=\Big[ (\Omega,\tribF,P),(X_{\theta})_{\theta\in\Theta},(\mu_{\theta})_{\theta\in\Theta} \Big]
\end{equation}
où \( (\Omega,\tribF,P)\) est un espace probabilisé, \( (X_{\theta})\) est une famille de variables aléatoires définies sur \( \Omega\) et telles que pour tout \( \theta\in\Theta\), la variable aléatoire \( X_{\theta}\) suive la loi \( \mu_{\theta}\). Les $\mu_{\theta}$ sont des mesures sur les boréliens de \( \eR\) et pour tout \( B\in\Borelien(\eR)\) nous avons
\begin{equation}
    P(X_{\theta}\in B)=\mu_{\theta}(B).
\end{equation}
\begin{remark}
    D'une certaine manière, l'introduction de \( \mu_{\theta}\) dans la définition est redondante parce que ces mesures sont déjà contenues dans la données des variables aléatoires \( X_{\theta}\).
\end{remark}

\begin{example}[Modèle statistique gaussien]
    Si nous savons que les variables aléatoires \( X_i\) suivent une loi gaussienne, alors nous considérons \( \Theta=\eR\times\eR^+\) et \( \theta=(m,\sigma^2j)\). Dans ce cas, \( \mu_{\theta}=\dN(m,\sigma^2)\) et le but de la statistique est de déterminer la valeur de \( \theta\) qui correspond à une population en partant de l'observation d'un échantillon.
\end{example}

\begin{definition}
    Si \( \Theta\subset\eR^k\), nous disons que le modèle statistique est un modèle \defe{paramétrique}{modèle!paramétrique}.
\end{definition}
Le modèle gaussien est un modèle paramétrique : dès que \( m\) et \( \sigma^2\) sont déterminés, la loi du phénomène \( X\) est connue.

\begin{definition}
    Pour chaque \( \theta\in\theta\), un \defe{échantillon}{échantillon} de taille \( n\) associé à un modèle statistique \( \big[ (\Omega,\tribF,P),(X_{\theta}),(\mu_{\theta}) \big]\) est un vecteur \( \big( X_{\theta,1},\ldots,X_{\theta,n} \big)\) de taille \( n\) de variables aléatoires indépendantes et identiquement distribuées de la même loi que la variable aléatoire \( X_{\theta}\). La loi \( \mu_{\theta}\) est la \defe{loi parente}{loi!parente} de l'échantillon.
\end{definition}

\begin{definition}
    Un \defe{modèle d'échantillonnage}{modèle!échantillonnage} sur le modèle statistique \( \statS\) est une famille \( (X_{\theta,1},\ldots, X_{\theta,n})_{\theta\in\Theta}\) d'échantillons de taille \( n\geq 1\).
\end{definition}

Nous noterons souvent \( (X_1,\ldots,X_n)\) à la place de \( (X_{\theta,1},\ldots,X_{\theta,n})\) un échantillon, mais il faut se souvenir que les \( X_i\) suivent toujours la même loi donnée par \( \theta\). La loi du vecteur \( (X_1,\ldots,X_n)\) est \( \mu_{\theta}\otimes\ldots\otimes\mu_{\theta}\) et est définie sur l'espace \( (\Omega^n,\tribF\otimes\ldots\otimes\tribF,P^{\otimes n})\).

\begin{remark}
    Le travail du statisticien est de proposer un modèle statistique \( \statS\) a priori. Si nous étudions la taille d'une population, nous allons choisir un modèle gaussien. Plus le modèle est précis, plus l'espace \( \Theta\) est petit mais plus il y a de risques que le vérité soit hors de l'ensemble considéré.
\end{remark}

\begin{example}
    Soit \( X\) une variable aléatoire de carré intégrable que l'on sait simuler. Affin d'évaluer la moyenne \( \mu\) de \( X\), nous pouvons considérer la moyenne empirique des simulations : \( \bar X_n=\frac{1}{ n }\sum_{i=1}^nX_i\) où les variables aléatoires \( X_i\) sont indépendantes, identiquement distribuées et de même loi que \( X\). 

    La loi des grands nombres nous enseigne que \( \bar X_n\to\mu\). De plus,
    \begin{equation}
        \lim_{n\to \infty} P\left( \mu\in\left[ \bar X_n-\frac{ a\sigma }{ \sqrt{n} },\bar X_n+\frac{ a\sigma }{ \sqrt{n} } \right] \right)=\int_{-a}^a e^{-x^2/2}\frac{ dx }{ \sqrt{2\pi} }.
    \end{equation}
    En effet, la condition sur \( \mu\) est équivalente à
    \begin{equation}
        -a\leq \frac{ \bar X_n-\mu }{ \sigma/\sqrt{n} }\leq a,
    \end{equation}
    tandis que le théorème central limite nous enseigne que la variable aléatoire \( \frac{ \bar X_n-\mu }{ \sigma/\sqrt{n} }\) se comporte comme \( \dN(0,1)\) lorsque \( n\) est grand. Dans ce cas, nous avons que
    \begin{equation}
        P\left( \frac{ \bar X_n-\mu }{ \sigma/\sqrt{n} }\in\mathopen[ -a , a \mathclose] \right)=\frac{1}{ \sqrt{2\pi} }\int_{-a}^a e^{-x^2/2}dx.
    \end{equation}
    Notons que dans ce calcul nous avons utilisé le fait que \( \mu=E(X_1)\).

    Montrons que la suite
    \begin{equation}
        \sigma_n^2=\frac{1}{ n }\sum_{i=1}^nX_i^2-\left( \frac{1}{ n }\sum_{i=1}^nX_i \right)^2
    \end{equation}
    converge presque sûrement vers \( \sigma^2\). Le théorème central limite implique que
    \begin{equation}
        \frac{1}{ n }\sum_{i=1}^nX_i^2\stackrel{p.s.}{\longrightarrow} E(X_1^2)
    \end{equation}
    et que
    \begin{equation}
        \left( \frac{1}{ n }\sum_{i=1}^nX_i \right)^2\stackrel{p.s.}{\longrightarrow}E(X_1)^2.
    \end{equation}
    La différence converge donc presque sûrement vers \( \sigma^2\) en vertu de la proposition \ref{PrropVarAlterfrom}.

    Nous avons également \( E(\sigma_n^2)=\sigma^2\). En effet, sachant que \( E(X_i)=E(X_1)=\mu\) et que \( E(X_i^2)=E(X_1^2)=\mu^2+\sigma^2\),
    \begin{subequations}
        \begin{align}
            E(\sigma_n^2)&=\frac{1}{ n }\sum_{i=1}^nE(X_i^2)-\frac{1}{ n^2 }\left( \sum_{i=1}^nE(X_i^2) \right)+\sum_{i\neq j}E(X_iX_j))\\
            &=\sigma^2+\mu^2-\frac{1}{ n^2 }\big( n(\sigma^2+\mu^2)+(n^2-n)\mu^2 \big)\\
            &=\sigma^2-\frac{1}{ n }\sigma^2,
        \end{align}
    \end{subequations}
    dont la limite \( n\to\infty\) donne bien \( \sigma^2\).

    Nous voudrions à présent montrer que 
    \begin{equation}
        \frac{ \bar X_n-\mu }{ \sigma_n/\sqrt{n} }\stackrel{\hL}{\longrightarrow}\dN(0,1).
    \end{equation}
    Vu que le théorème central limite donne une convergence en loi, nous pouvons utiliser le lemme de Slutsky pour montrer que
    \begin{equation}
        \left( \frac{ \bar X_n-\mu }{ 1/\sqrt{n} },\sigma_n^2 \right)\stackrel{\hL}{\longrightarrow}(\sigma Z,\sigma^2)
    \end{equation}
    où \( Z\sim\dN(0,1)\). En vertu de la proposition \ref{PropcvLsousfonc} appliqué à la fonction \( f\colon \eR^2\to \eR\),
    \begin{equation}
        f(x,y)=\begin{cases}
            \frac{ x }{ \sqrt{y} }    &   \text{si \( y\neq 0\)}\\
            0    &    \text{sinon}
        \end{cases}
    \end{equation}
    nous avons la convergence en loi
    \begin{equation}
        f\left( \frac{ \bar X_n-\mu }{ 1/\sqrt{n} },\sigma_n^2 \right)\stackrel{\hL}{\longrightarrow}f(\sigma Z,\sigma^2),
    \end{equation}
    c'est à dire 
    \begin{equation}
        \frac{ \bar X_n-\mu }{ \sigma_n/\sqrt{n} }\stackrel{\hL}{\longrightarrow}Z.
    \end{equation}
    Affin d'être complet, précisons que 
    \begin{equation}
        P\big( (\sigma Z,\sigma)\in\eR\times \{ 0 \} \big)=0.
    \end{equation}
\end{example}

\begin{proposition}     \label{PropLimxBNpxbxbsqrt}
    Soit \( X_i\) des variables aléatoires indépendantes et identiquement distribuées de loi parente \( \dB(n,p)\). Alors si \( \bar X_n\) désigne la moyenne empirique,
    \begin{equation}
        \sqrt{n}\frac{ \bar X_n-p }{ \sqrt{\bar X_n(1-\bar X_n)} }\stackrel{\hL}{\longrightarrow}Z\sim\dN(0,1).
    \end{equation}
\end{proposition}

\begin{proof}
    Cela est une application de la loi des grands nombres, tu théorème central limite, du lemme de Slutsky et de la proposition \ref{PropcvLsousfonc}.

    D'abord, la loi des grands nombres nous indique que \( \bar X_n\to p\) parce que \( p\) est l'espérance de Bernoulli. Ensuite nous avons
    \begin{equation}
        \frac{ \bar X_n-E(X) }{ \sqrt{\Var(X)}/\sqrt{n} }=\sqrt{n}\frac{ \bar X_n-p }{ \sqrt{p(1-p)} }
    \end{equation}
    parce que la variance d'une loi de Bernoulli est \( p(1-p)\). Le théorème central limite nous indique par conséquent que
    \begin{equation}
        \sqrt{n}\frac{ \bar X_n-p }{ \sqrt{p(1-p)} }\stackrel{\hL}{\longrightarrow}Z\sim\dN(0,1).
    \end{equation}
    Le lemme de Slutsky implique alors la convergence du couple :
    \begin{equation}
        \left( \sqrt{n}\frac{ \bar X_n-p }{ \sqrt{p(1-p)} },\bar X_n \right)\stackrel{\hL}{\longrightarrow}(Z,p).
    \end{equation}
    Nous appliquons maintenant la proposition \ref{PropcvLsousfonc} avec la fonction
    \begin{equation}
        f(x,y)=\frac{ \sqrt{p(1-p)}x }{ \sqrt{y(1-y)} }
    \end{equation}
    qui est une fonction dont l'ensemble des points de discontinuité est \( C=\{ 0 \}\). Étant donné que \( P(\bar X_n=0)=0\), la proposition s'applique et nous avons
    \begin{equation}
        f\left( \sqrt{n}\frac{ \bar X_n-p }{ \sqrt{p(1-p)} },\bar X_n \right)\stackrel{\hL}{\longrightarrow}f(Z,p),
    \end{equation}
    c'est à dire
    \begin{equation}
        \sqrt{n}\frac{ \bar X_n-p }{ \sqrt{\bar X_n(1-\bar X_n)} }\stackrel{\hL}{\longrightarrow}Z\sim\dN(0,1).
    \end{equation}
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Statistiques descriptives}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Modèles d'échantillonnages}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Soit \( X\), une variable aléatoire sur \( (\Omega,\tribF,P)\). Un \defe{échantillon}{échantillon} de taille \( n\) pour \( X\) est une suite de \( n\) variables aléatoires \( (X_1,\ldots,X_n)\) définies sur \( (\Omega,\tribF,P)\) indépendantes et de même loi que \( X\). Nous disons que la loi de \( X\) est la \defe{loi parente}{loi!parente d'un échantillon} de la suite \( X_i\).

\begin{definition}
    Soit
    \begin{equation}
        \statS=\Big[ (\Omega,\tribF,P),(X_{\theta}),(\mu_{\theta}) \Big]_{\theta\in\Theta},
    \end{equation}
    un modèle statistique. Un \defe{modèle d'échantillonnage}{modèle!échantillonnage} de taille \( n\) associée au modèle statistique \( \statS\) est la donnée d'une famille de \( n\)-échantillons \( (X_{\theta,1}),\ldots,X_{\theta,n}\) telle que pour tout \( \theta\in\Theta\), l'échantillon \( (X_{\theta,i})\) soit de variable parente \( X_{\theta}\).
\end{definition}

La \defe{moyenne empirique}{moyenne!empirique d'un échantillon} du \( n\)-échantillon \( (X_i)\) est la variable aléatoire
\begin{equation}
    \bar X_n=\frac{1}{ n }\sum_{i=1}^{n}X_i.
\end{equation}

La proposition suivante signifie que la moyenne empirique est une «bonne» façon d'approcher la variable aléatoire.
\begin{proposition}
    Soit \( X\), une variable aléatoire dans \( L^2(\Omega)\) (c'est à dire \( E(X^2)<\infty\)) d'espérance \( m\) et de variance \( \sigma^2\). Alors
    \begin{enumerate}
        \item
            \( E(\bar X_n)=m\) et \( \Var(\bar X_n)=\frac{ \sigma^2 }{ n }\).
        \item
            Nous avons les convergences
            \begin{subequations}
                \begin{align}
                    \bar X_n&\stackrel{p.s.}{\longrightarrow} m\\
                    \frac{ \bar X_n-m }{ \sigma/\sqrt{n} }&\stackrel{\hL}{\longrightarrow} Z\sim\dN(0,1).
                \end{align}
            \end{subequations}
        \item
            Si \( X\) est de loi \( \dN(m,\sigma^2)\), alors \( \bar X_n\sim\dN(m,\frac{ \sigma^2 }{ n })\), c'est à dire
            \begin{equation}
                \frac{ \bar X_n -m}{ \sigma/\sqrt{n} }\sim\dN(0,1).
            \end{equation}
            
            
    \end{enumerate}
    
\end{proposition}
L'intérêt de prendre la moyenne \( \bar x_n\) des données expérimentales en statistiques descriptives est que \( \bar X_n\to m\).

La \defe{variance empirique}{variance!empirique} d'un échantillon est la variable aléatoire
\begin{equation}
    V_n^2=\frac{1}{ n }\sum_{i=1}^n(X_i-\bar X_n)^2.
\end{equation}
La \defe{variance empirique corrigée}{variance!empirique corrigée} est la variable aléatoire 
\begin{equation}        \label{Eqdefvarempicorri}
    S_n^2=\frac{1}{ n-1 }\sum_{i=1}^n(X_i-\bar X_n)^2.
\end{equation}

\begin{lemma}

    La variance corrigée et la variance empirique ont comme espérances :
    \begin{subequations}
        \begin{align}
            E(V_n^2)&=\frac{ n-1 }{ n }\sigma^2\\
            E(S_n^2)&=\sigma^2.
        \end{align}
    \end{subequations}
\end{lemma}

\begin{proof}
    Nous commençons par calculer l'espérance de la variance non corrigée. La première étape est de la récrire sous la forme
    \begin{equation}
        \begin{aligned}[]
            V_n^2&=\frac{1}{ n }\sum_k(X_k^2-2X_k\bar X_n+\bar X_n^2)\\
            &=\frac{1}{ n }\sum_kX_k^2-2\bar X_n\underbrace{\sum_kX_k}_{=n\bar X_n}+\bar X_n^2\\
            &=\frac{1}{ n }\sum_k X_k-\bar X_n^2.
        \end{aligned}
    \end{equation}
    Nous calculons séparément l'espérance de ces deux termes. Si \( X\) est la loi parente des \( X_i\), en utilisant l'indépendance des \( X_i\) nous trouvons
    \begin{equation}
        \begin{aligned}[]
            E\left( \frac{1}{ n }\sum_kX_k^2 \right)&=\frac{1}{ n }\sum_{k=1}^nE(X_k^2)\\
            &=E(X^2)\\
            &=E(X)^2-\Var(X).
        \end{aligned}
    \end{equation}
    Nous devons à présent calculer l'espérance de \( \bar X_n^2\):
    \begin{equation}
        E(\bar X_n^2)=E(\bar X_n)^2+\Var(\bar X_n).
    \end{equation}
    En utilisant le lemme \ref{LemVarXpYsmindep},
    \begin{subequations}
        \begin{align}
            \Var(\bar X_n)&=\Var\left( \frac{1}{ n }\sum_kX_k \right)\\
            &=\frac{1}{ n^2 }\sum_k\Var(X_k)\\
            &=\frac{1}{ n }\Var(X).
        \end{align}
    \end{subequations}
    Par conséquent
    \begin{equation}
        E(V_n^2)=\Var(X)\left( 1-\frac{1}{ n } \right)=\frac{ n-1 }{ n }\Var(X).
    \end{equation}

    En ce qui concerne la variance corrigée,
    \begin{equation}
        S_n^2=\frac{1}{ n-1 }\sum_k(X_k-\bar X_n)^2=\frac{ n }{ n-1 }V_n^2,
    \end{equation}
    par conséquent \( E(S_n^2)=\frac{ n }{ n-1 }E(V_n^2)=\Var(X)\).
\end{proof}

\begin{proposition}
    Soit \( X\) une variable aléatoire de variance \( \Var(X)=\sigma\). Si \( E(X^4)<\infty\), alors
    \begin{enumerate}
        \item
            \( S_n^2\stackrel{p.s.}{\longrightarrow}\sigma^2\).
        \item
            \begin{equation}
                \frac{ S_n^2-\sigma^2 }{ \sqrt{\frac{ \mu^4-\sigma^4 }{ n }} }\stackrel{\hL}{\longrightarrow}Z\sim\dN(0,1)
            \end{equation}
            où \( \mu^4=E(X^4)\) est le moment d'ordre \( 4\) de \( X\).
    \end{enumerate}
\end{proposition}

\begin{theorem}
    Si \( (X_1,\ldots,X_n)\) est un \( n\)-échantillon de loi parente \( \dN(m,\sigma^2)\), alors
    \begin{enumerate}
        \item
            Les variables aléatoires 
            \begin{equation}
                \begin{aligned}[]
                    \frac{ \bar X_n-m }{ \sigma/\sqrt{n} }&&\text{et}&&(n-1)\frac{ S_n^2 }{ \sigma^2 }
                \end{aligned}
            \end{equation}
            sont indépendantes.
        \item
            La loi de \( (n-1)\frac{ S_n^2 }{ \sigma^2 }\) est \( \chi^2(n-1)\).
    \end{enumerate}
    Si un échantillon vérifie ces deux propriétés, alors les \( X_i\) sont de loi \( \dN(m,\sigma^2)\).
\end{theorem}


L'inégalité de Markov donne une borne supérieure à la probabilité qu'une variable aléatoire positive soit plus grande ou égale à une constante.
\begin{theorem}[Inégalité de Markov]\index{Markov!inégalité}    \label{ThoInegMarkov}
    Soit \( X\) une variable aléatoire à valeurs dans \( \eR^d\) et \( \varphi\colon \eR^d\to \mathopen[ 0 , \infty [\). Alors
    \begin{equation}
        P\big( \varphi(X)\geq a \big)\leq\frac{ E\big( \varphi(X) \big) }{ a }
    \end{equation}
    pour tout \( a>0\).
\end{theorem}

\begin{proof}
    Calculons le second membre :
    \begin{equation}
        \begin{aligned}[]
            \frac{ E\big( \varphi(X) \big) }{ a }&=\int_{\Omega}\frac{ \varphi(X) }{ a }dP\\
            &=\int_{\varphi(X)\geq a}\underbrace{\frac{ \varphi(X) }{ a }}_{\leq 1}dP+\int_{\varphi(X)<a}\frac{ \varphi(X) }{ a }dP\\
            &\geq\int_{\varphi(X)\leq a}dP\\
            &=P\big( \varphi(X)\leq a \big).
        \end{aligned}
    \end{equation}
    D'où l'inégalité voulue.
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Estimation ponctuelle}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Nous considérons un modèle statistique 
\begin{equation}
    \statS=\big[ (\Omega,\tribF,P),(X_{\theta}),(\mu_{\theta}) \big]_{\theta\in\Theta}
\end{equation}
et pour tout \( \theta\) nous notons \( X=(X_{\theta,1},\ldots,X_{\theta,n})\) un échantillon de loi parente \( \mu_{\theta}\). Tant que nous travaillerons avec un \( \theta\) fixé, nous écrirons \( X=(X_1,\ldots,X_n)\) sans expliciter la paramètre \( \theta\). Nous noterons 
\begin{equation}
    E_{\theta}\big( \varphi(X_1,\ldots,X_n) \big)=\int_{\eR^n}\varphi(x_1,\ldots,x_n)d\mu_{\theta}^{\otimes n}(x_1,\ldots,x_n).
\end{equation}
Dans cette notation nous plaçons le \( \theta\) sur l'espérance, tandis qu'en réalité le \( \theta\) devrait être sur chaque \( X_1\). Tant qu'aucune confusion n'est possible nous ferons toujours cet abus d'écriture.

Le but de la théorie de l'estimation est de déduire la valeur de \( \theta\) (et donc la loi \( \mu_{\theta}\)) à partir d'un échantillon de loi parente \( \theta\). 

Nous posons les hypothèses suivantes.
\begin{enumerate}
    \item
        Le modèle statistique \( \statS\) est paramétré, c'est à dire que \( \Theta\subset\eR^d\) avec le plus souvent \( d=1,2\). Typiquement les paramètres seront la moyenne et la variance.
    \item
        Le modèle statistique est \defe{identifiable}{identifiable}, c'est à dire que pour tout couple \( (\theta_1,\theta_2)\in\Theta^2\), si \( \theta_1\neq\theta_2\), alors \( \mu_{\theta_1}\neq\mu_{\theta_2}\).
    \item
        Le modèle \( \statS\) est \defe{dominé}{dominé!modèle statistique} par la mesure de Lebesgue si les lois \( \mu_{\theta}\) sont continues et par la mesure de comptage si les lois \( \mu_{\theta}\) sont discrètes.
\end{enumerate}

\begin{example}
    La famille des lois exponentielles \( \big( \dE(\lambda) \big)_{\lambda>0}\) est identifiable. Les lois gaussiennes \( \big( \dN(m,\sigma^2) \big)_{m\in\eR,\sigma^2>0}\) sont également identifiables.

    En réalité il est assez compliqué de trouver un exemple de modèle non identifiable à moins de la faire exprès. Par exemple en paramétrant les lois exponentielles de la façon suivante : \( \big( \dE(\sin(\lambda)) \big)_{\lambda\in\eR}\). Cette famille n'est pas identifiable.
\end{example}

Le corollaire \ref{CorDomDens} ainsi que l'hypothèse de modèle dominé implique que les lois ont des densités. Si la loi \( \mu_{\theta}\) est discrète, nous notons 
\begin{equation}
    p(x,\theta)=\mu_{\theta}(\{ x \})
\end{equation}
la densité de \( \mu_{\theta}\) par rapport à la mesure de comptage. Si La loi \( \mu_{\theta}\) est continue, nous notons
\begin{equation}
    p(x,\theta)=f_{\theta}(x)
\end{equation}
la densité par rapport à la mesure de Lebesgue.

Si \( \mu_{\theta}\) est une loi discrète et si \( (X_1,\ldots,X_n)\) est un échantillon de taille \( n\), alors pour tout \( (x_1,\ldots,x_n)\in\eR^n\) nous avons
\begin{equation}
    p_n(x_1,\ldots,x_n;\theta)=\mu_{\theta}^{\otimes n}\big( \{ x_1,\ldots,x_n \} \big)=\mu_{\theta}(\{ x_1 \})\ldots\mu_{\theta}(\{ x_n \})=p(x_1,\theta)\ldots p(x_n,\theta).
\end{equation}
La première et la dernière égalité sont des notations; la seconde est une conséquence de l'indépendance des \( X_i\) contenues dans l'échantillon. Pour une loi continues, nous adoptons la même notation. Le vecteur aléatoire \( (X_1,\ldots,X_n)\) admet la densité
\begin{equation}
    (x_1,\ldots,x_n)\mapsto p_n(x_1,\ldots,x_n;\theta)=f_{\theta}(x_1)\ldots f_{\theta}(x_n)=p(x_1,\theta)\ldots p(x_n,\theta).
\end{equation}

\begin{example}
    Soit \( (X_1,\ldots,X_n)\) un \( n\)-échantillon de loi \( \dB(1,\theta)\) avec \( \theta\in\mathopen] 0 , 1 \mathclose[\). C'est une loi discrète portée par l'ensemble \( \{ 0,1 \}\). Nous avons
    \begin{equation}
        p(x,\theta)=\begin{cases}
            0    &   \text{si \( 0\neq x\neq 1\)}\\
            1-\theta    &   \text{si \( x=0\)}\\
            \theta    &    \text{si \( x=1\).}
        \end{cases}
    \end{equation}
    De façon plus condensée nous pouvons écrire 
    \begin{equation}
        p(x,\theta)=\theta^x(1-\theta)^{1-x}\mtu_{\{ 0,1 \}}(x).
    \end{equation}
    Pour tout \( (x_1,\ldots,x_n)\in\eR^p\), la densité du \( n\)-échantillon est donnée par
    \begin{equation}
        p_n(x_1,\ldots,x_n;\theta)=\theta^{x_1+\ldots+x_n}(1-p)^{1-\sum_i(1-x_i)}\mtu_{\{ 0,1 \}^n}(x_1,\ldots,x_n).
    \end{equation}
\end{example}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Statistiques et estimateurs}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{definition}
    Une \defe{statistique}{statistique} sur un modèle d'échantillonnage est une variable aléatoire fonction de l'échantillon \( (X_1,\ldots,X_n)\) ne dépendant pas de \( \theta\). C'est à dire une application borélienne \( T\colon \eR^n\to \eR\) ne dépendant pas de \( \theta\). La statistique associée à cette application est $S=T(X_1,\ldots,X_n)$.
\end{definition}

Les fonctions \( T(X_1,\ldots,X_n)\) données par \( \sum_iX_i\), \(  e^{\sum X_i}\) sont des statistiques. La constante \( \frac{ 1 }{2}\) est également une statistique (mais elle est moins intéressante).

Un \defe{estimateur}{estimateur} est une statistique qui prend ses valeurs dans \( \Theta\). Nous la noterons
\begin{equation}
    \hat\theta_n=\theta(X_1,\ldots,X_n).
\end{equation}
La fonction \( \hat\theta_n\) est borélienne à valeurs dans \( \Theta\).

\begin{example}
    Soit un \( n\)-échantillon de loi \( \dB(1,\theta)_{\theta\in\mathopen[ 0 , 1 \mathclose]}\). Les fonctions \( \hat\theta_n=\frac{1}{ n }\sum_{i=1}^nX_i\) et \( \hat\varphi_n=\frac{ 1 }{2}\) sont des estimateurs. Cependant nous devinons que la première va être plus intéressante que la seconde.
\end{example}
Pour la suite, nous travaillerons avec des estimateurs de carré intégrable, c'est à dire que
\begin{equation}
    E_{\theta}\big( | \hat\theta_n(X_1,\ldots,X_n) |^2 \big)<\infty
\end{equation}
pour tout \( \theta\in\Theta\).

\begin{definition}
    Une estimateur est \defe{convergent}{convergent!estimateur} si pour tout \( \theta\in\Theta\), la suite de variables aléatoires \( \hat\theta_n(X_1,\ldots,X_n)\) converge en probabilité vers \( \theta\).
\end{definition}
En d'autres termes, l'estimateur \( \hat\theta_n\) est convergent si pour tout \( \theta\in\Theta\) et pour tout \( \eta>0\),
\begin{equation}
    \lim_{n\to \infty} P\big( | \hat\theta_n(X_1,\ldots,X_n)-\theta |>\eta \big)=0.
\end{equation}
La probabilité dans le membre de gauche est donnée par
\begin{equation}
    \mu^{\otimes n}_{\theta}\Big( \big\{ (x_1,\ldots,x_n)\in\eR^n\tq| \hat\theta_n(x_1,\ldots,x_n)-\theta |>\eta \big\} \Big).
\end{equation}

Nous allons maintenant étudier quelque manières de construire des estimateurs convergents. Il vont évidemment s'appuyer sur la loi des grands nombres.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Méthode des moments}
%---------------------------------------------------------------------------------------------------------------------------

Sans surprises, un bon estimateur pour la moyenne est
\begin{equation}
    \hat\theta_n(X_1,\ldots,X_n)=\frac{1}{ n }\sum_{i=1}^nX_i.
\end{equation}

Plus généralement, nous supposons qu'il existe une fonction borélienne \( M\colon \eR\to \eR\) telle que
\begin{equation}
    E_{\theta}\big( | M(X) | \big)<\infty
\end{equation}
où \( X\) est la loi parente de l'échantillon. Supposons également que la fonction 
\begin{equation}
    h(\theta)=E_{\theta}\big( M(X) \big)
\end{equation}
soit inversible et continue sur \( \Theta\). Dans ce cas, pour estimer le paramètre \( \theta\), nous considérons l'estimateur
\begin{equation}
    \hat\theta_n=h^{-1}\left( \frac{1}{ n }\sum_{i=1}^nM(X_i) \right).
\end{equation}
Cela est un estimateur convergent. En effet, la loi des grands nombres dit que
\begin{equation}
    \frac{1}{ n }\sum_iM(X_i)\stackrel{p.s.}{\longrightarrow}E_{\theta}\big( M(X) \big).
\end{equation}
En composant avec la fonction \( h\), nous avons
\begin{equation}
    \hat\theta_n\stackrel{p.s.}{\longrightarrow}h^{-1}\Big( E_{\theta}\big( M(X) \big) \Big)=\theta.
\end{equation}
Dans cette construction, \( M(X)\) est le moment de \( X\) que l'on souhaite déterminer.

\begin{example}
    Soit \( (X_1,\ldots,X_n)\) un échantillon de loi \( \dE(\lambda)\). Construire \( \hat\lambda_n\). Pour une loi exponentielle,
    \begin{equation}
        E(X)=\frac{1}{ \lambda }.
    \end{equation}
    Nous devons donc déterminer le moment d'ordre \( 1\) de \( X\) (c'est à dire sa moyenne). Nous considérons donc la fonction \( M(x)=x\); par conséquent
    \begin{equation}
        h(\lambda)=E(X)=\frac{1}{ \lambda }
    \end{equation}
    et \( h^{-1}(\theta)=1/\theta\). L'estimateur que nous considérons pour \( \lambda\) est finalement
    \begin{equation}
        \hat\theta_n=\frac{1}{ \frac{1}{ n }\sum_{i=1}^nX_i }.
    \end{equation}
    
\end{example}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Méthode de substitution}
%---------------------------------------------------------------------------------------------------------------------------

Supposons que nous connaissions un estimateur convergent \( \hat\theta_n\to\theta\). Si \( g\colon \eR^d\to \eR\) est une fonction continue, alors
\begin{equation}
    g(\hat\theta_n)\to g(\theta).
\end{equation}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Méthode du maximum de vraisemblance}
%---------------------------------------------------------------------------------------------------------------------------

\begin{example}     \label{ExVrasMaxLp}
    Nous désirons contrôler la qualité d'une chaîne de production; pour cela nous prélevons un échantillon de \( 10\) pièces, et nous en trouvons \( 3\) défectueuses. Que dire de la proportion de pièces défectueuses ?

    Évidemment, le plus probable est que la proportion de pièces défectueuses soit de \( 1/3\). Analysons en détail comment nous arrivons à ce résultat. Nous considérons que le fait de tirer \( 10\) pièces revient à une expérience binomiale de paramètres \( 10\) et de probabilité \( p\) inconnue. Dans ce cas, la probabilité d'observer exactement \( 3\) pièces défectueuses est de 
    \begin{equation}
        L(p)=P(X=3)={10\choose 3}p^3(1-p)^{7}.
    \end{equation}
    Le maximum de \( L(p)\) est \( p=3/10\).

    % \ref{LabelFigMaxVraissLp}.
    \newcommand{\CaptionFigMaxVraissLp}{La fonction de vraisemblance de l'exemple \ref{ExVrasMaxLp}.}
    \input{Fig_MaxVraissLp.pstricks}
\end{example}

Soit \( (x_1,\ldots,x_n)\), une réalisation de l'échantillon \( (X_1,\ldots,X_n)\). L'application
\begin{equation}
    \theta\mapsto p_n(x_1,\ldots,x_n;\theta)=\prod_{i=1}^np(x_i,\theta)
\end{equation}
est la \defe{vraisemblance}{vraisemblance} de l'échantillon. Nous définissons \( \hat\theta_n\) par
\begin{equation}
    p_n(x_1,\dots,x_n;\hat\theta_n)=\sup_{\theta\in\Theta}p_n(x_1,\ldots,x_n;\theta).
\end{equation}

\begin{remark}
    Nous passons sous le silence le fait que la fonction \( \sup\) soit une fonction mesurable, et que par conséquent \( \hat\theta_n\) soit bien une variable aléatoire.
\end{remark}

La variable aléatoire \( \hat\theta_n=\hat\theta_n(X_1,\ldots,X_n)\) est l'\defe{estimateur de maximum de vraisemblance}{estimateur!maximum de vraisemblance} de \( \theta\).


\Exo{Model-0000}
\Exo{Model-0001}
\Exo{Model-0002}

\Exo{Model-0003}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Qualité des estimateurs}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Soit \( \hat\theta_n\) un estimateur pour \( \theta\). Nous cherchons à minimiser l'erreur commise en remplaçant \( \theta\) par \( \hat\theta_n\). Nous introduisons donc le \defe{risque quadratique}{risque quadratique} de l'estimateur \( \hat\theta_n\) par
\begin{equation}
    R(\hat\theta_n,\theta)=E_{\theta}\big( (\hat\theta_n-\theta)^2 \big).
\end{equation}
Nous disons qu'un estimateur \( \hat\theta_{n,1}\) est préférable à \( \hat\theta_{n,2}\) si pour tout \( \theta\in\Theta\) nous avons
\begin{equation}
    R(\hat\theta_{n,1},\theta)<R(\hat\theta_{n,2},\theta).
\end{equation}

\begin{lemma}
    Une formule alternative pour le risque quadratique :
    \begin{equation}
        R(\hat\theta_n,\theta)=\Var(\hat\theta_n)+\big( E_{\theta}(\hat\theta_n)-\theta \big)^2
    \end{equation}
\end{lemma}

\begin{proof}
    Nous avons
    \begin{equation}
        E_{\theta}\left( (\hat\theta_n-\theta)^2 \right)=\Var(\hat\theta_n-\theta)-E_{\theta}(\hat\theta_n-\theta)^2.
    \end{equation}
    D'une part \( \Var(\hat\theta_n-\theta)=\Var(\hat\theta_n)\) et d'autre part \( E_{\theta}(\hat\theta_n-\theta)^2=\big[ E(\hat\theta_n)-\theta \big]^2\). Par conséquent
    \begin{equation}    \label{EqRisqueetbaisiVar}
        R(\hat\theta_n,\theta)=\Var(\hat\theta_n)-\Big( E(\hat\theta_n)-\theta \Big)^2.
    \end{equation}
\end{proof}

Le \defe{biais}{biais!d'estimateur} de l'estimateur \( \hat\theta_n\) est la quantité
\begin{equation}
    E_{\theta}(\hat\theta_n)-\theta.
\end{equation}

\begin{example}
    La moyenne empirique \( \bar X_n\) est un estimateur sans billet de la moyenne. L'estimateur
    \begin{equation}
        \frac{1}{ n-1 }\sum_{i=1}^n(X_i-\bar X_i)^2
    \end{equation}
    est un estimateur sans billet de la variance.
\end{example}

Un estimateur sans biais n'est pas toujours de meilleur qualité qu'un estimateur sans biais. En effet ce que nous voulons est de se donner un (petit) intervalle  \( I\) autour de la bonne valeur de \( \theta\) et de maximiser \( P(\hat\theta_n\in I)\). Sur la figure \ref{LabelFigBiaisOuPas}, c'est l'estimateur biaisé rouge tombe plus souvent sur le bon intervalle que l'estimateur non biaisé bleu.
\newcommand{\CaptionFigBiaisOuPas}{Un estimateur sans biais et un avec biais.}
\input{Fig_BiaisOuPas.pstricks}

\Exo{Model-0004}

\Exo{Model-0005}
%---------------------------------------------------------------------------------------------------------------------------
\subsection{Espérance et variance d'un estimateur}
%---------------------------------------------------------------------------------------------------------------------------

Soit \( T_n=T_(X_1,\ldots,X_n)\) un estimateur du paramètre \( \theta\) dans un modèle d'échantillonnage. Les moyennes et variances de l'estimateur sont les variables aléatoires
\begin{subequations}
    \begin{align}
        m_{\theta,n}&=E_{\theta}(T_n)=\int_{\eR^n}T_n(x_1,\ldots,x_n)d\mu_{\theta}^{\otimes n}(x1,\ldots,x_n),\\
        \Var_{\theta}(T_n)&=\int_{\eR^n}[T_n(x_1,\ldots,x_n)-m_{\theta,n}]^2d\mu_{\theta}^{\otimes n}(x1,\ldots,x_n),
    \end{align}
\end{subequations}

\begin{lemma}
    Si l'estimateur \( T_n\) satisfait
    \begin{subequations}
        \begin{align}
            \lim_{n\to \infty} E_{\theta}(T_n)&=\theta\\
            \lim_{n\to \infty} \Var_{\theta}(T_n)&=0,
        \end{align}
    \end{subequations}
    alors il est convergent.
\end{lemma}

\begin{proof}
    Nous utilisons l'inégalité de Markov (théorème \ref{ThoInegMarkov}) et nous introduisons l'espérance de l'estimateur :
    \begin{subequations}
        \begin{align}
            P\big( | T_n(X_1,\ldots ,X_n)-\theta |>\epsilon \big)&\leq\frac{1}{ \epsilon }E\big( T_n(X_1,\ldots,X_n)-\theta \big)\\
            &\leq \frac{1}{ \epsilon }E\big( | T_n-m_{n,\theta} | \big)+\frac{1}{ \epsilon }E\big(| m_{n,\theta}-\theta |\big)\\
        \end{align}
    \end{subequations}
    Le second terme est l'espérance d'une constante. Nous majorons le premier terme en utilisant le fait que \( \| . \|_1\leq\| . \|_2\) (voir la remarque \ref{RemNormuptNird} après l'inégalité de Hölder):
    \begin{subequations}
        \begin{align}
            P\big( | T_n(X_1,\ldots ,X_n)-\theta |>\epsilon \big)&\leq \frac{1}{ \epsilon }E\big( | T_n-m_{n,\theta} |^2 \big)^{1/2}+\frac{1}{ \epsilon }| E_{\theta}(T_n)-\theta |\\
            &=\frac{1}{ \epsilon }\Var(T_n)^{1/2}+\frac{1}{ \epsilon }| E_{\theta}(T_n)-\theta |.
        \end{align}
    \end{subequations}
    Les deux termes tendent séparément vers zéro par hypothèse. Nous avons par conséquent la convergence en probabilité \( T_n\to \theta\).
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Estimation par intervalle de confiance}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Nous voudrions estimer la proportion d'individus dans une population ayant un certain caractère déterminé par une variable booléenne : chaque individu a ou non le caractère étudié. L'échantillon sera donc une suite de \( 0\) et de \( 1\).

Pour tout \( i\in\{ 1,\ldots, n \}\) nous notons
\begin{equation}
    x_i=\begin{cases}
        1    &   \text{si le \( i\)ème individu a la caractère}\\
        0    &    \text{sinon}.
    \end{cases}
\end{equation}
et \( \bar x_n=\frac{1}{ n }\sum_{i=1}^n x_i\). Notre modèle statistique sera
\begin{equation}
    \statS=\Big[ (\Omega,\tribF,P),(X_{\theta}),B(1,\theta) \Big]
\end{equation}
où \( \Omega\) est l'ensemble des individus étudiés, \( P\) est la manière de choisir les individus lors du sondage (essentiellement c'est une loi uniforme) et \( X_{\theta}\) est la variable aléatoire
\begin{equation}
    X(\omega)=\begin{cases}
        1    &   \text{si \( \omega\) a le caractère}\\
        0    &    \text{sinon}
    \end{cases}
\end{equation}
Cela est une variable aléatoire de distribution \( \dB(1,p)\) où \( p\) est inconnu. Ici, \( \Theta=\mathopen[ 0 , 1 \mathclose]\) est l'ensemble des \( p\) possibles.

\begin{remark}
    Nous supposons que \( \Omega\) est la population entière et que la variable aléatoire est l'opinion de la personne \( \omega\). En cela, nous considérons que le tirage de l'échantillon est sans remise. Le fait que nous modélisions par une variable aléatoire de Bernoulli signifie que nous considérons l'approximation dans laquelle la population globale est grande.
\end{remark}

Nous supposons que nous ayons un échantillon \( (X_1,\ldots,X_n)\) dont nous avons observé une réalisation \( (x_1,\ldots,x_n)\) de fréquence \( \bar x_n\). Nous voudrions déterminer un intervalle dans lequel \( \bar X_n\) a de fortes chances de se trouver. Plus précisément nous considérons un petit \( \alpha\) et nous cherchons \( \epsilon\) tel que
\begin{equation}
    P\big( p\in\mathopen[ \bar X_n-\epsilon , \bar X_n+\epsilon \mathclose] \big)=1-\alpha.
\end{equation}
Typiquement, \( \alpha=5\%\). Le nombre \( \alpha\) est le \defe{niveau de confiance}{niveau de confiance} que nous nous fixons a priori.

Si nous trouvons un intervalle \( I\) tel que \( P(p\in I)=1-\alpha\), nous disons que l'intervalle est \defe{exact}{exact!intervalle de confiance}, si nous avons \( P(p\in I)\geq 1-\alpha\), nous disons que l'intervalle est \defe{par excès}{excès!intervalle de confiance}.

Il y a deux points de départs pour trouver l'intervalle. Le plus simple est d'utiliser le théorème central limite et considérer
\begin{equation}
    \sqrt{n}\frac{ \bar X_n-p }{ \sqrt{p(1-p)} }\stackrel{\hL}{\longrightarrow}\dN(0,1).
\end{equation}
La seconde est d'utiliser la loi exacte : \( n\bar X_n=\sum_i X_i\sim \dB(n,p)\).

Bien entendu la seconde donne lieu à des calculs plus compliquée.

\begin{remark}
    Dans certaines vraies vies (par exemple en médecine), la taille des échantillons est très réduite. Dans ce cas le théorème central limite n'a aucun sens et les calculs exact s'imposent.
\end{remark}

Dans la suite, nous allons supposer que \( n\) est suffisamment grand pour justifier l'approximation normale. Si \( Z\) est une variable aléatoire normale centrée réduite, nous avons
\begin{subequations}
    \begin{align}
        1-\alpha&=P\big( p\in\mathopen[ \bar X_n-\epsilon , \bar X_n+\epsilon \mathclose] \big) \label{subEqumaleftLthe}\\
        &=P\left( \frac{ -\epsilon\sqrt{n} }{ \sqrt{p(1-p)} }\leq \sqrt{n}\frac{ \bar X_n-p }{ \sqrt{p(1-p)} }\leq \frac{ \epsilon\sqrt{n} }{ \sqrt{p(1-p)} } \right)\\
        &\simeq P\left( -\frac{ \epsilon\sqrt{n} }{ \sqrt{p(1-p)} }\leq Z\leq \frac{ \epsilon\sqrt{n} }{ \sqrt{p(1-p)} } \right)\\
        &=2P\left( Z\leq \frac{ \epsilon\sqrt{n} }{ \sqrt{p(1-p)} } \right)-1.
    \end{align}
\end{subequations}
La dernière ligne utilise la symétrie de la distribution \( \dN(0,1)\). Le nombre \( \epsilon\) que nous cherchons vérifie donc
\begin{equation}
    P\left( Z\leq \frac{ \epsilon\sqrt{n} }{ \sqrt{p(1-p)} } \right)=1-\frac{ \alpha }{2}.
\end{equation}
De nos jours, les ordinateur donnent la loi de répartition inverse des normales. Cela nous fournit un nombre \( t_{\alpha}\) tel que
\begin{equation}    \label{Eqepsnqsrtpptalpah}
    \frac{ \epsilon\sqrt{n} }{ \sqrt{p(1-p)} }=t_{\alpha}
\end{equation}
où \( t_{\alpha}\) est le nombre tel que \( P(Z\leq t_{\alpha})=1-\alpha/2\). Le problème est que nous ne pouvons pas déduire \( \epsilon\) de l'équation \eqref{Eqepsnqsrtpptalpah} parce que \( p\) est inconnu.

L'astuce est évidemment de remplacer \( p\) par \( \bar X_n\), mais il faut le justifier. 

\begin{description}
    \item[Première méthode] 

Une première façon de le justifier est de remarquer que l'événement 
\begin{equation}
    -\frac{ \epsilon\sqrt{n} }{ \sqrt{p(1-p)} }\leq \sqrt{n}\frac{ \bar X_n-p }{ \sqrt{p(1-p)} }\leq \frac{ \epsilon\sqrt{n} }{ \sqrt{p(1-p)} }
\end{equation}
est le même que l'événement
\begin{equation}
    \left| \sqrt{n}\frac{ \bar X_n-p }{ \sqrt{p(1-p)} } \right| \leq t_{\alpha}.
\end{equation}
Vu que \( t_{\alpha}\) est positif, cela est encore le même événement que
\begin{equation}
    n\frac{ (\bar X_n-p)^2 }{ p(1-p) }\leq t_{\alpha}^2
\end{equation}
ou encore
\begin{equation}
    p^2(n+t_{\alpha}^2)-p(2n\bar X_n+t_{\alpha}^2)+n\bar X_n^2\leq 0.
\end{equation}
Les racines du polynôme du membre de gauche sont
\begin{equation}
    p_{\pm}=\frac{ 2n\bar X_n+t_{\alpha}^2\pm\sqrt{ (2n\bar X_n+t_{\alpha})^2-4(n+t_{\alpha}^2)n\bar X_n^2  } }{ 2(n+t_{\alpha}^2) }.
\end{equation}
Le but étant d'effectuer une limite \( n\to\infty\), nous mettons \( n\) en évidence. Après simplification
\begin{equation}
    p_{\pm}=\frac{ \bar X_n+\frac{ t_{\alpha} }{ 2n }\pm t_{\alpha}\sqrt{\frac{ t_{\alpha}^2 }{ 4n^2 }+\frac{ \bar X_n(1-\bar X_n) }{ n }} }{ 1+\frac{ t_{\alpha} }{ n } }.
\end{equation}
Étant donné que nous considérons que \( n\) est grand, nous allons négliger les termes en \( \frac{1}{ n }\) en faisant attention à ce que le terme en $\frac{1}{ n }$ sous la racine est en réalité \( 1/\sqrt{n}\) et ne doit pas être négligé. Nous trouvons, à cette approximation, que
\begin{equation}
    p\in\mathopen\Big[  \bar X_n-t_{\alpha}\sqrt{\frac{ \bar X_n(1-\bar X_n) }{ n }}  , \bar X_n+t_{\alpha}\sqrt{\frac{ \bar X_n(1-\bar X_n) }{ n }} \mathclose\Big]
\end{equation}
avec une probabilité \( 1-\alpha\).

    \item[Seconde méthode]

        Nous pouvons utiliser le lemme de Slutsky. Étant donné le théorème central limite,
        \begin{equation}
            \sqrt{n}\frac{ \bar X_n-p }{ \sqrt{p(1-p)} }\stackrel{\hL}{\longrightarrow}\dN(0,1)
        \end{equation}
        et par la loi des grands nombres,
        \begin{equation}
            \bar X_n(1-\bar X_n)\stackrel{p.s.}{\longrightarrow}p(1-p).
        \end{equation}
        Par conséquent le lemme de Slutsky implique la convergence en loi du couple. En appliquant maintenant la proposition \ref{PropcvLsousfonc} avec la fonction 
        \begin{equation}
            h(x,y)=\frac{ x\sqrt{p(1-p)} }{ y },
        \end{equation}
        nous trouvons que
        \begin{equation}
            \sqrt{n}\frac{ \bar X_n-p }{ \sqrt{\bar X_n(1-\bar X_n)} }\stackrel{\hL}{\longrightarrow}\dN(0,1).
        \end{equation}
        Nous pouvons alors écrire, à la place de la formule \eqref{subEqumaleftLthe}:
        \begin{equation}
            1-\alpha=P\left( \frac{ -\sqrt{n}\epsilon }{ \sqrt{\bar X_n(1-\bar X_n)} }\leq \sqrt{n}\frac{ \bar X_n-p }{ \sqrt{\bar X_n(1-\bar X_n)} }\leq \frac{ \epsilon\sqrt{n} }{ \sqrt{\bar X_n(1-\bar X_n)} } \right);
        \end{equation}
        en continuant le calcul de la même façon, nous trouvons à la place de \eqref{Eqepsnqsrtpptalpah} la relation
        \begin{equation}
            t_{\alpha}=\frac{ \epsilon\sqrt{n} }{ \sqrt{\bar X_n(1-\bar X_n)} }.
        \end{equation}

\end{description}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Région de confiance}
%---------------------------------------------------------------------------------------------------------------------------

Soit un \( n\)-échantillon \( (X_1,\ldots,X_n)\) de loi parente \( \mu_{\theta}\). Nous supposons \( \Theta\subset\eR\) avec \( \Theta\) ouvert. Soit \( \alpha\in\mathopen[ 0 , 1 \mathclose]\) un intervalle de confiance et une application mesurable
\begin{equation}
    \begin{aligned}
        \Lambda\colon \eR^n&\to \Borelien(\Theta) \\
        (x_1,\ldots,x_n)&\mapsto \Lambda(x_1,\ldots,x_n).
    \end{aligned}
\end{equation}
On appelle \defe{région de confiance exact}{région de confiance exact} au niveau de confiance \( 1-\alpha\) une région aléatoire \( \Lambda(x_1,\ldots,x_n)\) telle que
\begin{equation}
    P\big( \theta\in\Lambda(x_1,\ldots,x_n) \big)=1-\alpha.
\end{equation}
Si \( d=1\), la région \( \Lambda(x_1,\ldots,x_n)\) est un intervalle.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Fonction pivotale}
%---------------------------------------------------------------------------------------------------------------------------

Soit \( \hat\theta_n\), un estimateur de \( \theta\). Une fonction \( v\) sur \( \Theta\times\Theta\) est \defe{pivotale}{pivotale} pour \( \theta\) si la loi de la variable aléatoire \( v(\hat\theta_n,\theta)\) ne dépend pas de \( \theta\). Elle est \defe{asymptotiquement pivotale}{asymptotiquement pivotale} si
\begin{equation}
    v(\hat\theta_n,\theta)\stackrel{\hL}{\longrightarrow}\xi
\end{equation}
où \( \xi\) est une variable aléatoire indépendante de \( \theta\).

En pratique, nous essayons de faire apparaître une variable aléatoire de loi connue qui ne dépend pas du paramètre que l'on recherche. Si la variance est connue et si l'échantillon est grand, le théorème central limite nous permet d'introduire une loi normale centrée réduite.

\begin{example}
    Soit \( X_1,\ldots,X_n\) des variables aléatoires de loi parente \( \dN(m,\sigma^2)\). Une fonction asymptotiquement pivotale pour \( m\) est
    \begin{equation}
        v(z_1,z_2)=\frac{ z_1-z_2 }{ \sigma/\sqrt{n} }
    \end{equation}
    parce que la variable aléatoire
    \begin{equation}
        v(\bar X_n,m)=\frac{ \bar X_n-m }{ \alpha/\sqrt{n} }
    \end{equation}
    tend vers \( \dN(0,1)\) qui ne dépend pas de \( m\).
\end{example}

\begin{example}
    Si \( (X_n)\) est une suite de variables aléatoires indépendantes et identiquement distribuées de moyenne \( m\) et d'écart type \( \sigma\) que nous supposons inconnus. Le fonction suivante est asymptotiquement pivotale pour \( m\) :
    \begin{equation}
        v(\bar X_n,m)=\frac{ \bar X_n-m }{ \sigma/\sqrt{n} }.
    \end{equation}
\end{example}

Soit \( (X_1,\ldots,X_n)\) un échantillon de loi \( \dN(m,\sigma_0^2)\) avec \( \sigma_0^2\) connu. Nous cherchons un intervalle de confiance \( 1-\alpha\) pour \( m\). Pour cela nous allons utiliser une fonction asymptotiquement pivotale, à savoir
\begin{equation}
    \frac{ \bar X_n-m }{ \sigma_0^2/\sqrt{n} }\sim\dN(0,1).
\end{equation}
Nous devrions chercher des valeurs \( z_+\) de \( z_-\) telles que
\begin{equation}
    P\left( z_-\leq \frac{ \bar X_n-m }{ \sigma_0/\sqrt{n} }\leq z_+ \right)=1-\alpha.
\end{equation}
Pour des raisons de symétries (de la courbe gaussienne), nous allons chercher un intervalle symétrique : \( z_-=-z_+\). Le nombre à chercher est donc le \( z_{\alpha}\) tel que 
\begin{equation}
    P\big( | Z |\leq z_{\alpha} \big)=1-\alpha.
\end{equation}
Si nous demandons \( \alpha=5\%\), la réponse est \( z_{\alpha}=1.96\), c'est à dire que
\begin{equation}
    P\left( -1.96\leq \frac{ \bar X_n-m }{ \sigma/\sqrt{n} }\leq 1.96 \right)=0.95.
\end{equation}
Nous avons donc
\begin{equation}
    P\left( m\in\big[ \bar X_n-\frac{ 1.96\sigma }{ \sqrt{n} },\bar X_n+\frac{ 1.96\sigma }{ \sqrt{n} } \big] \right)=0.95.
\end{equation}

Supposons maintenant que nous avons observé \( 100\) valeurs numériques avec \( \bar x_n=12\) et \( \sigma=1\). La réalisation de l'intervalle de confiance pour \( m\) au niveau de confiance \( 0.95\) est :
\begin{equation}
    \big[ 12-0.196,12+0.196 \big].
\end{equation}
Cet intervalle est à interpréter de la façon suivante : si nous recommençons un grand nombre de fois le sondage, la moyenne tombera \( 95\%\) des fois dans l'intervalle ainsi calculé. Mais il faut bien comprendre que la probabilité
\begin{equation}
    P\left( m\in\big[ 12-0.196,12+0.196 \big] \right)
\end{equation}
vaut zéro ou un.

\Exo{Model-0006}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Sondage de proportion}
%---------------------------------------------------------------------------------------------------------------------------

Une utilisation classique des statistiques est d'interpréter une proportion donnée par un sondage. Nous considérons une élection avec deux candidats \( A\) et \( B\). Nous avons interrogés \( n=2500\) personnes et nous avons obtenus \( 51\%\) pour le candidat \( A\) et \( 49\%\) pour le candidat \( B\). Que peut on dire ?

La modélisation de cette situation est que nous avons des variables aléatoires \( X_i\sim\dB(p_A)\) et que nous en avons observés \( n\) avec une moyenne
\begin{equation}
    \bar x_n=0.51.
\end{equation}
La loi de \( \bar X_n\) est une binomiale. Sa densité n'est pas symétrique, mais si \( n\) est grand, elle le devient. Nous cherchons un intervalle 
\begin{equation}
    I=[\bar X_n-\epsilon,\bar X_n+\epsilon]
\end{equation}
tel que \( P(p_A\in I)=1-\alpha\). Pour cela nous considérons le fait que \( n=2500\) est grand et nous utilisons la limite de la proposition \ref{PropLimxBNpxbxbsqrt} :
\begin{equation}
    Z_n=\sqrt{n}\frac{ \bar X_n-p_A }{ \sqrt{\bar X_n(1-\bar X_n)} }\stackrel{\hL}{\longrightarrow}Z\sim\dN(0,1).
\end{equation}
La variable aléatoire \( Z_n\) est asymptotiquement pivotale et normale centrée réduite. Nous cherchons donc un intervalle symétrique pour \( \bar X_n-p_A\) :
\begin{equation}
    1-\alpha=P(-\epsilon\leq \bar X_n-p_A\leq \epsilon),
\end{equation}
c'est à dire, si \( n\) est grand, 
\begin{equation}
    1-\alpha=P\left( -\epsilon\frac{ \sqrt{n} }{ \sqrt{\bar X_n(1-\bar X_n)} }\leq Z_n\leq\epsilon\frac{ \sqrt{n} }{ \sqrt{\bar X_n(1-\bar X_n)} } \right)
\end{equation}
où \( Z_n\) est une normale centrée réduite. Nous trouvons ainsi, via les tables que
\begin{equation}
    \frac{ \epsilon\sqrt{n} }{ \sqrt{\bar X_n(1-\bar X_n)} }=1.96
\end{equation}
si nous voulons un intervalle à \( 5\%\). Par conséquent nous avons \( \epsilon=1.96\frac{ \sqrt{\bar X_n(1-\bar X_n)} }{ \sqrt{nj} }\) et l'intervalle de confiance est 
\begin{equation}
    I_C=\left[ \bar X_n-\frac{ 1.96\sqrt{\bar X_n(1-\bar X_n)} }{ \sqrt{n} },\bar X_n+\frac{ 2.96\sqrt{\bar X_n(1-\bar X_n)} }{ \sqrt{n} } \right].
\end{equation}
La propriété de cet intervalle est que
\begin{equation}
    \lim_{n\to \infty} P(p_A\in I_c)=1-\alpha.
\end{equation}

\begin{remark}
    À quel moment avons nous fait une hypothèse sur la taille de la population globale ? En modélisant les sondés par des variables de Bernoulli et leur somme par une binomiale, nous supposons que le sondage est \emph{avec remise}, sinon, elles ne seraient pas indépendantes. En supposant les sondés indépendants, nous avons donc fait comme si la population totale était infinie.
\end{remark}
