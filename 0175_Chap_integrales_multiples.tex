% This is part of Mes notes de mathématique
% Copyright (c) 2011-2013
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Différentiabilité sous l'intégrale}
%---------------------------------------------------------------------------------------------------------------------------

Le gros des résultats sur les fonctions définies par des intégrales est dans la section \ref{SecCHwnBDj}.

Le théorème suivant est restrictif sur l'ensemble d'intégration (qui doit être compact), mais accepte des fonctions de plusieurs variables, ce qui est un premier pas vers la différentiabilité.
\begin{proposition}		\label{PropDerrSSIntegraleDSD}
    Supposons $A\subset\eR^m$ ouvert et $B\subset\eR^n$ compact. Nous considérons une fonction \( f\colon A\times B\to \eR\). Si pour un $i\in\{ i,\ldots,n \}$, la dérivée partielle $\frac{ \partial f }{ \partial x_i }$ existe dans $A\times B$ et est continue, alors la fonction
    \begin{equation}
        F(x)=\int_Bf(x,t)dt
    \end{equation}
    admet une dérivée partielle dans la direction \( x_i\) sur \( A\). Cette dérivée partielle y est continue et
    \begin{equation}
        \frac{ \partial F }{ \partial x_i }(a)=\int_B\frac{ \partial f }{ \partial x_i }(a,t)dt,
    \end{equation}
    pour tout \( a\) dans l'ouvert \( A\).
\end{proposition}
\index{fonction!définie par une intégrale}
\index{inversion de limite}
L'égalité signifie que l'on peut \og dériver sous le signe intégral\fg.

\begin{proof}
    Nous procédons en plusieurs étapes.
    \begin{subproof}
    \item[\( F\) est dérivable]
            
        Nous voulons prouver que \( \frac{ \partial F }{ \partial x_i }(a,t)\) existe. Pour cela nous posons
        \begin{equation}
            g_l(t)=\frac{ f(a_1,\ldots, a_i+\epsilon_l,\ldots, a_n,t)-f(a_1,\ldots, a_k,\ldots, a_n,t) }{ \epsilon_l }
        \end{equation}
        où \( \epsilon_l\) est une suite de nombres tendant vers zéro. La fonction \( f\) est dérivable dans la direction \( x_i\) si et seulement si \( \lim_{l\to \infty}g_l(t) \) existe et ne dépend pas du choix de la suite. À ce moment, la valeur de la dérivée partielle sera cette limite. Dans notre cas, nous savons que \( f\) admet une dérivée partielle dans la direction \( x_i\) et donc nous avons
        \begin{equation}
            \frac{ \partial f }{ \partial x_i }(a,t)=\lim_{l\to \infty} g_l(t).
        \end{equation}
        
        De la même façon pour \( F\) nous avons
        \begin{equation}
            \frac{ \partial F }{ \partial x_i }=\lim_{l\to \infty} \int_{B}g_l(t)dt.
        \end{equation}
        Sous-entendu : si la limite de droite ne dépend pas de la suite choisie, alors \( \frac{ \partial F }{ \partial x_i }\) existe et vaut cette limite.

        Vu la continuité de \( f\), le seul point à vérifier pour le théorème de la convergence dominée de Lebesgue est l'existence d'une fonction intégrable de \( t\) majorant \( g_l\). Pour cela le théorème de accroissements finis (théorème \ref{ThoAccFinisUneVariable}) appliqué à la fonction \( \epsilon\mapsto f(a_n,\ldots, a_i+\epsilon,\ldots, a_n)\) nous dit que
        \begin{equation}
            f(a_1,\ldots, a_i+\epsilon_l,\ldots, a_n,t)-f(a_1,\ldots, a_i,\ldots, a_n,t)=\epsilon_l\frac{ \partial f }{ \partial x_i }(a_1,\ldots, \theta,\ldots, a_n,t)
        \end{equation}
        pour un certain \( \theta\in B(a_i,\epsilon_l)\). Notons que ce \( \theta\) dépend de \( t\) mais pas de \( l\). Vu que \( \partial_if\) est continue par rapport à ses deux variables, si \( K\) est un voisinage compact autour de \( a\), il existe \( M>0\) tel que
        \begin{equation}    \label{EqMXqviPC}
            \left| \frac{ \partial f }{ \partial x_i }(x,t) \right| < M
        \end{equation}
        pour tout \( x\in K\) et tout \( t\in B\). La valeur de \( \frac{ \partial f }{ \partial x_i }(a_1,\ldots, \theta,\ldots, a_n,t)\) est donc bien majorée par rapport à \( \theta\) et par rapport à \( t\) en même temps par une constante qui n'a pas de mal à être intégrée sur le compact \( B\).
        
        Le théorème de la convergence dominée (théorème \ref{ThoConvDomLebVdhsTf}) s'applique donc bien et nous avons
        \begin{equation}
            \lim_{l\to \infty} \int_Bg_l(t)dt=\int_B\lim_{l\to \infty} g_l(t)=\int_B\frac{ \partial f }{ \partial x_i }(a,t)dt.
        \end{equation}
        Le membre de droite ne dépendant pas de la suite \( \epsilon_l\) choisie, le membre de gauche est bien la dérivée de \( F\) par rapport à \( x_i\) et nous avons
        \begin{equation}
            \frac{ \partial F }{ \partial x_i }(a)=\int_B\frac{ \partial f }{ \partial x_i }(a,t)dt.
        \end{equation}
        Cela prouve la première partie de la proposition.

    \item[La dérivée est continue]

        Soit \( K\) un voisinage compact autour de \( a\) et \( U'\) un ouvert tel que \( a\in U'\subset K\). Nous avons encore la majoration \eqref{EqMXqviPC} sur \( U'\) et donc le théorème de continuité sous l'intégrale \ref{ThoKnuSNd} nous indique que la fonction
        \begin{equation}
            \begin{aligned}
                U'&\to \eR \\
                x&\mapsto \int_{B}\frac{ \partial f }{ \partial x_i }(x,t)dt 
            \end{aligned}
        \end{equation}
        est continue en \( a\).
        
    \end{subproof}
\end{proof}

Une conséquence de la proposition \ref{PropDerrSSIntegraleDSD} est que si elle fonctionne pour tous les \( i\), alors \( F\) est différentiable et même de classe \( C^1\), et la différentielle de \( F\) s'obtient comme intégrale de la différentielle de \( f\).

\begin{proposition}\label{PropAOZkDsh}
    Supposons $A\subset\eR^m$ ouvert et $B\subset\eR^n$ compact. Si pour tout $i\in\{ i,\ldots,n \}$, la dérivée partielle $\frac{ \partial f }{ \partial x_i }$ existe dans $A\times B$ et est continue, alors \( F\) est de classe \( C^1\) et
    \begin{equation}
        (dF)_a=\int_B(df_t)_adt
    \end{equation}
    où \( f_t(x)=f(x,t)\).
\end{proposition}

\begin{proof}
    En vertu de la proposition \ref{PropDerrSSIntegraleDSD}, toutes les dérivées partielles de \( F\) sont continues. Cela implique que \( F\) est de classe \( C^1\) par la proposition \ref{PropDerContCun} et que la différentielle s'écrive en terme des dérivées partielles avec la formule usuelle. Nous avons alors
    \begin{subequations}
        \begin{align}
            (dF)_a(u)&=\sum_k\frac{ \partial F }{ \partial x_k }(a)u_k\\
            &=\int_B\sum_k\frac{ \partial f }{ \partial x_k }(a,t)dt\\
            &=\int_B\sum_k\frac{ \partial f_t }{ \partial x_k }(a)u_kdt\\
            &=\int_B (df_t)_a(u)dt.
        \end{align}
    \end{subequations}
    Cela est la formule annoncée.
\end{proof}

Un autre théorème tourne autour du pot, et me semble inutile.
\begin{theorem} \label{ThoOLAQyRL}
    Soit \( (\Omega,\mu)\) un espace mesuré, une fonction \( f\colon \eR^n\times \Omega\to \eR\) et \( a\in \eR^n\). Nous considérons la fonction
    \begin{equation}
        F(x)=\int_{\Omega}f(x,\omega)d\mu(\omega).
    \end{equation}
    Pour chaque \( k=1,\ldots, n\) nous supposons avoir
    \begin{equation}
        \frac{ \partial F }{ \partial x_k }(a)=F_{|_k}'(a)=\int_{\Omega}\frac{ \partial f_{|_k} }{ \partial t }(a_k,\omega)d\mu(\omega)
    \end{equation}
    où \( F_{|_k}(t)=F(a_1,\ldots, t,\ldots, a_n)\) et \( f_{|_k}\) est définie de façon similaire.

    Nous supposons de plus que les fonctions \( \partial_{x_k}F\) sont continues.

    Alors \( F\) est de classe \( C^1\) et sa différentielle est donnée par
    \begin{equation}
        df_a=\int_{\Omega}(df_{\omega})_ad\omega
    \end{equation}
    où \( f_{\omega}\) est définie par \( f_{\omega}(x)=f(x,\omega)\).
\end{theorem}

\begin{proof}
    Étant donné que les dérivées partielles de \( F\) en \( a\) existent et sont continues, la proposition \ref{PropDerContCun} dit que \( F\) est différentiable et que
    \begin{equation}
        dF_a(u)=\sum_{k=1}^n\frac{ \partial F }{ \partial x_k }(a)u_k.
    \end{equation}
    La linéarité de l'intégrale et les hypothèses nous donnent alors
    \begin{subequations}
        \begin{align}
            df_a(u)&=\sum_{k=1}^n\frac{ \partial F }{ \partial x_k }(a)u_k\\
            &=\int_{\Omega}\sum_k\frac{ \partial f_{|_k} }{ \partial t }(a_k;\omega)u_kd\mu(\omega)\\
            &=\int_{\Omega}\sum_k\frac{ \partial f }{ \partial x_k }(a;\omega)u_kd\mu(\omega)\\
            &=\int_{\Omega}(df_{\omega})_a(u)d\mu(\omega),
        \end{align}
    \end{subequations}
    et donc \( df_a=\int_{\Omega}(df_{\omega})_ad\mu(\omega)\).
\end{proof}
Notons qu'en passant aux composantes, ce théorème fonctionne tout aussi bien pour des fonctions à valeurs dans un espace vectoriel normé de dimension finie plutôt que dans \( \eR\).

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Forme différentielle et intégrale sur un chemin}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\label{SecFormDiffRappel}

Une \defe{forme}{forme} sur un espace vectoriel $V$ est une application linéaire $\omega\colon V\to \eR$. Si $D$ est un ouvert dans $\eR^n$, une \defe{forme différentielle}{forme!différentielle} sur $D$ est une application $\omega\colon D\to (\eR^n)^*$, c'est à dire, en chaque point $x\in D$, une forme $\omega_x\colon \eR^n\to \eR$.

Un exemple type de forme différentielle est la différentielle d'une fonction $f\colon D\to \eR$. En effet, la différentielle d'une telle fonction est l'application linéaire
\begin{equation}
    \begin{aligned}
        df\colon \eR^n&\to \eR \\
        v&\mapsto \frac{ \partial f }{ \partial x }v_x+\frac{ \partial f }{ \partial y }v_y. 
    \end{aligned}
\end{equation}
La forme différentielle $\omega$ est \defe{exacte}{forme!différentielle!exacte} si il existe une fonction $f$ telle que $\omega=df$; elle est dite \defe{fermée}{forme!différentielle!fermée} si $d\omega=0$.

Soit $D\subset\eR^n$. Par définition de la différentielle d'une $1$-forme, nous avons une formule de Leibnitz
\begin{equation}
    d(f\omega)=df\wedge\omega+fd\omega.
\end{equation}
En particulier,
\begin{equation}
    d(fdx)=df\wedge dx+f\underbrace{d(dx)}_{=0}=\frac{ \partial f }{ \partial x }dx\underbrace{dx\wedge dx}_{=0}+\frac{ \partial f }{ \partial y }dy\wedge dx. S
\end{equation}
Une forme différentielle $\omega$ continue de degré $1$ sur $D$ est \defe{exacte}{forme!différentielle!exacte} si il existe $F\colon D\to \eR$ telle que $\omega=dF$. On dit que la forme est \defe{fermée}{forme!différentielle!fermée} si $d\omega=0$. Dire que la forme différentielle $\omega=fdx+gdy$ est fermée, c'est dire que
\begin{equation}
    \frac{ \partial g }{ \partial x }=\frac{ \partial f }{ \partial y }.
\end{equation}

Si $F\colon \eR^2\to \eR$ est une fonction $C^2$, sa différentielle est la forme
\begin{equation}
    dF=\frac{ \partial F }{ \partial x }dx+\frac{ \partial F }{ \partial y }dy.
\end{equation}
Si nous nommons $f$ et $g$ les fonctions $\partial_xF$ et $\partial_yF$, nous avons donc
\begin{equation}
    Df=fdx+gdy,
\end{equation}
qui vérifie
\begin{equation}
    \partial_yf=\partial_xg,
\end{equation}
parce que $\frac{ \partial f }{ \partial y }=\frac{ \partial^2F  }{ \partial x\partial y }=\frac{ \partial^2F  }{ \partial y\partial x }=\frac{ \partial g }{ \partial x }$. Ce que nous avons donc prouvé, c'est que 
\begin{lemma}
Si $fdx+gdy$ est la différentielle d'une fonction de classe $C^2$, alors $\partial_yf=\partial_xg$.
\end{lemma}

\begin{theorem}        \label{ThoFermeExactFormRappel}
Supposons que $D\subset\eR^n$ soit un ouvert simplement connexe. Alors toute forme différentielle de degré $1$ et de classe $C^1$ sur $D$ qui est fermée est exacte.
\end{theorem}

Nous allons prouver ce théorème dans un cas un peu moins général : celui d'un domaine étoilé de \( \eR^2\) plutôt que simplement connexe de \( \eR^n\).

\begin{theorem} \label{ThoMSofFxL}
Soit $D\subset\eR^2$, une ouvert étoilé, et $\omega$, une $1$-forme fermée de classe $C^1$. Alors $\omega$ est exacte.
\end{theorem}
\begin{proof}

Soit $D\subset\eR^2$, un ouvert étoilé par rapport à l'origine. Soient $f\colon D\to \eR$, $g\colon D\to \eR$, des fonctions de classe $C^1$ telles que
\begin{equation}
	\frac{ \partial f }{ \partial y }=\frac{ \partial g }{ \partial x }
\end{equation}
sur $D$, et
\begin{equation}		\label{EqIMDefFformI33}
	F(x,y)=\int_0^1\big[  f(tx,ty)x+g(tx,ty)y  \big]dt
\end{equation}
pour tout $(x,y)\in D$. 

Étant donné que nous ne définissons $F(x,y)$ que pour des $(x,y)\in D$, la fonction $t\mapsto f(tx,ty)$ est $C^1$ sur tout le compact $[0,1]$ et aucune divergence de l'intégrale n'est à craindre. Nous sommes donc dans le cadre de la proposition \ref{PropDerrSSIntegraleDSD}, et nous pouvons dériver sous le signe intégral.

Nous calculons, en utilisant la règle de dérivation de fonctions composées
\begin{equation}		\label{EqIMI33dsdsFlolo}
	\begin{aligned}[]
		\frac{ \partial F }{ \partial x }(x,t)	&=\int_0^1\left[   f\frac{ \partial f }{ \partial x }(tx,ty)x+f(tx,ty)+t\frac{ \partial g }{ \partial x }(tx,ty)y  \right]dt\\
		&=\int_0^1\left[ t\Big( x\frac{ \partial f }{ \partial x }(tx,ty)+y\frac{ \partial f }{ \partial y }(tx,ty) \Big)+f(tx,ty) \right]dt
	\end{aligned}
\end{equation}
où nous avons utilisé l'hypothèse $\partial_yf=\partial_xg$. Ce qui se trouve dans la parenthèse n'est autre que $\partial_t\big( f(tx,ty) \big)$, plus précisément, si nous posons $\mF(x,y,t)=f(tx,ty)$, nous avons
\begin{equation}
	\frac{ \partial \mF }{ \partial t }(x,y,t)= x\frac{ \partial f }{ \partial x }(tx,ty)+y\frac{ \partial f }{ \partial y }(tx,ty).
\end{equation}
En recopiant le résultat \eqref{EqIMI33dsdsFlolo} en termes de $\mF$, nous avons
\begin{equation}
	\begin{aligned}[]
		\frac{ \partial F }{ \partial x }(x,t)	&=\int_0^1\left( t\frac{ \partial \mF }{ \partial t }(x,y,t)+\mF(x,y,t) \right)dt\\
		&=\int_0^1\partial_t\big( t\mF(x,y,t) \big)dt\\
		&=\big[ f\mF(x,y,t) \big]_0^1\\
		&=\mF(x,y,1)\\
		&=f(x,y).
	\end{aligned}
\end{equation}
Le résultat correspondant pour $\frac{ \partial F }{ \partial y }(x,y)=g(x,y)$ s'obtient de la même manière. Nous avons donc obtenu que
\begin{equation}		\label{EqIMFormI33Fffdd}
	\begin{aligned}[]
		\frac{ \partial F }{ \partial x }&=f,  &\text{et}&& \frac{ \partial F }{ \partial y }=g.
	\end{aligned}
\end{equation}
En ayant prouvé cela, nous avons prouvé que si $\omega=fdx+gdy$ avec $\partial_yf=\partial_xg$, alors $\omega=dF$ où $F$ est définie par \eqref{EqIMDefFformI33}.
\end{proof}

\begin{proof}[Démonstration alternative du théorème \ref{ThoMSofFxL}]
Nous posons $u=tx$ et $v=ty$, ainsi que $\mF(x,y,t)=f(u,v)$ et $\mG(x,y,t)=g(u,v)$. Avec cette notation, nous avons $F(x,y)=\int_0^1\big( x\mF(x,y,t)+y\mG(x,y,t) \big)dt$, et
\begin{equation}
	\begin{aligned}[]
		\frac{ \partial \mF }{ \partial x }&=\frac{ \partial f }{ \partial u }\frac{ \partial u }{ \partial x }+\frac{ \partial f }{ \partial v }\frac{ \partial v }{ \partial x }=t\frac{ \partial f }{ \partial u },\\
		\frac{ \partial \mG }{ \partial x }&=t\frac{ \partial g }{ \partial u }.
	\end{aligned}
\end{equation}
Ainsi,
\begin{equation}
	\begin{aligned}[]
		\frac{ \partial F }{ \partial x }	&=\int_0^1\left( x\frac{ \partial \mF }{ \partial x }+\mF+y\frac{ \partial G }{ \partial x } \right)dt\\
							&=\int_0^1\left( xt\frac{ \partial f }{ \partial u } +\mF+yt\frac{ \partial g }{ \partial u } \right)dt\\
							&=\int_0^1\left[  t\left( x\frac{ \partial f }{ \partial u }+y\frac{ \partial f }{ \partial v } \right)+\mF  \right]dt.
	\end{aligned}
\end{equation}
où nous avons utilisé le fait que, par hypothèse, $\frac{ \partial g }{ \partial u }=\frac{ \partial f }{ \partial v }$. Nous calculons par ailleurs que
\begin{equation}
	\frac{ \partial F }{ \partial t }=\frac{ \partial f }{ \partial u }\frac{ \partial u }{ \partial t }+\frac{ \partial f }{ \partial v }\frac{ \partial v }{ \partial t }=x\frac{ \partial f }{ \partial u }+y\frac{ \partial f }{ \partial v }.
\end{equation}
Donc, nous avons
\begin{equation}
	\frac{ \partial F }{ \partial x }=\int_0^1\left( t\frac{ \partial \mF }{ \partial t }+\mF \right)dt=\int_0^1\frac{ \partial  }{ \partial t }(t\mF)dt.
\end{equation}
Par conséquent,
\begin{equation}
	\frac{ \partial F }{ \partial x }=[t\mF]_0^1=\mF(x,y,1)=f(x,y).
\end{equation}
Le même genre de calculs fournit $\frac{ \partial F }{ \partial y }=g(x,y)$.
\end{proof}
    
%---------------------------------------------------------------------------------------------------------------------------
\subsection{Forme différentielle}
%---------------------------------------------------------------------------------------------------------------------------

La formule d'intégration d'un champ de vecteur,
\begin{equation}
	\int_{\gamma}G=\int_{[a,b]}\langle G (\gamma(t)), \gamma'(t)\rangle dt,
\end{equation}
contient quelque chose d'intéressant : la combinaison $\langle G( \gamma(t) ), \gamma'(t)\rangle$. Cette combinaison sert à transformer le vecteur tangent $\gamma'(t)$ en un nombre en utilisant le produit scalaire avec le vecteur $G( \gamma(t) )$.

Si $G$ est un champ de vecteur sur $\eR^n$, et si $x\in\eR^n$, nous pouvons considérer, de façon un peu plus abstraite, l'application
\begin{equation}		\label{EqDefBemol}
	\begin{aligned}[]
		G^{\flat}_x\colon \eR^n&\to \eR \\
			v&\mapsto \langle G(x), v\rangle . 
	\end{aligned}
\end{equation}
Cela permet de compactifier la notation et écrire
\begin{equation}
	\int_{\gamma}G=\int_{[a,b]} G^{\flat}_{\gamma(t)}\big( \gamma'(t)\big) dt.
\end{equation}

Nous nous proposons maintenant d'étudier plus en détail ce qu'est l'objet $G^{\flat}$. La règle \eqref{EqDefBemol} dit que pour chaque $x$, l'application $G_x^{\flat}$ est une forme sur $\eR^n$, c'est à dire une application linéaire de $\eR^n$ vers $\eR$. Nous écrivons que
\begin{equation}
	G_x^{\flat}\in\big( \eR^n \big)^*.
\end{equation}
Nous connaissons la \defe{base duale}{base!duale} de $(\eR^n)^*$, ce sont les formes $e^*_i$ définies par $e^*_i(e_j)=\delta_{ij}$. Dans le cadre du cours d'analyse, nous allons noter ces formes\footnote{Parce que ce sont les différentielles des fonctions (projections)
\begin{equation}
	\begin{aligned}
			x_i\colon \eR^n&\to \eR \\
			x&\mapsto x_i 
		\end{aligned}
	\end{equation}
}
par $dx_i$ :
\begin{equation}
	\begin{aligned}[]
		e^*_1&=dx_1\colon v\mapsto v_1	\\
			&\vdots			\\
		e^*_n&=dx_n\colon v\mapsto v_n
	\end{aligned}
\end{equation}
Étant donné que ces $dx_i$ forment une base de l'espace vectoriel $(\eR^n)^*$, toute application linéaire $L\colon \eR^n\to \eR$ s'écrit
\begin{equation}
	\begin{aligned}[]
		Lv&=a_1v_1+\ldots+a_nv_n\\
			&=a_1dx_1(v)+\ldots+a_ndx_n(v).
	\end{aligned}
\end{equation}
Plus abstraitement, nous notons
\begin{equation}
	\begin{aligned}[]
		L&=a_1dx_1+\ldots+a_ndx_n\\
		&=\sum_{i=1}^na_idx_i.
	\end{aligned}
\end{equation}
L'application $L$ est une combinaison linéaire des $dx_i$ au sens de l'espace vectoriel $(\eR^n)^*$.

L'objet $G^{\flat}$ est la donnée, en chaque point de $D$, d'une telle forme sur $\eR^n$. Nous donnons alors la définition suivante.
\begin{definition}
	Soit $D$, un domaine dans $\eR^n$. Une $1$-\defe{forme différentielle}{forme!différentielle} $\omega$ sur $D$ est une application
	\begin{equation}
		\begin{aligned}
				\omega\colon D&\to (\eR^n)^* \\
				x&\mapsto \omega_x. 
			\end{aligned}
		\end{equation}
\end{definition}
Étant donné que $\{ dx_i \}$ est une base de $(\eR^n)^*$, pour chaque $x\in D$, il existe des uniques réels $a_i(x)$ tels que
\begin{equation}
	\omega_x=a_1(x)dx_1+\ldots+a_n(x)dx_n.
\end{equation}
Nous disons qu'une $1$-forme différentielle est \defe{continue}{continue!forme différentielle} si les fonctions $a_i$ sont continues. La forme sera $C^k$ quand les $a_i$ seront $C^k$.

\begin{remark}
	L'ensemble des $1$-formes différentielles forment un espace vectoriel avec les définitions
	\begin{equation}
		\begin{aligned}[]
			(\lambda\omega)_x(v)&=\lambda\omega_x(v)\\
			(\omega+\mu)_x(v)&=\omega_x(v)+\mu_x(v).
		\end{aligned}
	\end{equation}
\end{remark}

Lorsque une $1$-forme différentielle s'écrit toujours sous la forme
\begin{equation}
	\omega=\sum_i a_idx_i
\end{equation}
pour certaines fonctions $a_i$. Évidemment, ces fonctions $a_i$ peuvent être trouvées en appliquant $\omega$ aux éléments de la base canonique de $\eR^n$ :
\begin{equation}
	a_j(x)=\omega_x(e_j)
\end{equation}
parce que $\omega_x(e_j)=\sum_ia_i(x)dx_i(e_i)=\sum_ia_i(x)\delta_{ij}=a_j(x)$.

Nous pouvons ainsi déterminer le développement de $G^{\flat}$ dans la base des $dx_i$ en faisant le calcul
\begin{equation}
	G_x^{\flat}(e_i)=\langle G(x), e_i\rangle =G_i(x),
\end{equation}
donc les composantes de $G^{\flat}$ dans la base $dx_i$ sont exactement les composantes de $G$ dans la base $e_i$ :
\begin{equation}
	G^{\flat}_x=G_1(x)dx_1+\ldots+G_n(x)dx_n.
\end{equation}


%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Une petite note pour titiller monsieur Jean Doyen}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Pensons pendant quelque minutes aux fonctions de $\eR$ dans $\eR$. Monsieur Jean Doyen dit toujours que quand le sage demande la fonction $f$, le simple dit \og $f(x)$\fg. Or $f(x)$ n'est pas une fonction; c'est $f$, la fonction. En poussant un petit peu nous pouvons prétendre que $x$ désigne la fonction identité qui à chaque $x$ fait correspondre $x$ lui-même. Il est d'ailleurs un peu normal de désigner comme ça cette fonction. Dans ce cas, $f(x)$ désigne la fonction composée de la fonction $f$ avec la fonction $x$, et tout le monde est content\footnote{J'offre un pot à qui ose écrire que $f(x)$ est bien la \emph{fonction} composée de $f$ avec $x$ sur sa feuille d'examen du cours d'algèbre linéaire.}. .

Avouons que cela est un petit peu de mauvaise foi\footnote{De toutes façons, qui a la foi à l'ULB ?? ;)}. Vraiment ?

La fonction $x$ est une fonction de $\eR$ vers $\eR$. Sa différentielle en un point est donc une application de $\eR$ vers $\eR$. Devinez ce qu'elle vaut ? Ben oui : la différentielle de la fonction $x$ est \emph{vraiment} le $dx$ qu'on écrit tout le temps, la forme différentielle, la base de l'espace dual !

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{L'isomorphisme musical}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Nous savons qu'un champ de vecteur $G$ produit la forme différentielle $G^{\flat}$. La construction inverse existe également. Si $\omega$ est une $1$-forme différentielle, nous pouvons définir le champ de vecteur $\omega^{\sharp}$ par la formule (implicite)
\begin{equation}
	\omega_x(v)=\langle \omega^{\sharp}(x), v\rangle 
\end{equation}
pour tout $v\in\eR^n$. Par définition, $(\omega^{\sharp})^{\flat}=\omega$. 

\begin{exercice}
	Prouver que, en composantes, 
	\begin{equation}
		\omega^{\sharp}(x)=\big( a_1(x),\ldots,a_n(x) \big),
	\end{equation}
	et vérifier que si $G$ est un champ de vecteurs, alors $(G^{\flat})^{\sharp}=G$.
\end{exercice}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Formes différentielles exactes et fermées}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Considérons une fonction différentiable $f\colon D\to \eR$. Pour chaque $x\in D$, nous avons l'application différentielle
\begin{equation}
	\begin{aligned}
		df(x)\colon \eR^n&\to \eR \\
		v&\mapsto \sum_{i=1}^n\frac{ \partial f }{ \partial x_i }(x)v_i, 
	\end{aligned}
\end{equation}
c'est à dire que $df$ est une $1$-forme différentielle dont les composantes sont
\begin{equation}
	df(x)=\frac{ \partial f }{ \partial x_1 }(x)dx_1+\ldots+\frac{ \partial f }{ \partial x_n }(x)dx_n.
\end{equation}

Il est naturel de se demander si toutes les formes différentielles sont des différentielles de fonctions. Une réponse complète est délicate à établir, mais a d'innombrables conséquences en physique, notamment en ce qui concerne l'existence d'un potentiel vecteur pour le champ magnétique dans les équations de Maxwell.
\begin{definition}
	Deux classes importantes de formes différentielles sont à mettre en évidence
	\begin{enumerate}
		\item
			Une forme différentielle $\omega$ sur un ouvert $D\subset\eR^n$ est \defe{exacte}{forme!différentielle!exacte} si il existe une fonction différentiable $f\colon D\to \eR$ telle que
			\begin{equation}
				 \omega_x=df(x)
			\end{equation}
			pour tout $x\in D$.
		\item
			Une $1$-forme de classe $C^1$ sur l'ouvert $D$ est \defe{fermée}{forme!différentielle!fermée} si pour tout $i,j=1,\ldots n$, nous avons
			\begin{equation}
				\frac{ \partial a_i }{ \partial x_j }=\frac{ \partial a_j }{ \partial x_i }.
			\end{equation}
	\end{enumerate}
\end{definition}

\begin{proposition}
	Si $\omega$ est une $1$-forme exacte de classe $C^1$, alors $\omega$ est fermée.
\end{proposition}

\begin{proof}
	Le fait que $\omega$ soit exacte implique l'existence d'une fonction $f$ telle que $\omega=df$, c'est à dire
	\begin{equation}
		\omega_x=\sum_i a_i(x)dx_i=\sum_i\frac{ \partial f }{ \partial x_i }(x)dx_i,
	\end{equation}
	c'est à dire que $a_i(x)=\frac{ \partial f }{ \partial x_i }(x)$. L'hypothèse que $\omega$ est $C^1$ implique que $f$ est $C^2$, et donc que nous pouvons inverser l'ordre de dérivation pour les dérivées secondes $\partial^2_{ij}f=\partial^2_{ji}f$. Nous pouvons donc faire le calcul suivant :
	\begin{equation}
		\frac{ \partial a_i }{ \partial x_j }=\frac{ \partial  }{ \partial x_j }\frac{ \partial f }{ \partial x_i }=\frac{ \partial  }{ \partial x_i }\frac{ \partial f }{ \partial x_j }=\frac{ \partial a_j }{ \partial x_i },
	\end{equation}
	ce qu'il fallait démontrer.
\end{proof}

Ceci est assez pour les formes différentielles pour cette année.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Intégration d'une forme différentielle sur un chemin}
%---------------------------------------------------------------------------------------------------------------------------

Les formes intégrales que nous avons déjà vues sont celles de fonctions et de champs de vecteur sur des chemins. Si $\gamma\colon [a,b]\to \eR^n$ est le chemin, les formules sont
\begin{equation}
	\begin{aligned}[]
		\int_{\gamma}f&=\int_{[a,b]}f\big( \gamma(t) \big)\| \gamma'(t) \|dt\\
		\int_{\gamma}G&=\int_{[a,b]}\langle G\big( \gamma(t) \big), \gamma'(t)\rangle dt.
	\end{aligned}
\end{equation}
Dans les deux cas, le principe est que nous disposons de quelque chose (la fonction $f$ ou le vecteur $G$), et du vecteur tangent $\gamma'(t)$, et nous essayons d'en tirer un nombre que nous intégrons. Lorsque nous avons une $1$-forme, la façon de l'utiliser pour produire un nombre avec le vecteur tangent est évidement d'appliquer la $1$-forme au vecteur tangent. La définition suivante est donc naturelle.

\begin{definition}
	Soit $\gamma\colon [a,b]\to \eR^n$, un chemin de classe $C^1$ tel que son image est contenue dans le domaine $D$. Si $\omega$ es une $1$-forme différentielle sur $D$, nous définissons l'\defe{intégrale de $\omega$ le long de $\gamma$}{intégrale!d'une forme différentielle} le nombre
	\begin{equation}
		\begin{aligned}[]
			\int_{\gamma}\omega&=\int_a^b\omega_{\gamma(t)}\big( \gamma'(t) \big)dt\\
				&=\int_a^b\Big[ a_1\big( \gamma(t) \big)\gamma'_1(t)+\ldots +  a_n\big( \gamma(t) \big)\gamma'_n(t) \Big]dt.
		\end{aligned}
	\end{equation}
\end{definition}

Cette définition est une bonne définition parce que si on change la paramétrisation du chemin, on ne change pas la valeur de l'intégrale, c'est la proposition suivante.
\begin{proposition}
	Si $\gamma$ et $\beta$ sont des chemins équivalents, alors
	\begin{equation}
		\int_{\gamma}\omega=\int_{\beta}\omega,
	\end{equation}
	c'est à dire que l'intégrale est invariante sous les reparamétrisation du chemin.
\end{proposition}
\begin{proof}
	Deux chemins sont équivalents quand il existe un difféomorphisme $C^1$ $h\colon [a,b]\to [c,d]$ tel que $\gamma(t)=(\beta\circ h)(t)$. En remplaçant $\gamma$ par $(\beta\circ h)$ dans la définition de $\int_{\gamma}\omega$, nous trouvons
	\begin{equation}
		\int_a^b\omega_{\gamma(t)}\big( \gamma'(t) \big)dt=\int_a^b\omega_{(\beta\circ h)(t)}\big( (\beta\circ h)'(t) \big)dt.
	\end{equation}
	Un changement de variable $u=h(t)$ transforme cette dernière intégrale en $\int_{\beta}\omega$, ce qui prouve la proposition.
\end{proof}

\begin{remark}
	Si $\gamma$ est une somme de chemins, $\gamma=\gamma^{(1)}+\ldots+\gamma^{(n)}$, où chacun des $\gamma^{(i)}$ est un chemin, alors
	\begin{equation}
		\int_{\gamma}\omega=\sum_{i=1}^n\int_{\gamma_i}\omega
	\end{equation}
	parce que $\omega$ est linéaire.
\end{remark}

\begin{remark}
	Si $-\gamma$ est le chemin
	\begin{equation}
		\begin{aligned}
			- \gamma\colon [a,b]&\to \eR^n \\
			t&\mapsto \gamma\big( b-(t-a) \big),
		\end{aligned}
	\end{equation}
	alors
	\begin{equation}
		\int_{-\gamma}\omega=-\int_{\gamma}\omega,
	\end{equation}
	c'est à dire que si l'on parcours le chemin en sens inverse, alors on change le signe de l'intégrale.
\end{remark}

L'intégrale d'une forme différentielle sur un chemin est compatible avec l'intégrale déjà connue d'un champ de vecteur sur le chemin parce que si $G$ est un champ de vecteurs,
\begin{equation}
	\int_{\gamma}G^{\flat}=\int_{\gamma}G.
\end{equation}
En effet,
\begin{equation}
	\begin{aligned}[]
		\int_{\gamma G^{\flat}}	&=\int_a^b G_{\gamma(t)}^{\flat}(\gamma'(t))\\
					&=\int_a^b\big[ G_1( \gamma(t) )dx_1+\ldots G_n(\gamma(t))dx_n \big]\big( \gamma'_1(t),\ldots,\gamma'_n(t) \big)\\
					&=\int_{a}^b\langle G(\gamma(t)), \gamma'(t)\rangle \\
					&=\int_{\gamma}G.
	\end{aligned}
\end{equation}


\begin{proposition}
	Soit $\omega=df$, une $1$-forme exacte et continue sur le domaine $D$. Alors la valeur de $\int_{\gamma}df$ ne dépend que des valeurs de $f$ aux extrémités de $\gamma$.
\end{proposition}

\begin{proof}
	Nous avons
	\begin{equation}
		\begin{aligned}[]
			\int_{\gamma}\omega=\int_{\gamma}df&=\int_{a}^b\sum_{i=1}n\frac{ \partial f }{ \partial x_i }\big( \gamma(t) \big)\gamma'_i(t)dt\\
				&=\int_a^b\frac{ d }{ dt }\Big( (f\circ\gamma)(t) \Big)dt\\
				&=(f\circ\gamma)(b)-(f\circ\gamma(a)).
		\end{aligned}
	\end{equation}
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Interprétation physique : travail}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}
	Une force $F\colon D\subset\eR^n\to \eR^n$ est \defe{\href{http://fr.wikipedia.org/wiki/Force_conservative}{conservative}}{Conservative} si elle dérive d'un potentiel, c'est à dire si il existe une fonction $V\in C^1(D,\eR)$ telle que 
	\begin{equation}
		F(x)=(\nabla V)(x).
	\end{equation}
\end{definition}
Étant donné que $F$ est un champ de vecteurs, nous avons une forme différentielle associée $F^{\flat}$,
\begin{equation}
	F^{\flat}_x\colon x\mapsto \langle F(x), v\rangle .
\end{equation}

\begin{lemma}
	Le champ $F$ est conservatif si et seulement si la $1$-forme différentielle $F^{\flat}$ est exacte.
\end{lemma}

\begin{proof}
	Supposons que la force $F$ soit conservative, c'est à dire qu'il existe une fonction $V$ telle que $F=\nabla V$. Dans ce cas, il est facile de prouver que $F^{\flat}$ est exacte et est donnée par $F_x^{\flat}=dV(x)$. En effet,
	\begin{equation}
		\begin{aligned}[]
			F_x^{\flat}(v)	&=\langle F(x), v\rangle \\
					&=F_1(x)v_1+\ldots+F_n(x)v_n\\
					&=\frac{ \partial V }{ \partial x_1 }(x)v_1+\ldots\frac{ \partial V }{ \partial x_n }(x)v_n\\
					&=dV(x)v.
		\end{aligned}
	\end{equation}
	
	Pour le sens inverse, supposons que $F^{\flat}$ soit exacte. Dans ce cas, nous avons une fonction $V$ telle que $F^{\flat}=dV$. Il est facile de prouver qu'alors, $F=\nabla V$.
\end{proof}
En résumé, nous avons deux façons équivalentes d'exprimer que la force $F$ dérive du potentiel $V$ :  soit nous disons $F=\nabla V$, soit nous disons $F^{\flat}=dV$.

\begin{proposition}
	Si $F$ est une force conservative, alors le \href{http://fr.wikipedia.org/wiki/Travail_d'une_force}{travail} de $F$ lors d'un déplacement ne dépend pas du chemin suivit.
\end{proposition}

\begin{proof}
	Le travail d'une force le long d'un chemin n'est autre que l'intégrale de la force le long du chemin, et le calcul est facile :
	\begin{equation}
		W_{\gamma}(F)=\int_{\gamma}F=\int_{\gamma}dV=V\big( \gamma(b) \big)-V\big( \gamma(a) \big).
	\end{equation}
	Donc si $\beta$ est un autre chemin tel que $\beta(a)=\gamma(a)$ et $\beta(b)=\gamma(b)$, nous avons $W_{\beta}(F)=W_{\gamma}(F)$.
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Intégrale sur une variété}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Mesure sur une carte}
%---------------------------------------------------------------------------------------------------------------------------

Nous considérons dans cette section uniquement des variétés $M$ de dimension $2$ dans $\eR^3$.  Une particularité de $\eR^3$ (par rapport aux autres $\eR^n$) est qu'il existe le produit vectoriel. 

Si $v$, $w\in\eR^3$, alors le vecteur $v\times w$ est une vecteur normal au plan décrit par $v$ et $w$ qui jouit de l'importante propriété suivante :
\begin{equation}
	\text{aire du parallélogramme}=\| v\times w \|.
\end{equation}
L'aire du parallélogramme construit sur $v$ et $w$ est donnée par la norme du produit vectoriel. Afin de donner une mesure infinitésimale en un point $p\in M$, nous voudrions prendre deux vecteurs tangents à $M$ en $p$, et puis considérer la norme de leur produit vectoriel. Cette idée se heurte à la question du choix des vecteurs tangents à considérer.

Dans $\eR^2$, le choix est évident : nous choisissons $e_x$ et $e_y$, et nous avons $\|e_x\times e_y\|=1$. L'idée est donc de choisir une carte $F\colon W\to F(w)$ autour du point $p=F(w)$, et de choisir les vecteurs tangents qui correspondent à $e_x$ et $e_y$ via la carte, c'est à dire les vecteurs
\begin{equation}
	\begin{aligned}[]
		\frac{ \partial F }{ \partial x }(w),&&\text{et}&&\frac{ \partial F }{ \partial y }(w).
	\end{aligned}
\end{equation}
L'\defe{élément infinitésimal de surface}{élément de surface} sur $M$ au point $p=F(w)$ est alors défini par
\begin{equation}
	d\sigma_F=\|  \frac{ \partial F }{ \partial x }(w)\times\frac{ \partial F }{ \partial y }(w) \|dw,
\end{equation}
et si la partie $A\subset M$ est entièrement contenue dans $F(W)$, nous définissons la \defe{mesure}{mesure!dans une carte} de $A$ par
\begin{equation}		\label{EqDefMuDeuxDF}
	\mu_2(A)=\int_{F^{-1}(A)}d\sigma_F=\int_{F^{-1}(A)}\| \frac{ \partial F }{ \partial x }(w)\times\frac{ \partial F }{ \partial y }(w) \|dw.
\end{equation}
\begin{remark}
	Afin que cette définition ait un sens, nous devons prouver qu'elle ne dépend pas du choix de la carte $F$. En effet, les vecteurs $\partial_xF$ et $\partial_yF$ dépendent de la carte $F$, donc leur produit vectoriel (et sa norme) dépendent également de la carte $F$ choisie. Il faudrait donc un petit miracle pour que le nombre $\mu_2(A)$ donné par \eqref{EqDefMuDeuxDF} soit indépendant du choix de $F$.  Nous allons bientôt voir comme cas particulier du théorème \ref{ThoIntIndepF} que c'est en fait le cas. C'est à dire que si $F$ et $\tilde F$ sont deux cartes qui contiennent $A$, alors
	\begin{equation}
		\int_{F^{-1}(A)}d\sigma_F=\int_{\tilde F^{-1}(A)}d\sigma_{\tilde F}.
	\end{equation}
\end{remark}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Exemple : la mesure de la sphère}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Nous nous proposons maintenant de calculer la surface de la sphère $S^2=x^2+y^2+z^2=R^2$. L'application $F\colon B( (0,0),R)\to R^3$ donnée par
\begin{equation}
	F(x,y)=\begin{pmatrix}
		x	\\ 
		y	\\ 
		\sqrt{R^2-x^2-y^2}	
	\end{pmatrix}
\end{equation}
est une carte pour une demi sphère. Ses dérivées partielles sont
\begin{equation}
	\begin{aligned}[]
		\frac{ \partial F }{ \partial x }&=\begin{pmatrix}
			1	\\ 
			0	\\ 
			-\frac{ x }{ \sqrt{R^2-x^2-y^2} }	
		\end{pmatrix},
		&\frac{ \partial F }{ \partial y }&=\begin{pmatrix}
			0	\\ 
			1	\\ 
			-\frac{ y }{ \sqrt{R^2-x^2-y^2} }	
		\end{pmatrix}.
	\end{aligned}
\end{equation}
Le produit vectoriel de ces deux vecteurs tangents donne
\begin{equation}
	\frac{ \partial F }{ \partial x }(x,y)\times\frac{ \partial F }{ \partial y }(x,y)=\frac{ x }{ \alpha }e_1+\frac{ y }{ \alpha }e_2+e_3
\end{equation}
où $\alpha=\sqrt{R^2-x^2-y^2}$. En calculant la norme, nous trouvons
\begin{equation}
	\| \frac{ \partial F }{ \partial x }(x,y)\times\frac{ \partial F }{ \partial y }(x,y)\| =\sqrt{  \frac{ R^2 }{ R^2-x^2-y^2 } },
\end{equation}
et en passant aux coordonnées polaires, nous écrivons l'intégrale \eqref{EqDefMuDeuxDF} sous la forme
\begin{equation}
	\int_B\| \partial_xF\times\partial_yF \|=\int_0^{2\pi}d\theta\int_0^R r\sqrt{  \frac{ R^2 }{ R^2-x^2-y^2 } }dr=2\pi R^2,
\end{equation}
qui est bien la mesure de la demi sphère.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Intégrale sur une carte}
%---------------------------------------------------------------------------------------------------------------------------

Nous pouvons maintenant définir l'intégrale d'une fonction sur une carte de la variété $M$.
\begin{definition}
	Soit $F\colon W\subset \eR^2\to \eR^3$, une carte pour une variété $M$. Soit $A$, une partie de $F(W)$ telle que $A=F(B)$ où $B\subset W$ est mesurable.  Soit encore $f\colon A\to \eR$, une fonction continue. L'\defe{intégrale}{intégrale!d'une fonction sur une carte} de $f$ sur $A$ est le nombre
	\begin{equation}	\label{EqDefIntDeuxDF}
		\int_Af=\int_Afd\sigma_F=\int_{F^{-1}(A)}(f\circ F)(w)\|  \frac{ \partial F }{ \partial x }(w)\times\frac{ \partial F }{ \partial y }(w) \| dw
	\end{equation}
\end{definition}

\begin{remark}
	L'intégrale \eqref{EqDefIntDeuxDF} n'est pas toujours bien définie. Étant donné que $F$ est $C^1$ et que $f$ est continue, l'intégrante est continue. L'intégrale sera donc bien définie par exemple lorsque $B$ est borné et si la fermeture $\bar A$ est un compact contenu dans $F(w)$.
\end{remark}

Le théorème suivant montre que le travail que nous avons fait jusqu'à présent ne dépend en fait pas du choix de carte $F$ effectué.

\begin{theorem}\label{ThoIntIndepF}
	Soient $F\colon W\to F(w)$ et $\tilde F\colon \tilde W\to \tilde F(\tilde W)$, deux cartes de la variété $M$. Soit une partie $A\subset F(W)\cap\tilde F(\tilde W)$ telle que $A=F(B)$ avec $B\subset W$ mesurable.  Alors $A=\tilde F(\tilde B)$ avec $\tilde B\subset\tilde W$ mesurable.

	Si $f$ est une fonction continue, et si $\int_Afd\sigma_F$ existe, alors $\int_Afd\sigma_{\tilde F}$ existe et
	\begin{equation}
		\int_Afd\sigma_F=\int_Afd\sigma_{\tilde F}.
	\end{equation}
\end{theorem}


%---------------------------------------------------------------------------------------------------------------------------
\subsection{Exemples}
%---------------------------------------------------------------------------------------------------------------------------

Intégrons la fonction $f(x,y,z)$ sur le carré $K=\mathopen] 0 , 1 \mathclose[\times \mathopen] 0 , 2 \mathclose[\times\{ 1 \}$. La première carte que nous pouvons utiliser est
\begin{equation}
	\begin{aligned}
		F\colon \mathopen] 0 , 1 \mathclose[\times\mathopen] 0 , 2 \mathclose[&\to K \\
		(x,y)&\mapsto (x,y,1). 
	\end{aligned}
\end{equation}
Nous trouvons aisément les vecteurs tangents qui forment l'élément de surface:
\begin{equation}
	\begin{aligned}[]
		\frac{ \partial F }{ \partial x }&=\begin{pmatrix}
			1	\\ 
			0	\\ 
			0	
		\end{pmatrix},
		&\frac{ \partial F }{ \partial y }&=\begin{pmatrix}
			0	\\ 
			1	\\ 
			0	
		\end{pmatrix},
	\end{aligned}
\end{equation}
donc $d\sigma_F=1\cdot dxdy$, et
\begin{equation}		\label{IntKSurcarrUn}
	\int_Kfd\sigma_F=\int_{\mathopen] 0 , 1 \mathclose[\times\mathopen] 0 , 2 \mathclose[}f(x,y,1)\cdot 1\cdot dxdy.
\end{equation}

Nous pouvons également utiliser la carte
\begin{equation}
	\begin{aligned}
		\tilde F\colon \mathopen] 0 , \frac{ 1 }{2} \mathclose[\times\mathopen] 0 , 6 \mathclose[&\to K \\
		(\tilde x,\tilde y)&\mapsto (2\tilde x,\frac{ \tilde y }{ 3 },1). 
	\end{aligned}
\end{equation}
Les vecteurs tangents sont maintenant
\begin{equation}
	\begin{aligned}[]
		\frac{ \partial \tilde F }{ \partial \tilde x }&=\begin{pmatrix}
			2	\\ 
			0	\\ 
			0	
		\end{pmatrix},
		&\frac{ \partial \tilde F }{ \partial \tilde y }&=\begin{pmatrix}
			0	\\ 
			1/3	\\ 
			0	
		\end{pmatrix},
	\end{aligned}
\end{equation}
de telle façon à ce que $d\sigma_{\tilde F}=\| \frac{ 2 }{ 3 }e_3 \|=\frac{ 2 }{ 3 }$. Cette fois, l'intégrale de $f$ sur $K$ s'écrit
\begin{equation}
	\int_Kfd\sigma_{\tilde F}=\int_{\mathopen] 0 , \frac{ 1 }{2} \mathclose[\times\mathopen] 0 , 6 \mathclose[}f\big( 2\tilde x,\frac{ \tilde y }{ 3 },1 \big)\cdot\frac{ 2 }{ 3 }\cdot d\tilde xs\tilde y.
\end{equation}
Conformément au théorème \ref{ThoIntIndepF}, cette dernière intégrale est égale à l'intégrale \eqref{IntKSurcarrUn} parce qu'il s'agit juste d'un changement de variable.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Orientation}
%---------------------------------------------------------------------------------------------------------------------------

Soient $F\colon W\to F(w)$ et $\tilde F\colon \tilde W\to \tilde F(\tilde W)$, deux cartes de la variété $M$. Nous pouvons considérer la fonction $h=\tilde F^{-1}\circ F$, définie uniquement sur l'intersection des cartes :
\begin{equation}
	h\colon F^{-1}\big( F(W)\cap\tilde F(\tilde W) \big)\to \tilde F^{-1}\big( F(W)\cap\tilde F(\tilde W) \big).
\end{equation}
Nous disons que $F$ et $\tilde F$ ont même \defe{orientation}{orientation} si
\begin{equation}
	J_h(w)>0
\end{equation}
pour tout $w\in  F^{-1}\big( F(W)\cap\tilde F(\tilde W) \big)$.

Considérons les deux carte suivantes pour le même carré:
\begin{equation}
	\begin{aligned}
		F\colon\mathopen] 0 , 1 \mathclose[\times \mathopen] 0 , 1 \mathclose[ &\to \eR^3 \\
		(x,y)&\mapsto (x,y,0) 
	\end{aligned}
\end{equation}
et
\begin{equation}
	\begin{aligned}
		\tilde F\colon\mathopen] 0 , \frac{ 1 }{2} \mathclose[\times\mathopen] 0 , \frac{1}{ 3 } \mathclose[ &\to \eR^3 \\
		(x,y)&\mapsto (2x,3y,0) 
	\end{aligned}
\end{equation}
Ici, $h(x,y)=\left( \frac{ x }{ 2 },\frac{ y }{ 3 } \right)$ et nous avons $J_h=\frac{1}{ 6 }>0$. Ces deux cartes ont même orientation. Notez que
\begin{equation}
	\frac{ \partial F }{ \partial x }\times\frac{ \partial F }{ \partial y }=e_3,
\end{equation}
tandis que
\begin{equation}
	\frac{ \partial \tilde F }{ \partial x }\times\frac{ \partial \tilde F }{ \partial y }=6e_3.
\end{equation}
Les vecteurs normaux à la paramétrisation pointent dans le même sens.

Si par contre nous prenons la paramétrisation
\begin{equation}
	\begin{aligned}
		G\colon \mathopen] 0,1 \mathclose[\times\mathopen] 0,1 ,  \mathclose[&\to \eR^2 \\
		(x,y)&\mapsto (x,(1-y),0), 
	\end{aligned}
\end{equation}
nous avons
\begin{equation}
	\frac{ \partial G }{ \partial x }\times\frac{ \partial G }{ \partial y }=-e_3,
\end{equation}
et si $g=G^{-1}\circ F$, alors $J_g=-1$.

L'orientation d'une carte montre donc si le vecteur normal à la surface pointe d'un côté ou de l'autre de la surface.

\begin{definition}
	Une variété $M$ est \defe{orientable}{orientable!variété} si il existe un atlas de $M$ tel que deux cartes quelconques ont toujours même orientation. Une variété est \defe{orientée}{variété !orientée} lorsque qu'un tel choix d'atlas est fait.
\end{definition}

\begin{proposition}
	Soit $M$, une variété orientable et un atlas orienté $\{ F_i\colon W_i\to \eR^3 \}$. Alors le vecteur unitaire
	\begin{equation}
		\frac{   \frac{ \partial F }{ \partial x }(x,y)\times\frac{ \partial F }{ \partial y }(x,y)   }{ \| \frac{ \partial F }{ \partial x }(x,y)\times\frac{ \partial F }{ \partial y }(x,y)\| }
	\end{equation}
	ne dépend pas du choix de $F$ parmi les $F_i$.
\end{proposition}


\begin{proof}
	Considérons deux cartes $F_1$ et $F_2$, ainsi que l'application $h=F_2^{-1}\circ F_1$. Écrivons le vecteur $\partial_x F_1\times\partial_yF_1$ en utilisant $F_1=F_2\circ h$. D'abord, par la règle de dérivation de fonctions composées,
	\begin{equation}
		\frac{ \partial (F_2\circ h) }{ \partial x }=\frac{ \partial F_2 }{ \partial x }\frac{ \partial h_1 }{ \partial x }+\frac{ \partial F_2 }{ \partial y }\frac{ \partial h_2 }{ \partial x }.
	\end{equation}
	Après avoir fait le même calcul pour $\frac{ \partial (F_2\circ h) }{ \partial y }$, nous pouvons écrire
	\begin{equation}
		\partial_x(F_2\circ h)\times\partial_y(F_2\circ h)=(\partial_xh_1\partial_xF_2+\partial_xh_2\partial_yF_2)\times(\partial_yh_1\partial_xF_2+\partial_yh_2\partial_yF_2).
	\end{equation}
	Dans cette expression, les facteurs $\partial_ih_j$ sont des nombres, donc ils se factorisent dans les produits vectoriels. En tenant compte du fait que $\partial_xF_2\times\partial_xF_2=0$ et $\partial_yF_2\times\partial_yF_2=0$, ainsi que de l'antisymétrie du produit vectoriel, l'expression se réduit à
	\begin{equation}
		\left( \frac{ \partial F_2 }{ \partial x }\times\frac{ \partial F_2 }{ \partial y } \right)(\partial_xh_1\partial_yh_2-\partial_xh_2\partial_yh_2).
	\end{equation}
	Par conséquent,
	\begin{equation}
		\frac{ \partial F_1 }{ \partial x }\times\frac{ \partial F_1 }{ \partial y } =\frac{ \partial (F_2\circ h) }{ \partial x }\times\frac{ \partial (F_2\circ h) }{ \partial y } =\left( \frac{ \partial F_2 }{ \partial x }\times\frac{ \partial F_2 }{ \partial y } \right)\det J_h.
	\end{equation}
	Donc, tant que $J_h$ est positif, les vecteurs unitaires correspondants au membre de gauche et de droite sont égaux.
\end{proof}

\begin{corollary}
	Si nous avons choisit un atlas orienté pour la variété $M$, nous avons une fonction continue $G\colon M\to \eR^3$ telle que $\| G(p) \|=1$ pour tout $p\in M$. Cette fonction est donnée par
	\begin{equation}		\label{DefCarteGOritn}
		G(F(x,y))=\frac{   \frac{ \partial F }{ \partial x }(x,y)\times\frac{ \partial F }{ \partial y }(x,y)   }{ \| \frac{ \partial F }{ \partial x }(x,y)\times\frac{ \partial F }{ \partial y }(x,y)\| }
	\end{equation}
	sur l'image de la carte $F$.
\end{corollary}

\begin{proof}
	La fonction $G$ est construite indépendamment sur chaque carte $F(W)$ en utilisant la formule \eqref{DefCarteGOritn}. Cette fonction est une fonction bien définie sur tout $M$ parce que nous venons de démontrer que sur $F_1(W_1)\cap F_2(W_2)$, les fonctions construites à partir de $F_1$ et à partir de $F_2$ sont égales.
\end{proof}

Il est possible que prouver, bien que cela soit plus compliqué, que la réciproque est également vraie.
\begin{proposition}
	Une variété $M$ de dimension $2$ dans $\eR^3$ est orientable si et seulement si il existe une fonction continue $G\colon M\to \eR^3$ telle que pour tout $p\in M$, le vecteur $G(p)$ soit de norme $1$ et normal à $M$ au point $p$.
\end{proposition}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Formes différentielles}
%---------------------------------------------------------------------------------------------------------------------------

Nous allons donner une toute petite introduction aux formes différentielles sur des variétés compactes.

\begin{lemma}[\cite{SpindelGeomDoff}]       \label{LemdwLGFG}
    Soit \( \omega\) une \( k\)-forme sur \( \eR^n\) et \( f\), une fonction \( C^{\infty}\) sur \( \eR^n\). Alors \( d(f^*\omega)=f^*d\omega\).
\end{lemma}

\begin{proof}
    Nous effectuons la preuve par récurrence sur le degré de la forme. Soit d'abord une \( 0\)-forme, c'est à dire une fonction \( g\colon \eR^n\to \eR\). Nous avons
    \begin{equation}
        d(d^*g)X=d(g\circ f)X=(dg\circ df)X=dg\big( df X \big)=(f^*dg)(X).
    \end{equation}
    
    Supposons maintenant que le résultat soit exact pour toute les \( p-1\) formes et montrons qu'il reste valable pour les \( p\)-formes. Par linéarité de la différentielle nous pouvons nous contenter de considérer la forme différentielle
    \begin{equation}
        \omega=g\,dx^1\wedge\ldots dx^p
    \end{equation}
    où \( g\) est une fonction \(  C^{\infty}\). Pour soulager les notations nous allons noter \( dx^I=dx^1\wedge\ldots dx^{p-1}\). Nous avons
    \begin{subequations}
        \begin{align}
            d(f^*\omega)&=d\big( f^*(gdx^I\wedge dx^p) \big)\\
            &=d\big( f^*(gdx^I)\wedge f^*dx^p \big)\\
            &=d\big( f^*(gdx^I)\big)\wedge f^*dx^p+(-1)^{p-1}f^*(gdx^I)\wedge(f^*dx^p)  \label{gnAnSt}\\
            &=f^*\big( d(gdx^I) \big)\wedge f^*dx^p      \label{xZrfjZ}\\
            &=f^*\big( d(gdx^I)\wedge dx^p \big)\\
            &=f^*d\omega        \label{loWUji}
        \end{align}
    \end{subequations}
    Justifications : \eqref{gnAnSt} est la formule de Leibnitz. \eqref{xZrfjZ} est parce que le second terme est nul : \( d(f^*dx^p)=f^*(d^2x^p)=0\). Nous avons utilisé l'hypothèse de récurrence et le fait que \( d^2=0\). L'étape \eqref{loWUji} est une utilisation à l'envers de la règle de Leibnitz en tenant compte que \( d^2x^p=0\).
\end{proof}

Soit \( M\) une variété de dimension \( n\) et \( \omega\) une \( n\)-forme différentielle
\begin{equation}
    \omega_p=f(p)dx_1\wedge\ldots\wedge dx_n.
\end{equation}
 Si \( (U,\varphi)\) est une carte (\( U\subset\eR^n\) et \( \varphi\colon U\to M\)) alors nous définissons
\begin{equation}
    \int_{\varphi(U)}\omega=\int_{U}f\big( \varphi(x) \big)dx_1\ldots dx_n.     
\end{equation}
Lorsque nous voulons intégrer sur une partie plus grande qu'une carte nous utilisons une partition de l'unité.
\begin{lemma}   \label{LemGPmRGZ}
    Soit \( \{ U_i \}\) un recouvrement de \( M\) par un nombre fini d'ouverts\footnote{Si \( M\) n'est pas compacte, alors il faut utiliser une version un peu plus élaborée du lemme\cite{SpindelGeomDoff}.}. Alors il existe une famille de fonctions \( f_i\in  C^{\infty}(M)\) telle que
    \begin{enumerate}
        \item
            \( \supp f_i\subset U_i\),
        \item
            pour tout \( i\), nous avons \( f_i\geq 0\),
        \item
            pour tout \( p\in M\) nous avons \( \sum_i f_i(p)=1\).
    \end{enumerate}
\end{lemma}
La famille \( (f_i)\) est une \defe{partition de l'unité}{partition!de l'unité} subordonnée au recouvrement \( \{ U_i \}\). Si \( \{ f_i \}\) est une partition de l'unité subordonnée à un atlas de \( M\) nous définissons
\begin{equation}
    \int_M\omega=\sum_i\int_{U_i}f\omega.
\end{equation}
Il est possible de montrer que cette définition ne dépend pas du choix de la partition de l'unité.

\begin{remark}
    Nous ne définissons pas d'intégrale de \( k\)-forme différentielle sur une variété de dimension \( n\neq k\). Le seul cas où cela se fait est le cas de \( 0\)-formes (les fonctions), mais cela n'est pas vraiment un cas particulier vu que les \( 0\)-formes sont associées aux \( n\)-formes de façon évidente.
\end{remark}


%---------------------------------------------------------------------------------------------------------------------------
\subsection{Intégrale d'une fonction sur une variété}
%---------------------------------------------------------------------------------------------------------------------------

Nous supposons à présent que $M$ est une variété compacte de dimension $2$ dans $\eR^3$. La compacité fait que $M$ possède un atlas contenant un nombre fini de cartes $F_i\colon W_i\to F_i(W_i)$. 

Si $A\subset M$ est tel que pour chaque $i$, $A\cap F_i(W_i)=F_i(V_i)$ pour une ensemble $V_i$ mesurable dans $\eR^2$, alors nous considérons
\begin{equation}
	A_1=A\cap F_1(W_2)=F_1(V_1).
\end{equation}
Ensuite, nous construisons $A_2$ en considérant $F_A(W_2)$ et en lui retranchant $A_1$ :
\begin{equation}
	A_2=\big( A\cap F_2(W_2) \big)\cap F_1(V_1).
\end{equation}
En continuant de la sorte, nous construisons la décomposition
\begin{equation}
	A=A_1\cup\ldots\cup A_p
\end{equation}
de $A$ en ouverts disjoints, chacun de ouverts $A_p$ étant compris dans une carte.

Il est possible de prouver que dans ce cas, la définition suivante a un sens et ne dépend pas du choix de l'atlas effectué.
\begin{definition}
	Si $f\colon A\to \eR$ est une fonction continue, alors l'\defe{intégrale}{intégrale!d'une fonction sur une variété} est le nombre
	\begin{equation}
		\int_Af=\sum_{i=1}^p\int_{A_i}fd\sigma_{F_i}.
	\end{equation}
\end{definition}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Intégrales curvilignes}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\label{secintcurvi}

\subsection{Chemins de classe \texorpdfstring{$C^1$}{C1}}

Soit $p, q\in \eR^n$. Un \defe{chemin}{chemin} $C^1$ par morceaux joignant $p$ à $q$ est une application continue
\begin{equation}
  \gamma : [a,b] \to \eR^n \qquad \gamma(a) = p, \gamma(b) = q
\end{equation}
pour laquelle il existe une subdivision $a = t_0 < t_1 < \ldots < t_{r-1} < t_r = b$ telle que :
\begin{enumerate}
\item la restriction de $\gamma$ sur chaque ouvert $\mathopen]t_i,
  t_{i+1}\mathclose[$ est de classe $C^1$~;
\item pour tout $0 \leq i \leq r$, $\gamma^\prime$ possède une limite
  à gauche (sauf pour $i = 0$) et une limite à droite (sauf pour $i =
  r$) en $t_i$.
\end{enumerate}
Le \defe{chemin $\gamma$ est (globalement) de classe $C^1$}{Chemin!classe $C^2$} si la
subdivision peut être choisie de \og longueur\fg{} $r = 1$.

\begin{remark}
	Si $a$ et $b$ sont des points de
  $\eR^n$, on peut créer le chemin particulier
  \begin{equation*}
    \gamma : [0,1] \to \eR^n : t \mapsto (1-t)a + tb
  \end{equation*}
  qui relie ces points par un segment de droite.
\end{remark}

\subsection{Intégrer une fonction}

Soit $f : D \subset \eR^n \to \eR$ une fonction continue, et $\gamma
: [a,b] \to D$ un chemin $C^1$. On définit \Defn{l'intégrale de $f$
  sur $\gamma$} par
  \begin{equation}    \label{EqhJGRcb}
  \int_\gamma f d s = \int_\gamma f = \int_a^b f(\gamma(t)) \norme{\gamma^\prime(t)} d t.
\end{equation}

\begin{remark}
  Cette définition ne dépend pas de la paramétrisation choisie, ni du
  sens du chemin (échange entre point de départ et point d'arrivée).
\end{remark}

\begin{remark}      \label{RemiqswPd}
    Attention : les intégrales sur des chemins dans \( \eC\) ne sont la même chose. En effet \( \eC\) doit être souvent plutôt traité comme \( \eR\) que comme \( \eR^2\). Si \( \gamma\) est un chemin dans \( \eC\), l'intégrale
    \begin{equation}
        \int_{\gamma}f
    \end{equation}
    doit être comprise comme une généralisation de \( \int_a^bf(x)dx\) et non comme l'intégrale sur un chemin. La différence est qu'en retournant les bornes d'une intégrale usuelle sur \( \eR\) on change le signe, alors qu'en retournant un chemin dans \( \eR^2\), on ne change pas. Bref, la définition est que si \( \gamma\colon \mathopen[ a , b \mathclose]\to \eC\) est un chemin, alors
    \begin{equation}
        \int_{\gamma}f=\int_{\gamma}f(z)dz=\int_a^bf\big( \gamma(t) \big)\gamma'(t)dt.
    \end{equation}
\end{remark}


La formule qui donne la longueur d'un chemin est évidement l'intégrale de la fonction $1$ sur le chemin, c'est à dire
\begin{equation}
	L=\int_a^b\| \gamma'(t) \|dt.
\end{equation}
Si on veut savoir la longueur d'une courbe donnée sous la forme d'une fonction $y=y(x)$, un chemin qui trace la courbe est évidement donné par
\begin{equation}
	\gamma(t)=(t,y(t)),
\end{equation}
et le vecteur tangent au chemin est $\gamma'(t)=(1,y'(t))$. Donc
\begin{equation}
	\| \gamma'(t) \|=\sqrt{1+y'(t)^2},
\end{equation}
et 
\begin{equation}			\label{EqLongFonction}
	L=\int_a^b\sqrt{1+y'(t)^2}.
\end{equation}


\subsection{Intégrer un champ de vecteurs}
Un \Defn{champ de vecteur} est une application $G : \eR^n \to
\eR^n$. On définit l'intégrale de $G$ sur un chemin $\gamma : [a,b]
\to \eR^n$ par
\begin{equation*}
  \int_\gamma G \pardef \int_a^b \scalprod {G(\gamma(t))}{\gamma^\prime(t)} d t.
\end{equation*}

\begin{remark}
  Cette définition ne dépend pas de la paramétrisation choisie, mais
  le signe change selon le sens du chemin.
\end{remark}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Intégrer une forme différentielle sur un chemin}
%---------------------------------------------------------------------------------------------------------------------------

Une \defe{forme différentielle}{forme!différentielle} sur $\eR^n$ est une application
\begin{equation}
	\begin{aligned}
		\omega\colon \eR^n&\to (\eR^n)^* \\
		x&\mapsto \omega_x 
	\end{aligned}
\end{equation}
qui à chaque point $x$ de $\eR^n$ associe une forme linéaire $\omega_x: \eR^n \to \eR$.

On sait que $\{ d x_i \}_{1\leq i\leq n}$ est une base de
${(\eR^{n})}^{*}$, donc toute forme différentielle s'écrit
\begin{equation*}
  \omega_x = \sum_{i=0}^n a_i(x) d x_i
\end{equation*}
où $a_1,\ldots,a_n$ sont les \Defn{composantes de $\omega$} dans la
base usuelle, et sont des fonctions à valeurs réelles. Pour un vecteur
$v = (v_1,\ldots,v_n)$ on a donc par définition de $d x_i$
\begin{equation*}
  \omega_x v = \sum_{i=0}^n a_i(x) v_i.
\end{equation*}

L'intégrale d'une forme différentielle sur un chemin est définie par
\begin{equation}    \label{EqEFIZyEe}
    \int_\gamma \omega = \int_a^b \omega_{\gamma(t)}\gamma^\prime(t) d t
\end{equation}

\begin{remark}
  Cette définition ne dépend pas de la paramétrisation choisie, mais
  le signe change selon le sens du chemin.
\end{remark}


\subsection{Lien entre forme différentielle et champ vectoriel}
Si $G$ est un champ de vecteurs, on peut définir la forme différentielle
\begin{equation*}
  \omega^G : \eR^n \to {(\eR^n)}^\ast : x \mapsto \left\lbrack \omega^G_x :
  \eR^n \to \eR : v \mapsto \omega^G_x v = \scalprod {G(x)}v \right\rbrack
\end{equation*}
et réciproquement, si $\omega_x = \sum_i a_i(x)d x_i$ est une forme
différentielle on définit le champ de vecteurs
\begin{equation*}
  G^\omega(x) = (a_1(x),\ldots,a_n(x)).
\end{equation*}

Avec ces définitions, pour un chemin $\gamma$ donné on a
\begin{equation*}
  \int_\gamma \omega^G = \int_\gamma G^\omega
\end{equation*}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Intégrer un champs de vecteurs sur un bord en $2D$}
%---------------------------------------------------------------------------------------------------------------------------

Si $D\subset\eR^2$ est tel que $\partial D$ est une variété de dimension $1$ et tel que $D$ accepte un champ de vecteur normal extérieur unitaire $\nu$. Si nous voulons définir 
\begin{equation}
	\int_{\partial D}G,
\end{equation}
le mieux est de prendre une paramétrisation $\gamma\colon \mathopen[ 0 , 1 \mathclose]\to \eR^2$ et de calculer
\begin{equation}
	\int_0^1 \langle G_{\gamma(t)}, \frac{ \dot\gamma(t) }{ \| \dot\gamma(t) \| }\rangle dt.
\end{equation}
Hélas, cette définition ne fonctionne pas parce que son signe dépend du sens de la paramétrisation $\gamma$. Si la paramétrisation tourne dans l'autre sens, il y a un signe de différence.

Nous allons définir
\begin{equation}		\label{EqIntVectbordDeux}
	\int_{\partial D}G=\int_0^1\langle G_{\gamma(t)}, T(t)\rangle dt
\end{equation}
où $T(t)=\dot\gamma(t)/\| \dot\gamma(t) \|$ et où $\gamma$ est choisit de telle façon à ce que la rotation d'angle $\frac{ \pi }{ 2 }$ amène $\nu$ sur $T$. Cela fixe le choix de sens.

Ce choix de sens aura des répercussions dans l'application de la formule de Green et du théorème de Stokes.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Intégrer une forme différentielle sur un bord en $2D$}
%---------------------------------------------------------------------------------------------------------------------------

Nous n'allons pas chercher très loin :
\begin{equation}
	\int_{\partial D}\omega=\int_{\partial D}\omega^{\sharp},
\end{equation}
c'est à dire que l'intégrale de la forme différentielle est celle du champ de vecteur associé. Le membre de droite est définit par \eqref{EqIntVectbordDeux}, avec le choix d'orientation qui va avec.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Intégrer une forme différentielle sur un bord en $3D$}
%---------------------------------------------------------------------------------------------------------------------------

Nous allons maintenant intégrer une forme différentielle sur certains chemins fermés dans $\eR^3$. Soit $F(D)\subset\eR^3$, une variété de dimension $2$ dans $\eR^3$ où $F\colon D\subset\eR^2\to \eR^3$ est la carte. Nous supposons que $D$ vérifie les hypothèses de la formule de Green. Alors nous définissons
\begin{equation}		\label{EqDefIntTroisForBord}
	\int_{F(\partial D)}\omega = \int_{\partial D} F^*\omega
\end{equation}
où $F^*\omega$ est la forme différentielle définie sur $\partial D$ par $(F^*\omega)(v)=\omega\big( dF(v) \big)$.

Cette définition est très abstraite, mais nous n'allons, en pratique, jamais l'utiliser, grâce au théorème de Stokes.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Intégrer d'un champ de vecteurs sur un bord en $3D$}
%---------------------------------------------------------------------------------------------------------------------------

Encore une fois, nous n'allons pas chercher bien loin :
\begin{equation}
	\int_{F(\partial D)G}=\int_{F(\partial D)}G^{\flat}
\end{equation}
où $G^{\flat}$ est la forme différentielle associée au champ de vecteur. Le membre de droite est définit par l'équation \eqref{EqDefIntTroisForBord}.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Dérivées croisées et forme différentielle exacte}
%---------------------------------------------------------------------------------------------------------------------------

Nous considérons le problème suivant : trouver une fonction \( f\colon \eR^2\to \eR\) telle que
\begin{subequations}        \label{EqskfgfNr}
    \begin{numcases}{}
        \frac{ \partial f }{ \partial x }=a(x,y)\\
        \frac{ \partial f }{ \partial y }=b(x,y)
    \end{numcases}
\end{subequations}
où \( a\) et \( b\) sont des fonctions supposées suffisamment régulières. Nous savons que ce problème n'a pas de solutions lorsque
\begin{equation}
    \frac{ \partial a }{ \partial y }\neq\frac{ \partial b }{ \partial x }
\end{equation}
parce que cela impliquerait \( \partial^2_{xy}f\neq \partial^2_{yx}f\). Nous sommes en droit de nous demander si la condition
\begin{equation}
    \frac{ \partial a }{ \partial y }=\frac{ \partial b }{ \partial x }
\end{equation}
impliquerait qu'il existe une solution au problème \eqref{EqskfgfNr}. La réponse est oui, et nous allons brièvement la justifier. Pour plus de détails nous vous demandons de chercher un peu \href{http://www.bing.com/search?q=forme+diff\%C3\%A9rentielle+exacte+filetype\%3Apdf&form=QBRE&fit=all}{sur internet} les mots-clefs \emph{forme différentielles exacte}. Vous consulterez également avec profit \cite{DiffExact}.

\begin{proposition}
    Si \( a\) et \( b\) sont des fonctions qui satisfont à la condition
    \begin{equation}
        \frac{ \partial a }{ \partial y }=\frac{ \partial b }{ \partial x },
    \end{equation}
    alors la fonction
    \begin{equation}        \label{EqllhTaT}
        f(x,y)=\int_0^x a(t,0)dt+\int_0^yb(x,t)dt
    \end{equation}
    répond au problème
    \begin{subequations}     
        \begin{numcases}{}
            \frac{ \partial f }{ \partial x }=a(x,y)\\
            \frac{ \partial f }{ \partial y }=b(x,y)
        \end{numcases}
    \end{subequations}
\end{proposition}

La preuve qui suit n'en est pas complètement une parce qu'il manque des justification, notamment au moment de permuter la dérivée et l'intégrale.
\begin{proof}
    La clef de la preuve est le théorème fondamental de l'analyse :
    \begin{equation}
        \int_0^x \frac{ \partial f }{ \partial x }(t,y)dt=f(x,y)
    \end{equation}
    et son pendant par rapport à \( y\) :
    \begin{equation}
        \int_0^y \frac{ \partial f }{ \partial y }(x,t)dt=f(x,y).
    \end{equation}
    En appliquant ces version du théorème fondamental, nous obtenons immédiatement.
    \begin{equation}
        \frac{ \partial f }{ \partial y }=b(x,y).
    \end{equation}
    En ce qui concerne la dérivée par rapport à \( y\),
    \begin{subequations}
        \begin{align}
            \frac{ \partial f }{ \partial x }&=a(x,0)+\int_0^y\frac{ \partial b }{ \partial x }(x,t)dt\\
            &=a(x,0)+\int_0^y\frac{ \partial a }{ \partial y }(x,t)dt\\
            &=a(x,0)+[a(x,t)]_{t=0}^{t=y}\\
            &=a(x,y).
        \end{align}
    \end{subequations}
\end{proof}

En ce qui concerne l'unicité, supposons que \( f\) et \( g\) soient deux solutions au problème. L'équation
\begin{equation}
    \frac{ \partial f }{ \partial x }=a(x,y)=\frac{ \partial g }{ \partial x }
\end{equation}
implique que 
\begin{equation}
    f(x,y)=g(x,y)+C(y)
\end{equation}
où \( C\) est une fonction seulement de \( y\). L'autre équation implique
\begin{equation}
    f(x,y)=g(x,y)+D(x)
\end{equation}
où \( D\) est seulement une fonction de \( x\). En égalisant nous voyons que les fonctions \( C\) et \( D\) doivent être des constantes.

Par conséquent la fonction \( f\) est donnée à une constante près et en réalité la fonction \eqref{EqllhTaT} est suffisante pour répondre au problème de trouver toutes les fonctions dont les dérivées partielles sont données par les fonctions \( a\) et \( b\).

La fonction \( f\) ainsi créée est un \defe{potentiel}{potentiel} pour le champ de force
\begin{equation}
    F(x,y)=\begin{pmatrix}
        a(x,y)    \\ 
        b(x,y)  
    \end{pmatrix}.
\end{equation}
Notez que ce champ de vecteurs est le gradient de \( f\). La question initiale aurait donc pu être posée en les termes suivants : trouver une fonction \( f\) dont le gradient est donné par
\begin{equation}
    \nabla f=\begin{pmatrix}
        a(x,y)    \\ 
        b(x,y)    
    \end{pmatrix}.
\end{equation}


%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Intégrales de surface}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Intégrale d'une fonction}
%---------------------------------------------------------------------------------------------------------------------------
\label{secintsurfaciques}
Soit $M$ une variété de dimension $n$ dans $\eR^m$. Soit $F : W \subset \eR^n \to M$ une paramétrisation d'un ouvert relatif de $M$.  

Si $f$ est une fonction définie sur un sous-ensemble $A \subset F(W)$ tel que $F^{-1}(A)$ est mesurable, l'\Defn{intégrale de $f$ sur $A$} est définie par
\begin{equation*}
  \int_A f = \int_{F^{-1}(A)} f(F(w)) \sqrt{\det(\transpose{J_F(w)} {J_F(w)})} dw
\end{equation*}
où l'intégrale est l'intégration usuelle (de Lebesgue) sur $F^{-1}(A) \subset \eR^n$. On écrit parfois cette intégrale $\int_{F^{-1}(A)} f(F(w)) d\sigma$ où
\begin{equation*}
  d\sigma = \sqrt{\det(\transpose{J_F(w)} {J_F(w)})} dw
\end{equation*}
est l'\Defn{élément infinitésimal de volume} de la variété. 

Si $m = 3$ et $n = 2$, l'élément infinitésimal de volume vaut
\begin{equation*}
  d \sigma = \norme{\pder F {w_1} \wedge \pder F {w_2}} dw
\end{equation*}
où $\wedge$ représente le produit vectoriel dans $\eR^3$, et $(w_1,w_2)$ sont les coordonnées sur $W \subset \eR^2$. Dans la suite, nous ne regarderons plus que ce cas.

\subsection{Intégrale d'un champ de vecteurs}
Dans l'intégration curviligne, on a noté que si l'intégrale d'une fonction ne dépendait pas de l'orientation du chemin, l'intégrale d'un champ de vecteurs ou d'une forme différentielle en dépendait. Ce problème d'orientation apparait également dans l'intégration sur des surfaces de l'espace.

%% Page 530, exemple 4
Une \Defn{orientation} sur une surface $S \subset \eR^3$ est le choix
d'un champ de vecteurs continu $\nu : S \to \eR^3$ dont la norme en
tout point de $S$ vaut $1$. On remarque qu'ayant fait un tel choix
d'orientation $\nu(x)$ en un point $x$, le seul autre choix possible
en $x$ est $-\nu(x)$.
%% Page 
Si $S$ est le bord d'un ouvert $D \subset \eR^3$, l'\Defn{orientation
  induite par $D$ sur $S$} est, si elle existe, l'orientation qui
pointe hors de $D$ en tout point de $S$. Plus précisément, il faut que
pour tout $x \in D$ il existe $\epsilon > 0$ vérifiant, pour tout $0 <
t < \epsilon$, la relation $t \nu(x) \notin D$. Dans ce cas, le champ
de vecteurs $\nu$ est appelé le \Defn{vecteur normal unitaire
  extérieur} à $D$ et il est forcément unique.

Soit $G$ un champ de vecteurs défini sur une surface orientée par un
champ $\nu$. L'intégrale de $G$ sur $S$, aussi appelée le \Defn{flux
de $G$ à travers $S$}, est
\begin{equation}\label{eqflux-star}
  \iint_S G \cdot d S \pardef \iint_S \scalprod{G}{\nu} d \sigma.
\end{equation}
Si on suppose que la surface est paramétrisée par une application
\begin{equation*}
  F : W \subset \eR^2 \to \eR^3 : (u,v) \mapsto (F_1(u,v),F_2(u,v),F_3(u,v))
\end{equation*}
alors un vecteur unitaire $\nu$ peut s'écrire sous la forme
\begin{equation*}
  \nu = \frac{\pder F u \wedge \pder F v}{\norme{\pder F u \wedge \pder F v}}
\end{equation*}
et grâce à cette paramétrisation l'intégrale \eqref{eqflux-star}
devient
\begin{equation*}
  \iint_S G \cdot d S = \iint_W \scalprod{G(F(u,v))}{\pder F u \wedge \pder F v} d u
  d v.
\end{equation*}
où on utilise l'expression de $d \sigma$ obtenue précédemment dans le
cas qui nous intéresse (surface dans l'espace).


%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Divergence, Green, Stokes}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Le théorème de Stokes (et ses variations) peut se voir comme une généralisation du théorème fondamental du calcul différentiel et intégral qui stipule que
\begin{equation*}
	\int_a^b f^\prime(x) d x = f(b) - f(a)
\end{equation*}
c'est-à-dire qui relie l'intégrale de $f^\prime$ sur $I = [a,b]$ aux valeurs de $f$ sur le bord $\partial I = \{a,b\}$. Le signe $-$ qui apparait vient de l'orientation ; celle-ci requiert de la prudence dans l'utilisation des théorèmes.

Voici, pour votre culture générale, un énoncé général :
\begin{theorem} \label{ThoATsPuzF}
	Si $M$ est une variété orientable de dimension $n$ avec un bord noté $\partial  M$, alors pour toute forme différentielle $\omega$ de degré $n-1$ on a 
	\begin{equation*}
		\int_{ M} d \omega = \int_{\partial  M} \omega.
	\end{equation*}
	où $d \omega$ désigne la différentielle extérieure de $\omega$.
\end{theorem}
Attention : la différentielle extérieure n'est pas la différentielle usuelle. Certes dans le cas d'une \( 0\)-forme (c'est à dire d'une fonction), les deux notions coïncident, mais ça ne va pas plus loin. La différentielle extérieure vérifie \( d^2\omega=0\) pour tout \( \omega\), y compris pour les fonctions : si \( \omega=df\) alors \( d\omega=0\).

%TODO : donner la définition et quelque exemples de différentielle extérieure.

Nous allons maintenant voir quelque cas particuliers. 

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Intégrales curviligne}
%---------------------------------------------------------------------------------------------------------------------------

Une des nombreuses formes du théorème de Stokes (théorème \ref{ThoATsPuzF}) est que si la forme différentielle \( \omega\) est exacte alors son intégrale est facile.
\begin{theorem} \label{ThoUJMhFwU}
    Si \( \gamma\) est une chemin de classe \( C^1\) dans un ouvert \( \Omega\) et si \( \omega\) est la forme différentielle exacte \( \omega=df\), alors
    \begin{equation}
        \int_{\gamma}df=f\big( \gamma(1) \big)-f\big( \gamma(0) \big).
    \end{equation}
\end{theorem}
Cela est également une extension du théorème fondamental du calcul différentiel.
%TODO : Ce serait vachement mieux de donner une preuve indépendante de cela.


\subsection{Théorème de la divergence}

Si nous considérons une surface dans $\eR^n$ et un champ de vecteurs, il est bon de se demander quelle \og quantité de vecteurs\fg{} traverse la surface. Soit $D$, un ouvert borné de $\eR^n$ telle que $\partial D$ soit une variété de dimension $n-1$, et $G$, un champ de vecteurs défini sur $\bar D$. Afin de compter combien de $G$ traverse $\partial D$, il faudra faire en sorte de ne considérer que la composante de $G$ normale à $\partial D$ : pas question d'intégrer par exemple la norme de $G$ sur $\partial D$.

Comme nous le savons, la composante du vecteur $v$ dans la direction $w$ est le produit scalaire $v\cdot 1_w$ où $1_w$ est le vecteur de norme $1$ dans la direction $w$. Nous allons donc introduire le concept de vecteur normal extérieur. Soit $x\in\partial D$ et $\nu\in\eR^n$, nous disons que $\nu$ est un \defe{vecteur normal extérieur}{normal extérieur!vecteur} de $\partial D$ si
\begin{enumerate}

	\item
		$\langle \nu, v\rangle =0$ pour tout vecteur tangent $v$ à $\partial D$ au point $x$. Pour rappel, $\partial D$ étant une variété de dimension $n-1$, il y a $n-1$ tels vecteurs $v$ linéairement indépendants.
	
	\item
		Il existe un $\delta>0$ tel que $\forall t\in\mathopen] 0 , \delta \mathclose[$, nous avons $c+t\nu\notin \bar D$ et $x-t\nu\in D$.
 
\end{enumerate}

Nous pouvons maintenant définir le concept de flux. Soit $D\subset \eR^n$ tel que $\partial D$ soit une variété de dimension $n-1$ qui admette un vecteur normal extérieur $\nu(x)$ en chaque point. Soit aussi $G\colon \bar D\to \eR^n$, un champ de vecteur de classe $C^1$. Le \defe{flux}{flux!d'un champ de vecteur} de $G$ au travers de $\partial D$ est le nombre
\begin{equation}
	\int_{\partial D}\langle G(x), \nu(x)\rangle d\sigma(x).
\end{equation}

Cette intégrale est en général très compliquée à calculer parce qu'il faut trouver le champ de vecteur normal, puis une paramétrisation de la surface $\partial D$ et ensuite appliquer la méthode décrite au point \ref{secintsurfaciques}. 

Heureusement, il y a un théorème qui nous permet de calculer plus facilement : sans devoir trouver de vecteurs normaux.

Il n'est pas plus contraignant d'énoncer ce théorème dans le cadre d'une hypersurface de $\eR^n$, ce que nous faisons donc~:
\begin{theorem}[Formule de la divergence]
	Soit $D$ un ouvert borné de $\eR^n$ dont le bord est \og assez régulier par morceaux\fg{}, c'est-à-dire~:
	\begin{equation}
		\partial D = A_1 \cup \ldots A_p \cup N
	\end{equation} 
	où
	\begin{enumerate}
		\item $A_1, \ldots, A_p, N$ sont deux à deux disjoints,
		\item pour tout $i \leq p$, $A_i$ est un ouvert relatif d'une certaine variété $M_i$ de dimension $(n-1)$
		\item $\bar A_i \subset M_i$
		\item $N$ est un compact contenu dans une réunion finie de variétés de dimensions $(n-2)$.
	\end{enumerate}
	Supposons également qu'en chaque point de $A_1 \cup \ldots \cup A_p$ il existe un vecteur normal extérieur $\nu$.
	
	Si $G$ est un champ de vecteurs de classe $C^1$ sur $\bar D$ alors
	\begin{equation}
		\int_D \nabla\cdot G = \sum_{i=1}^p \int_{A_i} \scalprod{G}{\nu}.
	\end{equation}
	L'intégrale du membre de gauche est l'intégrale sur un ouvert d'une simple fonction.
\end{theorem}

\subsection{Formule de Green}

Pour rappel, une chemin $\gamma\colon \mathopen[ 0 , 1 \mathclose]\to \eR^n$ est \defe{régulier}{régulier!chemin} si il est $C^1$ et si $\gamma(t)\neq 0$ pour tout $r$. Le chemin est de \defe{Jordan}{Jordan!chemin} si $\gamma(1)=\gamma(0)$ et si $\gamma\colon \mathopen[ a , b [\to \eR^n$ est injective.

La formule de Green est un cas particulier du théorème de la divergence dans
le cas $n = 2$, légèrement reformulé~:
\begin{theorem}
	Soit $D \subset \eR^2$ ouvert borné tel que son bord est est la réunion finie d'un certain nombre de chemins de classe $C^1$ de Jordan réguliers.  Supposons qu'en chaque point de son bord, $D$ possède un vecteur normal unitaire extérieur $\nu$. Soient $P$ et $Q$ deux fonctions réelles de classe $C^1$ sur $\bar D$. Alors
    \begin{equation}  \label{EqYLblSqV}
    \iint_D (\partial_xQ - \partial_yP)dx\,dy = \oint_{\partial D}
    Pd x + Q d y
  \end{equation}
  où chaque chemin $\gamma$ formant le bord de $D$ est orienté de
  sorte que $T \nu = \frac{\dot\gamma}{\norme{\dot\gamma}}$ où $T$
  représente la rotation d'angle $+\frac\pi2$.
\end{theorem}

Justifions le fait que cela soit un cas particulier de la formule de Stokes du théorème \ref{ThoATsPuzF}. Nous considérons la forme différentielle
\begin{equation}
    \omega=Pdx+Qdy,
\end{equation}
et sa différentielle
\begin{subequations}
    \begin{align}
    d\omega&=\sum_id\omega_i\wedge dx_i\\
    &=\left( \frac{ \partial P }{ \partial x }dx+\frac{ \partial P }{ \partial y }dy \right)\wedge dx+\left( \frac{ \partial Q }{ \partial x }dx+\frac{ \partial Q }{ \partial y }dy \right)\wedge dy\\
    &=\left( \frac{ \partial Q }{ \partial x }-\frac{ \partial P }{ \partial y } \right)dx\wedge dy.
    \end{align}
\end{subequations}

Intégrons cette forme \( d\omega\) sur le domaine ouvert \( D\) que nous paramétrons de façon triviale par
\begin{equation}
    \begin{aligned}
        \varphi\colon D&\to \eR^2 \\
        (u,v)&\mapsto (u,v).
    \end{aligned}
\end{equation}
Ce que nous avons est
\begin{equation}\label{EqKYjFEGF}
    \iint_D d\omega=\iint_D d\omega_{(u,v)}\left( \frac{ \partial \varphi }{ \partial u },\frac{ \partial \varphi }{ \partial v } \right)dudv
\end{equation}
Nous avons aussi \( T_u=\frac{ \partial \varphi }{ \partial u }=\begin{pmatrix}
    1    \\ 
    0    
\end{pmatrix}\) et \(T_v= \frac{ \partial \varphi }{ \partial v }=\begin{pmatrix}
    0    \\ 
      1  
\end{pmatrix}\) et donc 
\begin{equation}
    (dx\wedge dy)(T_u,T_v)=dx(T_u)dy(T_v)-dx(T_v)dy(T_u)=1-0=1.
\end{equation}
L'intégrale \eqref{EqKYjFEGF} se développe donc en
\begin{equation}
    \iint_Dd\omega=\iint_D\left( \frac{ \partial Q }{ \partial x }(u,v)-\frac{ \partial P }{ \partial y }(u,v) \right)(dx\wedge dy)(T_u,T_v)dudv=\iint_D\left( \frac{ \partial Q }{ \partial x }-\frac{ \partial P }{ \partial y } \right)dudv.
\end{equation}
Par conséquent la formule de Stokes nous donne la formule \eqref{EqYLblSqV}.

La formule de Green nous permet de calculer l'aire de la surface délimitée par une courbe fermée en termes de l'intégrale d'une forme bien choisie le long du contour. Pour cela nous prenons la forme
\begin{equation}    \label{EqZNXYMQb}
    \omega=-\frac{ y }{2}dx+\frac{ x }{2}dy,
\end{equation}
de telle sorte que \( \partial_xQ-\partial_yQ=1\) et que
\begin{equation}
    \iint_Dd\omega=\iint_Dddudv=S,
\end{equation}
et au final l'aire est donnée par
\begin{equation}
    S=\int_{\partial D}\left( -\frac{ y }{2}dx+\frac{ x }{2}dy \right).
\end{equation}

Lorsque le bord de \( D\) est paramétré par
\begin{equation}
    \begin{aligned}
        \gamma\colon \mathopen[ a , b \mathclose]&\to \eR^2 \\
        u&\mapsto \begin{pmatrix}
            x(u)    \\ 
            y(u)    
        \end{pmatrix},
    \end{aligned}
\end{equation}
nous avons
\begin{equation}
    (Pdx+Qdy)\gamma'(u)=Px'+Qy',
\end{equation}
et alors
\begin{equation}
    \int_{\partial D}Pdx+Qdy=\int_a^b P\big( x(u),y(u) \big)x'(u)+Q\big( x(u),y(u) \big)y'(u)du.
\end{equation}
En ce qui concerne l'aire de la surface, nous prenons les \( P\) et \( Q\) de la forme \ref{EqZNXYMQb} :
\begin{equation}    \label{EqAJGrtOk}
    S=\frac{ 1 }{2}\int_a^b\Big( -y(u)x'(u)+x(u)y'(u) \Big)du.
\end{equation}

\subsection{Formule de Stokes}
\label{secstokesusuel}

La formule de Stokes est la version classique, qui permet d'exprimer la circulation d'un champ de vecteur le long d'une courbe de $\eR^3$ comme le flux de son rotationnel à travers n'importe quel surface dont le bord est la courbe. La version présentée ici suppose que la surface peut se paramétrer en un seul morceau~:
\begin{theorem}
  Soit $F : W\subset \eR^2 \to \eR^3$ une paramétrisation (carte) d'une surface dans $\eR^3$, supposée de classe $C^2$. Soit $D$ un ouvert de $\eR^2$ vérifiant les hypothèses de la formule de Green, et tel que $\bar D \subset W$. Soit $G$ un champ de vecteurs de classe $C^1$ défini sur $F(\bar D)$, et soit $N$ le champ normal unitaire donné par la paramétrisation
  \begin{equation}		
	N = \frac{\pder F u \wedge \pder F v}{\norme{\pder F u \wedge \pder F v}}
\end{equation}
  alors
  \begin{equation}\label{EqStokesTho}
    \iint_{F(D)} \scalprod{\rot G}{N} d\sigma_F = \int_{F(\partial D)} G
  \end{equation}
  où les chemins formant le bord $\partial D$ sont orientés comme dans le théorème de Green.
\end{theorem}
Notons, juste pour avoir une bonne nouvelle de temps en temps, que 
\begin{equation}
	d\sigma_F=\left\| \frac{ \partial F }{ \partial u }\times\frac{ \partial F }{ \partial v }  \right\|dudv,
\end{equation}
mais cette norme apparaît exactement au dénominateur de $N$. Il ne faut donc pas la calculer parce qu'elle se simplifie.

Sous forme un peu plus physicienne\footnote{et surtout plus explicite.}, la formule \eqref{EqStokesTho} s'écrit
\begin{equation}
	\int_{F(D)}\langle \nabla\times G, N(x)\rangle\, d\sigma_F(x)=\int_{F(\gamma)}\langle G, T\rangle\, ds
\end{equation}
où $T$ est le vecteur unitaire tangent à $F(\gamma)$.

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Quelle est la bonne orientation ?}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Le signe du vecteur normal $N$ dépend du choix de l'ordre des coordonnées dans la carte. Supposons que je veuille paramétrer la surface $x^2+y^2=1$, $z=1$. Nous prenons naturellement comme carte le cercle $C$ de rayon $1$ dans $\eR^2$ et la carte
\begin{equation}
	F(r,\theta)=\begin{pmatrix}
		r\cos\theta	\\ 
		r\sin\theta	\\ 
		1	
	\end{pmatrix}.
\end{equation}
Mais nous aurions aussi pu mettre les coordonnées $r$ et $\theta$ dans l'autre ordre :
\begin{equation}
	\tilde F(\theta,r)=\begin{pmatrix}
		r\cos\theta	\\ 
		r\sin\theta	\\ 
		1	
	\end{pmatrix}.
\end{equation}
Les vecteurs normaux ne sont pas les même : la carte $F$ donnera $\partial_rF\times\partial_{\theta}F$, tandis que l'autre donnera $\partial_{\theta}\tilde F\times\partial_r\tilde F$. Le signe change !

Il faut savoir laquelle choisir. Le cercle $C\subset \eR^2$ a une orientation donnée par le théorème de Green. Nous choisissons l'ordre des coordonnées pour que $1_{\theta}$ et $1_{r}$ soient dans la même orientation que les vecteurs $\nu$ et $T$ tels que donnés par le théorème de Green, et tels que dessinés sur la figure \ref{LabelFigCercleTnu}.
\newcommand{\CaptionFigCercleTnu}{L'orientation sur le cercle. Si nous les prenons dans l'ordre, les vecteurs $(1_r,1_{\theta})$ ont la même orientation que celle donnée par les vecteurs $(\nu,T)$ donnés par la convention de Green.}
\input{Fig_CercleTnu.pstricks}

%\ref{LabelFigCercleTnu}.
%\newcommand{\CaptionFigCercleTnu}{L'orientation sur le cercle. Si nous les prenons dans l'ordre, les vecteurs $(1_r,1_{\theta})$ ont la même orientation que celle donnée par les vecteurs $(\nu,T)$ donnés par la convention de Green.}
%\input{Fig_CercleTnu.pstricks}

Plus généralement, nous choisissons l'ordre des coordonnées $u$ et $v$ pour que la base $(1_u,1_v)$ ait la même orientation que $(\nu,T)$ où $T$ a le sens convenu dans le théorème de Green.


%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
					\section[Intégrales de fonctions et domaines non bornées]{Intégrales de fonctions non bornées sur des domaines non bornés}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
					\subsection[Fonctions et ensembles non bornés]{Intégrales de fonctions non bornées sur des ensembles non bornés}
%---------------------------------------------------------------------------------------------------------------------------

Soit $f\colon \eR^n\to \overline{ \eR }$, une fonction positive. On dit qu'elle est \defe{intégrable}{intégrable!fonction positive} sur $E\subset\eR^n$ si
\begin{enumerate}
    \item $\forall r>0$, la fonction $f_r(x)=f(x)\mtu_{f<r}$ est intégrable sur $E_r$;
\item la limite $\lim_{r\to\infty}\int_{E_r}f_r$ est finie.
\end{enumerate}
Dans ce cas, on pose 
\begin{equation}
	\int_Ef=\lim_{r\to\infty}\int_{E_r}f_r.
\end{equation}

\begin{theorem}[Page I.38]		\label{ThoFnTestIntnnBorn}
Soit $E$ mesurable dans $\eR^n$ et $f\colon E\to \overline{ \eR }$. Si $f$ est mesurable et si il existe $g\colon E\to \overline{ \eR }$ intégrable sur $E$ telle que $| f(x) |\leq g(x)$ pour tout $x\in E$, alors $f$ est intégrable sur~$E$.

Réciproquement, si $f$ est intégrable sur $E$, alors $f$ est mesurable.
\end{theorem}

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Passage à la limite sous le signe intégral}
%---------------------------------------------------------------------------------------------------------------------------

Un autre résultat très important pour l'étude de l'intégrabilité est le théorème de la \defe{convergence dominée de Lebesgue}{}:
\begin{theorem}
	Soit $E\subset \eR^n$ un ensemble mesurable et $\{ f_k \}$, une suite de fonctions intégrables sur $E$ qui converge simplement vers une fonction $f\colon E\to \overline{ \eR }$. Supposons qu'il existe une fonction $g$ intégrable sur $E$ telle que pour tout $k$,
\begin{equation}
	| f(x) |\leq g(x)
\end{equation}
pour tout $x\in E$. Alors $f$ est intégrable sur $E$ et 
\begin{equation}
	\int_Ef=\lim_{k\to\infty}\int_Ef_k.
\end{equation}
\end{theorem}

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Théorème de Fubini et changement de variables}
%---------------------------------------------------------------------------------------------------------------------------

\begin{theorem}[Fubini]\label{ThoFubini}
Soit $(x,t)\mapsto f(x,y)\in\bar \eR$ une fonction intégrable sur $B_n\times B_m\subset\eR^{n+m}$ où $B_n$ et $B_m$ sont des ensembles mesurables de $\eR^n$ et $\eR^m$. Alors :
\begin{enumerate}
\item pour tout $x\in B_n$, sauf éventuellement en les points d'un ensemble $G\subset B_n$ de mesure nulle, la fonction $y\in B_m\mapsto f(x,y)\in\bar\eR$ est intégrable sur $B_m$
\item
la fonction
\begin{equation}
	x\in B_n\setminus G\mapsto\int_{B_m}f(x,y)dy\in\eR
\end{equation}
est intégrable sur $B_n\setminus G$

\item 
On a
\begin{equation}
	\int_{B_n\times B_m}f(x,y)dxdy=\int_{B_n}\left( \int_{B_m}f(x,y)dy \right)dx.
\end{equation}

\end{enumerate}
\end{theorem}
\index{théorème!Fubini!dans $ \eR^n$}
\index{Fubini!théorème!dans $ \eR^n$}


Notons en particulier que si $f(x,y)=\varphi(x)\phi(y)$, alors $\int_{B_m}\varphi(y)dy$ est une constante qui peut sortir de l'intégrale sur $B_n$, et donc
\begin{equation}		\label{EqFubiniFactori}
	\int_{B_n\times B_m}\varphi(x)\phi(y)dxdy=\int_{B_n}\varphi(x)dx\int_{B_m}\phi(y)dy.
\end{equation}

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Intégrale en dimension un}
%---------------------------------------------------------------------------------------------------------------------------

\begin{proposition}[Critère de comparaison]
Soit $f$ mesurable sur $]a,\infty[$ et bornée sur tout $]a,b]$, et supposons qu'il existe un $X_0\geq a$, tel que sur $]X_0,\infty[$,
\begin{equation}
	| f(x) |\leq g(x)
\end{equation}
où $g(x)$ est intégrable. Alors $f(x)$ est intégrable sur $]a,\infty[$.
\end{proposition}

\begin{corollary}[Critère d'équivalence]
Soient $f$ et $g$ des fonctions mesurables et positives ou nulles sur $]a,\infty[$, bornées sur tout $]a,b]$, telles que 
\begin{equation}
	\lim_{x\to\infty}\frac{ f(x) }{ g(x) }=L
\end{equation}
existe dans $\bar\eR$.
\begin{enumerate}
\item Si $L\neq\infty$ et $\int_{a}^{\infty}g(x)$ existe, alors $\int_a^{\infty}f(x)dx$ existe,
\item Si $L\neq 0$ et si $\int_a^{\infty}f(x)dx$ existe, alors $\int_a^{\infty}g(x)dx$ existe,
\end{enumerate}
\end{corollary}

\begin{corollary}[Critère des fonctions test]			\label{CorCritFonsTest}
Soit $f(x)$ une fonction mesurable et positive ou nulle sur $]a,\infty[$ et bornée pour tout $]a,b]$. Nous posons
\begin{equation}
	L(\alpha)=\lim_{x\to\infty}x^{\alpha}f(x),
\end{equation}
et nous supposons qu'elle existe.
\begin{enumerate}
\item Si il existe $\alpha>1$ tel que $L(\alpha)\neq\infty$, alors $\int_a^{\infty}f(x)dx$ existe,
\item Si il existe $\alpha\leq1$ et $L(\alpha)\neq 0$, alors $\int_a^{\infty}f(x)dx$ n'existe pas.
\end{enumerate}
\end{corollary}

\begin{corollary}		\label{CorAlphaLCasInteabf}
	Soit $f\colon ]a,b]\to \eR$ une fonction mesurable, positive ou nulle, et bornée sur $[a+\epsilon,b]$ $\forall\epsilon>0$. Si $\lim_{x\to a}(x-a)^{\alpha}f(x)=L$ existe, alors
	\begin{enumerate}
		\item Si $\alpha<1$ et $L\neq\infty$, alors $\int_a^bf(x)dx$ existe,
		\item Si $\alpha\geq 1$ et $L\neq 0$, alors $\int_a^bf(x)dx$ n'existe pas.
	\end{enumerate}
\end{corollary}

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Intégrales convergentes}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}
    Soit $f$, une fonction mesurable sur $[a,\infty[$, bornée sur tout intervalle $[a,b]$. On dit que l'intégrale
    \begin{equation}
        \int_a^{\infty}f(x)dx
    \end{equation}
    \defe{converge}{intégrale!convergente} si la limite
    \begin{equation}		\label{EqDEfConvergeZeroInftX}
        \lim_{X\to\infty}\int_a^{X}f
    \end{equation}
    existe et est finie.
\end{definition}
