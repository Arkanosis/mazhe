% This is part of Mes notes de mathématique
% Copyright (c) 2011-2013,2015
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Espaces de matrices}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

L'ensemble des matrices est un espace vectoriel. Nous identifions $\eM(n,\eR)$ avec $ \eR^{n^2}$; plus précisément, nous identifions une matrice 
\begin{equation}
    A = (a_{i,j})_{1\leq i \leq n, 1 \leq j \leq n}
\end{equation}
avec le vecteur $x = (x_1, x_2, \dots, x_{n^2}) \in \eR^{n^2}$, où $ a_{i,j} = x_{(n-1)i + j}$. 

\begin{definition}  \label{DefWQNooKEeJzv}
    Un endomorphisme est \defe{normal}{normal!endomorphisme}\index{matrice!normale} si il commute avec son adjoint.
\end{definition}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Connexité par arcs}
%---------------------------------------------------------------------------------------------------------------------------

\begin{lemma}
    Les groupes \( \gU(n)\) et \( \SU(n)\) sont connexes par arcs.
\end{lemma}

\begin{proof}
    Soit \( A\), une matrice unitaire et \( Q\) une matrice unitaire qui diagonalise \( A\). Étant donné que les valeurs propres arrivent par paires complexes conjuguées,
    \begin{equation}
        QAQ^{-1}=\begin{pmatrix}
            e^{i\theta_1}    &       &       &       &   \\  
            &    e^{-i\theta_1}    &       &       &   \\  
            &       &    \ddots    &       &   \\  
            &       &       &    e^{i\theta_r}    &   \\  
            &       &       &       &        e^{-i\theta_r}
        \end{pmatrix}.
    \end{equation}
    Le chemin \( U(t)\) obtenu en remplaçant \( \theta_i\) par \( t\theta_i\) avec \( t\in\mathopen[ 0 , 1 \mathclose]\) joint \( QAQ^{-1}\) à l'identité. Par conséquent \( Q^{-1}U(t)Q\) joint \( A\) à l'unité.
\end{proof}

\begin{theorem}
    Les matrices \wikipedia{fr}{Endomorphisme_normal}{normales}\footnote{Définition \ref{DefWQNooKEeJzv}.} forment un espace connexe par arc.
\end{theorem}

\begin{proof}
    Soit \( A\) une matrice normale, et \( U\) une matrice unitaire qui diagonalise \( A\). Nous considérons \( U(t)\), un chemin qui joint \( \mtu\) à \( U\) dans \( \gU(n)\). Pour chaque \( t\), la matrice
    \begin{equation}
        A(t)=U(t)^{-1} AU(t)
    \end{equation}
    est normale. Nous avons donc trouvé un chemin dans les matrices normales qui joint \( A\) à une matrice diagonale. Il est à présent facile de la joindre à l'identité.

    Toutes les matrices normales étant connexes à l'identité, l'ensemble des matrices normales est connexe.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Densité}
%---------------------------------------------------------------------------------------------------------------------------

\begin{proposition}     \label{PropDigDensVxzPuo}
    Les matrices diagonalisables sont denses dans \( \eM(n,\eC)\).
\end{proposition}
\index{densité!matrices diagonalisables dans \( \eM(n,\eC)\)}

\begin{proof}
    D'après le lemme de Schur \ref{LemSchurComplHAftTq}, une matrice de \( \eM(n,\eC)\) est de la forme
    \begin{equation}
        A=Q\begin{pmatrix}
            \lambda_1    &   *    &   *    \\
              0  &   \ddots    &   *    \\
            0    &   0    &   \lambda_n
        \end{pmatrix}Q^{-1}.
    \end{equation}
    Les valeurs propres sont sur la diagonale. La matrice est diagonalisable si les éléments de la diagonales sont tous différents. Il suffit maintenant de considérer \( n\) suites \( (\epsilon^{(r)}_k)_{k\in\eN}\) convergentes vers zéro telles que pour chaque \( k\) les nombres \( \lambda_r+\epsilon^{(r)}_k\) soient tous différents. La suite de matrices
    \begin{equation}
        A_k=Q\begin{pmatrix}
            \lambda_1+\epsilon^{(1)}_k    &   *    &   *    \\
              0  &   \ddots    &   *    \\
              0    &   0    &   \lambda_n+\epsilon^{(n)}_k
        \end{pmatrix}Q^{-1}.
    \end{equation}
    est alors diagonalisable pour tout \( k\) et nous avons \( \lim_{k\to \infty} A_k=A\).
\end{proof}

\begin{proposition}
    Si \( A\in\eM(n,\eC)\) alors
    \begin{equation}
        e^{\tr(A)}=\det( e^{A}).
    \end{equation}
\end{proposition}

\begin{proof}
    Ici, \( e^A\) est l'exponentielle soit d'endomorphisme soit de matrice définie par la proposition \ref{PropPEDSooAvSXmY}.

    Le résultat est un simple calcul pour les matrices diagonalisable. Si \( A\) n'est pas diagonalisable, nous considérons une suite de matrices diagonalisables \( A_k\) dont la limite est \( A\) (proposition \ref{PropDigDensVxzPuo}). La suite
    \begin{equation}
        a_k= e^{\tr(A_k)}
    \end{equation}
    converge vers \(  e^{\tr(A)}\) tandis que la suite 
    \begin{equation}
        b_k=\det( e^{A_k})
    \end{equation}
    converge vers \( \det( e^{A})\). Mais nous avons \( a_k=b_k\) pour tout \( k\); les limites sont donc égales.
\end{proof}

\begin{theorem}[Cayley-Hamilton\cite{QATooFIHVMw,MOSooRVRrHw}]  \label{ThoHZTooWDjTYI}
    Tout endomorphisme d'un espace vectoriel de dimension finie sur un corps commutatif quelconque annule son propre polynôme caractéristique
\end{theorem}
\index{théorème!Cayley-Hamilton}
% position EYRooJkxiFf

Une autre démonstration est donnée en le théorème \ref{ThoCalYWLbJQ}.
\begin{proof}
    La preuve est divisée en plusieurs étapes.
    \begin{subproof}
        \item[Endomorphisme diagonalisable]
            Soit \( u\) un endomorphisme sur un espace vectoriel \( V\) de dimension \( n\) sur un corps \( \eK\) et \( \chi_u\) sont polynôme caractéristique. Nous savons que si \( \lambda\) est une valeur propre de \( u\) alors \( \chi_u(\lambda)=0\) le théorème \ref{ThoWDGooQUGSTL}\ref{ItemeXHXhHii}. En combinant avec le lemme \ref{LemVISooHxMdbr}, si \( x\) est vecteur propre pour la valeur propre \( \lambda\) de \( u\) nous avons
            \begin{equation}
                \chi_u(u)x=\chi_u(\lambda)x=0.
            \end{equation}
            Donc tant que \( u\) possède une base de vecteurs propres nous avons \( \chi_u(u)=0\).

        \item[Le cas complexe]

            Nous nous restreignons à présent (et provisoirement) au cas \( \eK=\eC\), ce qui nous donne \( u\in \eM(n,\eC)\). Les matrices diagonalisables sont denses dans \( \eM(n,\eC)\) par la proposition \ref{PropDigDensVxzPuo}. Si \( A\in \eM(n,\eC)\) nous considérons une suite de matrices diagonalisables \( A_k\stackrel{\eM(n,\eC)}{\longrightarrow}A\). Pour chaque \( k\) nous avons par le point précédent 
            \begin{equation}
                \chi_{u_k}(u_k)=0.
            \end{equation}
            Chacune des composantes de \( \chi_{u_k}(u_k)\) est un polynôme en les composantes de \( u_k\), ce qui légitime le passage à la limite :
            \begin{equation}
                \chi_u(u)=0.
            \end{equation}
            Le théorème est établi pour toutes les matrices de \( \eM(n,\eC)\) et donc aussi pour tous les sous-corps de \( \eC\) comme \( \eR\) ou \( \eZ\).

        \item[La cas général]

            Par définition, \( \chi_u(X)=\det(u-X\mtu)\); les coefficients de \( X\) sont des polynômes à coefficients entiers en les composantes de \( u\). En substituant \( u\) à \( X\) nous obtenons une matrice dont chacune des entrées est un polynôme à coefficients entiers en les coefficients de \( u\). Pour chaque \( i\) et \( j\) entre \( 1\) et \( n\) il existe donc un polynôme \( P_{ij}\in \eZ(X_1,\ldots, X_{n^2})\) tel que
            \begin{equation}
                \chi_u(u)_{ij}=P(u_{11},\ldots, u_{nn}).
            \end{equation}
            Ces polynômes ne dépendent pas de \( u\) ni du corps sur lequel on travaille. Notre but est maintenant de prouver que \( P_{ij}=0\).

            Étant donné que le cas complexe (et a fortiori entier) est déjà prouvé nous savons que pour tout \( u\in \eM(n,\eZ)\) nous avons \( P(u_{11},\ldots, u_{nn})=0\). La proposition \ref{PropTETooGuBYQf} nous donne effectivement \( P=0\), en conséquence de quoi l'endomorphisme \( \chi_u(u)\) est nul.

    \end{subproof}
\end{proof}

\begin{example}
    Pour montrer que chaque composante \( \chi_u(u)\) est bien un polynôme à coefficients entiers en les coefficients de \( u\), voyons l'exemple \( 2\times 2\) : \( u=\begin{pmatrix}
        a    &   b    \\ 
        c    &   d    
    \end{pmatrix}\). D'abord
    \begin{equation}
        \chi_u(X)=\det\begin{pmatrix}
            a-X    &   b    \\ 
            c    &   d-X    
        \end{pmatrix}=X^2-(a+d)X+ad-cb.
    \end{equation}
    Le coefficient de \( X^2\) est \( 1\), celui de \( X\) est \( -a-d\) et le terme indépendant est \( ad-cb\); tout trois sont des polynômes à coefficients entiers en \( a,b,c,d\). Après substitution de \( X\) par \( u\), 
    \begin{equation}
        \chi_u(u)_{ij}=(u^2)_{ij}-(a+d)u_{ij}+ad-cb.
    \end{equation}
    Cela est bien un polynôme à coefficients entiers en les entrées de la matrice \( u\).
\end{example}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Racine carré d'une matrice hermitienne positive}
%---------------------------------------------------------------------------------------------------------------------------

\begin{proposition}     \label{PropVZvCWn}
    Si \( A\in \eM(n,\eC)\) est une matrice hermitienne positive, alors il existe une unique matrice hermitienne positive \( R\) telle que \( A=R^2\). De plus \( R\) est un polynôme (de \( \eR[X]\)) en \( A\).
\end{proposition}
\index{matrice!semblable}
\index{polynôme!d'endomorphisme}
\index{endomorphisme!diagonalisable}
\index{matrice!hermitienne!racine carré}
\index{racine!carré!de matrice hermitienne}

La matrice \( R\) ainsi définie est la \defe{racine carré de}{matrice!racine carré}\index{racine!carré de matrice!hermitienne positive} de \( A\), et est notée \( \sqrt{A}\)\nomenclature[A]{\( \sqrt{A}\)}{racine d'une matrice hermitienne positive}. Une des applications usuelles de cette proposition est la décomposition polaire.

\begin{proof}
    \begin{subproof}
    \item[Existence]
        Étant donné que \( A \) est hermitienne, elle est diagonalisable par une unitaire (proposition \ref{ThogammwA}), et ses valeurs propres sont réelles et positives (parce que \( A\) est positive). Soit donc \( P\) une matrice unitaire telle que
        \begin{equation}
            P^*AP=\begin{pmatrix}
                \alpha_1    &       &       \\
                    &   \ddots    &       \\
                    &       &   \alpha_n
            \end{pmatrix}
        \end{equation}
        avec \( \alpha_i>0\). Si on pose
        \begin{equation}
            R=P\begin{pmatrix}
                \sqrt{\alpha_1}    &       &       \\
                    &   \ddots    &       \\
                    &       &   \sqrt{\alpha_n}
            \end{pmatrix}P^*,
        \end{equation}
        alors \( R^2=A\) parce que \( P^*P=\mtu\).
    \item[Hermitienne positive]
        La matrice \( R\) est hermitienne parce que, avec un peu de notation raccourcie, \( R=P^*\sqrt{\alpha}P\) et \( R^*=P^*\sqrt{\alpha}P\). D'autre part, elle est positive parce que ses valeurs propres sont les \( \sqrt{\alpha_i}\) qui sont positives.
        
    \item[Polynôme]
        Nous montrons maintenant que la matrice \( R\) est un polynôme en \( A\). Pour cela nous considérons un polynôme \( Q\) tel que \( A(\alpha_i)=\sqrt{\alpha_i}\) pour tout \( i\). Soit \( \{ e_i \}\) une base de diagonalisation de \( A\) : \( Ae_i=\alpha_ie_i\). Alors c'est encore une base de diagonalisation de \( Q(A)\). En effet si \( Q=\sum_ka_kX^k\), alors
        \begin{equation}
            Q(A)e_i=(\sum_ka_kA^k)e_i=(\sum_ka_k\alpha_i^k)e_i=Q(\alpha_i)e_i=\sqrt{\alpha_i}e_i.
        \end{equation}
        Les valeurs propres de \( Q(A)\) sont donc \( \sqrt{\alpha_i}\). Nous savons maintenant que \( Q(A)\) a la même base de diagonalisation de \( A\) (et donc la même matrice unitaire \( P\) qui diagonalise), c'est à dire que
        \begin{equation}
            Q(A)=P^*\begin{pmatrix}
                \sqrt{\alpha_1}    &       &       \\
                    &   \ddots    &       \\
                    &       &   \sqrt{\alpha_n}
            \end{pmatrix}=R.
        \end{equation}
        Donc oui, \( R\) est un polynôme en \( A\).

        Notons que ce \( Q\) n'est pas du tout unique; il existe une infinité de polynômes qui envoient \( n\) nombres donnés sur \( n\) nombres donnés.

    \item[Unicité]
        Soit \( S\) une matrice hermitienne positive telle que \( R^2=S^2=A\). D'abord \( S\) commute avec \( A\) parce que
        \begin{equation}
            SA=S^3=S^2S=AS.
        \end{equation}
        Donc \( S\) commute aussi avec \( Q(A)=R\). Étant donné que \( S\) et \( R\) commutent et sont diagonalisables, ils sont simultanément diagonalisables par le corollaire \ref{CorQeVqsS}. Soient \( D_R=PRP^*\) et \( D_S=PSP^*\) les formes diagonales de \( R\) et \( S\) dans une base de simultanée diagonalisation. Les carrés des valeurs propres de \( R\) et \( S\) étant identiques (ce sont les valeurs propres de \( A\)) et les valeurs propres de \( R\) et \( S\) étant positives, nous déduisons que \( D_R=D_S\) et donc que \( R=P^*D_RP=P^*D_SP=S\).
    \end{subproof}
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Racine carré d'une matrice symétrique positive}
%---------------------------------------------------------------------------------------------------------------------------

\begin{lemma}[\cite{JJdQPyK}]   \label{LemTLlTAAf}
    Le groupe orthogonal \( O(n,\eR) \) est compact.
\end{lemma}

\begin{proof}
    Nous avons \( O(n)=f^{-1}\big( \{ \mtu_n \} \big)\) où \( f\) est l'application continue \( A\mapsto A^tA\). En tant qu'image inverse d'un fermé par une application continue, le groupe \( O(n)\) est fermé.

    De plus il est borné parce que tous les coefficients d'une matrice orthogonale sont \( \leq 1\), donc \( \| A \|_{\infty}\) pour tout \( A\in O(n)\).
\end{proof}

\begin{proposition} \label{PropPEMDqVT}
    Une matrice symétrique semi (ou pas) définie positive admet une unique racine carré symétrique. Le spectre de la racine carré est la racine carré du spectre de la matrice de départ.
\end{proposition}

\begin{proof}
    Ceci est une phrase pour que les titres se mettent bien.
    \begin{subproof}
        \item[Existence]
            Soit \( T\) une matrice symétrique et \( Q\) une matrice orthogonale qui diagonalise\footnote{Théorème \ref{ThoeTMXla}.} \( T\) : \( QTQ^{-1}=D\) avec \( D=\diag(\lambda_i)\) et \( \lambda_i\geq 0\). En posant \( R=Q^{-1}\sqrt{D}Q\), il est vite vérifié que \( R^2=T\) et que \( R\) est symétrique. En ce qui concerne le spectre, \( R\) a pour valeurs propres les \( \sqrt{\lambda_i}\).
        \item[Unicité]

            Soit \( R\) une matrice symétrique de \( T\) : \( R^2=T\). Du coup \( R\) et \( T\) commutent : \( RT=R^3=TR\). Par conséquent les espaces propres de \( T\) sont stables sous \( R\). Soit \( E_{\lambda} \) l'un d'eux de dimension \( d\), et \( T_F\), \( R_F\) les restrictions de \( T\) et \( R\) à \( E_{\lambda}\). L'application \( T_F\) est une homothétie et \( R_F^2=T_F=\lambda\mtu\). Mais \( R_F\) est encore une matrice symétrique définie positive, donc nous pouvons considérer une base \( \{ e_1,\ldots, e_d \}\) de \( E_{\lambda}\) qui diagonalise \( R_F\) avec les valeurs propres \( \mu_i\); nous avons donc en même temps
            \begin{subequations}
                \begin{align}
                    R_f^2(e_i)&=\mu_i^2 e_i\\
                    T_F(e_i)&=\lambda e_i,
                \end{align}
            \end{subequations}
            de telle sorte que \( \mu_i^2=\lambda\). Mais les valeurs propres de \( R_F\) sont positives, sont \( \mu_i=\sqrt{\lambda}\) pour tout \( i\). En conclusion \( R_F\) est univoquement déterminé par la donnée de \( T\). Vu que cela est valable pour tous les espaces propres de \( T\) et que ces espaces propres engendrent tout \( E\), l'opérateur \( R\) est déterminé de façon univoque par \( T\).
    \end{subproof}
\end{proof}
Notons que nous n'avons démontré l'unicité qu'au sein des matrices symétriques.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Décomposition polaires : cas réel}
%---------------------------------------------------------------------------------------------------------------------------

Nous nommons \( S^+(n,\eR)\) l'ensemble des matrices \( n\times n\) symétriques réelles définies positives et \( S^{++}(n,\eR)\) le sous-ensemble de \( S^+(n,\eR)\) des matrices strictement définies positives.
\nomenclature[B]{\( S^+(n,\eR)\)}{matrices symétriques définies positives}
\nomenclature[B]{\( S^{++}(n,\eR)\)}{matrices symétriques strictement définies positives}

\begin{lemma}   \label{LemMGUSooPqjguE}
    La partie \( S^+(n,\eR)\) est fermée dans \( \eM(n,\eR)\).
\end{lemma}

\begin{proof}
    En effet si \( S_k\) est une suite de matrices symétriques convergeant dans \( \eM(n,\eR)\) vers la matrice \( A\), les suites \( (S_k)_{ij}\) et \( (S_k)_{ji}\) des composantes \( ij\) et \( ji\) sont des suites égales, et donc leurs limites sont égales\footnote{Ici nous utilisons le critère de convergence composante par composante et le fait que nous ne sommes pas trop inquiétés par la norme que nous choisissons parce que toutes les normes sont équivalentes par le théorème \ref{ThoNormesEquiv}.}. Donc la limite est symétrique.

    En ce qui concerne le spectre, le théorème \ref{ThoeTMXla} nous permet de diagonaliser : \( S_k=Q_kD_kQ_k^{-1}\) où les \( D_k\) sont des matrices diagonales remplies de nombres positifs ou nuls. Vu que \( O(n)\) est compact\footnote{Lemme \ref{LemTLlTAAf}.}, nous avons une sous-suite \( Q_{\varphi(k)}\) convergente : \( Q_{\varphi(k)}\to Q\). Pour chaque \( k\), nous avons
    \begin{equation}
        S_{\varphi(k)}=Q_{\varphi(k)}D_{\varphi(k)}Q^{-1}_{\varphi(k)},
    \end{equation}
    dont la limite existe et vaut \( A\). Vu que pour tout \( k\), \( D_{\varphi(k)}=Q^{-1}_{\varphi(k)}S_{\varphi(k)}Q_{\varphi(k)}\) et que le produit matriciel est continu, la suite \( k\mapsto D_{\varphi(k)}\) est une suite convergente dans \( \eM(n,\eR)\). Nous notons \( D\) sa limite qui est encore une matrice diagonale contenant des nombres positifs ou nuls sur la diagonale.
    \begin{equation}
        A=\lim_{k\to \infty } S_{\varphi(k)}=QDQ^{-1},
    \end{equation}
    et donc le spectre de \( A\) est la limite de ceux des matrices \( D_{\varphi(k)}\). Chacun étant positif, la limite est positive. Donc \( A\in S^+(n,\eR)\).
\end{proof}

\begin{lemma}   \label{LemZKJWqIP}
    La fermeture de l'ensemble des matrice symétriques strictement définies positives est l'ensemble des matrices définies positives : \( \overline{ S^{++}(n,\eR) }=S^+(n,\eR)\).
\end{lemma}

\begin{proof}
    Le lemme \ref{LemMGUSooPqjguE} nous a à peine dit que \( S^+(n,\eR)\) était fermé. Nous devons prouver que pour tout élément de \( S^+(n,\eR)\), il existe une suite \( (S_k)\) dans \( S^{++}(n,\eR)\) convergeant vers \( S\).

    Si \( S\in S^+(n,\eR)\) alors nous avons la diagonalisation
    \begin{equation}
        S=QDQ^{-1} =Q
        \begin{pmatrix}
            \lambda_1    &       &       \\
                &   \ddots    &       \\
                &       &   \lambda_n
        \end{pmatrix}
        Q^{-1}
    \end{equation}
    où \( \lambda_i\geq 0\) pour tout \( i\). Nous définissons
    \begin{equation}
        D_k=
        \begin{pmatrix}
            \lambda_1+\epsilon^{(1)}_k    &       &       \\
                &   \ddots    &       \\
                &       &   \lambda_n+\epsilon^{(n)}_k
        \end{pmatrix}
    \end{equation}
    où \( \epsilon^{i}_k\) est une suite convergent vers \( 0\) telle que \( \lambda_i+\epsilon^{(i)}_n>0\) pour tout \( n\). Typiquement si \( \lambda_i>0\) alors \( \epsilon^{(i)}_k=0\) et sinon \( \epsilon^{(i)}_k=1/k\).

    Pour tout \( k\) nous avons \( QD_kQ^{-1}\in S^{++}(n,\eR)\) et de plus \( QD_kQ^{-1}\to QDQ=S\).
\end{proof}

\begin{theorem}[Décomposition polaire de matrices symétriques définies positives\cite{JJdQPyK,AABkVai,WWBTooITOwEn}] \label{ThoLHebUAU}
   En ce qui concerne les matrices inversibles :
   \begin{equation}
       \begin{aligned}
           f\colon O(n,\eR)\times S^{++}(n,\eR)&\to \GL(n,\eR) \\
           (Q,S)&\mapsto SQ 
       \end{aligned}
   \end{equation}
   est un difféomorphisme\footnote{Définition \ref{DefAQIQooYqZdya}.}.

   En ce qui concerne les matrices en général :
   \begin{equation}
       \begin{aligned}
           g\colon O(n,\eR)\times S^+(n,\eR)&\to \eM(n,\eR) \\
           (Q,S)&\mapsto SQ 
       \end{aligned}
   \end{equation}
   est une surjection mais pas une injection.

   De plus les mêmes conclusions tiennent si nous regardons \( (Q,S)\mapsto QS\) au lieu de \( SQ\).
\end{theorem}
\index{groupe!linéaire!décomposition polaire}
\index{endomorphisme!décomposition!polaire}
\index{décomposition!polaire}

%TODO : prouver le difféomorphisme.
%TODO : je crois qu'on doit pouvoir prouver que les éléments de la décomposition polaire sont des polynômes en M.

\begin{proof}
    Nous commençons par prouver les résultats concernant les matrices inversibles.
    \begin{subproof}
        \item[Existence et unicité]

            Si \( M=SQ\), alors \( MM^t=SQQ^tS^t=S^2\), donc \( S\) doit être une racine carré symétrique de la matrice définie positive \( MM^t\). La proposition \ref{PropPEMDqVT} nous dit que ça existe et que c'est unique. Donc \( S\) est univoquement déterminé par \( M\). Maintenant avoir \( Q=MS^{-1}\) est obligatoire (unicité) et fonctionne :
            \begin{equation}
                Q^tQ=(S^{-1})^tM^tMS^{-1}=S^{-1}S^2S^{-1}=\mtu,
            \end{equation}
            donc \( Q\) ainsi défini est orthogonale.

            Notons que ceci ne fonctionne pas lorsque \( M\) n'est pas inversible parce qu'alors \( S\) n'est pas inversible.
        
        \item[Homéomorphisme]

            Le fait que \( f\) soit continue n'est pas un problème : c'est un produit de matrice. Nous devons vérifier que \( f^{-1}\) est continue. Soit une suite convergente \( M_k\to M\) dans \( \GL(n,\eR)\). Si nous nommons \( (Q_k,S_k)\) la décomposition polaire de \( M_k\) et \( (Q,S)\) celle de \( M\), nous devons prouver que \( Q_k\to Q\) et \( S_k\to S\). En effet dans ce cas nous aurions
            \begin{equation}    \label{EqJIkoaJv}
                \lim_{k\to \infty} f^{-1}(M_k)=\lim_{k\to \infty} (Q_k,S_k)=(Q,S)=f^{-1}(M).
            \end{equation}
            
            Étant donné que \( O(n)\) est compact (lemme \ref{LemTLlTAAf}), la suite \( (Q_k)\) admet une sous-suite convergente (Bolzano-Weierstrass, théorème \ref{ThoBWFTXAZNH}) que nous nommons
            \begin{equation}
                Q_{\varphi(k)}\to F\in O(n).
            \end{equation}
            Vu que la suite \( (M_k)\) converge, sa sous-suite converge vers la même limite : \( M_{\varphi(k)}\to M\) et vu que pour tout \( k\) nous avons \( S_k=M_kQ_k^{-1}\),
            \begin{equation}
                S_{\varphi(k)}\to G=MF^{-1}.
            \end{equation}
            Vu que chacune des matrices \( S_{\varphi(k)}\) est symétrique définie positive, la limite est symétrique et semi-définie positive\footnote{Lemme \ref{LemZKJWqIP}}. Donc \( G\in S^+(n,\eR)\cap \GL(n,\eR)\) parce que de plus \( M\) et \( F\) étant inversibles, \( G\) est inversible. En ce qui concerne la sous-suite nous avons
            \begin{equation}
                M_{\varphi(k)}=S_{\varphi(k)}Q_{\varphi(k)}\to GF=M
            \end{equation}
            où \( F\in O(n)\) et \( G\in S^+(n,\eR)\). Par unicité de la décomposition polaire de \( M\) (partie déjà démontrée), nous avons \( G=S\) et \( F=Q\).

            Nous avons prouvé que toute sous-suite convergente de \( Q_k\) a \( Q\) pour limite. Donc la suite elle-même converge\footnote{Proposition \ref{PropHNylIAW}, pas difficile.} vers \( Q\). Donc \( Q_k\to Q\). Du coup vu que \( S_k=M_kQ_k^{-1}\) est un produit de suites convergentes, \( S_k\) converge également, vers \( S\) :  \( S_k\to S\).

            Au final l'application \( f^{-1}\) est bien continue parce que les égalités \eqref{EqJIkoaJv} ont bien lieu.
    \end{subproof}

    Nous passons maintenant à la preuve dans le cas des matrices en général.

    

\end{proof}

\begin{definition}
    Sur \( C\) est un ensemble convexe, un point \( x\in C\) est un \defe{point extrémal}{extrémal!point dans un convexe} si \( C\setminus\{ x \}\) est encore convexe.
\end{definition}

\begin{theorem}[\cite{KXjFWKA}] \label{ThoBALmoQw}
    Soit \( E\) un espace euclidien de dimension \( n\geq 1\) et \( \aL(E)\) l'espace des opérateurs linéaires sur \( E\) sur lequel nous considérons la norme subordonnée\footnote{Voir la définition donnée dans l'exemple \ref{ExemdefnormpMrt}.} à celle sur \( E\). L'ensemble des points extrémaux de la boule unité fermée de \( \aL(E)\) est le groupe orthogonal \( O(n,\eR)\).
\end{theorem}
\index{densité!points extrémaux dans \( \aL\)}

\begin{proof}
    Nous notons \( \mB\) la boule unité fermée de \( \aL(E)\). Montrons pour commencer que les éléments de \( O(n)\) sont extrémaux dans \( \mB\). D'abord si \( A\in O(E)\) alors \( \| A \|=1\) parce que \( \| Ax \|=\| x \|\). Supposons maintenant que \( A\) n'est pas extrémal, c'est à dire qu'il est le milieu d'un segment joignant deux points (distincts) de la boule unité de \( \aL(E)\). Soient donc \( T,U\in\mB\) tels que \( A=\frac{ 1 }{2}(T+U)\). Pour tout \( x\in E\) tel que \( \| x \|=1\) nous avons 
    \begin{equation}    \label{EqKTuAIIE}
        1=\| x \|=\| Ax \|=\frac{ 1 }{2}\| Tx+Ux \|\leq \frac{ 1 }{2}\big( \| Tx \|+\| Ux \| \big)\leq\frac{ 1 }{2}\big( \| T \|+| U | \big)\leq 1
    \end{equation}
    Toutes les inégalités sont en réalité des égalités. En particulier nous avons
    \begin{equation}
        \| Tx+Ux \|=\| Tx \|+\| Ux \|,
    \end{equation}
    mais alors nous sommes dans un cas d'égalité dans l'inégalité de Cauchy-Schwartz (théorème \ref{ThoAYfEHG}) et donc il existe \( \lambda\geq 0\) tel que \( Tx=\lambda Ux\). Mais de plus les \sout{inégalité} égalités \eqref{EqKTuAIIE} nous donnent
    \begin{equation}
        \frac{ 1 }{2}\big( \| Tx \|+\| Ux \| \big)=1
    \end{equation}
    alors que nous savons que \( \| Tx \|,\| Ux \|\leq 1\), donc \( \| Tx \|=\| Ux \|=1\). La seule possibilité est d'avoir \( \lambda=1\) et donc que \( U=T\) parce que nous avons \( Tx=Ux\) pour tout \( x\) de norme \( 1\). Au final \( A\) n'est pas le milieu d'un segment dans \( \mB\).

    Nous passons donc à l'inclusion inverse : nous prouvons que les points extrémaux de \( \mB\) sont dans \( O(E)\). Pour cela nous prenons \( U\in\mB\setminus O(E)\) et nous allons montrer que \( U\) n'est pas un point extrémal : nous allons l'écrire comme milieu d'un segment dans \( \mB\).

    Par la seconde partie du théorème de décomposition polaire \ref{ThoLHebUAU}, il existe \( Q\in O(n,\eR)\) et \( S\in S^+(n,\eR)\) tels que \( U=QS\). Nous diagonalisons \( S\) à l'aide de la matrice orthogonale \( P\) :
    \begin{equation}
        S=PDP^{-1}
    \end{equation}
    avec \( D=\diag(\lambda_i)\). En termes de normes, nous avons
    \begin{equation}
        \| U \|=\| S \|=\| S \|.
    \end{equation}
    En effet vu que \( Q\) est orthogonale, \( \| Ux \|=\| QSx \|=\| Sx \|\) pour tout \( x\), donc \( \| U \|=\| S \|\). De plus pour tout \( x\) nous avons
    \begin{equation}
        \| Sx \|=\| PDP^{-1} x \|=\| DP^{-1}x \|.
    \end{equation}
    Étant donné que \( P^{-1}\) est une bijection, le supremum des \( \| Sx \|\) sera le même que celui des \( \| Dx \|\) et donc \( \| S \|=\| D \|\). Étant donné que par définition \( \| U \|\leq 1\), nous avons aussi \( \| D \|\leq 1\) et donc \( 0\leq\lambda_i\leq 1\) (pour rappel, les valeurs propres de \( D\) sont positives ou nulles parce que \( S\) est ainsi). 

    Comme \( U\notin O(E)\), au moins une des valeurs propres n'est pas \( 1\), supposons que ce soit \( \lambda_1\). Alors nous avons \( \alpha,\beta\in\mathopen[ -1 , 1 \mathclose]\) avec \( -1\leq \alpha<\beta\leq 1\) et \( \lambda_1=\frac{ 1 }{2}(\alpha+\beta)\). Nous posons alors
    \begin{subequations}
        \begin{align}
            D_1=\diag(\alpha,\lambda_2,\ldots, \lambda_n)\\
            D_2=\diag(\beta,\lambda_2,\ldots, \lambda_n).
        \end{align}
    \end{subequations}
    Nous avons bien \( D_1\neq D2\) et \( D_1+ D_2=D\). Par conséquent
    \begin{equation}
        U=\frac{ 1 }{2}\big( QPD_1P^{-1}+QPD_2P^{-1} \big)
    \end{equation}
    avec \( QPD_1P^{-1}\neq QPD_2^{-1}\). La matrice \( U \) est donc le milieu d'un segment. Reste à montrer que ce segment est dans \( \mB\). Pour ce faire, prenons \( x\in E\) et calculons :
    \begin{equation}
        \| QPD_iP^{-1}x \|=\| D_iP^{-1}x \|\leq\| P^{-1}x \|=\| x \|
    \end{equation}
    parce que \( \| D_i \|\leq 1\) et \( P^{-1}\) est orthogonale. Au final la norme de \( QPD_iP\) est plus petite que \( 1\) et donc \( U\) est bien le milieu d'un segment dans \( \mB\), et donc non extrémal.
\end{proof}

\begin{theorem}[\cite{NHXUsTa}] \label{ThoVBzqUpy}
    L'enveloppe convexe de \( O(n)\) dans \( \eM_n(\eR)\) est la boule unité pour la norme induite de \( \| . \|_2\) sur \( \eR^n\).
\end{theorem}
\index{convexité!enveloppe de $O(n)$}
\index{groupe!linéaire!enveloppe convexe de $\Omega(n)$}

\begin{proof}
    Nous notons \( \mB\) la boule unité fermée de \( \eM(n,\eR)\) et \( \Conv\big( O(n,\eR) \big)\) l'enveloppe convexe de \( O(n,\eR)\). Vu que \( \mB\) est convexe nous avons \( \Conv\big( O(n) \big)\subset\mB\).


    Maintenant nous devons prouver l'inclusion inverse. Pour ce faire nous supposons avoir un élément \( A\in \mB\setminus\Conv\big( O(n) \big)\) et nous allons dériver une contradiction.
    
    Remarquons que \( O(n)\) est compact par le lemme \ref{LemTLlTAAf} et que par conséquent \( \Conv(O(n))\) est compacte par le corollaire \ref{CorOFrXzIf} et donc fermée. Nous considérons un produit scalaire \( (X,Y)\mapsto X\cdot Y\) sur \( \eM\). Vu que \( \Conv\big( O(n) \big)\) est un fermé convexe nous pouvons considérer la projection\footnote{Le théorème de projection : théorème \ref{ThoWKwosrH}.} sur \( \Conv(A)\) relativement au produit scalaire choisis.

    Nous notons \( P=\pr_{\Conv\big( O(n) \big)}(A)\). En vertu du théorème de projection, nous avons
    \begin{equation}    \label{EqYSisLTL}
        (A-P)\cdot (M-P)\leq 0
    \end{equation}
    pour tout \( M\in\Conv O(n)\). Notons \( B=A-P\) pour alléger les notations. L'équation \eqref{EqYSisLTL} s'écrit
    \begin{equation}    \label{EqQDLZqXQ}
        B\cdot M\leq B\cdot P.
    \end{equation}
    D'autre par vu que \( B \neq 0\) nous avons \( B\cdot B> 0\), c'est à dire \( B\cdot (A-P)>0\) et donc
    \begin{equation}
        B\cdot A>B\cdot P.
    \end{equation}
    En combinant avec \eqref{EqQDLZqXQ},
    \begin{equation}        \label{EqIQNlwql}
        B\cdot M\leq B\cdot P<B\cdot A.
    \end{equation}
    Nous utilisons maintenant la décomposition polaire, théorème \ref{ThoLHebUAU}, pour écrire \( B=QS\) avec \( Q\in O(n)\) et \( S\in S^+(n,\eR)\). Vu que l'inégalité \eqref{EqIQNlwql} tient pour tout \( M\in\Conv(O(n))\), elle tient en particulier pour \( Q\in O(n)\). Donc
    \begin{equation}
        B\cdot Q=B\cdot A.
    \end{equation}
    Nous nous particularisons à présent au produit scalaire \( (X,Y)\mapsto\tr(X^tY)\) de la proposition \ref{PropMAQoKAg}. D'abord
    \begin{equation}    \label{EaHVxWdau}
        B\cdot Q=\tr(B^tQ)=\tr(S^tQ^tQ)=\tr(S^t)=\tr(S),
    \end{equation}
    et ensuite l'inégalité \eqref{EaHVxWdau} devient
    \begin{equation}
        \tr(S)<B\cdot A=\tr(S^tQ^tA).
    \end{equation}
    Nous choisissons une basse \( \{ e_i \}\) diagonalisant \( S\) : \( Se_i=\lambda_ie_i\) vérifiant automatiquement \( \lambda_i\geq 0\) parce que \( S\) est semi-définie positive\footnote{Définition \ref{DefAWAooCMPuVM}.}. Alors
    \begin{subequations}
        \begin{align}
            \tr(S)&<\tr(S^tQ^tA)\\
            &=\sum_i\langle S^tQ^tAe_i, e_i\rangle \\
            &=\sum_i\langle Ae_i, QSe_i\rangle \\
            &\leq \sum_i \| Ae_i \| | \lambda_i | \underbrace{\| Qe_i \|}_{=1} \\
            &\leq \sum_i\lambda_i   & A\in\mB\Rightarrow\| Ae_i \|\leq 1\\
            &=\tr(S).
        \end{align}
    \end{subequations}
    Il faut noter que la première inégalité est stricte, et donc nous avons une contradiction.
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Sous-groupes du groupe linéaire}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{lemma}[\cite{KXjFWKA}]       \label{LemOCtdiaE}
    Soit \( V\) un espace vectoriel de dimension finie muni d'une norme euclidienne \( \| . \|\). Soit \( K\) un compact convexe de \( V\) et \( G\), un sous groupe compact de \( \GL(V)\) tel que
    \begin{equation}
        u(K)\subset K
    \end{equation}
    pour tout \( u\in G\). Alors il existe \( a\in K\) tel que \( u(a)=a\) pour tout \( u\in G\).
\end{lemma}
\index{groupe!linéaire!sous-groupes compacts}
\index{compacité!sous-groupes du groupe linéaire}

\begin{proof}
    Avant de nous lancer dans la preuve, nous avons besoin d'un petit résultat.
    \begin{subproof}
        \item[Un pré-résultat]

        Nous commençons par prouver que si \( v\in \aL(V)\) vérifie \( v(K)\subset K\), alors \( v\) a un point fixe dans \( K\). Pour cela nous considérons \( x_0\in K\) et la suite
        \begin{equation}
            x_k=\frac{1}{ k+1 }\sum_{i=0}^kv^i(x_0).
        \end{equation}
        Étant donné que \( K\) est convexe et stable par \( v\), la suite \( (x_k)\) est contenue dans \( K\) et accepte une sous-suite convergente\footnote{C'est Bolzano-Weierstrass, théorème \ref{ThoBWFTXAZNH}.} que nous allons noter \( x_{\varphi(n)}\) avec \( \varphi\colon \eN\to \eN\) strictement croissante. Soit \( a\in K\) la limite :
        \begin{equation}
            \lim_{n\to \infty} x_{\varphi(n)}=a.
        \end{equation}
        Tant que nous y sommes nous pouvons aussi calculer \( v(x_k)\) :
        \begin{subequations}
            \begin{align}
                v(x_k)&=v\left( \frac{1}{ k+1 }\sum_{i=1}^kv^i(x_0) \right)\\
                &=\frac{1}{ k+1 }\sum_{i=0}^kv^{i+1}(x_0)\\
                &=x_k+\frac{1}{ k+1 }\Big( v^{k+1}(x_0)-x_0 \Big).      \label{EqUAfcaKG}
            \end{align}
        \end{subequations}
        La norme \( \| v^{k+1}(x_0)-x_0 \|\) est bornée par le diamètre de \( K\), donc en prenant la limite \( k\to \infty\) le second terme de \eqref{EqUAfcaKG} tend vers zéro. En prenant ces égalités en \( k=\varphi(n)\) et en prenant \( n\to\infty\), nous trouvons
        \begin{equation}
            v(a)=a,
        \end{equation}
        c'est à dire le résultat que nous voulions dans un premier temps.

    \item[Une norme sur \( V\)]

        Nous passons maintenant à la preuve du lemme. D'abord nous remarquons que le groupe \( G\) agit sur \( V\) par \( u\cdot x=u(x)\) et de plus, considérant la fonction continue
        \begin{equation}
            \begin{aligned}
                \alpha\colon G&\to V \\
                u&\mapsto u(x), 
            \end{aligned}
        \end{equation}
        nous voyons que les orbites de cette action sont compactes en tant qu'image par \( \alpha\) du compact \( G\) (théorème \ref{ThoImCompCotComp}). Nous posons
        \begin{equation}
            \begin{aligned}
                \nu\colon V&\to \eR^+ \\
                x&\mapsto \max_{u\in G}\| u(x) \|. 
            \end{aligned}
        \end{equation}
        Cette définition a un sens parce que l'orbite \( \{ u(x)\tq u\in G \}\) est compacte dans \( V\) et donc l'ensemble des normes est compact dans \( \eR\) et admet un maximum. De plus cela donne une norme sur \( V\) parce que nous vérifions les conditions de la définition \ref{DefNorme} :
        \begin{enumerate}
            \item
                Pour tout \( x,y\in V\) nous avons :
                \begin{equation}
                    \nu(x+y)=\max_{u\in G}\| u(x)+u(y) \|\leq \max_{u\in G}\left( \| u(x) \|+\| u(y) \| \right)\leq \nu(x)+\nu(y).
                \end{equation}
            \item
                Si \( \nu(x)=0\), alors l'égalité \( \max_{u\in G}\| u(x) \|=0\) nous enseigne que \( \| u(x) \|=0\) pour tout \( u\in G\) et donc en particulier avec \( u=\id\) nous trouvons \( x=0\).
            \item
                Pour tout \( \lambda\in \eR\) et \( x\in V\),
                \begin{equation}
                    \nu(\lambda x)=\max_{u\in G}\| u(\lambda x) \|=\max\| \lambda u(x) \|=\max| \lambda |\| u(x) \|=| \lambda |\nu(x).
                \end{equation}
        \end{enumerate}
        De plus la fonction \( \nu\) est constante sur les orbites de \( G\).

    \item[Un point fixe]

        Pour tout \( u\in G\) nous posons
        \begin{equation}
            F_u=\{ x\in K\tq u(x)=x \};
        \end{equation}
        par le pré-résultat, aucun de ces ensembles n'est vide. Ils sont de plus tous fermés par continuité de \( u\) (le complémentaire est ouvert). Nous devons prouver que \( \bigcap_{u\in G}F_u\neq \emptyset\) parce qu'une intersection serait un point fixe de tous les éléments de \( G\). Supposons donc que \( \bigcap_{u\in G}F_u=\emptyset\). Alors les complémentaires des \( F_u\) forment un recouvrement ouvert de \( K\) et nous pouvons en extraire un sous-recouvrement fini par compacité. Soient \( \{ u_i \}_{i=1,\ldots, p}\) les éléments qui réalisent ce recouvrement. Alors
        \begin{equation}
            \bigcap_{i=1}^pF_{u_i}=\emptyset.
        \end{equation}
        Nous considérons l'opérateur
        \begin{equation}
            v=\frac{1}{ p }\sum_{i=1}^pu_i\in\aL(V).
        \end{equation}
        Vu que \( K\) est convexe et stable sous chacun des \( u_i\), nous avons aussi \( v(K)\subset K\) et donc il existe \( a\in K\) tel que \( v(a)=a\). Pour ce \( a\), nous avons
        \begin{subequations}
            \begin{align}
                \nu\big( v(a) \big)&=\nu\left( \frac{1}{ p }\sum_{i=1}^pu_i(a) \right)      \label{EqDXSnwPb}\\
                &\leq \frac{1}{ p }\sum_{i=1}^p\nu\left( u_i(a) \right)\\
                &=\frac{1}{ p }\sum_{i=1}^p\nu(a)\\
                &=\nu(a)
            \end{align}
        \end{subequations}
        où nous avons utilisé la constance de \( \nu\) sur les orbites de \( G\). Par ailleurs nous savons que \( v(a)=a\), donc en réalité à gauche dans \eqref{EqDXSnwPb} nous avons \( \nu(a)\) et toutes les inégalités sont des égalités. Nous avons en particulier
        \begin{equation}        \label{EqBMjypoV}
                \nu\left( \sum_{i=1}^pu_i(a) \right) =\sum_{i=1}^p\nu\left( u_i(a) \right).
        \end{equation}
        Notons \( u_0\in G\) l'élément qui réalise le maximum de la définition de \( \nu\) pour le vecteur \( \sum_iu_i(a)\) :
        \begin{equation}
            \nu\left( \sum_i u_i(a) \right)=\| u_0\left( \sum_iu_i(a) \right) \|\leq\sum_i\| u_0u_i(a) \|\leq \sum_i\nu\big( u_i(a) \big).
        \end{equation}
        Mais nous venons de voir (équation \eqref{EqBMjypoV}) que l'expression de gauche est égale à celle de droite. Donc les inégalités sont des égalités et en particulier la première inégalité devient l'égalité
        \begin{equation}
            \| \sum_iu_0u_i(a)  \|=\sum_i\| u_0u_i(a) \|.
        \end{equation}
        En vertu du lemme \ref{LemLPOHUme}, il existe des nombres positifs \( \lambda_i\) tels que
        \begin{equation}
            u_0u_1(a)=\lambda_2u_0u_2(a)=\ldots =\lambda_pu_0u_p(a).
        \end{equation}
        Du fait que \( u_0\) est inversible nous avons aussi 
        \begin{equation}       \label{EqSTQwfIl}
            u_1(a)=\lambda_2u_2(a)=\ldots =\lambda_pu_p(a).
        \end{equation}
        Mais par constance de \( \nu\) sur les orbites nous avons \( \nu(u_i(a))=\nu(u_j(a))\) pour tout \( i\) et \( j\); en appliquant \( \nu\) à la série d'égalités \eqref{EqSTQwfIl}, nous trouvons que tous les \( \lambda_i\) doivent être égaux à \( 1\). En particulier
        \begin{equation}     
            u_1(a)=u_2(a)=\ldots =u_p(a).
        \end{equation}
        
        Nous récrivons maintenant l'équation \( v(a)=a\) avec la définition de \( v\) :
        \begin{equation}
            a=v(a)=\frac{1}{ p }\sum_{i=1}^pu_i(a)=u_j(a)
        \end{equation}
        pour n'importe quel \( j\). Donc
        \begin{equation}
            a\in\bigcap_{i=1}^pF_{u_i},
        \end{equation}
        ce qui contredit notre hypothèse de départ.
        \end{subproof}
\end{proof}

\begin{proposition}[\cite{NHXUsTa,KXjFWKA,RXvMqkd}]     \label{PropQZkeHeG}
    Soit \( G\) un sous-groupe compact de \( \GL(n,\eR)\). Alors 
    \begin{enumerate}
        \item
            Il existe une forme quadratique définie positive \( q\) sur \( \eR^n\) telle que \( G\subset \gO(q)\).
        \item
            Le groupe \( G\) est conjugué à un sous-groupe de \( \gO(n,\eR)\).
    \end{enumerate}
\end{proposition}
\index{groupe!action!utilisation}
\index{matrice!équivalence!dans le groupe linéaire}
\index{forme!quadratique!groupe orthogonal}
\index{groupe!orthogonal!d'une forme quadratique}
\index{endomorphisme!préservant une forme quadratique}

\begin{proof}
    Nous considérons le (pas tout à fait) morphisme de groupe
    \begin{equation}
        \begin{aligned}
            \rho\colon G&\to \GL\big( \gS(n,\eR) \big) \\
            u&\mapsto \rho_u\colon s\to  u^tsu,
        \end{aligned}
    \end{equation}
    et tant que nous y sommes à considérer, nous considérons l'ensemble
    \begin{equation}
        H=\{ M^tM\tq M\in G \}\subset \gS(n,\eR).
    \end{equation}
    Cet ensemble est constitué de matrices définies positives parce que si \( \langle M^tMx, x\rangle =0\), alors \(0= \langle Mx, Mx\rangle =\| Mx \|\), mais \( M\) étant inversible, cela implique que \( x=0\). Qui plus est cet ensemble est compact dans \( \GL(n,\eR)\) en tant qu'image du compact \( G\) par l'application continue \( M\mapsto M^tM\). L'enveloppe convexe \( K=\Conv(H)\) est alors également compacte par le théorème \ref{CorOFrXzIf}. Enfin nous considérons \( L=\rho(G)\), qui est un sous-groupe compact de \( \GL\big( \gS(n,\eR) \big)\) parce que \( \rho_u\rho_v=\rho_{vu}\in\rho(G)\). Nous remarquons que \( \rho_u\) étant linéaire, elle préserve les combinaisons convexes et donc pour tout \( u\in G\), \( \rho_u(K)\subset K\).

    Bref, \( L\) est un sous-groupe compact de \( \GL(n,\eR)\) préservant le compact \( K\) de \( \gS(n,\eR)\). Par le lemme \ref{LemOCtdiaE}, il existe \( s\in K\) tel que \( \rho_u(s)=s\) pour tout \( u\in G\). Ou encore :
    \begin{equation}
        u^tsu=s
    \end{equation}
    pour tout \( u\in G\). Fort de ce \( s\) bien particulier, nous considérons la forme quadratique associée : \( q(x)=x^tsx\). Cette forme est définie positive parce que \( s\) l'est. Nous avons \( G\subset \gO(q)\) parce que si \( u\in G\) alors
    \begin{equation}
        q\big( ux \big)=(ux)^tsux=x^t\underbrace{u^tsu}_{=s}x=q(x).
    \end{equation}
    Le premier point est prouvé.

    La matrice \( s\) est symétrique et définie positive. Elle peut donc être diagonalisée\footnote{Théorème \ref{ThoeTMXla}} en \( \diag(\lambda_1,\ldots, \lambda_n)\) avec \( \lambda_i>0\), et ensuite transformée en la matrice \( \mtu_n\) par la matrice \( \diag(1/\sqrt{\lambda_i})\). Nous avons donc une matrice \( a\in\GL(n,\eR)\) telle que \( a^tsa=\mtu_n\). Avec ça, si \( u\in G\), nous avons
    \begin{equation}
        (a^{-1}ua)^t(a^{-1} ua)=(a^{-1}ua)^t\mtu_n(a^{-1} ua)=a^tu^t(a^t)^{-1}a^tsaa^{-1}ua=a^tu^tsua=a^tsa=\mtu,
    \end{equation}
    ce qui prouve que \( a^{-1} ua\) est dans \( \gO(n,\eR)\), et donc que \( a^{-1} G a\subset \gO(n,\eR)\).
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Isométries de l'espace euclidien}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Nous considérons l'espace affine euclidien \( A=\affE_n(\eR)\) modelé sur \( \eR^n\) avec sa métrique usuelle. Un premier grand résultat sera le théorème \ref{ThoDsFErq} qui dira que les isométries de cet espace sont des applications linéaires\footnote{Regardez un coup dans le second tome du Landau et Lifchitz voir comment ils démontrent que les transformations de Lorentz doivent être linéaires. Ça vous donnera une idée à quel point notre théorème est cool.}.

\begin{example}
    La forme quadratique \( q(x)=x_1^2+x_2^2\) donne la norme euclidienne. La forme bilinéaire associée est \( b(x,y)=x_1y_1+x_2y_2\), qui est le produit scalaire usuel.
\end{example}

Il ne faudrait pas déduire trop vite que la formule \( \| x \|^2=q(x)\) donne une norme dès que \( q\) est non dégénérée. En effet \( q\) peut ne pas être définie positive. La forme \( q(x)=x_1^2-x_2^2\) prend des valeurs positives et négatives. A fortiori \( d(x,y)=q(x-y)\) ne donne pas toujours une distance.

Nous allons cependant appeler \defe{isométrie}{isométrie!de forme quadratique} pour la forme \( q\) une application bijective \( f\colon V\to V\) telle que \( q(x-y)=q\big( f(x)-f(y) \big)\). Dans les cas où \( q\) donne une distance, alors c'est une isométrie au sens usuel.

\begin{lemma}   \label{LemewGJmM}
    Pour une application bijective \( f\colon E\to E\) telle que \( f(0)=0\), les conditions suivantes sont équivalentes: 
    \begin{enumerate}
        \item
            \( b\big( f(x),f(y) \big)=b(x,y)\) pour tout \( x,y\in E\);
        \item
            \( q\big( f(x)-f(y) \big)=q(x-y)\) pour tout \( x,y\in E\).
    \end{enumerate}
\end{lemma}

\begin{proof}
    Dans le sens direct, en posant \( x=y\) nous trouvons tout de suite \( q(f(x))=q(f)\); ensuite en utilisant la distributivité de \( b\),
    \begin{subequations}
        \begin{align}
            q\big( f(x)-f(y) \big)&=b\big( f(x)-f(y),f(x)-f(y) \big)\\
            &=q\big( f(x) \big)-2b\big( f(x),f(y) \big)+q\big( f(y) \big)\\
            &=q(x)+q(y)-2b(x,y)\\
            &=q(x-y).
        \end{align}
    \end{subequations}
    
    Dans l'autre sens, nous commençons par remarquer que l'hypothèse \( f(0)=0\) donne \( q(x)=q\big( f(x) \big)\). Ensuite nous utilisons l'identité de polarisation \eqref{EqMrbsop} :
    \begin{subequations}
        \begin{align}
            b\big( f(x),f(y) \big)&=\frac{ 1 }{2}\big[ q\big( f(x) \big)+q\big( f(y) \big)-q\big( f(x-y) \big) \big]\\
            &=\frac{ 1 }{2}\big[ q(x)+q(y)-q(x-y) \big]\\
            &=b(x,y).
        \end{align}
    \end{subequations}
\end{proof}

\begin{theorem}     \label{ThoDsFErq}
    Soit \( f\colon E\to E\) une bijection telle que
    \begin{equation}
        q(x-y)=q\big( f(x)-f(y) \big)
    \end{equation}
    pour tout \( x,y\in E\). Alors
    \begin{enumerate}
        \item
            si \( f(0)=0\), alors \( f\) est linéaire;
        \item
            si \( f(0)\neq 0\) alors \( f\) est affine.
    \end{enumerate}
\end{theorem}
La rédaction la preuve a bénéficié d'un coup de main de la part de \href{http://www.ilemaths.net/forum-sujet-500814.html}{GaBuZoMeu}. Une autre preuve, utilisant un peut plus d'indices et un peu plus de mots comme «tenseurs», peut être trouvée  \href{http://physics.stackexchange.com/questions/12664/proving-that-interval-preserving-transformations-are-linear}{ici}. Le fait que la preuve donnée soit tensorielle me fait penser que le résultat peut encore être généralisé.

\begin{proof}
    Si \( f(0)=0\), nous savons par le lemme \ref{LemewGJmM} que \( b\big( f(x),f(y) \big)=b(x,y)\). Soit \( z\in E\); étant donné que \( f\) est bijective nous pouvons considérer l'élément \( f^{-1}(z)\in E\) et calculer
    \begin{subequations}
        \begin{align}
            b\big( f(x+y),z \big)&=b\big( f(x+y),f(f^{-1}(z)) \big)\\
            &=b(x+y,f^{-1}(z))\\
            &=b(x,f^{-1}(z))+b(y,f^{-1}(z))\\
            &=b(f(x),z)+b(f(y),z)\\
            &=b\big( f(x)+f(y),z \big),
        \end{align}
    \end{subequations}
    donc \( f(x+y)=f(x)+f(y)\) par le lemme \ref{LemyKJpVP}. 

    De la même façon on trouve \( b\big( f(\lambda x),z \big)=b\big( \lambda f(x),z \big)\) qui prouve que \( f(\lambda x)=\lambda f(x)\) et donc que \( f\) est linéaire.

    Si \( f(0)\neq 0\), alors nous posons \( g(x)=f(x)-f(0)\) qui vérifie \( g(0)=0\) et
    \begin{equation}
        q\big( g(x)-g(y) \big)=q\big( f(x)-f(0)-f(y)+f(0) \big)=q(x-y).
    \end{equation}
    Nous pouvons donc appliquer le premier point à \( g\), déduire que \( g\) est linéaire et donc que \( f\) est affine.
\end{proof}

Maintenant nous savons que le groupe des isométries d'un espace quadratique \( (E,q)\) est un sous-groupe de \( \GL(E)\). Dans le cas de la métrique euclidienne, il est connu que ce sont les matrices orthogonales.

Nous pouvons maintenant avoir une discussion plus détaillée des groupes d'isométries de l'espace euclidien, parce que nous savons maintenant qu'elles sont des applications linéaires. Pour en savoir plus sur le groupe des isométries, il faut lire le théorème de Cartan-Dieudonné dans \cite{JGAdTA}.



\begin{lemma}[\cite{JGAdTA}]
    Si \( n\geq 3\), alors toute droite est intersection de deux plans non isotropes.
\end{lemma}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Théorème de Sylvester}
%---------------------------------------------------------------------------------------------------------------------------

% TODO : Il y a une démonstration sur wikipédia, à voir.

\begin{theorem}[de Sylvester]   \label{ThoQFVsBCk}
    Soit $Q$ une forme quadratique réelle de signature \( (p,q)\). Alors pour toute base orthonormée on a
    \begin{subequations}
        \begin{align}
            p&=\Card\{ i\tq Q(e_i)>0 \}\\
            q&=\Card\{ i\tq Q(e_i)<0 \}.
        \end{align}
    \end{subequations}
    Le rang de \( Q\) est \( p+q\).

    Si \( A\) est la matrice de \( Q\) dans une base, alors il existe une matrice inversible \( P\) telle que
    \begin{equation}
        P^tAP=\begin{pmatrix}
            -\mtu_q    &       &       \\
                &   \mtu_p    &       \\
                &       &   0
        \end{pmatrix}.
    \end{equation}
\end{theorem}
\index{théorème!Sylvester}
\index{rang}
\index{matrice!semblables}
\index{forme!quadratique}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Produit semi-direct}
%---------------------------------------------------------------------------------------------------------------------------

Les isométries directes\footnote{Directes au sens où nous ne considérons pas les retournements.} de cet espace sont données d'une part par les rotations de \( \SO(n)\) et d'autre part par les translations données par les vecteurs de \( \eR^n\). Plus précisément, un couple \( (v,\Lambda)\in \eR^n\times\SO(n)\) agit sur \( x\in A\) par
\begin{equation}
    (v,\Lambda)x=\Lambda x+v.
\end{equation}
La loi de composition est donnée par
\begin{subequations}
    \begin{align}
        (v,\Lambda)\cdot(v',\Lambda')x&=(v,\Lambda)(\Lambda'x+v')\\
        &=\Lambda\Lambda'x+\Lambda v'+v\\
        &=(\Lambda v'+v,\Lambda\Lambda')x.
    \end{align}
\end{subequations}
Nous avons donc, pour tout \( v,v'\in \eR^n\), \( \Lambda,\Lambda'\in\SO(n)\) la loi de groupe
\begin{equation}    \label{EqDiHcut}
        (v,\Lambda)\cdot(v',\Lambda')=(\Lambda v'+v,\Lambda\Lambda').
\end{equation}
    
Le groupe \( \SO(n)\) agit naturellement sur \( \eR^n\) par
\begin{equation}
    \begin{aligned}
        \phi\colon \SO(n)&\to \Aut(\eR^n) \\
        \Lambda&\mapsto \phi_{\Lambda}\colon v\to \Lambda v. 
    \end{aligned}
\end{equation}
Il est à noter qu'ici, \( \eR^n\) est vu comme l'ensemble des applications \( v\colon A\to A\), \( v(x)=x+a\). Voir aussi la remarque \ref{RemAobrlX}.

Nous pourrions alors présenter le groupe de isométries de \( A\) sous la forme du produit semi-direct
\begin{equation}
    \Iso^+(A)=\eR^n\times_{\phi}\SO(n).
\end{equation}
Plusieurs choses sont à vérifier :
\begin{enumerate}
    \item
        Pour chaque \( \Lambda\), l'application \( \phi_{\Lambda}\) est un automorphisme du groupe \( \eR^n\) (en tant qu'agissant sur \( A\)). Le fait que \( \phi_{\Lambda}\) soit une bijection n'est pas un problème. Nous devons vérifier que
        \begin{equation}
            \phi_{\Lambda}(v+w)=\phi_{\Lambda}(v)\circ\phi_{\Lambda}(w)
        \end{equation}
        en tant qu'égalité dans l'ensemble des isométries de \( A\). Nous la testons donc sur un élément \( x\in A\). D'une part
        \begin{equation}
            \phi_{\Lambda}(v+w)x=x+\Lambda(v+m),
        \end{equation}
        et d'autre part,
        \begin{equation}
            \phi_{\Lambda}(v)\circ\phi_{\Lambda}(w)x=\phi_{\Lambda}(v)\big( x+\Lambda w \big)=x+\Lambda w+\Lambda v.
        \end{equation}
    \item
        L'application \( \phi\colon \SO(n)\to \Aut(\eR^n)\) est un morphisme de groupe. Nous devons vérifier l'égalité
        \begin{equation}
            \phi_{\Lambda\Lambda'}=\phi_{\Lambda}\circ\phi_{\Lambda'}
        \end{equation}
        dans \( \Aut(\eR^n)\), c'est à dire que pour tout \( v\in \eR^n\) et \( x\in A\) nous devons avoir
        \begin{equation}
            \phi_{\Lambda\Lambda'}(v)x=\big( \phi_{\Lambda}\circ\phi_{\Lambda'}\big)(v)x.
        \end{equation}
        Le membre de gauche fait immédiatement \( x+\Lambda\Lambda'v\) tandis que le membre de droite vaut
        \begin{equation}
            \big( \phi_{\Lambda}\circ\phi_{\Lambda'}\big)(v)x=\big( \phi_{\Lambda}(\Lambda'v) \big)x=(\Lambda\Lambda'v)x=x+\Lambda\Lambda'v.
        \end{equation}
    \item
        La loi de groupe donnée par \( \phi\) sur \( \SO(n)\times \eR^n\) par la définition \eqref{EqDRgbBI} est bien la loi de groupe \eqref{EqDiHcut}. Cela est encore un calcul immédiat. L'utilisation de la définition \eqref{EqDRgbBI} donne
        \begin{equation}
            (v,\Lambda)\cdot(v',\Lambda')=(v+\phi_{\Lambda}(v'),\Lambda\Lambda')=(v+\Lambda v',\Lambda\Lambda'),
        \end{equation}
        qui est bien la formule \eqref{EqDiHcut}.
\end{enumerate}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Groupe diédral}
%---------------------------------------------------------------------------------------------------------------------------
\label{subsecHibJId}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Définition et générateurs : vue géométrique}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Le \defe{groupe diédral}{groupe!diédral} \( D_n\)\nomenclature[R]{\( D_n\)}{groupe diédral} est le groupe des isométries de \( \eR^2\) laissant invariant un polygone régulier à \( n\) côtés. Il peut être vu comme le stabilisateur de l'ensemble
\begin{equation}
    \{  e^{2ik\pi/n},k=0,\ldots, n-1 \}
\end{equation}
dans le groupe des isométries affines de \( \eC^*\).
\index{groupe!agissant sur un ensemble!diédral}
\index{groupe!en géométrie}
\index{groupe!fini!diédral}
\index{groupe!permutation!diédral}
% TODO : prouver que les racines de l'unité forment un polygone régulier.

Si \( f\in D_n\), alors \( f( e^{2ik\pi/n}) \) doit être l'un des \(  e^{2ik'\pi/n}\), et vu que \( f\) conserve les longueurs dans \( \eC\), nous devons avoir
\begin{equation}
    1=d(0, e^{2ik\pi/n})=d\big( f(0), e^{2ik'\pi/n} \big).
\end{equation}
Donc \( f(0)\) est à l'intersection de tous les cercles de rayon \( 1\) centrés en les \(  e^{2ik\pi/n}\), ce qui montre que \( f(0))0\) (dès que \( n\geq 3\)). Par conséquent notre étude du groupe diédral ne doit prendre en compte que les isométries vectorielles de \( \eR^2\). En d'autres termes
\begin{equation}
    D_n\subset O(2,\eR).
\end{equation}

\begin{proposition}[\cite{tzHydF}]
    Le groupe \( D_n\) contient un sous groupe cyclique d'ordre \( 2\) et un sous groupe cyclique d'ordre \( n\).
\end{proposition}

\begin{proof}
    Si \( s\) est la réflexion d'axe \( \eR\), alors \( s\) est d'ordre \( 2\). De plus \( s\) est bien dans \( D_n\) parce que
    \begin{equation}    \label{EqSUshknP}
        s\big(  e^{2ki\pi/n} \big)= e^{2(n-k)i\pi/n}.
    \end{equation}

    De la même façon, la rotations d'angle \(2\pi/n\), que l'on note \( r\), agit sur les racines de l'unité et engendre un le groupe d'ordre \( n\) des rotations d'angle \(2 k\pi/n\).
\end{proof}

Notons que la conjugaison complexe ne fait pas spécialement partie du groupe \( D_n\). En effet pour \( n=3\) par exemple les points fixes sont \( A_1=(1,0)\), \( A_2=(-\frac{ 1 }{2},\frac{ \sqrt{3} }{2})\) et \( A_3=(\frac{ 1 }{2},-\frac{ \sqrt{3} }{2})\). La conjugaison complexe envoie évidemment \( A_1\) sur \( A_1\), mais pas du tout \( A_2\) sur \( A_3\).
%TODO : un dessin du triangle équilatéral serait pas mal ici.

\begin{proposition}[\cite{tzHydF}]
    Nous avons \( (sr)^2=\id\).
\end{proposition}

\begin{proof}
    Si \( z^n=1\), alors
    \begin{equation}
        (srsr)z=srs e^{2 i\pi/n}z=sr\big( e^{-2\pi i/n\bar z}\big)=s\bar z=z.
    \end{equation}
\end{proof}

\begin{proposition}[\cite{tzHydF}] \label{PropLDIPoZ}
    Le groupe diédral \( D_n\) est engendré par \( s\) et \( r\). De plus tous les éléments de \( D_n\) s'écrivent sous la forme \( s\circ r^m\).
\end{proposition}
\index{groupe!diédral!générateurs (preuve)}
\index{racine!de l'unité}
\index{géométrie!avec nombres complexes}
\index{géométrie!avec des groupes}
\index{isométrie!de l'espace euclidien \( \eR^2\)}

\begin{proof}
    Nous considérons les points \( A_0=1\) et \( A_k= e^{2ki\pi/n}\) avec \( k\in\{ 1,\ldots, n-1 \}\). Par convention, \( A_n=A_0\). L'action des éléments \( s\) et \( r\) sur ces points est
    \begin{subequations}
        \begin{align}
            r(A_k)&=A_{k+1}\\
            s(A_k)&=A_{n-k}.
        \end{align}
    \end{subequations}
    Cette dernière est l'équation \eqref{EqSUshknP}.
    
    Soit \( f\in D_n\). Étant donné que c'est une isométrie de \( \eR^2\) avec un point fixe (le point \( 0\)), \( f\) est soit une rotation soit une réflexion.
    %TODO : il faut démontrer ce point et mettre un lien vers ici.

    Supposons pour commencer que un des \( A_k\) est fixé par \( f\). Dans ce cas \( f\) a deux points fixes : \( O\) et \( A_k\) et est donc la réflexion d'axe \( (OA_k)\). Dans ce cas, nous avons \( f=s\circ r^{n-2k}\). En effet
    \begin{equation}
        s\circ r^{n-2k}(A_k)=s(A_{k+n-2k})=s(A_{n-k})=A_k.
    \end{equation}
    Donc \( O\) et \( A_k\) sont deux points fixes de l'isométrie \( f\); donc \( f\) est bien la réflexion sur le bon axe.

    Nous passons à présent au cas où \( f\) ne fixe aucun des \( A_k\). 
    \begin{enumerate}
        \item
            Supposons que \( f\) soit une rotation. Si \( f(A_k)=A_m\), alors l'angle de la rotation est 
            \begin{equation}
                \frac{ 2(m-k)\pi }{ n },
            \end{equation}
            et donc \( f=r^{m-k}\), qui est de la forme demandée.
        \item
            Supposons à présent que \( f\) soit une réflexion d'axe \( \Delta\). Cette fois, \( \Delta\) ne passe par aucun des points \( A_k\), par contre \( \Delta\) passe par \( 0\). Nous commençons par montrer que \( \Delta\) doit être la médiatrice d'un des côtés \( [A_p,A_{p+1}]\) du polygone. Vu que \( \Delta\) passe par \( O\) et n'est aucune des droites \( (OA_k)\), cette droite passe par l'intérieur d'un des triangles \( OA_pA_{p+1}\) et intersecte donc le côté correspondant.

            Notre tâche est de montrer que \( \Delta\) coupe \( [A_p,A_{p+1}]\) en son milieu. Dans ce cas, \( \Delta\) sera automatiquement perpendiculaire parce que le triangle \( OA_pA_{p+1}\) est isocèle en \( O\). Nommons \( l\) la longueur des côtés du polygone, \( P=\Delta\cap[A_p,A_{p+1}]\), \( x=d(A_p,P)\) et \( \delta=d(A_p,\Delta)\). Vu que \( f\) est la symétrie d'axe \( \Delta\), nous avons aussi \( d\big( f(A_p),\Delta \big)=\delta\) et \( d\big( A_p,f(A_p) \big)=2\delta\). D'autre part, par la définition de la distance, \( \delta<x\). Si \( x<\frac{ l }{2}\), alors \( \delta<\frac{ \delta }{2}\) et donc \( d\big( A_p,f(A_p) \big)<l\). Or cela est impossible parce que le polygone ne possède aucun sommet à distance plus courte que \( l\) de \( A_p\).

            De la même manière si \( x>\frac{ l }{2}\), nous raisonnons avec \( A_{p+1}\) pour obtenir une contradiction. Nous en concluons que la seule possibilité est \( x=\frac{ l }{2}\), et donc \( f(A_p)=A_{p+1}\). Montrons alors que \( f=s\circ r^{n-2p-1}\). Il faut montrer que c'est une réflexion qui envoie \( A_p\) sur \( A_{p+1}\). D'abord c'est une réflexion parce que
            \begin{equation}
                \det(sr^{n-2p-1})=\det(s)\det(r^{n-2p-1})=-1
            \end{equation}
            parce que \( \det(s)=-1\) alors que \( \det(r^k)=1\) parce que \( r\) est une rotation dans \( \SO(2)\). Ensuite nous avons
            \begin{equation}
                s\circ r^{n-2p-1}(A_p)=s(A_{p+n-2p-1})=s(A_{n-p-1})=A_{n-(n-p-1)}=A_{p+1}.
            \end{equation}

            Donc \( s\circ r^{n-2p-1}\) est bien une réflexion qui envoie \( A_p\) sur \( A_{p+1}\).

    \end{enumerate}
\end{proof}

\begin{corollary}   \label{CorWYITsWW}
La liste des éléments de \( D_n\) est 
\begin{equation}
    D_n=\{ 1,r,\ldots, r^{n-1},s,sr,\ldots, sr^{n-1} \}
\end{equation}
et \( | D_n |=2n\).
\end{corollary}

\begin{proof}
    Nous savons par la proposition \ref{PropLDIPoZ} que tous les élément de \( D_n\) s'écrivent sous la forme \( r^k\) ou \( sr^k\). Vu que \( r\) est d'ordre \( n\), il ne faut considérer que \( k\in\{ 1,\ldots, n-1 \}\). Les éléments \( 1\), \( r\),\ldots, \( r^{n-1}\) sont tous différents, et sont (pour des raisons de déterminant) tous différents des \( sr^k\). Les isométries \( sr^k\) sont toutes différentes entre elles pour essentiellement la même raison :
    \begin{equation}
        sr^k(A_p)=s(A_{p+k})=A_{n-p+k}
    \end{equation}
    donc si \( k\neq k'\), \( sr^k(A_p)\neq sr^{k'}(A_p)\). La liste des éléments de \( D_n\) est donc
    \begin{equation}
        D_n=\{ 1,r,\ldots, r^{n-1},s,sr,\ldots, sr^{n-1} \}
    \end{equation}
    et donc \( | D_n |=2n\).
\end{proof}

\begin{example}
    Nous considérons le carré \( ABCD\) dans \( \eR^2\) et nous cherchons les isométries de \( \eR^2\) qui laissent le carré invariant. Nous nommons les points comme sur la figure \ref{LabelFigIsomCarre}. La symétrie d'axe vertical est nommée \( s\) et la rotation de \( 90\) degrés est notée \( r\).
    \newcommand{\CaptionFigIsomCarre}{Le carré dont nous étudions le groupe diédral.}
    \input{Fig_IsomCarre.pstricks}

    Il est facile de vérifier que toutes les symétries axiales peuvent être écrites sous la forme \( r^is\). De plus le groupe engendré par \( s\) agit sur le groupe engendré par \( r\) parce que
    \begin{equation}
        (srs^{-1})(A,B,C,D)=sr(B,A,D,C)=s(A,D,C,B)=(B,C,D,A),
    \end{equation}
    c'est à dire \( srs^{-1}=r^{-1}\). Nous sommes alors dans le cadre du corollaire \ref{CoroGohOZ} et nous pouvons écrire que
    \begin{equation}
        D_4=\gr(r)\times_{\sigma}\gr(s).
    \end{equation}
\end{example}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Générateurs : vue abstraite}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Nous allons montrer que \( D_n\) peut être décrit de façon abstraite en ne parlant que de ses générateurs. Nous considérons un groupe \( G\) engendré par des éléments \( a\) et \( b\) tels que
\begin{enumerate}
    \item
        \( a\) est d'ordre \( 2\),
    \item
        \( b\) est d'ordre \( n\) avec \( n\geq 3\),
    \item
        \( abab=e\).
\end{enumerate}
Nous allons prouver que ce groupe doit avoir la même liste d'éléments que celle du corollaire \ref{CorWYITsWW}.

\begin{proposition}[\cite{tzHydF}]
    Le groupe \( G\) n'est pas abélien.
\end{proposition}

\begin{proof}
    Nous savons que \( abab=e\), donc \( abab^{-1}=b^{-2}\), mais \( b^{-2}\neq e\) parce que \( b\) est d'ordre \( n>2\). Donc \( abab^{-1}\neq e\). En manipulant un peu :
    \begin{equation}
        e\neq abab^{-1}=(ab)(ba^{-1})^{-1}=(ab)(ba)^{-1}
    \end{equation}
    parce que \( a^{-1}=a\). Donc \( ab\neq ba\).
\end{proof}

\begin{lemma}[\cite{tzHydF}]        \label{LemKKXdqdL}
    Pour tout \( k\) entre \( 1\) et \( n-1\) nous avons
    \begin{equation}
        ab^ka=b^{-k}.
    \end{equation}
\end{lemma}

\begin{proof}
    Nous faisons la démonstration par récurrence. D'abord pour \( k=1\), nous devons avoir \( aba=b^{-1}\), ce qui est correct parce que par construction de \( G\) nous avons \( abab=e\). Ensuite nous supposons que le lemme tient pour \( k\) et nous regardons ce qu'il se passe avec \( k+1\) :
    \begin{equation}
            ab^{k+1}ba=ab^kba=\underbrace{ab^ka}_{b^{-k}}\underbrace{aba}_{b^{-1}}=b^{-k}b^{-1}=b^{-(k+1)}.
    \end{equation}
\end{proof}

\begin{proposition}
    L'élément \( a\) n'est pas une puissance de \( b\).
\end{proposition}

\begin{proof}
    Supposons le contraire : \( a=b^k\). Dans ce cas nous aurions
    \begin{equation}
        e=(ab)(ab)=b^{k+1}b^{k+1}=b^{2k+2}=b^{2k}b^2=a^2b^2=b^2,
    \end{equation}
    ce qui signifierait que \( b\) est d'ordre \( 2\), ce qui est exclu par construction.
\end{proof}

\begin{proposition}[\cite{tzHydF}]
    La liste des éléments de \( G\) est donnée par
    \begin{equation}
        G=\{ 1,b,\cdots,b^{n-1},a,ab,\ldots, ab^{n-1} \}.
    \end{equation}
\end{proposition}

\begin{proof}
    Étant donné que \( a\) n'est pas une puissance de \( b\), les éléments \( 1\), \( a\), \( b\),\ldots, \( b^{n-1}\) sont distincts. De plus si \( k\) et \( m=k+p\) sont deux éléments distincts de \( \{ 1,\ldots, n-1 \}\), nous avons \( ab^k\neq ab^m\) parce que si \( ab^k=ab^{k+p}\), alors \( a=ab^p\) avec \( p<n\), ce qui est impossible. Pour la même raison, \( ab^k\neq e\), et \( ab^k\neq b^m\).

    Au final les éléments \( 1,a,b,\ldots, b^{n-1},ab,\ldots, ab^{n-1}\) sont tous différents. Nous devons encore voir qu'il n'y en a pas d'autres.

    Par définition le groupe \( G\) est engendré par \( a\) et \( b\), donc tout élément \( x\in G\) s'écrit $x=a^{m_1}b^{k_1}\ldots a^{m_r}b^{k_r}$ pour un certain \( r\) et avec pour tout \( i\), \( k_i\in\{ 1,\ldots, n-1 \}\) (sauf \( k_r\) qui peut être égal à zéro) et \( m_i=1\), sauf \( m_1\) qui peut être égal à zéro. Donc
    \begin{equation}
        x=a^mb^{k_1}ab^{k_2}a\ldots b^{k_{r-1}}ab^{k_r}
    \end{equation}
    où \( m\) et \( k_r\) peuvent éventuellement être zéro. En utilisant le lemme \ref{LemKKXdqdL} sous la forme \( b^{k_i}a=ab^{-k_i}\), quitte à changer les valeurs des exposants, nous pouvons passer tous les \( a \) à gauche et tous les \( b\) à droite pour finir sous la forme \( x=a^kb^m\). 

    Donc non, il n'existe pas d'autres éléments dans \( G\) que ceux déjà listés.

\end{proof}

\begin{theorem}
    Les groupes \( G\) et \( D_n\) sont isomorphes.
\end{theorem}

\begin{proof}
        Nous utilisons l'application
    \begin{equation}
        \begin{aligned}
            \psi\colon G&\to D_n \\
            a^kb^m&\mapsto s^kr^m. 
        \end{aligned}
    \end{equation}
    C'est évidemment bien défini et bijectif, mais c'est également un homomorphisme parce que si nous calculons \( \psi\) sur un produit, nous devons comparer
    \begin{equation}        \label{EqBULPilp}
        \psi\big( a^{k_1}b^{m_1}a^{k_2}b^{m_2} \big)
    \end{equation}
    avec
    \begin{equation}        \label{EqIVEIphI}
        \psi\big( a^{k_1}b^{m_1}\big)\psi\big(a^{k_2}b^{m_2} \big)= s^{k_1}r^{m_1}s^{k_2}r^{m_2}.
    \end{equation}
    Vu que \( D_n\) et \( G\) ont les mêmes propriétés qui permettent de permuter \( a\) et \( b\) ou \( s\) et \( r\), l'expression à l'intérieur du \( \psi\) dans \eqref{EqBULPilp} se simplifie en \( a^kb^m\) avec les même \( k\) et \( n\) que l'expression à droite dans \eqref{EqIVEIphI} ne se simplifie en \( s^kr^m\).
\end{proof}

\begin{corollary}
    Toutes les propriétés démontrées pour \( G\) sont vraies pour \( D_n\). En particulier, avec quelque redites :
    \begin{enumerate}
        \item
            Le groupe \( D_n\) peut être défini comme étant le groupe engendré par un élément \( s\) d'ordre \( 2\) et un élément \( r\) d'ordre \( n-1\) assujettis à la relation \( srsr=e\).
        \item
            Le groupe \( D_n\) n'est pas abélien.
        \item
            Pour tout \( k\in\{ 1,\ldots, n-1 \}\) nous avons \( sr^ks=r^{-k}\).
        \item
            L'élément \( s\) ne peut pas être obtenu comme une puissance de \( r\).
        \item
            La liste des éléments de \( D_n\) est
            \begin{equation}
                D_n=\{ 1,r,\ldots, r^{n-1},s,sr,\ldots, sr^{n-1} \}
            \end{equation}
        \item
            Le groupe diédral \( D_n\) est d'ordre \( 2n\).
    \end{enumerate}
\end{corollary}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Classes de conjugaison}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\label{subsubsecZQnBcgo}

Pour les classes de conjugaison du groupe diédral nous suivons \cite{HRIMAJJ}.

D'abord pour des raisons de déterminants\footnote{Vous notez qu'ici nous utilisons un argument qui utilise la définition de \( D_n\) comme isométries de \( \eR^2\). Si nous avions voulu à tout prix nous limiter à la définition «abstraite» en termes de générateurs, il aurait fallu trouver autre chose.}, les classes des éléments de la forme \( r^k\) et de la forme \( sr^k\) ne se mélangent pas. Nous notons \( C(x)\) la classe de conjugaison de \( x\), et \( y\cdot x=yxy^{-1}\).

Les relations que nous allons utiliser sont 
\begin{subequations}
    \begin{align}
        sr^ks=r^{-k}\\
        rs=sr^{-1}=sr^{n-1}.
    \end{align}
\end{subequations}

La classe de conjugaison qui ne rate jamais est bien entendu \( C(1)={1}\). Nous commençons les vraies festivités \( C(r^{m})\). D'abord \( r^k\cdot r^m=r^m\), ensuite
\begin{equation}
    (sr^k)\cdot r^m=sr^kr^mr^{-k}s^{-1}=sr^ms^{-1}=r^{-m}.
\end{equation}
Donc
\begin{equation}    \label{EqVFfFxgi}
    C(r^m)=\{ r^m,r^{-m} \}.
\end{equation}
À ce niveau il faut faire deux remarques. D'abord si \( m>\frac{ n }{2}\), alors \( C(r^m)\) est la classe de \( C^{n-m}\) avec \( n-m<\frac{ n }{2}\). Donc les classes que nous avons trouvées sont uniquement à lister avec \( m<\frac{ n }{2}\). Ensuite si \( m=\frac{ n }{2}\) alors \( r^m=r^{-m}\) et la classe est un singleton. Cela n'arrive que si \( n\) est pair.

Nous passons ensuite à \( C(s)\). Nous avons
\begin{equation}
    r^k\cdot s=r^ksr^{-k}=ssr^ksr^{-k}=sr^{-k}r^{-k}=sr^{n-2k},
\end{equation}
et
\begin{equation}
    (sr^k)\cdot s=\underbrace{sr^ks}_{r^{-k}}r^{-k}s^{-1}=r^{-2k}s=r^{n-2k}s=sr^{(n-1)(n-2k)}=sr^{n^2-2kn-n+2k}=sr^{2k}.
\end{equation}
donc
\begin{equation}
    C(s)=\{ sr^{n-2k},sr^{2k} \}_{k=0,\ldots, n-1}.
\end{equation}
Ici aussi l'écriture n'est pas optimale : peut-être que pour certains \( k\) il y a des doublons. Nous reportons l'écriture exacte à la discussion plus bas qui distinguera \( n\) pair de \( n\) impair. Notons juste que si \( n\) est pair, l'élément \( sr\) n'est pas dans la classe \( C(s)\).

Nous en faisons donc à présent le calcul en gardant en tête le fait qu'il n'a de sens que si \( n\) est pair. D'abord
\begin{equation}
    s\cdot (sr)=ssrs=rs=sr^{n-1}.
\end{equation}
Ensuite
\begin{equation}
    (sr^k)\cdot (sr)=sr^ksrr^{-k}s=r^{-2k+1}s=sr^{2k-1}.
\end{equation}
Avec \( k=\frac{ n }{2}\), cela rend \( s\cdot (sr)\), donc pas besoin de le recopier. Nous avons
\begin{equation}
    C(sr)=\{ sr^{2k-1} \}_{k=1,\ldots, n-1}.
\end{equation}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Le compte pour $ n$ pair}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\label{SubsubsecROVmHuM}

Si \( n\) est pair, nous avons les classes
\begin{subequations}
    \begin{align}
        C(1)&=\{ 1 \}       &&&\text{\( 1\) élément}\\
        C(r^m)&=\{ r^m,r^{m-1} \}&\text{ pour }&0<m<\frac{ n }{2}   &\text{\( \frac{ n }{2}-1\) fois \( 2\) éléments}\\
        C(r^{n/2})&=\{ r^{n/2} \}   &&& \text{\( 1\) élément}\\ 
        C(s)&=\{ sr^{2k} \}_{k=0,\ldots, \frac{ n }{2}-1} &&& \text{\( \frac{ n }{2}\) éléments}\\
        C(sr)&=\{ sr^{2k+1} \}_{k=0,\ldots, \frac{ n }{2}-1} &&& \text{\( \frac{ n }{2}\) éléments}.
    \end{align}
\end{subequations}
Au total nous avons bien listé \( 2n\) éléments comme il se doit, dans \(  \frac{ n }{2}+3\) classes différentes.

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Le compte pour $ n$ impair}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\label{Subsubsec*GJIzDEP}

Si \( n\) est impair, nous avons les classes
\begin{subequations}
    \begin{align}
        C(1)&=\{ 1 \}       &&&\text{\( 1\) élément}\\
        C(r^m)&=\{ r^m,r^{m-1} \}&\text{ pour }&0<m<\frac{ n-1 }{2}   &\text{\( \frac{ n-1 }{2}\) fois \( 2\) éléments}\\
        C(s)&=\{ sr^k \}_{k=0,\ldots, n-1} &&& \text{\( n\) éléments}
    \end{align}
\end{subequations}
Au total nous avons bien listé \( 2n\) éléments comme il se doit, dans \(  \frac{ n+3 }{2}\) classes différentes.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Théorèmes de Sylow}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{lemma}
    Soient \( H\) et \( K\) des sous-groupes finis de \( G\). Alors
    \begin{equation}
        \Card(HK)=\frac{ | H |\cdot | K | }{ | H\cap K | }.
    \end{equation}
\end{lemma} 
Attention : dans ce lemme, l'ensemble \( HK\) n'est pas spécialement un groupe. Ce serait le cas si \( H\) normaliserait \( K\), c'est à dire si nous avions \( hkh^{-1}\in K<,\forall h,k\in H\times K\).

\begin{theorem}[Théorème de Cauchy]\index{Cauchy!théorème}\index{théorème!Cauchy}       \label{ThoCauchyGpFini}
    Soit \( G\) un groupe fini et \( p\) un nombre premier divisant \( | G |\). Alors 
    \begin{enumerate}
        \item
            \( G\) contient un élément d'ordre \( p\).  
        \item
            Si \( G\) est un \( p\)-groupe, il existe un élément central d'ordre \( p\) dans \( G\).
    \end{enumerate}
\end{theorem}
Une preuve du premier point est sur \wikipedia{fr}{Théorème_de_Cauchy_(groupes)}{wikipedia}.

\begin{lemma}[Théorème de Cayley]    \label{ThoIfdlEB}   \index{Cayley!théorème}
    Si \( G\) est un groupe d'ordre \( n\) alors il est isomorphe à un sous-groupe du groupe symétrique \( S_n\).
\end{lemma}

\begin{proof}
    L'action à gauche de \( G\) sur lui-même
    \begin{equation}
        \begin{aligned}
            \varphi\colon G&\to S_n \\
            \varphi(x)g&\mapsto xg 
        \end{aligned}
    \end{equation}
    est une permutation des éléments de \( G\). Cela donne un morphisme injectif parce que si \( \varphi(x)=\varphi(y)\) nous avons \( xg=yg\) pour tout \( g\) et en particulier pour \( g=e\) nous trouvons \( x=y\).
\end{proof}

\begin{lemma}       \label{LemaQxjcm}
    Soit \( p\) un diviseur premier de \( n\). Alors le groupe symétrique \( S_n\) se plonge dans \( \GL_n(\eF_p)\).
\end{lemma}

\begin{proof}
    Soit \( \{ e_i \}\) la base canonique de \( \eF_p\). Nous avons le morphisme injectif $\varphi\colon S_n\to \GL(n,\eF)$ donné par \( \varphi(\sigma)e_i=e_{\sigma(i)}\).
\end{proof}
 
\begin{remark}  \label{RemFzxxst}
    En mettant bout à bout les lemmes \ref{ThoIfdlEB} et \ref{LemaQxjcm}, nous trouvons que si \( p\) est un diviseur premier de \( | G |\), alors \( G\) peut être vu comme un sous-groupe de \( \GL(n,\eF_p)\).
\end{remark}

\begin{definition}
    Soit \( p\) un nombre premier. Un \defe{$p$-groupe}{$p$-groupe}\index{groupe!$p$-groupe} est un groupe dont tous les éléments sont d'ordre \( p^m\) pour un certain \( m\) (dépendant de l'élément).

    Soit \( G\) un groupe fini et \( p\), un diviseur premier de $| G |$. Un \defe{\(p\)-Sylow}{$p$-Sylow}\index{Sylow!$ p$-Sylow} dans \( G\) est un \( p\)-sous-groupe d'ordre \( p^n\) où \( p^n\) est la plus grande puissance de \( p\) divisant \( | G |\).
\end{definition}
Notons que si \( p\) est un nombre premier, alors tout groupe d'ordre \( p^m\) est un \( p\)-groupe.

\begin{lemma}
    Soit \( G\) un groupe fini et \( P\), \( Q\) des \( p\)-sous-groupes. Nous supposons que \( Q\) normalise \( P\). Alors \( PQ\) est un \( p\)-sous-groupe de \( G\).
\end{lemma}

Si \( S\) est un \( p\)-Sylow, alors \( p\) ne divise pas le nombre \( | G:S |=| G |/| S |\).

\begin{proposition}     \label{Propvocmon}
    Soit le corps fini \( \eF_p=\eZ/p\eZ\) (\( p\) premier). Soit \( T\) le sous-ensemble de \( \GL_n(\eF_p)\) formé des matrices triangulaires supérieures de rang\footnote{Définition \ref{DefALUAooSPcmyK}.} \( n\) et dont les éléments diagonaux sont \( 1\). Alors \( T\) est un \( p\)-Sylow de \( \GL_n(\eF_p)\).
\end{proposition}

\begin{proof}
    Nous commençons par étudier le cardinal de \( \GL_n(\eF_p)\). Pour la première colonne, la seule contrainte à vérifier est qu'elle ne soit pas nulle. Il y a donc \( p^n-1\) possibilités. Pour la seconde, il faut ne pas être multiple de la première. Il y a donc \( p^n-p\) possibilités (parce qu'il y a \( p\) multiples possibles de la premières colonne). Pour la \( k\)-ième colonne, il faut éviter toutes les combinaisons linéaires des \( (k-1)\) premières colonnes. Il y a \( p^{k-1}\) telles combinaisons et donc \( p^n-p^{k-1}\) possibilités pour la \( k\)-ième colonne. Nous avons donc
    \begin{subequations}
        \begin{align}
            \Card\big( \GL(n,\eF_{p}) \big)&=(p^n-1)(p^n-p)\ldots(p^n-p^{n-1})\\
            &=p\cdot p^2\cdots p^{n-1}(p^n-1)(p^{n-1}-1)\ldots (p-1)\\
            &=p^{\frac{ n(n-1) }{2}}m
        \end{align}
    \end{subequations}
    où \( m\) est un entier qui ne divise pas \( p\).

    En ce qui concerne le cardinal de \( T\), le calcul est plus simple : pour la première ligne nous avons \( p^{n-1}\) choix (parce qu'il y a un \( 1\) qui est imposé sur la diagonale), pour la seconde \( p^{n-2}\), etc. En tout nous avons alors
    \begin{equation}
        | T |=p^{\frac{ n(n-1) }{2}},
    \end{equation}
    et \( T\) est un \( p\)-Sylow de \( \GL_n(\eF_p)\).
\end{proof}


\begin{proposition}
    Soit \( p\) un nombre premier. Un groupe fini \( G\) est un $p$-groupe si et seulement l'ordre de \( G\) est \( p^n\) pour un certain \( n\).
\end{proposition}

\begin{proof}
    Supposons que \( G\) est un $p$-groupe. Soit \( q\) un nombre premier divisant \( | G |\). Par le théorème de Cauchy (\ref{ThoCauchyGpFini}), le groupe \( G\) contient un élément d'ordre \( q\), soit \( g\) un tel élément. Étant donné que \( G\) est un $p$-groupe, \( g^{p^n}=g^q=e\) pour un certain \( n\). Donc $q=p^n$ et \( q=p\) parce que \( q\) est premier. Nous venons de prouver que \( p\) est le seul nombre premier qui divise \( | G |\). L'ordre de \( G\) est par conséquent une puissance de \( p\).

    Nous nous intéressons maintenant à l'implication inverse. Nous supposons que \( | G |=p^n\) pour un certain entier \( n\geq 0\). Soit \( g\in G\); nous notons \( r\) l'ordre de \( G\). Le sous-groupe \( \gr(g)\) est d'ordre \( r\), donc \( r\) divise \( | G |\) (par le théorème \ref{ThoLagrange} de Lagrange). Le nombre \( r\) est alors une puissance de \( p\).
\end{proof}

\begin{lemma}       \label{LemwDYQMg}
    Soit \( G\), un groupe fini de cardinal \( | G |=n\) et \( p\), un diviseur premier de \( n\). Nous notons \( n=p^m\cdot r\) où \( p\) ne divise pas \( r\). Soit \( H\) un sous-groupe de \( G\) et \( S\), un \( p\)-Sylow de \( G\). Alors il existe \( g\in G\) tel que 
    \begin{equation}
        gSg^{-1}\cap H
    \end{equation}
    soit un \( p\)-Sylow de \( H\).
\end{lemma}

\begin{proof}
    Nous considérons l'ensemble \( G/S\) sur lequel \( H\) agit. Si \( a\in G\), le stabilisateur de \( [a]\) dans \( G/S\) est
    \begin{subequations}
        \begin{align}
            \Stab\big( [a] \big)&=\{ h\in H\tq [ha]=[a] \}\\
            &=\{ h\in H\tq a^{-1}ha\in S\}\\
            &=aSa^{-1}\cap H.
        \end{align}
    \end{subequations}
    Nous cherchons \( a\in G\) tel que l'entier
    \begin{equation}        \label{EqZpUbWx}
        \frac{ \Card(H) }{ \Card\big( aSa^{-1}\cap H \big) }
    \end{equation}
    soit premier avec \( p\). En effet, dans ce cas le groupe \( \Stab([a])\) est un $p$-Sylow de \( H\) parce que \( | H:aSa^{-1}\cap H |\) ne divise pas \( p\). La formule des orbites (équation \eqref{EqCewSXT}) nous dit que
    \begin{equation}
        \frac{ | H | }{ | aSa^{-1}\cap H | }=\Card\big( \mO_{[a]} \big).
    \end{equation}
    Supposons que toutes les orbites aient un cardinal divisible par \( p\). Étant donné que \( G/S\) est une réunion disjointe de ses orbites, nous aurions
    \begin{equation}
        p\divides \Card(G/S)=\frac{ | G | }{ | S | }
    \end{equation}
    alors que \( S\) étant un $p$-Sylow, \( p\) ne peut pas diviser \( | G |/| S |\). Toutes les orbites n'ont donc pas un cardinal divisible par \( p\), et il existe un \( a\in G\) tel que \eqref{EqZpUbWx} soit vérifiée.
\end{proof}


\begin{theorem}[Théorème de Sylow]  \label{ThoUkPDXf}
    Soit \( G\) un groupe fini et \( p\), un diviseur premier de \( | G |\). Alors
    \begin{enumerate}
        \item
            \( G\) possède des \( p\)-Sylow.
        \item
            Tout \( p\)-sous-groupe de \( G\) est contenu dans un \( p\)-Sylow.
        \item   \label{ItemMzNRVf}
            Les \( p\)-Sylow de \( G\) sont conjugués.
        \item   \label{ItemkYbdzZ}
            Si \( n_p\) est le nombre de $p$-Sylow de \( G\), alors \( n_p\) divise \( | G |\) et \( n_p\equiv 1\mod p\).
    \end{enumerate}
\end{theorem}
\index{groupe!fini}

\begin{proof}

    % Il y a ici un début d'une preuve qui fonctionne d'une autre manière. Dans cette démonstration, N est l'ordre de G.

    %\begin{enumerate}
        %\item
         %   Nous faisons la récurrence sur l'ordre \( N\) de \( G\). Pour \( N=1\), le seul \( p\)-Sylow est le groupe entier. Si \( N>1\), nous commençons par supposer que \( G\) contient un sous-groupe propre \( H\) tel que \( \pgcd(| G:H |,p)=1\).
%
 %           Si \( G\) contient un sous-groupe propre \( H\) tel que \( \pgcd(| G:H |,p)=1\), alors \( p\) divise \( | G:H |\). En effet \( p\) divise \( N\) et \( | G:H |=| G |/| H |\). Si il n'y a pas de \( p\) dans la décomposition de \( | H |\), alors \( p\) divise encore \( | G |/| H |\). Étant donné que \( p\) est un diviseur premier de \( | H |\), le groupe \( H\) contient des \( p\)-Sylow par hypothèse de récurrence. Montrons que si \( S\) est un \( p\)-Sylow de \( H\), alors \( S\) est également un $p$-Sylow de \( G\).
%
 %           Soit \( S\), un $p$-Sylow de \( H\). Nous avons \( | S |=p^n\) où \( n\) est la plus grande puissance de \( p\) divisant \( H\). Par hypothèse, il n'y a pas de \( p\) dans la décomposition de \( | G:H |\); par conséquent \( p^n\) est également la plus grande puissance de \( p\) qui divise \( | G |\) et \( S\) est alors un $p$-Sylow de \( G\).
%
 %           Nous supposons maintenant que \( G\) ne possède pas de sous-groupe \( H\) tels que \( \pgcd(| G:H |,p)=1\).
%
 %   \end{enumerate}

    \begin{enumerate}
        \item
            
            Nous savons de la remarque \ref{RemFzxxst} que \( G\) est un sous-groupe de \( \GL_n(\eF_p)\) et que ce dernier a un $p$-Sylow par la proposition \ref{Propvocmon}. Par conséquent \( G\) possède un $p$-Sylow par le lemme \ref{LemwDYQMg}.

        \item

            Soit \( H\) un \( p\)-sous-groupe de \( G\) et \( S\), un $p$-Sylow de \( G\) (qui existe par le point précédent). Par le lemme \ref{LemwDYQMg} il existe \( a\in G\) tel que \( aSa^{-1}\cap H\) soit un $p$-Sylow de \( H\). Mais \( H\) est un \(p\)-groupe et un $p$-Sylow dans un \( p\)-groupe est automatiquement le groupe entier. Par conséquent,
            \begin{equation}
                H=aSa^{-1}\cap H
            \end{equation}
            et \( H\subset aSa^{-1}\), ce qui signifie que \( H\) est inclus à un $p$-Sylow.

        \item

            Soit \( H\) un $p$-Sylow. Nous venons de voir que si \( S\) est un $p$-Sylow quelconque, alors \( H\) est inclus au $p$-Sylow \( aSa^{-1}\) pour un certain \( a\in G\). Donc \( H\) est un $p$-Sylow inclus dans le $p$-Sylow \( aSa^{-1}\), donc \( H=aSa^{-1}\).

        \item

            Le fait que \( n_p\) divise \( n\) est parce que tous les $p$-Sylow ont le même nombre d'éléments (ils sont conjugués) et sont deux à deux disjoints. Donc ils forment une partition de \( G\) et \( | G |=n_p| S |\) si \( S\) est un $p$-Sylow quelconque.
            
            Montrons maintenant que \( n_p\) est congru à un modulo \( p\). Soit \( E\) l'ensemble des $p$-Sylow de \( G\). Le groupe \( G\) agit sur \( E\) par conjugaison. Soit \( S\) un $p$-Sylow et considérons l'ensemble
            \begin{equation}
                E_S=\{ T\in E\tq s\cdot T=T\forall s\in S \}.
            \end{equation}
            où l'action est celle par conjugaison. C'est l'ensemble des points fixes de \( E\) sous l'action de \( S\). L'ensemble \( E\) est la réunion des orbites sous \( S\) et chacune de ces orbites a un cardinal qui divise \( | S |=p^m\). Par conséquent \( | \mO_T |\) vaut \( 1\) lorsque \( T\in E_S\) et est un multiple de \( p\) sinon. Nous avons donc
            \begin{equation}
                | E |\equiv | E_S |\mod p.
            \end{equation}
            Nous voulons obtenir \( | E_S |=1\). Évidemment \( S\in E_S\) parce que si \( s\in S\) alors \( sSs^{-1}=S\). Nous voudrions montrer que \( S\) est le seul élément de \( E_S\). Soit \( T\in E_S\), c'est à dire que \( T\) est un $p$-Sylow de \( G\) tel que
            \begin{equation}
                sTs^{-1}=T
            \end{equation}
            pour tout \( s\in S\). Soit \( N\) le groupe engendré par \( S\) et \( T\). Montrons que \( T\) est normal dans \( N\). Un élément \( g\) dans \( N\) s'écrit
            \begin{equation}
                g=s_1t_1\cdots s_rt_r
            \end{equation}
            avec \( s_i\in S\) et \( t_i\in T\). Si \( t\in T\), en utilisant le fait que \( T\) est un groupe et le fait que \( S\) le normalise, nous avons
            \begin{equation}
                gtg^{-1}=s_1t_1\ldots s_rt_rtt_r^{-1}s_r^{-1}\ldots t_1^{-1}s_r^{-1}\in T.
            \end{equation}
            Donc \( T\) est un sous-groupe normal de \( N\). Mais \( S\) et \( T\) sont conjugués dans \( N\) (parce que ils sont des $p$-Sylow de \( N\)), donc il existe un élément \( a\in N\) tel que \( aTa^{-1}=S\). Mais étant donné que \( T\) est normal,
            \begin{equation}
                S=aTa^{-1}=T.
            \end{equation}
            Ceci achève la démonstration des théorèmes de Sylow.

    \end{enumerate}
\end{proof}

\begin{proposition}
    Si \( S\) est un \( p\)-Sylow dans le groupe \( G\) alors pour tout \( g\in G\), l'ensemble \( gSg^{-1}\) est encore un \( p\)-groupe.    
\end{proposition}

\begin{proof}
    Si les éléments de \( S\) sont d'ordre \( p^n\), alors nous avons
    \begin{equation}
        (gsg^{-1})^q=gs^qg^{-1}=e.
    \end{equation}
    Pour avoir \( gs^qg^{-1}=e\), il faut et suffit que \( gs^q=g\), alors \( s^q=e\), c'est à dire \( q=p^n\). Donc \( gSg^{-1}\) est encore un \( p\)-Sylow.
\end{proof}

Les deux résultats \ref{Lemcmbzum} et \ref{PropyfhTmf} proviennent de la \wikiversity{fr}{Groupe_(mathématiques)/Exercice/Premiers_résultats_sur_les_groupes_simples}{wikiversité}.
\begin{lemma}\label{Lemcmbzum}
    Soit \( G\), un groupe fini et \( p\), un nombre premier. Si \( H\) et \( K\) sont des groupes distincts d'ordre \( p\), alors \( H\cap K=\{ e \}\).
\end{lemma}

\begin{proof}
    L'ensemble \( H\cap K\) est un sous-groupe de \( H\). Par conséquent son ordre divise celui de \( H\) qui est un nombre premier. Par conséquent soit \( | H\cap K |=1\), soit \( | H\cap K |=| H |\). Dans le second cas nous aurions \( H=K\), alors que nous avons supposé que \( H\) et \( K\) étaient distincts.
\end{proof}

\begin{proposition} \label{PropyfhTmf}
    Soit \( G\) un groupe fini et \( n\) le nombre de sous-groupes d'ordre \( p\) dans \( G\). Alors le nombre d'éléments d'ordre \( p\) dans \( G\) vaut \( n(p-1)\).
\end{proposition}

\begin{proof}
    Si \( g\) est un élément d'ordre \( p\) dans \( G\), le groupe \( H\) engendré par \( g\) est d'ordre \( p\). Réciproquement si \( H\) est un groupe d'ordre \( p\), tous les éléments de \( H\setminus\{ e \}\) sont d'ordre \( p\) (parce que l'ordre d'un élément divise l'ordre du groupe). Donc l'ensemble des éléments d'ordre \( p\) dans \( G\) est la réunion des ensembles \( H\setminus\{ e \}\) où \( H\) parcours les sous-groupes d'ordre \( p\) dans \( G\). Chacun de ces ensembles possède \( p-1\) éléments et le lemme \ref{Lemcmbzum} nous assure qu'ils sont disjoints. Par conséquent nous avons \( n(p-1)\) éléments d'ordre \( p\) dans \( G\).
\end{proof}

\begin{corollary}
    Un groupe d'ordre premier est cyclique.
\end{corollary}

\begin{proof}
    Soit \( p\) l'ordre de \( G\). Le nombre de sous-groupes d'ordre \( p\) est \( n=1\) (et c'est \( G\) lui-même). La proposition \ref{PropyfhTmf} nous dit alors que le nombre d'éléments d'ordre \( p\) dans \( G\) est \( p-1\). Donc tout élément est générateur.
\end{proof}

\begin{lemma}
    Le groupe \( A_6\) n'accepte pas de sous-groupes normaux d'ordre \( 60\).
\end{lemma}

\begin{proof}
    Soit \( G\) normal dans \( A_6\), et \( a\), un élément d'ordre \( 5\) dans \( G\) (qui existe parce que \( 5\) divise \( 60\)). Soit aussi un élément \( b\) d'ordre \( 5\) dans \( A_6\). Les groupes \( \gr(a)\) et \( \gr(b)\) sont deux \( 5\)-Sylow dans \( A_6\). En effet, \( 5\) un nombre premier et est la plus grande puissance de \( 5\) dans la décomposition de \( 60\); donc \( \gr(a)\) est un \( 5\)-Sylow dans \( G\). D'autre part, l'ordre de \( A_6\) (qui est \( \frac{ 1 }{2}6!\)) ne possède également que \( 5\) à la puissance \( 1\) dans sa décomposition.

    En vertu du théorème de Sylow \ref{ThoUkPDXf}\ref{ItemMzNRVf}, les \( 5\)-Sylow \( \gr(a)\) et \( \gr(b)\) sont conjugués et il existe \( \tau\in A_6\) tel que \( b=\tau a\tau^{-1}\). Mais \( G\) étant normal dans \( A_6\), l'élément \( \tau a\tau^{-1}\) est encore dans \( G\), de telle sorte que \( b\in G\). Du coup \( G\) doit contenir tous les éléments d'ordre \( 5\) de \( A_6\).

    Les éléments d'ordre $5$ de \( A_6\) doivent fixer un des points de \( \{ 1,2,3,4,5,6 \}\) puis permuter les autres de façon à n'avoir qu'un seul cycle. Un cycle correspond à écrire les nombres \( 1,2,3,4,5\) dans un certain ordre. Ce faisant, le premier n'a pas d'importance parce qu'on considère la permutation cyclique, par exemple \( (3,5,2,1,4)\) est la même chose que \( (5,2,1,4,3)\). Le nombre de cycles sur \( \{ 1,2,3,4,5 \}\) est donc de \( 4!\), et par conséquent le nombre d'éléments d'ordre \( 5\) dans \( A_6\) est \( 6\cdot 4!=144\).

    Le groupe \( G\) doit contenir au moins \( 144\) éléments alors que par hypothèse il en contient \( 60\); contradiction.
    
\end{proof}

\begin{proposition}[\cite{Exo7Sylow}]
    Tout groupe simple d'ordre \( 60\) est isomorphe au groupe alterné \( A_5\).
\end{proposition}
Une autre preuve de ce résultat peut être trouvée sur la \wikiversity{fr}{Groupe_(mathématiques)/Exercice/Premiers_résultats_sur_les_groupes_simples}{wikiversité}. 

\begin{proof}
    Nous avons la décomposition en nombres premiers \( 60=2^2\cdot 3\cdot 5\). Déterminons pour commencer le nombre \( n_5\) de \( 5\)-Sylow dans \( G\). Le théorème de Sylow \ref{ThoUkPDXf}\ref{ItemkYbdzZ} nous renseigne que \( n_5\) doit diviser \( 60\) et doit être égal à \( 1\mod 5\). Les deux seules possibilités sont \( n_5=1\) et \( n_5=6\). Étant donné que tous les \( p\)-Sylow sont conjugués, si \( n_5=1\) alors le \( 5\)-Sylow serait un sous-groupe invariant à l'intérieur de $G$, ce qui est impossible vu que \( G\) est simple. Donc \( n_5=6\).

    Par le point \ref{ItemMzNRVf} du théorème de Sylow, le groupe \( G\) agit transitivement sur l'ensemble des \( 5\)-Sylow par l'action adjointe :
    \begin{equation}
        g\cdot S=gSg^{-1}.
    \end{equation}
    Cela donne donc un morphisme \( \theta\colon G\to S_6\). Le noyau de \( \theta\) est un sous-groupe normal. En effet si \( k\in \ker\theta\) et si \( g\in G\) nous avons
    \begin{subequations}
        \begin{align}
            (gkg^{-1})\cdot S&=gkg^{-1} Ggk^{-1}g^{-1}\\
            &=gkTk^{-1}g^{-1}\\
            &=gTg^{-1}\\
            &=S
        \end{align}
    \end{subequations}
    où \( T\) est le Sylow \( T=g^{-1}Sg\). Étant donné que \( k\in \ker\theta\) nous avons utilisé \( kTk^{-1}=aT\). Au final \( gkg^{-1}\cdot S=S\), ce qui prouve que \( gkg^{-1} \in\ker\theta\).

    Étant donné que \( \ker\theta\) est normal dans \( G\), soit est soit réduit à \( \{ e \}\) soit il vaut \( G\). La seconde possibilité est exclue parce qu'elle reviendrait à dire que \( G\) agit trivialement, ce qui n'est pas correct étant donné qu'il agit transitivement. Nous en déduisons que \( \ker\theta=\{ e \}\), que \( \theta\) est injective et que \( G\) est isomorphe à un sous-groupe de \( S_6\).

    Par ailleurs le groupe dérivé de \( G\) est un sous-groupe normal (et non réduit à l'identité parce que \( G\) est non commutatif). Donc \( D(G)=G\). Étant donné que \( G\subset S_6\), nous avons
    \begin{equation}
        G=D(G)\subset D(S_6)=A_6
    \end{equation}
    parce que le groupe dérivé du groupe symétrique est le groupe alterné (lemme \ref{LemiApyfp}).

    L'ensemble \( \theta^{-1}(A_6)\) est distingué dans \( G\). En effet si \( \sigma\in A_6\) et si \( g\in G\) nous avons
    \begin{equation}
        \theta\big( g\theta^{-1}(\sigma)g^{-1} \big)=\theta(g)\sigma \theta(g)^{-1}\in A_6.
    \end{equation}
    Nous en déduisons que \( \theta^{-1}(A_6)\) est soit \( G\) entier soit réduit à \( \{ e \}\). Si \( \theta^{-1}(A_6)=\{ e \}\), alors pour tout \( g\in G\) nous aurions \( g^2=e\) parce que \( \theta(g^2)\in A_6\). L'ordre de \( G\) étant \( 60\), il n'est pas possible que tous ses éléments soient d'ordre \( 2\). Nous en déduisons que \( \theta(G)\subset A_6\).

    Nous nommons \( H=\theta(G)\) et nous considérons l'ensemble \( X=A_6/H\) où les classes sont prises à gauche, c'est à dire 
    \begin{equation}
        [\sigma]=\{ h\sigma\tq h\in H \}.
    \end{equation}
    Évidemment \( A_6\) agit sur \( X\) de façon naturelle. Au niveau de la cardinalité,
    \begin{equation}
        \Card(X)=\frac{ | A_6 | }{ | G | }=\frac{ 360 }{ 60 }=6.
    \end{equation}
    Le groupe \( A_6\) agit sur \( X\) qui a \( 6\) éléments. Nous avons donc une application \( \varphi\colon A_6\to A_6\). Encore une fois, la simplicité de \( A_6\) montre que \( \varphi(A_6)=A_6\).

    Nous étudions maintenant \( \varphi(H)\) agissant sur \( X\). Un élément \( x\in A_6\) fixe la classe de l'unité \( [e]\) si et seulement si \( x\in H\) et par conséquent \( \varphi(H)\) est la fixateur de \( [e]\) dans \( X\). À la renumérotation près, nous pouvons identifier \( \varphi(H)\) au sous-groupe de \( A_6\) agissant sur \( \{ 1,\ldots, 6 \}\) et fixant \( 6\). Nous avons alors \( \varphi(H)=S_5\cap A_6=A_5\). Nous venons de prouver que \( \varphi\) fournit un isomorphisme entre \( A_5\) et \( H\). Étant donné que \( H\) était isomorphe à \( G\), nous concluons que \( G\) est isomorphe à \( A_6\).
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Un peu de classification}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{definition}
    Un \defe{nombre premier}{nombre!premier} est un naturel acceptant exactement deux diviseurs distincts.
\end{definition}
Avec cette définition, \( 0\) n'est pas premier, \( 1\) n'est pas premier et \( 2\) est premier.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Automorphismes du groupe \texorpdfstring{$ \eZ/n\eZ$}{Z/nZ}}
%---------------------------------------------------------------------------------------------------------------------------

Notons que \( \eZ/n\eZ=\eZ/n\eZ=\eF_n\) est un groupe pour l'addition tandis que \( (\eZ/n\eZ)^*\) est un groupe pour la multiplication. Il ne peut donc pas y avoir d'équivoque.

\begin{theorem}[\href{https://fr.wikiversity.org/wiki/Groupe\_\%28math\%C3\%A9matiques\%29/Automorphismes\_d'un\_groupe\_cyclique}{Wikiversité}%
    ]   \label{ThoozyeSn}
    Pour chaque \( x\in (\eZ/n\eZ)^*\) nous considérons l'application
    \begin{equation}
        \begin{aligned}
            \sigma_x\colon \eZ/n\eZ&\to \eZ/n\eZ \\
            y&\mapsto xy. 
        \end{aligned}
    \end{equation}
    L'application
    \begin{equation}
        \sigma\colon \big( (\eZ/n\eZ)^*,\cdot\big)\to \Aut\big( \eZ/n\eZ,+ \big)
    \end{equation}
    ainsi définie est un isomorphisme de groupes.
\end{theorem}
L'énoncé de ce théorème s'écrit souvent rapidement par 
\begin{equation}
    \Aut(\eZ/n\eZ)=(\eZ/n\eZ)^*,
\end{equation}
mais il faut bien garder à l'esprit qu'à gauche on considère le groupe additif et à droite celui multiplicatif.

\begin{proof}
    Nous notons \( [x]\) la classe de \( x\) dans \( \eZ/n\eZ\). Nous avons \( \eZ/n\eZ=[1]\). Soit \( f\) un automorphisme de \( (\eZ/n\eZ,+)\); pour tout \( r\in \eZ\) nous avons
    \begin{equation}
        f([r])=f(r[1])=rf([1])=[r]f([1]).
    \end{equation}
En particulier, vu que \( f\) est surjective, il existe un \( r\) tel que \( f([r])=[1]\). Pour un tel \( r\) nous avons \( [1]=[r]f([1])\), c'est à dire que nous avons montré que \( f([1])\) est inversible dans \(  \big( (\eZ/n\eZ)^*,\cdot\big)\). Nous montrons à présent que\footnote{Le \( \sigma\) donné ici est l'inverse de celui donné dans l'énoncé. Cela ne change évidemment rien à la validité de l'énoncé et de la preuve.}
    \begin{equation}
        \begin{aligned}
            \sigma\colon \Aut( (\eZ/n\eZ,+))&\to \big( (\eZ/n\eZ)^*,\cdot \big)<++>\\
            f&\mapsto f([1]) 
        \end{aligned}
    \end{equation}
    est un isomorphisme.

    Nous commençons par la surjectivité. Soit \( [a]\in (\eZ/n\eZ)^*\). Les élément \( [a]\) et \( [1]\) étant tous deux des générateurs de \( (\eZ/n\eZ,+)\), il existe un automorphisme de \( \eZ/n\eZ\) qui envoie \( [1]\) sur \( [a]\) par le lemme \ref{LemZhxMit}. Cela prouve la surjectivité de \( \sigma\).

    En ce qui concerne l'injectivité, considérons \( f_1\) et \( f_2\) sont de automorphismes de \( (\eZ/n\eZ,+)\) tels que \( f_1([1])=f_2([1])\). Les automorphismes \( f_1\) et \( f_2\) prennent la même valeur sur un générateur et donc sur tout le groupe. Donc \( f_1=f_2\).

    Enfin nous prouvons que \( \sigma\) est un morphisme, c'est à dire que \( \sigma(f\circ g)=\sigma(f)\sigma(g)\). Nous avons
    \begin{subequations}
        \begin{align}
            f\big( g([1]) \big)&=f\big( g([1])[1j] \big)=g([1])f([1])=\sigma(f)\sigma(g).
        \end{align}
    \end{subequations}
\end{proof}

Ce dernier résultat s'étend aux groupes cycliques.
\begin{proposition}
    Si \( G\) est un groupe cyclique d'ordre \( n\), alors
    \begin{equation}
        \Aut(G)=(\eZ/n\eZ)^*.
    \end{equation}
\end{proposition}

\begin{corollary}       \label{CorwgmoTK}
    Si \( p\) divise \( q-1\) alors \( \Aut(\eF_q)\) possède un unique sous-groupe d'ordre \( p\).
\end{corollary}

\begin{proof}
    Si \( a\) est un générateur de \( \eF_q^*\) alors le groupe
    \begin{equation}    \label{EqAdGiil}
        \gr\left( a^{\frac{ q-1 }{ p }} \right)
    \end{equation}
    est un sous-groupe d'ordre \( p\). En ce qui concerne l'unicité, soit \( S\) un sous-groupe d'ordre \( p\). Il est donc d'indice \( (q-1)/p\) dans \( \eF_q^*\) et le lemme \ref{PropubeiGX} nous enseigne que le groupe donné en \eqref{EqAdGiil} est contenu dans \( S\). Il est donc égal à \( S\) parce qu'il a l'ordre de \( S\). Le fait que \( S\) soit normal est dû au fait que \( \eF_q^*\) est abélien.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Groupes abéliens finis}
%---------------------------------------------------------------------------------------------------------------------------
 
Source : \cite{FabricegPSFinis}.

Nous rappelons que l'exposant\index{exposant} d'un groupe fini est le \( \ppcm\) des ordres de ses éléments. Dans le cas des groupes abéliens finis, l'exposant joue un rôle important du fait qu'il existe un élément dont l'ordre est l'exposant. Cela est le théorème suivant.

\begin{theorem}[Exposant dans un groupe abélien fini]
    Un groupe abélien fini contient un élément dont l'ordre est l'exposant du groupe.
\end{theorem}

\begin{proof}
    Soit \( G\) un groupe abélien fini et \( x\in G\), un élément d'ordre maximum \( m\). Nous montrons par l'absurde que l'ordre de tous les éléments de \( G\) divise \( m\). Soit donc \( y\in G\), un élément dont l'ordre ne divise pas \( m\); nous notons $q$ son ordre. Vu que \( q\) ne divise pas \( m\), le nombre \( q\) possède au moins un facteur premier plus de fois que \( m\) : soit \( p\) premier tel que la décomposition de \( q\) contienne \( p^{\beta}\) et celle de \( m\) contienne \( p^{\alpha}\) avec \( \beta>\alpha\). Autrement dit,
    \begin{subequations}
        \begin{align}
            m=p^{\alpha}m'\\
            q=p^{\beta}q'
        \end{align}
    \end{subequations}
    où \( m'\) et \( q'\) ne contiennent plus le facteur \( p\). L'élément \( x\) étant d'ordre \( m\), l'élément \( x^{p^{\alpha}}\) est d'ordre \( m'\). De la même manière, l'élément \( y^{q'}\) est d'ordre \( p^{\beta}\). Étant donné que \( p^{\beta}\) et \( m'\) sont premiers entre eux, l'élément  \( x^{p^{\alpha}}y^{q'}\) est d'ordre \( p^{\alpha}m'>m\). D'où une contradiction avec le fait que \( x\) était d'ordre maximal.

    Par conséquent l'ordre de tous les éléments de $G$ divise celui de \( x\) qui est alors le \( \ppcm\) des ordres de tous les éléments de \( G\), c'est à dire l'exposant de \( G\).
\end{proof}

\begin{proposition} \label{PropfPRVxi}
    Soit \( G\) un groupe abélien fini et \( x\in G\), un élément d'ordre maximum. Alors
    \begin{enumerate}
        \item
            Il existe un morphisme \( \varphi\colon G\to \gr(x)\) tel que \( \varphi(x)=x\).
        \item   \label{ItemKRYwjU}
            Il existe un sous-groupe \( K\) de \( G\) tel que \( G=\gr(x)\oplus K\).
    \end{enumerate}
\end{proposition}

\begin{proof}
    Nous notons \( a\) l'ordre de \( x\) qui est également l'exposant du groupe \( G\).

    Nous allons prouver la première partie par récurrence sur l'ordre du groupe. Si \( G=\gr(x)\), alors c'est évident. Soit \( H\) un sous-groupe propre de \( G\) contenant \( x\) et tel que le problème soit déjà résolu pour \( H\) : il existe un morphisme \( \varphi\colon H\to \gr(x)\) tel que \( \varphi(x)=x\). Soit \( y\in G\setminus H\), d'ordre \( b\). Nous allons trouver un morphisme $\hat\varphi\colon \gr(H,y)\to \gr(x) $ telle que \( \hat\varphi(x)=x\).

    Pour cela nous commençons par construire les applications suivantes :
    \begin{equation}
        \begin{aligned}
            \tilde \varphi\colon \eZ/b\eZ\times H&\to \gr(x) \\
            (\bar k,h)&\mapsto x^{kl}\varphi(h) 
        \end{aligned}
    \end{equation}
    où \( l\) est encore à déterminer, et
    \begin{equation}
        \begin{aligned}
            p\colon \eZ/b\eZ\times H&\to \gr(y,H) \\
            (\bar k,h)&\mapsto y^kh. 
        \end{aligned}
    \end{equation}
    Pour que \( \tilde \varphi\) soit bien définie, il faut que \( a\) divise \( bl\). L'application \( p\) est bien définie parce que \( \bar k\) est pris dans \( \eZ/b\eZ\) et que \( b\) est l'ordre de \( y\).

    Nous allons construire le morphisme \( \hat \varphi\) en considérant le diagramme 
    \begin{equation}
    \xymatrix{%
    \ker(p) \ar@{^{(}->}[r]        &   \eZ/b\eZ\times H\ar[d]_{\tilde \varphi}\ar[r]^p&\gr(y,H)\ar[ld]^{\hat \varphi}\\
          &   \gr(x)
       }
    \end{equation}
    que l'on voudra être commutatif. Vu que \( p\) est surjective, les théorèmes d'isomorphismes nous disent que
    \begin{equation}
        \gr(y,H)\simeq\frac{ \eZ/b\eZ\times H }{ \ker p }.
    \end{equation}
    Si \( [\bar k,h]\) est la classe de \( (\bar k,h)\) modulo \( \ker(p)\) alors nous voudrions définir \( \hat \varphi\) par
    \begin{equation}        \label{EqeesVxc}
        \hat\varphi\big( [\bar k,h] \big)=\tilde \varphi(\bar k,h).
    \end{equation}
    Pour que cela soit bien définit, il faut que si \( (\bar r,z)\in \ker p\),
    \begin{equation}
        \hat\varphi\big( [\bar k\bar r,hz] \big)=\hat\varphi\big( [\bar k,h] \big),
    \end{equation}
    c'est à dire que \( \tilde \varphi(\bar r,z)=e\). Du coup la définition \eqref{EqeesVxc} n'est bonne que si et seulement si
    \begin{equation}
        \ker(p)\subset\ker(\tilde\varphi ).
    \end{equation}
    Nous pouvons obtenir cela en choisissant bien \( l\).

    Déterminons d'abord le noyau de \( p\). Pour cela nous considérons un nombre \( \beta\) divisant \( b\) tel que \( \gr(y)\cap H=\gr(y^{\beta})\). Nous aurons \( p(\bar k,h)=e\) si et seulement si \( y^h=e\). En particulier \( h=y^{-k}\in\gr(y)\cap H=\gr(y^{\beta})\). Si \( h=(y^{\beta})^m=y^{m\beta}\), alors \( k=-m\beta\) et nous avons
    \begin{equation}
        \ker(p)=\{ (-m\beta,y^{m\beta})\tq m\in \eZ \}.
    \end{equation}
    En plus court : \( \ker(p)=\gr(\beta,y^{-\beta})\). Nous devons donc fixer \( l\) de telle sorte que \( \tilde \varphi(\beta,y^{-\beta})=e\). Étant donné que \( \varphi\) prend ses valeurs dans \( \gr(x)\), il existe un entier \( \alpha\) tel que \( \varphi(y^{-\beta})=x^{\alpha}\); en utilisant cet \( \alpha\), nous écrivons
    \begin{equation}
        \tilde \varphi(\beta,y^{-\beta})=x^{\beta l}\varphi(y^{-\beta})=x^{\beta l+\alpha}.
    \end{equation}
    Par conséquent nous choisissons \( l=-\alpha/\beta\). Nous devons maintenant vérifier que ce choix est légitime, c'est à dire que \( a\) divise \( bl\) et que \( \alpha/\beta\) est un entier.

    Étant donné que \( y\) est d'ordre \( b\),
    \begin{equation}
        e=\varphi(y^b)=\varphi(y^{-\beta b/\beta})=\varphi(y^{-\beta})^{b/\beta}=x^{b\beta/\alpha}.
    \end{equation}
    Par conséquent \( a\) divise \( \frac{ b\alpha }{ \beta }=-bl\).

    Pour voir que \( l\) est entier, nous nous rappelons que \( a\) est l'exposant de \( G\) (parce que \( x\) est d'ordre maximum) et que par conséquent \( b\) divise \( a\). Mais \( a\) divise \( \alpha\frac{ b }{ \beta }\). Donc \( \alpha/\beta\) est entier.

    Nous passons maintenant à la seconde partie de la preuve. Nous considérons un morphisme \( \varphi\colon G\to \gr(x)\) tel que \( \varphi(x)=x\). La première partie nous en assure l'existence. Nous montrons que 
    \begin{equation}
        \begin{aligned}
            \psi\colon G&\to \gr(x)\oplus \ker(\varphi) \\
            g&\mapsto \big( \varphi(g),g\varphi(g)^{-1} \big) 
        \end{aligned}
    \end{equation}
    est un isomorphisme. D'abord \( g\varphi(g)^{-1}\) est dans le noyau de \( \varphi\) parce que \( \varphi(g)^{-1}\) étant dans \( \gr(x)\), et \( \varphi\) étant un morphisme,
    \begin{equation}
        \varphi\big( g\varphi(g)^{-1} \big)=\varphi(g)\varphi(g)^{-1}=e.
    \end{equation}
    L'application \( \psi\) est un morphisme parce que, en utilisant le fait que \( G\) est abélien,
    \begin{subequations}
        \begin{align}
            \psi(g_1g_2)&=\big( \varphi(g_1g_2),g_1g_2\varphi(g_1g_2)^{-1} \big)\\
            &=\big( \varphi(g_1)\varphi(g_2),g_1\varphi(g_1)^{-1}g_2\varphi(g_2)^{-1} \big)\\
            &=\psi(g_1)\psi(g_2).
        \end{align}
    \end{subequations}
    L'application \( \psi\) est injective parce que si \( \psi(g)=(e,e)\) alors \( \varphi(g)=e\) et \( g\varphi(g)^{-1}=e\), ce qui implique \( g=e\).

    Enfin \( \psi\) est surjective parce qu'elle est injective et que les ensembles de départ et d'arrivée ont même cardinal. En effet par le premier théorème d'isomorphisme (théorème \ref{ThoPremierthoisomo}) appliqué à \( \varphi\) nous avons
    \begin{equation}
        | G |=| \gr(x) |\cdot | \ker(\varphi) |.
    \end{equation}
\end{proof}

\begin{theorem} \label{ThoRJWVJd}
    Tout groupe abélien fini (non trivial) se décompose en
    \begin{equation}
        G\simeq \eZ/d_1\eZ\oplus\ldots\oplus \eZ/d_r\eZ
    \end{equation}
    avec \( d_1\geq 1\) et \( d_i\) divise \( d_{i+1}\) pour tout \( i=1,\ldots, r-1\).

    De plus la liste \( (d_1,\ldots, d_r)\) vérifiant ces propriétés est unique.
\end{theorem}

\begin{proof}
    Soit \( x_1\) un élément d'ordre maximal dans \( G\). Soit \( n_1\) son ordre et
    \begin{equation}
        H_1=\gr(x_1)=\eF_{n_1}.
    \end{equation}
    D'après la proposition \ref{PropfPRVxi}\ref{ItemKRYwjU}, il existe un supplémentaire \( K_1\) tel que \( G=\eF_{n_1}\oplus K_1\). Si \( K_1=\{ 1 \}\) on s'arrête et on garde \( G=\eF_{n_1}\). Sinon on continue de la sorte en prenant \( x_2\) d'ordre maximal dans \( K_1\) etc.

    Nous devons maintenant prouver l'unicité de cette décomposition. Soit
    \begin{equation}
        G=\eF_{d_1}\oplus\ldots\oplus \eF_{d_r}=\eF_{s_1}\oplus\ldots\oplus \eF_{s_q}.
    \end{equation}
    L'exposant de \( G\) est \( d_r\) et \( s_q\). Donc \( d_r=s_q\). Les complémentaires étant égaux nous avons
    \begin{equation}
        \eF_{d_1}\oplus\ldots\oplus \eF_{d_{r-1}}=\eF_{s_1}\oplus\ldots\oplus \eF_{s_{q-1}}.
    \end{equation}
    En continuant nous trouvons \( r=q\) et \( d_i=s_i\).
\end{proof}
 
%---------------------------------------------------------------------------------------------------------------------------
\subsection{Groupes d'ordre \texorpdfstring{$ pq$}{pq}}
%---------------------------------------------------------------------------------------------------------------------------
\index{quotient!de groupes}\index{sous-groupe!normal}

Soit \( G\) un groupe d'ordre \( pq\) où \( p\) et \( q\) sont des nombres premiers distincts. Nous supposons que \( p<q\). Montrons que \( G\) ne possède qu'un seul \( q\)-Sylow. Soit \( n_q\) le nombre de \( q\)-Sylow; par les théorèmes de Sylow nous avons
\begin{equation}
    n_q=1\mod q
\end{equation}
et \( n_q\) divise \( | G |=pq\). Donc \( n_q\) vaut \( p\), \( q\) ou \( 1\). Avoir \( n_q=p\) n'est pas possible parce que \( n_q=1\mod q\) et \( p<q\). Avoir \( n_q=q\) n'est pas possible non plus, pour la même raison. Donc \( n_q=1\). Notons \( H\) cet unique \( q\)-Sylow de \( G\).

Notons que cet unique \( q\)-Sylow est un sous-groupe normal dans \( G\) qui n'est égal ni à \( \{ 1 \}\) ni à \( \{ G \}\) parce que
\begin{equation}
    1<p=| H |<pq=| G |.
\end{equation}
Par conséquent \( G\) n'est pas simple.

\begin{theorem} \label{ThoLnTMBy}
    Soit \( G\) un groupe d'ordre \( pq\) où \( q>p\) sont des nombres premiers distincts\footnote{Le cas \( p=q\) sera traité par la proposition \ref{PropssttFK}.}. 

    Si \( q\neq 1\mod p\) alors \( G\) est cyclique et plus précisément \( G\simeq \eZ/pq\eZ\).

    Si \( q=1\mod p\), alors soit \( G\) est abélien et est le groupe cyclique \( G\simeq \eZ/pq\eZ\), soit \( G\) n'est pas abélien et
    \begin{equation}    \label{EqNuuTRE}
        G\simeq \eZ/q\eZ\times_{\varphi}\eZ/p\eZ
    \end{equation}
    où \( \varphi(\bar 1)\) est d'ordre \( p\) dans \( \Aut(\eZ/q\eZ)\).

    De plus tous les produits semi-directs non triviaux de la forme \eqref{EqNuuTRE} sont isomorphes entre eux, c'est à dire que si \( \eZ/q\eZ\times_{\varphi}\eZ/p\eZ\) et \( \eZ/q\eZ\times_{\varphi'}\eZ/p\eZ\) sont d'ordre \( pq\), alors ils sont isomorphes.

    En particulier si \( p\) et \( q\) sont premiers entre eux, le produit est direct.
\end{theorem}
\index{sous-groupe!distingué}
\index{groupe!fini}
\index{anneau!\( \eZ/n\eZ\)}
\index{nombre!premier}

\begin{proof}
    Soient \( H\), un \( q\)-Sylow et \( K\), un \( p\)-Sylow de \( G\). Ils existent parce que \( p\) et \( q\) sont des diviseurs premiers de \( | G |\) (théorème de Sylow \ref{ThoUkPDXf}). Si \( n_q\) est le nombre de \( q\)-Sylow dans \( G\) alors \( n_q\) divise \( | G |\) et \( n_q=1\mod q\). Donc d'abord \( n_q\) vaut \( 1\), \( p\) ou \( q\). Ensuite \( n_q=q\) est exclu par la condition \( n_q=1\mod q\); la possibilité \( n_q=p\) est également impossible parce que \( p=1\mod q\) est impossible avec \( p<q\). Donc \( n_q=1\) et \( H\) est normal dans \( G\).

    L'ensemble \( H\cap H\) est un sous-groupe à la fois de \( H\) et de \( K\), ce qui entraine que (théorème de Lagrange \ref{ThoLagrange}) \( | H\cap K |\) divise à la fois \( p\) et \( q\). Nous en déduisons que \( | H\cap K |=1\) et donc que \( H\cap K=\{ e \}\).

    Étant donné que \( H\) est normal, l'ensemble \( HK\) est un sous-groupe de \( G\). De plus l'application
    \begin{equation}
        \begin{aligned}
            \psi\colon H\times K&\to HK \\
            (h,k)&\mapsto hk 
        \end{aligned}
    \end{equation}
    est un bijection. Nous ne devons vérifier seulement l'injectivité. Supposons que \( hk=h'k'\). Alors \( e=h^{-1}h'k'k^{-1}\), et donc
    \begin{equation}
        h^{-1} h'=(k'k^{-1})^{-1}\in H\cap K=\{ e \}.
    \end{equation}
    Par conséquent \( | pq |=| H\times K |=| HK |\), et \( HK=G\). Le corollaire \ref{CoroGohOZ} nous indique que
    \begin{equation}    \label{EqGjQjFN}
        G=H\times{\varphi}K
    \end{equation}
    où \( \varphi\) est l'action adjointe. Nous devons maintenant identifier cette action. En d'autres termes, nous savons que \( H=\eZ/q\eZ\) et \( K=\eZ/p\eZ\) et que \( \varphi\colon \eZ/p\eZ\to \Aut(\eZ/q\eZ)\) est un morphisme. Nous devons déterminer les possibilités pour \( \varphi\).

    Soit \( n_p\) le nombre de \( p\)-Sylow de \( G\). Comme précédemment, \( n_p\) vaut \( 1\), \( p\) ou \( q\) et la possibilité \( n_p=p\) est exclue. Donc \( n_p\) est \( 1\) ou \( q\).

    Supposons \( q\neq 1\mod p\), c'est à dire \( q\notin [1]_p\). Dans ce cas \( n_p=q\) est impossible parce que \( n_p\in [1]_p\). Donc \( n_p=1\) et \( K\) est également normal dans \( G\). Du coupe le produit semi-direct \eqref{EqGjQjFN} est en réalité un produit direct (\( \varphi\) est triviale) et nous avons
    \begin{equation}
        G=\eZ/q\eZ\times \eZ/p\eZ=\eZ/pq\eZ.
    \end{equation}
    
    Supposons à présent\footnote{Note : il existe des nombres premiers \( p\) et \( q\) tels que \( q=1\mod p\). Par exemple \( 7=1\mod 3\).} que \( q=1\mod p\). Cette fois \( n_p=1\) et \( n_p=q\) sont tous deux possibles. Ce que nous savons est que \( \varphi(\eZ/p\eZ)\) est un sous-groupe de \( \Aut(\eZ/q\eZ)\). Par le premier théorème d'isomorphisme \ref{ThoPremierthoisomo}, nous avons
    \begin{equation}
        | \varphi(\eZ/p\eZ) |=\frac{ | \eZ/p\eZ | }{ | \ker\varphi | },
    \end{equation}
    ce qui signifie que \( | \varphi(\eZ/p\eZ) |\) divise \( | \eZ/p\eZ |=p\). Par conséquent, \( | \varphi(\eZ/p\eZ) |\) est égal à \( 1\) ou \( p\). Si c'est \( 1\), alors l'action est triviale et le produit est direct.

    Nous supposons que \( | \varphi(\eZ/p\eZ) |=p\). Le corollaire \ref{CorwgmoTK} nous indique que \( \Aut(\eZ/q\eZ)\) possède un unique sous-groupe d'ordre \( p\) que nous notons \( \Gamma\); c'est à dire que \( \Gamma=\Image(\varphi)\). Vu que \( \varphi\colon \eZ/p\eZ\to \Aut(\eZ/q\eZ)\) est un morphisme, \( \Gamma\) est généré par \( \varphi(\bar 1)\) qui est alors un élément d'ordre \( p\), comme annoncé.

    Nous nous attaquons maintenant à l'unicité. Soient \( \varphi\) et \( \varphi'\) deux morphismes non triviaux \( \eZ/p\eZ\to \Aut(\eZ/q\eZ)\). Étant donné que \( \Aut(\eZ/q\eZ)\) ne possède qu'un seul sous-groupe d'ordre \( p\), nous savons que \( \Image(\varphi)=\Image(\varphi')=\Gamma\). Nous pouvons donc parler de \( \varphi'^{-1}\) en tant qu'application de \( \eZ/p\eZ\) dans \( \Gamma\). Nous montrons que
    \begin{equation}
        \begin{aligned}
            f\colon \eZ/q\eZ\times_{\varphi}\eZ/p\eZ&\to \eZ/q\eZ\times_{\varphi'}\eZ/p\eZ \\
            (h,k)&\mapsto (h,\alpha(k)) 
        \end{aligned}
    \end{equation}
    où \( \alpha=\varphi'^{-1}\circ\varphi\) est un isomorphisme de groupes. Le calcul est immédiat :
    \begin{subequations}
        \begin{align}
            f(h_1,k_1)f(h_2mk_2)&=\big( h_1,\alpha(k_1) \big)(h_2,\alpha(k_2))\\
            &=\big( h_1\varphi'(\alpha(k_1))h_2m\alpha(k_1k_2) \big)\\
            &=f\big( h_1\varphi(k_1)h_2,k_1k_2 \big)\\
            &=f\big( (h_1,k_1),(h_2,k_2) \big).
        \end{align}
    \end{subequations}
    Par conséquent \( \eZ/q\eZ\times_{\varphi}\eZ/p\eZ\simeq \eZ/q\eZ\times_{\varphi'} \eZ/p\eZ\).
\end{proof}

\begin{proposition}[\cite{PDFpersoWanadoo}]
    Soit \( G\) un groupe fini d'ordre \( pq\) où \( p\) et \( q\) sont deux nombres premiers distincts vérifiant
    \begin{subequations}
        \begin{numcases}{}
            p\neq 1\mod q\\
            q\neq 1\mod p.
        \end{numcases}
    \end{subequations}
    Alors \( G\) est cyclique, abélien et 
    \begin{equation}
        G\simeq \eZ/p\eZ\times \eZ/q\eZ.
    \end{equation}
\end{proposition}

\begin{proof}
    Soient \( n_p\) et \( n_q\) les nombres de \( p\)-Sylow et \( q\)-Sylow. Par le théorème de Sylow \ref{ThoUkPDXf}, \( n_p\) divise \( pq\) et \( n_p=1\mod p\). Le second point empêche \( n_p\) de diviser \( p\). Par conséquent \( n_p\) divise \( q\) et donc \( n_p\) vaut \( 1\) ou \( q\). La possibilité \( n_p=q\) est exclue par l'hypothèse \( q\neq 1\mod p\). Donc \( n_p=1\), et de la même façon nous obtenons \( n_q=1\).

    Soient \( S\) l'unique \( p\)-Sylow et \( T\), l'unique \( q\)-Sylow. Pour les mêmes raisons que celles exposée plus haut, ce sont deux sous-groupes normaux dans \( G\). Étant donné que \( S\) est d'ordre \( p^n\) pour un certain \( n\) et que l'ordre de \( S\) doit diviser celui de \( G\), nous avons \( |S|=p\). De la même façon, \( | T |=q\). Par conséquent \( S\) est un groupe cyclique d'ordre \( p\) et nous considérons \( x\), un de ses générateurs. De la même façon soit \( y\), un générateur de \( T\).

    Nous montrons maintenant que \( x\) et \( y\) commutent, puis que \( xy\) engendre \( G\). Nous savons que \( S\cap T\) est un sous-groupe à la fois de \( S\) et de \( T\), de telle façon que \( | S\cap T |\) divise à la fois \( | S |=p\) et \( | T |=q\). Nous avons donc \( | S\cap T |=1\) et donc \( S\cap T\) se réduit au neutre. Par ailleurs, \( S\) et \( T\) sont normaux, donc
    \begin{subequations}
        \begin{align}
            (xyx^{-1})y^{-1}\in T\\
            x(yx^{-1})y^{-1})\in S,
        \end{align}
    \end{subequations}
    donc \( xyx^{-1}y^{-1}=e\), ce qui montre que \( xy=yx\). 

    Montrons que \( xy\) engendre \( G\). Soit \( m>0\) tel que \( (xy)^m=e\). Pour ce \( m\) nous avons \( x^m=y^{-m}\) et \( y^{-m}=x^m\), ce qui signifie que \( x^m\) et \( y^m\) appartiennent à \( S\cat T\) et donc \( x^m=y^m=e\). Les nombres \( p\) et \( q\) divisent donc tous deux \( m\); par conséquent \( \ppcm(p,q)=pq\) divise \( m\). Nous en concluons que \( xy\) est d'ordre \( pq\) (il ne peut pas être plus) et qu'il est alors générateur.

    Pour la suite nous allons d'abord prouver que \( G=ST\) puis que \( G\simeq S\times T\). Nous savons déjà que \( | S\cap T |=1\), ce qui nous amène à dire que \( | ST |=| S | |T |\). En effet si \( s,s'\in S\) et \( t,t'\in t\) et si \( st=s't'\), alors \( t=s^{-1}s't'\), ce qui voudrait dire que \( s^{-1}s'\in T\) et donc que \( s^{-1}s'=e\). Au final nous avons
    \begin{equation}
        | ST |=| S | |T |=pq=| G |.
    \end{equation}
    Par conséquent \( G=ST\). En nous rappelant du fait que \( S\cap T=\{ e \}\) et que \( S\) et \( T\) sont normaux, le lemme \ref{LemHUkMxp} nous dit que \( G\simeq S\times T\). Le groupe \( S\) étant cyclique d'ordre \( p\) nous avons \( S=\eZ/p\eZ\) et pour \( T\), nous avons la même chose : \( T=\eZ/q\eZ\). Nous concluons que
    \begin{equation}
        G\simeq \eZ/p\eZ\times \eZ/q\eZ.
    \end{equation}
\end{proof}
 


\begin{theorem}[Théorème de Burnside\cite{FabricegPSFinis}] \label{ThoImkljy}
    Le centre d'un \( p\)-groupe non trivial est non trivial.
\end{theorem}

\begin{proof}
    Soit \( G\) un $p$-groupe non trivial. Nous considérons l'action adjointe \( G\) sur lui-même. Les points fixes de cette action sont les éléments du centre :
    \begin{equation}
        \mZ_G=\{ z\in G\tq \sigma_x(z)=z\forall x\in G \}=\Stab_G(G).
    \end{equation}
    Nous utilisons l'équation aux classes \eqref{PropUyLPdp} pour dire que \( | G |=| \mZ_G |\mod p\). Mais \( | \mZ_G |\) n'est pas vide parce qu'il contient l'identité. Donc \( | \mZ_G |\) est au moins d'ordre \( p\).
\end{proof}

\begin{proposition} \label{PropssttFK}
    Si \( p\) est un nombre premier, tout groupe d'ordre \( p\) ou \( p^2\) est abélien.
\end{proposition}
Rappel : un groupe d'ordre \( p\) ou \( p^2\) est automatiquement un $p$-groupe.

\begin{proof}
    Si \( | G |=p\), alors le théorème de Cauchy \ref{ThoCauchyGpFini} nous donne l'existence d'un élément d'ordre \( p\). Cet élément est alors automatiquement générateur, \( G\) est cyclique et donc abélien.

    Si par contre \( G\) est d'ordre \( p^2\), alors les choses se compliquent (un peu). D'après le théorème de Burnside \ref{ThoImkljy}, le centre \( \mZ\) n'est pas trivial; il est alors d'ordre \( p\) ou \( p^2\). Supposons qu'il soit d'ordre \( p\) et prenons \( x\in G\setminus\mZ\). Alors le stabilisateur de \( x\) pour l'action adjointe contient au moins \( \mZ\) et \( x\), c'est à dire que \( |\Stab_G(x)|\geq p+1\). Étant donné que \( \Stab_G(x)\) est un sous-groupe, son ordre est automatiquement \( 1\), \( p\) ou \( p^2\). En l'occurrence, il doit être \( p^2\) (parce que plus grand que \( p\)), et donc \( x\) doit être central, ce qui est une contradiction.
\end{proof}


%---------------------------------------------------------------------------------------------------------------------------
\subsection{Groupe monogène}
%---------------------------------------------------------------------------------------------------------------------------

\begin{theorem}
    Un groupe monogène est abélien. Plus précisément,
    \begin{enumerate}
        \item
            un groupe monogène infini est isomorphe à \( \eZ\),
        \item
            un groupe monogène fini est isomorphe à \( \eZ/n\eZ\) pour un certain \( n\).
    \end{enumerate}
    Un groupe monogène d'ordre \( n\) possède \( \varphi(n)\) générateurs.
\end{theorem}

\begin{proof}
    Le groupe est abélien parce que $g=a^n$, \( g'=a^{n'}\) implique \( gg'=q^{n+n'}=g'g\). Nous considérons un générateur \( a\) de \( G\) (qui existe parce que $G$ est monogène) et le morphisme surjectif
    \begin{equation}
        \begin{aligned}
            f\colon \eZ&\to G \\
            p&\mapsto a^p. 
        \end{aligned}
    \end{equation}
    Si \( G\) est infini, alors \( f\) est injective parce que si \( a^n=a^{n'}\), alors \( a^{n-n'}=e\), ce qui rendrait \( G\) cyclique et par conséquent non infini. Nous concluons que si \( G\) est infini, alors \( f\) est une bijection et donc un isomorphisme \( \eZ\simeq G\).

    Si \( G\) est fini, alors \( f\) n'est pas injective et a un noyau \( \ker f\). Étant donné que \( \ker f\) est un sous-groupe de \( G\), il existe un (unique) \( n\) tel que \( \ker f=n\eZ\) et le premier théorème d'isomorphisme (théorème \ref{ThoPremierthoisomo}) nous indique que
    \begin{equation}
        \eZ/\ker f=\eZ/n\eZ=\Image f=G.
    \end{equation}
    Dans ce cas, le fait qu'un groupe monogène d'ordre \( n\) possède \( \varphi(n)\) générateurs est le contenu de la proposition \ref{PropZnmuphiGensn}.
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Fonction indicatrice d'Euler}
%---------------------------------------------------------------------------------------------------------------------------
\label{subSecKGDFooAbETjs}

\begin{corollary}       \label{CorlvTmsf}
    L'indicatrice d'Euler est multiplicative : si \( p\) est premier avec \( q\), alors \( \varphi(pq)=\varphi(p)\varphi(q)\). De plus si \( p\) et \( q\) sont premiers entre eux,
    \begin{equation}
        \varphi(pq)=(p-1)(q-1).
    \end{equation}
\end{corollary}

\begin{proof}
    Nous savons que si \( p\) et \( q\) sont premiers entre eux, alors le théorème \ref{ThoLnTMBy} nous donne l'isomorphisme de groupe
    \begin{equation}
        (\eZ/pq\eZ,+)\simeq(\eZ/p\eZ,+)\times(\eZ/q\eZ,+).
    \end{equation}
    Un élément \( (x,y)\) est générateur du produit si et seulement si \( x\) est générateur de \( \eZ/p\eZ\) et \( y\) est générateur de \( \eZ/q\eZ\). Par la proposition \ref{PropZnmuphiGensn}, il y a \( \varphi(p)\varphi(q)\) tels éléments. Par ailleurs le nombre de générateurs de \( \eZ/pq\eZ\) est \( \varphi(pq)\), d'où l'égalité.

    Si \( p\) est premier, nous avons \( \varphi(p)=p-1\) parce que tous les entiers de \( \{ 1,\ldots, p-1 \}\) sont premiers avec \( p\).
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Nombres premiers}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Dans \( \eN\), il y a assez bien de nombres premiers. Nous allons voir maintenant que la somme des inverses des nombres premiers diverge. Pour comparaison, la somme des inverses des carrés converge. Il y a donc plus de nombres premiers que de carrés.
\begin{lemma}   \label{LemheKdsa}
    Un entier \( n\geq 1\) se décompose de façon unique en produit de la forme \( n=qm^2\) où \( q\) est un entier sans facteurs carrés et \( m\), un entier.
\end{lemma}

\begin{proof}
    Pour \( n=1\), c'est évident. Nous supposons \( n\geq 2\).

    En ce qui concerne l'existence, nous décomposons \( n\) en facteurs premiers\footnote{Théorème \ref{ThoAJFJooAveRvY}.} et nous séparons les puissances paires des puissances impaires :
    \begin{subequations}
        \begin{align}
            n&=\prod_{i=1}^rp_p^{2\alpha_i}\prod_{j=1}^sq_{j}^{2\beta_j+1}\\
            &=\underbrace{\left( \prod_{i=1}^rp_i^{2\alpha_i}\prod_{j=1}^sq^{2\beta_j} \right)}_{m^2}\underbrace{\prod_{j=1}^sq_j}_{q}.
        \end{align}
    \end{subequations}
    
    Nous passons à l'unicité. Supposons que \( n=q_1m_1^2=q_2m_2^2\) avec \( q_1\) et \( q_2\) sans facteurs carrés (dans leur décomposition en facteurs premiers). Soit \( d=\pgcd(m_1,m_2)\) et \( k_1\), \( k_2\) définis par \( m_1=dk_1\), \( m_2=dk_2\). Par construction, \( \pgcd(k_1,k_2)=1\). Étant donné que
    \begin{equation}        \label{EqWPOtto}
        n=q_1d^2k_1^2=q_2d^2k_2^2,
    \end{equation}
    nous avons \( q_1k_1^2=q_2k_2^2\) et donc \( k_1^2\) divise \( q_2k_2^2\). Mais \( k_1\) et \( k_2\) n'ont pas de facteurs premiers en commun, donc \( k_1^2\) divise \( q_2\), ce qui n'est possible que si \( k_1=1\) (parce que \( k_1^2\) n'a que des facteurs premiers alors que \( q_2\) n'en a pas). Dans ce cas, \( d=m_1\) et \( m_1\) divise \( m_2\). Si \( m_2=lm_1\) alors l'équation \eqref{EqWPOtto} se réduit à  \( n=q_1m_1^2=q_2l^2m_1^2\) et donc
    \begin{equation}
        q_1=q_2l^2,
    \end{equation}
    ce qui signifie \( l=1\) et donc \( m_1=m_2\).

\end{proof}

\begin{theorem} \label{ThonfVruT}
    Soit \( P\), l'ensemble des nombres premiers. Alors la somme \( \sum_{p\in P}\frac{1}{ p }\) diverge et plus précisément,
    \begin{equation}
        \sum_{\substack{p\leq x\\p\in P}}\frac{1}{ p }\geq \ln(\ln(x))-\ln(2).
    \end{equation}
\end{theorem}
\index{nombre!premier}
\index{convergence!rapidité}
\index{série!numérique}

\begin{proof}
    Nous posons
    \begin{equation}
        S_x=\{ \text{\( q\leq x\) avec \( q\) sans facteurs carrés} \}
    \end{equation}
    et
    \begin{equation}
        P_x=\{ p\in P\tq p\leq x \}.
    \end{equation}
    Si
    \begin{equation}
        K_x=\{ \text{\( (q,m)\) tels que \( q\) n'a pas de facteurs carrés et \( qm^2\leq x\)} \},
    \end{equation}
    alors nous avons
    \begin{equation}
        K_x=\bigcup_{q\in S_x}\bigcup_{m\leq \sqrt{x/q}}(q,m).
    \end{equation}
    Par définition et par le lemme \ref{LemheKdsa} nous avons aussi
    \begin{equation}
        \{ n\leq x \}=\{ qm^2\tq (q,m)\in K_x \}.
    \end{equation}
    Tout cela pour décomposer la somme
    \begin{equation}        \label{EqpoJpuC}
        \sum_{n\leq x}\frac{1}{ n }=\sum_{q\in S_x}\sum_{m\leq\sqrt{x/q}}\frac{1}{ m^2 }\leq \sum_{q\in S_x}\frac{1}{ q }\underbrace{\sum_{m\geq 1}\frac{1}{ m^2 }}_{=C}.
    \end{equation}
    Nous avons aussi
    \begin{subequations}
        \begin{align}
            \prod_{p\in P_x}\left( 1+\frac{1}{ p } \right)&=1+\sum_{p\in P_x}\frac{1}{ p }+\sum_{\substack{p,q\in P_x\\p<q}}\frac{1}{ pq }+\sum_{\substack{p,q,r\in P_x\\p<q<r}}\frac{1}{ pqr }+\ldots\\
            &\geq 1+\sum_{p\in P_x}\frac{1}{ p }+\sum_{\substack{p,q\in P_x\\pq\leq x}}\frac{1}{ pq }+\sum_{\substack{p,q,r\in P_x\\pqr\leq x}}\frac{1}{ pqr }+\ldots
        \end{align}
    \end{subequations}
    Les sommes sont finies. Les sommes s'étendent sur toutes les façons de prendre des produits de nombres premiers distincts de telle sorte de conserver un produit plus petit que \( x\); c'est à dire que les sommes se résument en une somme sur les éléments de \( S_x\) :
    \begin{equation}        \label{EqooilOz}
        \exp\left( \sum_{p\in P_x}\frac{1}{ p } \right)\geq\prod_{p\in P_x}\left( 1+\frac{1}{ p } \right)\geq \sum_{q\in S_x}\frac{1}{ q }.
    \end{equation}
    La première inégalité est simplement le fait que \( 1+u\leq e^u\) si \( u\geq 0\). Nous prolongeons maintenant les inégalités
    \begin{equation}
        \ln(x)\leq \sum_{n\leq x}\int_{n}^{n+1}\frac{dt}{ t }\leq \sum_{n\geq x}\frac{1}{ n }
    \end{equation}
    avec les inégalités \eqref{EqpoJpuC} et \eqref{EqooilOz} :
    \begin{equation}
        \ln(x)\leq \sum_{n\geq}\frac{1}{ n }\leq C\sum_{q\in S_x}\frac{1}{ q }\leq C\leq \exp\left( \sum_{p\in P_x}\frac{1}{ p } \right).
    \end{equation}
    En passant au logarithme,
    \begin{equation}
        \ln\big( \ln(x) \big)\leq\ln(C)+\sum_{p\in P_x}\frac{1}{ p }.
    \end{equation}
    Ceci montre la divergence de la série de droite. Nous cherchons maintenant une borne pour \( C\). Pour cela nous écrivons
    \begin{subequations}
        \begin{align}
            \sum_{n=1}^N\frac{1}{ n^2 }&\leq 1+\sum_{n=2}\frac{1}{ n(n-1) }\\
            &=1+\sum_{n=2}^N\left( \frac{1}{ n-1 }-\frac{1}{ n } \right)\\
            &=1+1-\frac{1}{ N }\\
            &\leq 2.
        \end{align}
    \end{subequations}
    Donc \( C\leq 2\).
\end{proof}
Ce théorème prend une nouvelle force en considérant le théorème de Müntz \ref{ThoAEYDdHp} qui dit qu'alors l'ensemble \( \Span\{ x^p\tq \text{\( p\) est premier} \}\) est dense dans les fonctions continues sur \( \mathopen[ 0 , 1 \mathclose]\) muni de la norme uniforme ou \( \| . \|_2\).

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Chiffrement RSA}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\label{SecEVaFYi}
\index{groupe!fini}
\index{groupe!permutation}
\index{groupe!partie génératrice}
\index{anneau!\( \eZ/n\eZ\)}
\index{nombre!premier}

Ce passage sur RSA provient en bonne partie de la \wikipedia{fr}{Rivest_Shamir_Adleman}{la page Wikipédia}.

Alice veut envoyer un message à Bob. L'idée est que Bob va donner à Alice une clef publique qui va permettre de chiffrer le message tandis que Bob va garder pour lui une clef privée qui permet de déchiffrer.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Mise en place par Bob}
%---------------------------------------------------------------------------------------------------------------------------

Bob se crée une paire de clef publique, clef privée de la façon suivante.
\begin{enumerate}
    \item
        Bob choisit deux nombres premiers distincts \( p,q\).
    \item
        Il calcule \( n=pq\) .
    \item
        Par le corollaire \ref{CorlvTmsf}, l'indicatrice d'Euler \( \varphi(n)=(p-1)(q-1)\) est facile à calculer pour Bob.
    \item
        Bob choisit \( e\in \eN\) premier avec \( \varphi(n)\), puis \( d\) tel que \( ed\in[1]_{\varphi(n)}\).
\end{enumerate}
Maintenant la paire est : clef publique \( (n,e)\) et clef privée \( (n,d)\)\footnote{Le fait que \( e\) soit public et \( d\) soit privé est une convention. \( e\) comme  \emph{encryption} et \( d\) comme \emph{decryption}.}.

Bob envoie la paire \( (n,e)\) à Alice. 

\begin{remark}
    Ici nous ne supposons pas que la communication soit sure. Une tierce personne peut intercepter le message. D'ailleurs en principe les gens publient leurs clef publique sur leurs sites, voire sur des sites dédiés. Le problème de l'identification reste à résoudre \wikipedia{en}{Key_signing_party}{à l'ancienne}.
\end{remark}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Chiffrement}
%---------------------------------------------------------------------------------------------------------------------------

Nous chiffrons en utilisant la clef publique \( (n,e)\). D'abord Alice se débrouille pour transformer son message en un nombre plus petit que \( n\). Soit \( M\) ce message. Alice code \( M\) en
\begin{equation}
    C=M^e\mod n.
\end{equation}
Tout le truc est que nous allons voir que l'application \( x\mapsto x^e\) est une bijection de \( \eF_n\) et que l'inverse est facile à calculer par Bob et difficile pour les autres. Alice envoie \( C\) à Bob. Encore une fois, nous ne supposons pas que cette communication soit privée. Le nombre \( C\) peut être intercepté.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Déchiffrement}
%---------------------------------------------------------------------------------------------------------------------------

Nous allons montrer que \( M=C^d\mod n\), et donc que Bob, connaissant \( (n,d)\), peut déchiffrer. D'abord
\begin{equation}
    C^d=(M^e)^d=M^{ed},
\end{equation}
mais nous savons qu'il existe \( k\) tel que
\begin{equation}
    ed=1+k\varphi(n)=1+k(p-1)(q-1).
\end{equation}
L'étape astucieuse est de remarquer que
\begin{equation}    \label{EqreeHgn}
    M^{1+k(p-1)(q-1)}\in [M]_p\cap[M]_q.
\end{equation}
Pour montrer cela nous utilisons le petit théorème de Fermat \ref{ThoOPQOiO} et la remarque \ref{RemCoSnxh}.
\begin{itemize}
    \item Si \( M\) est premier avec \( p\), alors \( M^{p-1}\in[1]_p\).
    \item Si \( M\) n'est pas premier avec \( p\), alors \( M\) est multiple de \( p\) et on sait que \( M^{p-1}\in[0]_p=[M]_p\).
\end{itemize}
Dans les deux cas nous avons \eqref{EqreeHgn}. Le nombre \( M^{1+k\varphi(n)}-M\) est donc à la fois multiple de \( p\) et de \( q\).

Le lemme chinois \ref{LemCtUeGA} nous dit immédiatement\footnote{C'est ici qu'il est important que \( p\) ne soit pas égal à \( q\). Si \( p=q\), alors le lemme chinois ne fonctionne pas.} qu'alors
\begin{equation}
    M^{1+k\varphi(n)}-M
\end{equation}
est un multiple de \( pq=n\), c'est à dire que
\begin{equation}
    C^d=M^{ed}\in [M]_n.
\end{equation}

Si on ne croit pas au lemme chinois, on peut utiliser le lemme de Gauss. Posons
\begin{equation}
    M^{1+k\varphi(n)}-M=ap=bq.
\end{equation}
Dans ce cas \( p\) divise \( bq\), mais \( q\) est premier avec \( p\), donc le lemme de Gauss \ref{LemSdnZNX} nous enseigne\footnote{Ici aussi, si \( p=q\), ça ne marche pas.} que \( p\) divise \( b\).

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Une imprudence à ne pas commettre}
%---------------------------------------------------------------------------------------------------------------------------

Nous avons pris deux cas selon que \( M\) soit ou non premier avec \( p\). Une question qui se pose est la suivante : est-ce que c'est une bonne idée d'envoyer un message qui ne soit pas premier avec \( p\) ?

Si nous savons que \( M\) n'est pas premier avec \( p\), alors nous avons \( M^e=l^ep^e\) et \( n=pq\) qui sont publics. Donc un calcul de PGCD permettrait de trouver \( p\).

Il faut cependant savoir que \label{PageAKTBooMDeQxY}
\begin{itemize}
    \item La probabilité que ça arrive est infime : vu que \( M\) est entre \( 0\) et \( n=pq\), les multiples de \( p\) possibles sont \( p,2p,\cdots pq\). Il y a dont une chance sur \( p\) que cela arrive. Typiquement avec des si \( p\) de l'ordre de \( 10^{120}\), on peut utiliser RSA chaque milliseconde sur chaque atome de l'univers depuis le début des temps que ça ne se serait presque certainement pas encore produit.
    \item
        De toutes façons Alice ne sait pas vérifier si son message est premier avec \( p\) parce qu'elle ne connaît pas \( p\).
    \item 
        En conclusion la partie de la preuve qui montre que \( M^{1+\varphi(n)}\in [M]_p\cap[M]_q\) dans le cas \( M\) non premier avec \( p\) est, à toutes fins pratiques, inutile parce que ce cas de figure ne se présentera jamais dans toutes l'histoire de l'univers, même pas avec une civilisation intelligente autour de chaque étoile.
\end{itemize}

\begin{probleme}\label{ProbGAYFooZATuYy}
    Est-ce que ces trois points sont corrects ?
\end{probleme}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Problèmes calculatoires}
%---------------------------------------------------------------------------------------------------------------------------

Pour implémenter RSA, il faut pouvoir faire (au moins) trois choses :
\begin{enumerate}
    \item
        Trouver de grands nombres premiers.
    \item
        Trouver des couples de Bézout.
    \item
        Calculer \( M^e\) lorsque \( e\) est très grand.
\end{enumerate}
En ce qui concerne le problème de trouver des nombres premiers, c'est compliqué, mais il faut savoir qu'il y en a plein. À \( 120\) chiffres, il y a environ autant de nombres premiers que d'atomes dans \( 10^{20}\) fois l'univers connu. Cela rend impossible toute tentative de factoriser un grand nombre en essayant toutes les possibilités. Même pas en science-fiction\footnote{Cela donne une idée des connaissances en math des klingons, dont le docteur Spock parvient à craquer le code mentalement en deux heures.}.

Trouver des nombres \( u\) et \( v\) tels que \( Au+Bv=\pgcd(A,B)\) est un problème expliqué en \ref{subSecIpmnhO}.

En ce qui concerne le calcul de \( M^e\) lorsque \( e\) est grand, il n'est évidemment pas pensable de faire \( M\cdot M\cdot\ldots M\) avec \( e\) facteurs. Un truc pour calculer en moins d'étapes est l'\defe{exponentiation rapide}{exponentielle!rapide}. Si \( e=2k\) est pair, nous calculons
\begin{equation}
    M^e=(M^k)^2;
\end{equation}
si \( e=2k+1\) alors nous calculons
\begin{equation}
    M^e=M(M^k)^2.
\end{equation}
Le calcul prend alors seulement environ \(  \log_2(e)  \) étapes. Pour donner une idée,
\begin{equation}
    \log_2(10^{120})\simeq 400.
\end{equation}
Très raisonnable, mais un ordinateur reste indispensable.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{La solidité de RSA}
%---------------------------------------------------------------------------------------------------------------------------

La solidité de la méthode repose sur deux conjectures (non démontrées !!) :
\begin{itemize}
    \item Pour déchiffrer il \emph{faut} connaitre \( p\) et \( q\). 
    \item La difficulté de trouver \( p\) et \( q\) en partant de \( n=pq\) est exponentielle en \( n\).
\end{itemize}
Dans la méthode de déchiffrage proposée ici, \( p\) et \( q\) sont utilisés pour calculer \( d\) qui est solution de \( ed=[1]_{\varphi(n)}\). La seule formule connue pour calculer \( \varphi(n)\) est \( \varphi(n)=(p-1)(q-1)\). Si on trouve plus simple, alors RSA peut être craqué.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Note non mathématique pour doucher l'enthousiasme}
%---------------------------------------------------------------------------------------------------------------------------

Il est \href{https://www.torproject.org/about/torusers.html.en#activists}{souvent dit} que différents systèmes de chiffrement peuvent aider à avoir des discussions «discrètes» dans les régimes totalitaires. La technologie au service de la démocratie, voila qui enthousiasme la jeunesse\footnote{Cela dit, le \href{ https://www.torproject.org/projects/torbrowser.html.en }{navigateur Tor}, qui est un pur produit de RSA, permet effectivement d'accéder en France aux sites bloqués pour apologie du terrorisme (mars 2015).}. La réalité est qu'il est souvent possible de craquer un système de chiffrement arbitrairement complexe, même sans connaitre le petit théorème de Fermat \ldots

\begin{center}
        \ifpdf
            \includegraphics[width=10cm]{security.png}
        \else
            \includegraphics[width=10cm]{security.eps}
        \fi

        \url{http://xkcd.com/538/}. Ce dessin est publié sous licence \href{http://creativecommons.org/licenses/by-nc/2.5/}{ Creative Commons Attribution-NonCommercial 2.5 License}.
\end{center}

\noindent \ldots tout dépends du contexte.
