% This is part of (almost) Everything I know in mathematics
% Copyright (c) 2016
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Lax-Milgram theorem}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{definition}  \label{DEFooGFTZooUQfUdY}
    A bilinear form \( a\colon V\times V\to \eR\) is \defe{elliptic}{bilinear form!elliptic} or \defe{coercive}{bilinear form!coercive} is there exists a \( \alpha>0\) such that \( a(u,u)\geq \alpha\| u \|^2\) for every \( u\in V\).
\end{definition}

\begin{theorem}[Lax-Milgram\cite{ooRIEKooXIQYhE}]       \label{THOooFDJYooCSNnuv}
    Let \( V\) be ah Hilbert space and
    \begin{enumerate}
        \item
            a linear and bounded map \( L\colon V\to \eR\); we write \( \| L \|=C\),
        \item
            a bilinear map \( a\colon V\times V\to \eR\) is continuous; we write \( M\) a constant such that \( | a(u,v) |\leq M\| u \|\| v \|\) for all \( u,v\in V\),
        \item
            the bilinear form \( a\) is elliptic\footnote{Définition \ref{DEFooGFTZooUQfUdY}} and we write \( \alpha\) a strictly positive constant such that \( a(u,u)\geq \alpha\| u \|^2\).
    \end{enumerate}
    Then the problem of finding \( u\in V\) such that 
    \begin{equation}
        a(u,v)=L(v)
    \end{equation}
    for every \( v\in V\) has one and only one solution \( u\in V\). Moreover this solution satisfies
    \begin{equation}
        \| u \|\leq \frac{ M }{ \alpha }C.
    \end{equation}
\end{theorem}
The map \( L\) is linear and bounded; it is continuous by proposition \ref{PropmEJjLE}. The existence of \( M\) is due to the fact that \( a\) is bilinear on \( V\) and in particular linear (and continuous, then bounded) on \( V\times V\). But this is not quite obvious from the definition \eqref{DefFAJgTCE}. It is shown in \cite{ooCUHNooNYIeGt} that putting on \( V\times V\) the product topology\footnote{Définition \ref{DefIINHooAAjTdY}.} that a sesquilinear map is continuous if and only if there exist such a constant. And since the topology of the product norm is the product topology (lemma \ref{LEMooWVVCooIGgAdJ}), we are safe.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Variational formulation (not too rigorous)}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

As mentioned in the title, we are not going to deal with existence of the derivative and the integrals that we will write down.

Let the partial derivative equation
\begin{subequations}        \label{EQooZAISooSylvFH}
        \begin{numcases}{}
            -\Delta u=f\\
            u|_{\partial \Omega}=0
        \end{numcases}
    \end{subequations}
where \( \Delta u=\sum_{j=1}^n\frac{ \partial^2 v  }{ \partial x_j }\) on the open bounded part \( \Omega\) of \( \eR^n\). 

We are searching the solutions in a vector space
\begin{equation}
    V=\{ v\colon \Omega\to \eR\tq v|_{\partial \Omega}=0 \}.
\end{equation}
Our aim is to found a bilinear form \( a\colon V\times V\to \eR\) and a linear map \( L\colon V\to \eR\) such that the solutions of the original problem \eqref{EQooZAISooSylvFH} are solutions of the problem
\begin{subequations}
    \begin{numcases}{}
        u\in V\\
        a(u,v)=L(v)\,\forall v\in V
    \end{numcases}
\end{subequations}
The choice of \( V\), \( a\) and \( L\) is a \defe{variational formulation}{variational!formulation} of the differential equation\footnote{I said «not too rigorous» in the title, so please don't ask yourself now what space $V$ can be.}.

In order to have a variational formulation of the equation \eqref{EQooZAISooSylvFH} we multiply \( -\Delta u=f\) by a test function \( v\in V\) and we integrate over \( \Omega\) :
\begin{equation}
    -\int_{\omega}\Delta u\,v=\int_{\Omega}fv.
\end{equation}
Now if we set
\begin{subequations}
    \begin{align}
        a(u,v)&=-\int_{\Omega}(\Delta u)v   \label{SUBEQooKUNUooOtKVaP}\\
        L(v)&=\int_{\Omega}fv
    \end{align}
\end{subequations}
we have a variational formulation of our problem. A solution of a variational formulation is a \defe{weak solution}{solution!weak} of the partial derivative equation.

Does the form \eqref{SUBEQooKUNUooOtKVaP} check the hypothesis of the Lax-Milgram theorem \ref{THOooFDJYooCSNnuv} ? Obviously not because we did not defined the space \( V\), so nothing has any sense here. But we can say more : the bilinear form \( a\) is not \emph{obviously} positive. As we will see it is positive on \( V\) because of the boundary condition. We want to write is slightly differently in order to, taking into account the boundary condition, have a bilinear form that is for sure positive.

Using the integration by part of formula \eqref{EQooJLDTooIMtxEX} taking into account the fact that the boundary term vanishes we have
\begin{equation}
    \int_{\Omega}(\Delta u)v=-\int_{\Omega}\nabla u\cdot \nabla v,
\end{equation}
so that we can as well consider the variational problem
\begin{subequations}
    \begin{align}
        a(u,v)&=-\int_{\Omega}\nabla u\cdot \nabla v   \label{SUBEQooLFDKooTDKiDA}\\
        L(v)&=\int_{\Omega}fv
    \end{align}
\end{subequations}
In this case, the form \( a\) is more clearly positive defined :
\begin{equation}
    a(u,u)=\int_{\Omega}| \nabla u |^2\geq 0.
\end{equation}

Notons que cette formule pour \( a\) est symétrique et que nous n'avons pas encore démontré quoi que ce soit pour les hypothèses du théorème de Lax-Milgram. Nous espérons seulement que la forme bilinéaire \eqref{SUBEQooLFDKooTDKiDA} ait de meilleures propriétés que \eqref{SUBEQooKUNUooOtKVaP}.

The result of this sections is the following.
\begin{proposition}[Not too rigorous]
    A function \( u\in V\) is solution of the variational problem if and only if it is solution of the Poisson equation.
\end{proposition}

\begin{proof}
    The fact that the solution of the Poisson equation (including the boundary conditions) are solutions of the variational problem is what we just did.

    In the other sense we recall the equation :
    \begin{subequations}
        \begin{numcases}{}
            -\Delta u=f\\
            u|_{\partial \Omega}=0
        \end{numcases}
    \end{subequations}
    The variational problem is searching a function in \( V\), that is a function that automatically satisfy the boundary condition. If \( u\) is solution of the variational problem, then
    \begin{equation}
        \int_{\Omega}\nabla u\cdot \nabla v=\int_{\Omega}fv
    \end{equation}
    We integrate by part the left hand side :
    \begin{equation}
        \int_{\Omega}\nabla u\cdot \nabla v=-\int_{\Omega}(\Delta u)v+\underbrace{int_{\partial\Omega}\frac{ \partial u }{ \partial n }v}_{=0},
    \end{equation}
    so that
    \begin{equation}        \label{EQooAJMDooNJTYRm}
        \int_{\Omega}(f-\Delta u)v=0
    \end{equation}
    for every \( v\in V\).

    If we really know nothing about the space \( V\), we cannot conclude that \( f-\Delta u=0\). We can however do something that will probably work if \( V\) is not too strange. If \( f-\Delta u\neq 0\) at some point \( x\in \Omega\) (suppose \( (f-\Delta u)(x)>0\) in order to fix the ideas), then \( f-\Delta u>0\) on an open set \( A\) around \( x\). If \( v\) is a positive function that vanishes outside \( A\) then, taking \( B\subset A\) on which \( v>0\),
    \begin{equation}
        \int_{\Omega}(f-\Delta u)v=\int_A(f-\Delta u)v>\int_B(f-\Delta u)v.
    \end{equation}
    The last integral is for sure strictly positive, which contradicts \eqref{EQooAJMDooNJTYRm}.
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Galerkin's approximation}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Let us once again be not too rigorous and deal with the problem
\begin{subequations}
    \begin{numcases}{}
        -u''+u=f\\
        u(0)=u(1)=0
    \end{numcases}
\end{subequations}
on the open interval \( \mathopen] 0 , 1 \mathclose[\). The good functional space seems to be
\begin{equation}
    H_0^1\big( \mathopen] 0 , 1 \mathclose[ \big)=\{ u\in H^1\big( \mathopen] 0 , 1 \mathclose[ \big)\st u(0)=u(1)=0 \}.        
\end{equation}
Of course, this definition is not rigorous because the elements in the Sobolev spaces are classes of functions and the boundary values are not defined. Let us go on and see what happens. 

Let \( v\in H_0^1\). We multiply the equation by \( v\) and integrate over the interval \( I=\mathopen] 0 , 1 \mathclose[\) :
\begin{equation}
    -\langle u'', v\rangle +\langle u, v\rangle =\langle f, v\rangle,
\end{equation}
and an integration by part, taking into account the fact that \( v\) vanishes at the border gives
\begin{equation}
    \langle u', v'\rangle +\langle u, v\rangle =\langle f, v\rangle,
\end{equation}

If \( u\in C^2(I)\), the two formulations are equivalent. If not, we are not sure. The point of the second formulation is that one can build a piecewise affine approximation. We divide the interval \( I\) into \( N+1\) pieces
\begin{equation}
    x_j=\frac{ j }{ N+1 }
\end{equation}
with \( j=0,\ldots, N+1\). Let \( V_N\) be the set of continuous piecewise affine functions that are vanishing on the border :
\begin{equation}
V_N=\{ v\in C^0(I)\st v|_{\mathopen] x_j , x_{j+1} \mathclose[}\text{ is linear and } v(0)=v(1)=0 \}.
\end{equation}
This is a finite dimensional vector space because the elements are determined by the values on the \( x_i\)'s. Moreover the space \( V_N\) is included in \( H^1_0(I)\).

\begin{proposition}
    There exists an unique element \( u_N\in V_N\) satisfying the equation
    \begin{equation}        \label{EQooOFLCooHmjaOM}
        \langle u_n', v'\rangle +\langle u_N, v\rangle =\langle f, v\rangle 
    \end{equation}
    for all \( v\in V_N\). This solution is the \defe{Galerkin approximation}{Galerkin approximation}.
\end{proposition}

\begin{proof}
    We consider the basis \( \{ \phi_j \}_{j=1,\ldots, N}\) of \( V_N\) defined by
    \begin{equation}
        \phi_j(x_i)=\delta_{ij}.
    \end{equation}
    We are searching for \( u_N\) under the form \( u_N=\sum_{j=1}^Na_j\phi_j\). Just by computing on the point \( x_j\) we know that
    \begin{equation}
        a_j=u_N(x_j).
    \end{equation}
    At this moment, this equality does not help, but we keep it in mind. Since the equality \eqref{EQooOFLCooHmjaOM} has to hold for every \( v \in V_N\), it holds in particular for \( v=\phi_k\) :
    \begin{equation}
        \langle u_N', \phi_k'\rangle +\langle u_N, \phi_k\rangle =\langle f, \phi_k\rangle 
    \end{equation}
    and by linearity of the inner product,
    \begin{equation}
        \sum_la_l\big( \langle \phi'_k, \phi'_l\rangle +\langle \phi_l, \phi_k\rangle  \big)=\langle f, \phi_k\rangle .
    \end{equation}
    If we set
    \begin{subequations}
        \begin{align}
            R_{kl}&=\langle \phi_k', \phi_l'\rangle +\langle \phi_k, \phi_l\rangle \\
            b_k&=\langle f, \phi_k\rangle,
        \end{align}
    \end{subequations}
    we have to solve the linear system
    \begin{equation}
        Ra=b.
    \end{equation}
    In order to show that this system has an unique solution, we have to get some informations about the matrix \( R\). The matrix \( R\) is the matrix of the \( 2\)-form
    \begin{equation}
        R(f,g)=\langle f', g'\rangle +\langle f, g\rangle 
    \end{equation}
    in the basis \( \{ \phi_j \}\) of \( V_N\).

    \begin{subproof}
        \item[\( R\) is strictly positive defined]
            We have \( R(f,f)\geq 0\) and if \( R(f,f)=0\), then \( \langle f, f\rangle =0\) and \( \langle f', f'\rangle =0\). Thus \( f=0\) almost everywhere and since elements of \( V_N\) are continuous, \( f=0\).
        \item[\( R\) is symmetric] Clear from the definition.
    \end{subproof}
    
    The matrix is thus invertible (in fact we do not use the symmetry to reach this conclusion) and the system has an unique solution in \( V_N\).
    
\end{proof}

We can compute the matrix \( R\) : the elements are only some inner products and integrals. Here is a graph of \( \phi_1\) and \( \phi_2\) :
\begin{center}
   \input{pictures_tex/Fig_DGFSooWgbuuMoB.pstricks}
\end{center}
The affines pieces are :
\begin{subequations}
    \begin{align}
        f_1(x)&=(N+1)x\\
        f_2(x)&=-(N+1)x+2\\
        f_3(x)&=(N+1)x-1\\
        f_4(x)&=-(N+1)x+3.
    \end{align}
\end{subequations}
And we have to integrate. We make the computations :
\lstinputlisting{src_sage/sageSnip008.sage}
returns
\VerbatimInput[tabsize=3]{src_sage/sageSnip008.txt}
which means that
\begin{subequations}
    \begin{align}
        \langle \phi_j, \phi_j\rangle &=\frac{ 2 }{ 3(N+1) }\\
        \langle \phi_j, \phi_{j+1}\rangle&=\langle \phi_j, \phi_{j-1}\rangle =\langle f_2, f_3\rangle =\frac{1}{ 6(N+1) }\\
        \langle \phi'_j, \phi'_j\rangle &=2N+2\\
        \langle \phi'_j, \phi'_{j+1}\rangle &=-N-1
    \end{align}
\end{subequations}
The inner product \( \langle \phi_i, \phi_j\rangle \) is zero when \( | i-j |\geq 2\). 



