% This is part of Mes notes de mathématique
% Copyright (c) 2011-2014
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Lemme de Borel}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Fonctions plateaux}
%---------------------------------------------------------------------------------------------------------------------------

Soient \( a<b<c<d\) dans \( \eR\). Nous voulons trouver une fonction \( f\in C^{\infty}(\eR)\) à valeurs positives telle que
\begin{enumerate}
    \item
        \( f(x)=1\) si \( x\in\mathopen[ b , c \mathclose]\)
    \item
        \( \supp(f)\subset\mathopen[ a , d \mathclose]\).
\end{enumerate}

Nous commençons par l'exemple classique de fonction \(  C^{\infty}\) qui n'est pas nulle partout :
\begin{equation}
    \varphi(x)=\begin{cases}
        e^{-1/x}    &   \text{si \( x>0\)}\\
        0    &    \text{sinon}.
    \end{cases}
\end{equation}
Il est facile de vérifier que \( \varphi\) est de classe \(  C^{\infty}\) parce que
\begin{equation}
    \lim_{x\to 0^+} \frac{  e^{-1/x} }{ P(x) }=0 
\end{equation}
pour tout polynôme \( P\). De plus c'est une fonction qui vaut zéro sur \( \mathopen] -\infty , 0 \mathclose]\). Ensuite nous construisons la fonction
\begin{equation}
    \psi_m(x)=1-\frac{ \int_0^x \varphi(t)dt }{ \int_0^m\varphi(t)dt}=\begin{cases}
        1    &   \text{si \( x<0\)}\\
        0    &    \text{si \( x>m\)}\\
        \text{positive} &\text{si \( x\in\mathopen[ 0 , m \mathclose]\)}.
    \end{cases}
\end{equation}
Cette fonction est encore de classe $ C^{\infty}$. À partir de là nous considérons les fonctions
\begin{subequations}
    \begin{align}
        f_1(x)&=\psi_{d-c}(x-c)=\begin{cases}
            1    &   \text{si \( x<c\)}\\
            0    &    \text{si \( x>d\)}\\
            \text{positive} &\text{si \( x\in\mathopen[ c , d \mathclose]\)}.
        \end{cases}\\
        f_2(x)&=\psi(b-a)(b-x)=\begin{cases}
            0    &   \text{si \( x<a\)}\\
            1    &    \text{si \( x>b\)}\\
            \text{positive} &\text{si \( x\in \mathopen[ a , b \mathclose]\)}.
        \end{cases},
    \end{align}
\end{subequations}
et finalement la fonction suivante répond à la question des fonctions plateaux sur \( \eR\) :
\begin{equation}
    f(x)=f_1(x)f_2(x).
\end{equation}
\index{fonction!définie par une intégrale}

Une variation sur le même thème est l'existence de fonctions infiniment dérivables à support compact, c'est à dire des fonctions dans \(  C^{\infty}_c(\eR^d)=\swD(\eR^d)\). Ces espaces ne sont pas vides, par exemple nous avons la fonction
\begin{equation}    \label{EqOBYNEMu}
    \xi(x)=\begin{cases}
        e^{-1/(1-| x |^2)}    &   \text{si \( x\in B(0,1)\)}\\
        0    &    \text{sinon}.
    \end{cases}
\end{equation}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Le lemme de Borel}
%---------------------------------------------------------------------------------------------------------------------------

\begin{lemma}[Lemme de Borel\cite{KXjFWKA}] \label{LemRENlIEL}
    Soit \( (a_n)\) une suite dans \( \eR\). Il existe une fonction \( u\in C^{\infty}(\eR)\) telle que \( u^{(k)}(0)=a_k\) pour tout \( k\geq 0\).
\end{lemma}
\index{lemme!Borel}
\index{prolongement!de fonctions!lemme de Borel}
\index{dérivabilité!lemme de Borel}

\begin{proof}
    Soit \( \varphi\in C^{\infty}_c(\eR)\) une fonction telle que \( \varphi(x)=1\) si \( | x |\leq \frac{ 1 }{2}\) et telle que \( \supp(\varphi)\subset\mathopen] -1 , 1 \mathclose[\).

    Nous commençons par considérer une suite de réels strictement positifs \( (\lambda_k)\) dont nous fixerons une valeur précise plus tard, et nous posons
    \begin{equation}
        f_k(x)=\varphi(\lambda_k x)\frac{ a_k }{ k! }x^k.
    \end{equation}
    Nous allons étudier la convergence et les propriétés de \( u(x)=\sum_{k=0}^{\infty}f_k(x)\). 

    Calculons (formellement) la \( m\)\ieme dérivée de \( f_k\) :
    \begin{subequations}
        \begin{align}
            f_k^{(m)}(x)&=\frac{ a_k }{ k! }\sum_{l=0}^{m}\binom{ m }{ l }\lambda_k^{m-l}\varphi^{(m-l)}(\lambda_kx)(x^k)^{(l)}\\
            &=a_k\sum_{l=0}^{m}\binom{ l }{ m }\lambda_k^{m-l}\varphi^{(m-l)}(\lambda_kx)\frac{ x^{k-l} }{ (k-l)! }.
        \end{align}
    \end{subequations}
    Notons que nous travaillons à \( m\) fixé et que nous ne nous intéressons qu'aux termes avec \( k\) assez grand; nous pouvons donc supposer \( k\geq m\). De toutes façons pour \( \sum_{k=0}^mf_k\), on a la classe \(  C^{\infty}\), et la permutation de la somme avec tout ce qu'on veut. Vu que \( \varphi\) est continue à support compact nous pouvons poser
    \begin{equation}
        M_m=\max_{0\leq j\leq m}\| \varphi^{j} \|_{\infty}=\max_{0\leq j\leq m}\max_{x\in \eR}| \varphi^{(j)}(x) |.
    \end{equation}
    Nous continuons en nous fixant un \( x\in \eR\) et un \( k\geq m\).

    Si \( | x |>\frac{1}{ \lambda_k }\), alors \( \varphi^{(m)}(\lambda_kx)=0\) parce que \( \lambda_kx\) est strictement hors du support de \( \varphi\) qui est \( \mathopen] -1 , 1 \mathclose[\). Donc pour \( | x |>\frac{1}{ \lambda_k }\).

    Si par contre \( | x |\leq\frac{1}{ \lambda_k }\), nous avons les majorations
    \begin{subequations}
        \begin{align}
        | f^{(m)}_k(x) |&\leq  |a_k|\sum_{l=0}^{m}\binom{ l }{ m }|\lambda_k|^{m-l}\underbrace{\varphi^{(m-l)}(\lambda_kx)}_{\leq M_m}\frac{ 1 }{ (k-l)! }\underbrace{| x |^{k-l}}_{\leq (1/\lambda_k)^{k-l}}\\
        &\leq | a_k |M_m| \lambda_k |^{m-k}\frac{1}{ (k-m)! }\sum_{l=0}^{m}\binom{ m }{ l }\\
        &\leq \frac{ | a_k |M_m | \lambda_k |^{m-k}2^m }{ (k-m)! }\\
        &= \frac{ | a_k |M_m 2^m }{ (k-m)!  | \lambda_k |^{k-m} }       \label{EqQSPUaun}
        \end{align}
    \end{subequations}
    où pour faire disparaître la somme de coefficients binomiaux, nous avons remarqué que \( \sum_{l=0}^m\binom{ m }{ l }\) est le nombre total de termes dans le développement de \( (a+b)^m\), c'est à dire \( 2^m\). Nous voulons, pour \( m\) fixé, étudier la convergence de la somme de cela. Notons que le \( 2^m\) n'a en particulier strictement aucune importance parce qu'on travaille à \( m\) fixé.

    Nous fixons maintenant la valeur des \( \lambda_k\) :
    \begin{equation}
        \lambda_k=\max\{ | a_k |,1 \}.
    \end{equation}
    Avec cela, en nous souvenant que nous n'étudions que les termes \( k>m\), le dénominateur de \eqref{EqQSPUaun} est réellement croissant en \( k\), donc nous avons la majoration
    \begin{equation}
        | f^{(m)}_k(x) |\leq \frac{ M_m2^m }{ (k-m)! }.
    \end{equation}
    Au final nous avons
    \begin{equation}
        \| f_k^{(m)} \|_{\infty}\leq \frac{ 2^mM_m }{ (k-m)! }.
    \end{equation}
    Et la somme de cela converge sans difficultés. Donc la série
    \begin{equation}
        u(x)=\sum_{k=0}^{\infty}f_k^{(m)}(x)
    \end{equation}
    converge normalement et donc uniformément sur \( \eR\). Nous pouvons alors permuter la somme et la dérivation par le théorème \ref{ThoCSGaPY}. Donc
    \begin{equation}
        u^{(m)}=\sum_{k=0}^{\infty}f_k^{(m)}
    \end{equation}
    est continue. En particulier, pour évaluer en zéro, on peut faire
    \begin{equation}
        u^{(m)}(0)=\sum_{k=0}^{\infty}f_k^{(m)}(0).
    \end{equation}
    Nous avons
    \begin{equation}
        f_k(x)=\varphi(\lambda_kx)\frac{ a_k }{ k! }x^k.
    \end{equation}
    Pour calculer la dérivée en zéro, il suffit de la calculer sur un voisinage sur lequel \( \varphi(\lambda_kx)\) est la constante \( 1\); un tel voisinage existe pour tout \( k\). À ce moment le calcul est classique :
    \begin{equation}
        f_k^{(m)}(x)=\begin{cases}
            a_k    &   \text{si \( k=m\)}\\
            0    &    \text{sinon}.
        \end{cases}
    \end{equation}
    Finalement nous avons bien
    \begin{equation}
        u^{(m)}(0)=\sum_{k=0}^{\infty}f_k^{(m)}(0)=a_k.
    \end{equation}
    
\end{proof}

\begin{remark}
    Pour prouver le lemme de Borel, la première chose qui passe par la tête est la fonction toute simple
    \begin{equation}
        u(x)=\sum_{k=0}^{\infty}\frac{ a_k }{ k! }x^k.
    \end{equation}
    Évidemment si on calcule les dérivées successives de cette fonction, nous trouvons les bons résultats. Le problème est la convergence.  Rien qu'en prenant \( a_k=k!\), la série ne converge pour aucun \( x\) positifs. L'idée de multiplier chacun de \( f_k\) par une fonction plateau sur un petit intervalle autour de zéro a plusieurs avantages. D'abord on conserve les dérivées correctes parce qu'on ne touche pas à la valeur des \( f_k\) sur un petit voisinage. Ensuite cela ne modifie pas la continuité; et enfin en multipliant par \( \varphi(\lambda_kx)\), ça calme méchamment les divergences parce que \( \lambda_kx\) passe vite au-dessus de \( 1\) (et donc en dehors du support de \( \varphi\)) si \( \lambda_k\) est grand. D'où le fait qu'il soit normal que les \( \lambda_k\) soient de l'ordre des \( a_k\).
\end{remark}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Intégrales convergeant uniformément}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Définition et propriété}
%---------------------------------------------------------------------------------------------------------------------------

Soit \( (\Omega,\mu)\) un espace mesuré. Nous disons que l'intégrale
\begin{equation}
    \int_{\Omega}f(x,\omega)d\mu(\omega)
\end{equation}
\defe{converge uniformément}{convergence!uniforme!intégrale} en \( x\) si pour tout \( \epsilon>0\), il existe un compact \( K_0\) tel que pour tout compact \( K\) tel que \( K_0\subset K\) nous avons
\begin{equation}
    \left| \int_{\Omega\setminus K}f(x,\omega)d\mu(\omega) \right| \leq \epsilon.
\end{equation}
Le point important est que le choix de \( K_0\) ne dépend pas de \( x\).

\begin{lemma}       \label{LemOgQdpJ}
    Soit
    \begin{equation}
        F(x)=\int_{\Omega}f(x,\omega)d\mu(\omega),
    \end{equation}
    une intégrale uniformément convergente. Pour chaque \( k\in \eN\) nous considérons un compact \( K_k\) tel que
    \begin{equation}
        \left| \int_{\Omega\setminus K_k}f(x,\omega)d\mu(\omega) \right| \leq\frac{1}{ k }.
    \end{equation}
    Alors la suite de fonctions \( F_k\) définie par
    \begin{equation}
        F_k(x)=\int_{K_k}f(x,\omega)d\mu(\omega)
    \end{equation}
    converge uniformément vers \( F\).
\end{lemma}

\begin{proof}
    Nous avons
    \begin{subequations}
        \begin{align}
            \big| F_k(x)-F(x) \big|&=\left| \int_{K_k}f(x,\omega)d\mu(\omega)-\int_{\Omega}f(x,\omega)d\mu(\omega) \right| \\
            &=| \int_{\Omega\setminus K_k}f(x,\omega)d\mu(\omega) |\\
            &\leq \frac{1}{ k }.
        \end{align}
    \end{subequations}
\end{proof}

%------------------------------------------------------------------------------------------------------------------------
\subsection{Critères de convergence uniforme}
%---------------------------------------------------------------------------------------------------------------------------

Afin de tester l'uniforme convergence d'une intégrale, nous avons le \defe{critère de Weierstrass}{critère!Weierstrass}:
\begin{theorem}		\label{ThoCritWeiIntUnifCv}
Soit $f(x,t)\colon [\alpha,\beta]\times[a,\infty[ \to \eR$, une fonction dont la restriction à toute demi-droite $x=cst$ est mesurable. Si $| f(x,t) |< \varphi(t)$ et $\int_a^{\infty}\varphi(t)dt$ existe, alors l'intégrale
\begin{equation}
	\int_0^{\infty}f(x,t)dt
\end{equation}
est uniformément convergente.
\end{theorem}

Le théorème suivant est le \defe{critère d'Abel}{critère!Abel pour intégrales} :
\begin{theorem}		\label{ThoAbelIntUnif}
	Supposons que $f(x,t)=\varphi(x,t)\psi(x,t)$ où $\varphi$ et $\psi$ sont bornée et intégrables en $t$ au sens de Riemann sur tout compact $[a,b]$, $b\geq a$. Supposons que :
	\begin{enumerate}
		\item $| \int_a^{T}\varphi(x,t)dt |\leq M$ où $M$ est indépendant de $T$ et de $x$,
		\item $\psi(x,t)\geq 0$,
		\item pour tout $x\in[\alpha,\beta]$, $\psi(x,t)$ est une fonction décroissante de $t$,
		\item les fonctions $x\mapsto \psi(x,t)$ convergent uniformément vers $0$ lorsque $t\to\infty$.
	\end{enumerate}
	Alors l'intégrale
	\begin{equation}
		\int_a^{\infty}f(x,t)dt
	\end{equation}
	est uniformément convergente.
\end{theorem}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Fonctions définies par une intégrale}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\label{SecCHwnBDj}
\index{suite!de fonctions intégrables}
\index{fonction!définie par une intégrale}
\index{inversion de limite}

Soit \( (\Omega,\mu)\) un espace mesuré. Nous nous demandons dans quel cas l'intégrale
\begin{equation}
    F(x)=\int_{\Omega}f(x,\omega)d\omega
\end{equation}
définit une fonction \( F\) continue, dérivable ou autre. 

Dans la suite nous allons considérer des fonctions \( f\) à valeurs réelles. Quitte à passer aux composantes, nous pouvons considérer des fonctions à valeurs vectorielles. Par contre le fait que \( x\) soit dans \( \eR\) ou dans \( \eR^n\) n'est pas spécialement une chose facile à traiter.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Continuité sous l'intégrale}
%---------------------------------------------------------------------------------------------------------------------------
\index{continuité!fonction définie par une intégrale}

Nous allons présenter deux théorèmes donnant la continuité de \( F\).
\begin{enumerate}
    \item
        Si \( f\) est majorée par une fonction ne dépendant pas de \( x\), nous avons le théorème \ref{ThoKnuSNd},
    \item
        si l'intégrale est uniformément convergente, nous avons le théorème \ref{ThotexmgE}.
\end{enumerate}

\begin{theorem} \label{ThoKnuSNd}
    Soit \( (\Omega,\mu)\) est un espace mesuré, soit \( x_0\in \eR^m\) et \( f\colon U\times \Omega\to \eR\) où \( U\) est ouvert dans \( \eR^m\). Nous supposons que
    \begin{enumerate}
        \item
            La fonction \( f(x,.)\) est dans \( L^1(\Omega,\mu)\) pour tout \( x \in \eR^m\).
        \item
            La fonction \( f(.,\omega)\) est continue en \( x_0\) pour tout \( \omega\in\Omega\).
            %TODO : peut-être qu'on peut dire seulement pour presque tout omege dans Omega, voir la proposition \ref{prop:fdefint}.
        \item       \label{ItemNAuYNG}
            Il existe une fonction \( G\in L^1(\Omega)\) telle que
            \begin{equation}
                | f(x,\omega) |\leq G(\omega)
            \end{equation}
            pour tout \( x\in U\).
    \end{enumerate}
    Alors la fonction 
    \begin{equation}
        \begin{aligned}
            F\colon U&\to \eR \\
            x&\mapsto \int_{\Omega}f(x,\omega)d\mu(\omega) 
        \end{aligned}
    \end{equation}
    est continue en \( x_0\).
\end{theorem}

\begin{proof}
    Soit \( (x_n)\) une suite convergente vers \( x_0\). Nous considérons la suite de fonctions \( f_n\colon \Omega\to \eR\) définies par
    \begin{equation}
        f_n(\phi)=f(x_n,\omega).
    \end{equation}
    sur qui nous pouvons utiliser le théorème de la convergence dominée (théorème \ref{ThoConvDomLebVdhsTf}) pour obtenir
    \begin{subequations}
        \begin{align}
            \lim_{n\to \infty} F(x_n)&=\lim_{n\to \infty} \int_{\Omega}f(x_n,\omega)d\mu(\omega)\\
            &=\int_{\Omega}\lim_{n\to \infty} f(x_n,\omega)d\mu(\omega)\\
            &=\int_{\Omega}f(x,\omega)d\mu(\omega)\\
            &=F(x).
        \end{align}
    \end{subequations}
    Nous avons utilisé la continuité de \( f(.,\omega)\).
\end{proof}


Si nous avons un peu de compatibilité entre la topologie et la mesure, alors nous pouvons utiliser l'uniforme convergence d'une intégrale pour obtenir la continuité d'une fonction définie par une intégrale.

\begin{theorem} \label{ThotexmgE}
    Soit \( (\Omega,\mu)\) un espace topologique mesuré tel que tout compact est de mesure finie. Soit une fonction \( f\colon \eR\times \Omega\to \eR\) telle que
    \begin{enumerate}
        \item
            Pour chaque \( x\in \eR\), la fonction \( f(x,.)\) est \( L^1(\Omega,\mu)\).
        \item
            Pour chaque \( \omega\in \Omega\), la fonction \( f(.,\omega)\) est continue en \( x_0\).
        \item
            L'intégrale
            \begin{equation}
                F(x)=\int_{\Omega}f(x,\omega)d\mu(\omega)
            \end{equation}
            est uniformément convergente.
    \end{enumerate}
    Alors la fonction \( F\) est continue en \( x_0\).
\end{theorem}

\begin{proof}
    Nous reprenons les notations du lemme \ref{LemOgQdpJ}. Les fonctions
    \begin{equation}
        F_k(x)=\int_{K_k}f(x,\omega)d\mu(\omega)
    \end{equation}
    existent parce que les fonctions \( f(x,.)\) sont dans \( L^1(\Omega)\). Montrons que les fonctions \( F_k\) sont continues. Soit une suite \( x_k\to x_0\) nous avons
    \begin{equation}
        \lim_{n\to \infty} F_k(x_n)=\lim_{n\to \infty} \int_{K_k}f(x_n,\omega)d\mu(\omega).
    \end{equation}
    Nous pouvons inverser la limite et l'intégrale en utilisant le théorème de la convergence dominée. Pour cela, la fonction \( f(x_n,\omega)\) étant continue sur le compact \( K_k\), elle y est majorée par une constante. Le fait que les compacts soient de mesure finie (hypothèse) implique que les constantes soient intégrales sur \( K_k\). Le théorème de la convergence dominée implique alors que
    \begin{equation}
        \lim_{n\to \infty} F_k(x_n)=\int_{K_k}\lim_{n\to \infty} f(x_n,\omega)d\mu(\omega)=\int_{K_k}f(x_0,\omega)d\mu(\omega)=F_k(x_0).
    \end{equation}
    Nous avons utilisé le fait que \( f(.,\omega)\) était continue en \( x_0\).

    Le lemme \ref{LemOgQdpJ} nous indique alors que la convergence \( F_k\to F\) est uniforme. Les fonctions \( F_k\) étant continues, la fonction \( F\) est continue.
\end{proof}


Pour finir, citons ce résultat concernant les fonctions réelles.
\begin{theorem}		\label{ThoInDerrtCvUnifFContinue}
    Nous considérons \( F(x)=\int_a^{\infty}f(x,t)dt\). Si \( f\) est continue sur $[\alpha,\beta]\times[a,\alpha[$ et l'intégrale converge uniformément, alors $F(x)$ est continue.
\end{theorem}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Dérivabilité sous l'intégrale}
%---------------------------------------------------------------------------------------------------------------------------
\index{dérivabilité!fonction définie par une intégrale}

Nous traitons à présent de la dérivabilité de la fonction \( F\) définie comme intégrale de \( f\). Pour cela nous allons suivre \cite{MesIntProbb} avec, il faut le noter, notamment des notations notablement différentes\footnote{Vous en êtes notoirement notifiés.}.

\begin{theorem}[Dérivation sous le signe intégral\cite{MesIntProbb}]    \label{ThoMWpRKYp}
    Soit \( (\Omega,\mu)\) un espace mesuré et une fonction \( f\colon \eR\times \Omega\to \eR\) dont nous voulons étudier la dérivabilité en \(a\in \eR\). Nous supposons qu'il existe \( \delta>0\), \( A\) mesurable de mesure nulle dans \( \Omega\) tels que
    \begin{enumerate}
        \item
            \( f(x,\cdot)\) soit dans \( L^1(\Omega)\).
        \item
            L'application \( x\mapsto f(x,\omega)\) est dérivable pour tout \( x\in B(a,\delta)\) et pour tout \( \omega\in \complement A\).
        \item
            Il existe une fonction \( G\) intégrable sur \( \Omega\) telle que
            \begin{equation}
                \left| \frac{ \partial f }{ \partial x }(x,\omega) \right| \leq G(\omega)
            \end{equation}
            pour tout \( x\in B(a,\delta)\) et pour tout \( \omega\in\complement A\).
    \end{enumerate}
    Alors la fonction
    \begin{equation}
        F(x)=\int_{\Omega}f(x,\omega)d\mu(\omega)
    \end{equation}
    est dérivable en \( a\) et nous pouvons permuter la dérivée et l'intégrale :
    \begin{equation}
        F'(a)=\int_{\Omega}\frac{ \partial f }{ \partial x }(a,\omega)d\mu(\omega).
    \end{equation}
\end{theorem}

\begin{proof}
    Soit une suite \( (x_n)\) dans \( B(a,\delta)\) telle que \( x_n\neq a\) et \( x_n\to a\). Si la limite
    \begin{equation}
        \lim_{n\to \infty} \frac{ F(a)-F(x_n) }{ a-x_n }
    \end{equation}
    existe et ne dépend pas de la suite choisie, alors la fonction \( F\) est dérivable en \( a\) et sa dérivée vaut cette limite. Par linéarité de l'intégrale, nous devons étudier la limite
    \begin{equation}    \label{EqLIiralx}
        \lim_{n\to \infty} \int_{\Omega}\frac{ f(a,\omega)-f(x_n,\omega) }{ a-x_n }d\omega,
    \end{equation}
    montrer qu'elle existe, ne dépend pas de la suite choisie et vaut \( \int_{\Omega}\partial_xf(a,\omega)d\omega\). Nous sommes donc dans un problème d'inversion de limite et de dérivée pour lequel nous allons utiliser le théorème de la convergence dominée de Lebesgue. D'abord nous posons
    \begin{equation}    \label{EqAFOUbQB}
        g_n(\omega)=\frac{ f(x_n,\omega)-f(a,\omega) }{ x_n-a }.
    \end{equation}
    Cela est une suite de fonctions dans \( L^1(\Omega)\) parce qu'à la fois \( a\) et \( x_n\) sont dans \( B(a,\delta)\). De plus nous avons
    \begin{equation}
        \lim_{n\to \infty} g_n(\omega)=\frac{ \partial f }{ \partial x }(a,\omega)
    \end{equation}
    parce que nous savons que \( f\) est dérivable en \( a\) pour tout \( \omega\in\complement A\). En ce qui concerne la majoration de \( g_n\), nous utilisons le théorème des accroissements finis (théorème \ref{ThoAccFinis}) sur le numérateur de \eqref{EqAFOUbQB}. Pour tout \( n\) et pour tout \( \omega\in \complement A\), il existe un \( \theta_{n,\omega}\) dans \( \mathopen] a , x_n \mathclose[\) tel que
        \begin{equation}
            f(x_n,\omega)-f(a,\omega)=\frac{ \partial f }{ \partial x }(\theta_{n,\omega},\omega)(x_n-a),
        \end{equation}
        donc
        \begin{equation}
            | g_n(\omega) |=\left| \frac{ \partial f }{ \partial x }(\theta_{n,\omega},\omega) \right| \leq G(\omega).
        \end{equation}
        La dernière inégalité provient des hypothèses. Le théorème de la convergence dominée de Lebesgue (théorème \ref{ThoConvDomLebVdhsTf}) nous permet alors de calculer la limite \eqref{EqLIiralx} :
        \begin{equation}
            \lim_{n\to \infty} \int_{\Omega}g_n(\omega)d\omega=\int_{\Omega}\lim_{n\to \infty} g_n(\omega)d\omega=\int_{\Omega}\frac{ \partial f }{ \partial x }(a,\omega)d\omega.
        \end{equation}
        Notons que l'existence de la dernière intégrale fait partie du théorème de la convergence dominée.

        Nous avons donc prouvé que la limite de gauche existait et ne dépendant pas de la suite choisie. Donc \( F\) est dérivable en \( a\) et la dérivée vaut cette limite :
        \begin{equation}
            F'(a)=\int_{\Omega}\frac{ \partial f }{ \partial x }(a,\omega)d\mu(\omega).
        \end{equation}
\end{proof}

\begin{theorem}
		Supposons $f$ continue et sa dérivée partielle $\frac{ \partial f }{ \partial x }$ continue sur $[\alpha,\beta]\times[a,\alpha[$. Supposons que $F(x)=\int_a^{\infty}f(x,t)dt$ converge et que $\int_a^{\infty}\frac{ \partial f }{ \partial x }dt$ converge uniformément. Alors $F$ est $C^1$ sur $[\alpha,\beta]$ et 
		\begin{equation}
			\frac{ dF }{ dx }=\int_a^{\infty}\frac{ \partial f }{ \partial x }dt.
		\end{equation}
\end{theorem}

En ce qui concerne les fonctions dans \( \eR^n\), il y a les  propositions \ref{PropDerrSSIntegraleDSD} et \ref{PropAOZkDsh} qui parlent de différentiabilité sous l'intégrale.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Absolue continuité}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}      \label{DefAbsoluCont}
    Une fonction \( F\colon \eR\to \eR\) est \defe{absolument continue}{absolument continue} sur \( \mathopen[ a , b \mathclose]\) si il existe une fonction \( f\) sur \( \mathopen[ a , b \mathclose]\) telle que
    \begin{equation}
        F(x)=\int_a^xf(t)dt
    \end{equation}
    pour tout \( x\in\mathopen[ a , b \mathclose]\).
\end{definition}

\begin{theorem}     \label{ThoDerSousIntegrale}
    Soit \( A\) un ouvert de \( \eR\) et \( \Omega\), un espace mesuré. Soit une fonction \( f\colon A\times \Omega\to \eR\) et
    \begin{equation}
        F(x)=\int_{\Omega}f(x,\omega)d\omega.
    \end{equation}
    Nous supposons les points suivants.
    \begin{enumerate}
        \item
            La fonction \( f\) est mesurable en tant que fonction \( A\times\Omega\to \eR\). Pour chaque \( x\in A\), la fonction \( f(x,\cdot)\) est intégrable sur \( \Omega\).
        \item
            Pour presque tout \( \omega\in\Omega\), la fonction \( f(x,\omega)\) est une fonction absolument continue de \( x\).
        \item
            La fonction \( \frac{ \partial f }{ \partial x }\) est localement intégrable, c'est à dire que pour tout \( \mathopen[ a , b \mathclose]\subset A\),
            \begin{equation}
                \int_a^b\int_{\Omega}\left| \frac{ \partial f }{ \partial x }(x,\omega) \right| d\omega\,dx<\infty.
            \end{equation}
    \end{enumerate}
    Alors la fonction \( F\) est absolument continue et pour presque tout \( x\in A\), la dérivée est donné par
    \begin{equation}
        \frac{ d }{ dx }\int_{\Omega}f(x,\omega)d\omega=\int_{\Omega}\frac{ \partial f }{ \partial x }(x,\omega)d\omega.
    \end{equation}
\end{theorem}

La proposition suivante sera utilisée entre autres pour montrer que sous l'hypothèse d'une densité continue, la loi exponentielle est sans mémoire, proposition \ref{PropREXaIBg}.
\begin{proposition}		\label{PropDerrFnAvecBornesFonctions}
Soit $f(x,t)$ une fonction continue sur $[\alpha,\beta]\times[a,b]$, telle que $\frac{ \partial f }{ \partial x }$ existe et soit continue sur $]\alpha,\beta[\times[a,b]$. Soient $\varphi(x)$ et $\psi(x)$, des fonctions continues de $[\alpha,\beta]$ dans $\eR$ et admettant une dérivée continue sur $]\alpha,\beta [$. Alors la fonction
\begin{equation}
	F(x)=\int_{\varphi(x)}^{\psi(x)}f(x,t)dt
\end{equation}
admet une dérivée continue sur $]\alpha,\beta[$ et
\begin{equation}	\label{EqFormDerrFnAvecBorneNInt}
	\frac{ dF }{ dx }=\int_{\varphi(x)}^{\psi(x)}\frac{ \partial f }{ \partial x }(x,t)dt+f\big( x,\psi(x) \big)\cdot\frac{ d\psi }{ dx }- f\big( x,\varphi(x) \big)\cdot\frac{ d\varphi }{ dx }.
\end{equation}
\end{proposition}
%TODO : une preuve de ce théorème ? allons allons ...

L'exemple qui suit devrait pouvoir être rendu rigoureux en utilisant des distributions correctement.

\begin{example} \label{ExfYXeQg}
    Si \( g\) est une fonction continue, la fonction suivante est une primitive de \( g\) :
    \begin{equation}
        \int_0^xf(t)dt=\int_0^{\infty}f(t)\mtu_{t<x}(t)dt.
    \end{equation}
    Nous nous proposons de justifier \emph{de façon un peu heuristique} le fait que ce soit bien une primitive de \( g\) en considérant la fonction
    \begin{equation}
        f(t,x)=g(t)\mtu_{t<x}(t).
    \end{equation}
    Nous posons
    \begin{equation}
        F(x)=\int_0^{\infty}f(x,t)dt,
    \end{equation}
    et nous calculons \( F'\) en permutant la dérivée et l'intégrale\footnote{Ceci n'est pas rigoureux : il faudrait avoir un théorème à propos de distributions qui permet de le faire.}. D'abord,
    \begin{equation}
        f(t,x)=\begin{cases}
            g(t)    &   \text{si \( t\in \mathopen[ 0 , x \mathclose]\)}\\
            0    &    \text{sinon.}
        \end{cases}
    \end{equation}
    La dérivée de \( f\) par rapport à \( x\) est donnée par la distribution
    \begin{equation}
        \frac{ \partial f }{ \partial x }(t_0,x_0)=g(t_0)\delta(t_0-x_0).
    \end{equation}
    Donc
    \begin{equation}
        F'(x_0)=\int_0^{\infty}\frac{ \partial f }{ \partial x }(t,x_0)dt=\int_0^{\infty}g(t)\delta(t-x_0)=g(x_0),
    \end{equation}
    comme attendu.
\end{example}

Cet exemple est rendu rigoureux par la proposition suivante.
\begin{proposition} \label{PropJLnPpaw}
    Si \( f\in L^1(\eR)\), alors la fonction
    \begin{equation}
        F(x)=\int_{-\infty}^xf(t)dt
    \end{equation}
    est presque partout dérivable et pour les points où elle l'est nous avons \( F'(x)=f(x)\).
\end{proposition}
\index{fonction!définie par une intégrale}
%TODO : une preuve.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Différentiabilité sous l'intégrale}
%---------------------------------------------------------------------------------------------------------------------------

Le théorème suivant est restrictif sur l'ensemble d'intégration (qui doit être compact), mais accepte des fonctions de plusieurs variables, ce qui est un premier pas vers la différentiabilité.
\begin{proposition}		\label{PropDerrSSIntegraleDSD}
    Supposons $A\subset\eR^m$ ouvert et $B\subset\eR^n$ compact. Nous considérons une fonction \( f\colon A\times B\to \eR\). Si pour un $i\in\{ i,\ldots,n \}$, la dérivée partielle $\frac{ \partial f }{ \partial x_i }$ existe dans $A\times B$ et est continue, alors la fonction
    \begin{equation}
        F(x)=\int_Bf(x,t)dt
    \end{equation}
    admet une dérivée partielle dans la direction \( x_i\) sur \( A\). Cette dérivée partielle y est continue et
    \begin{equation}
        \frac{ \partial F }{ \partial x_i }(a)=\int_B\frac{ \partial f }{ \partial x_i }(a,t)dt,
    \end{equation}
    pour tout \( a\) dans l'ouvert \( A\).
\end{proposition}
\index{fonction!définie par une intégrale}
\index{inversion de limite}
L'égalité signifie que l'on peut \og dériver sous le signe intégral\fg.

\begin{proof}
    Nous procédons en plusieurs étapes.
    \begin{subproof}
    \item[\( F\) est dérivable]
            
        Nous voulons prouver que \( \frac{ \partial F }{ \partial x_i }(a,t)\) existe. Pour cela nous posons
        \begin{equation}
            g_l(t)=\frac{ f(a_1,\ldots, a_i+\epsilon_l,\ldots, a_n,t)-f(a_1,\ldots, a_k,\ldots, a_n,t) }{ \epsilon_l }
        \end{equation}
        où \( \epsilon_l\) est une suite de nombres tendant vers zéro. La fonction \( f\) est dérivable dans la direction \( x_i\) si et seulement si \( \lim_{l\to \infty}g_l(t) \) existe et ne dépend pas du choix de la suite. À ce moment, la valeur de la dérivée partielle sera cette limite. Dans notre cas, nous savons que \( f\) admet une dérivée partielle dans la direction \( x_i\) et donc nous avons
        \begin{equation}
            \frac{ \partial f }{ \partial x_i }(a,t)=\lim_{l\to \infty} g_l(t).
        \end{equation}
        
        De la même façon pour \( F\) nous avons
        \begin{equation}
            \frac{ \partial F }{ \partial x_i }=\lim_{l\to \infty} \int_{B}g_l(t)dt.
        \end{equation}
        Sous-entendu : si la limite de droite ne dépend pas de la suite choisie, alors \( \frac{ \partial F }{ \partial x_i }\) existe et vaut cette limite.

        Vu la continuité de \( f\), le seul point à vérifier pour le théorème de la convergence dominée de Lebesgue est l'existence d'une fonction intégrable de \( t\) majorant \( g_l\). Pour cela le théorème de accroissements finis (théorème \ref{ThoAccFinis}) appliqué à la fonction \( \epsilon\mapsto f(a_n,\ldots, a_i+\epsilon,\ldots, a_n)\) nous dit que
        \begin{equation}
            f(a_1,\ldots, a_i+\epsilon_l,\ldots, a_n,t)-f(a_1,\ldots, a_i,\ldots, a_n,t)=\epsilon_l\frac{ \partial f }{ \partial x_i }(a_1,\ldots, \theta,\ldots, a_n,t)
        \end{equation}
        pour un certain \( \theta\in B(a_i,\epsilon_l)\). Notons que ce \( \theta\) dépend de \( t\) mais pas de \( l\). Vu que \( \partial_if\) est continue par rapport à ses deux variables, si \( K\) est un voisinage compact autour de \( a\), il existe \( M>0\) tel que
        \begin{equation}    \label{EqMXqviPC}
            \left| \frac{ \partial f }{ \partial x_i }(x,t) \right| < M
        \end{equation}
        pour tout \( x\in K\) et tout \( t\in B\). La valeur de \( \frac{ \partial f }{ \partial x_i }(a_1,\ldots, \theta,\ldots, a_n,t)\) est donc bien majorée par rapport à \( \theta\) et par rapport à \( t\) en même temps par une constante qui n'a pas de mal à être intégrée sur le compact \( B\).
        
        Le théorème de la convergence dominée (théorème \ref{ThoConvDomLebVdhsTf}) s'applique donc bien et nous avons
        \begin{equation}
            \lim_{l\to \infty} \int_Bg_l(t)dt=\int_B\lim_{l\to \infty} g_l(t)=\int_B\frac{ \partial f }{ \partial x_i }(a,t)dt.
        \end{equation}
        Le membre de droite ne dépendant pas de la suite \( \epsilon_l\) choisie, le membre de gauche est bien la dérivée de \( F\) par rapport à \( x_i\) et nous avons
        \begin{equation}
            \frac{ \partial F }{ \partial x_i }(a)=\int_B\frac{ \partial f }{ \partial x_i }(a,t)dt.
        \end{equation}
        Cela prouve la première partie de la proposition.

    \item[La dérivée est continue]

        Soit \( K\) un voisinage compact autour de \( a\) et \( U'\) un ouvert tel que \( a\in U'\subset K\). Nous avons encore la majoration \eqref{EqMXqviPC} sur \( U'\) et donc le théorème de continuité sous l'intégrale \ref{ThoKnuSNd} nous indique que la fonction
        \begin{equation}
            \begin{aligned}
                U'&\to \eR \\
                x&\mapsto \int_{B}\frac{ \partial f }{ \partial x_i }(x,t)dt 
            \end{aligned}
        \end{equation}
        est continue en \( a\).
        
    \end{subproof}
\end{proof}

Une conséquence de la proposition \ref{PropDerrSSIntegraleDSD} est que si elle fonctionne pour tous les \( i\), alors \( F\) est différentiable et même de classe \( C^1\), et la différentielle de \( F\) s'obtient comme intégrale de la différentielle de \( f\).

\begin{proposition}\label{PropAOZkDsh}
    Supposons $A\subset\eR^m$ ouvert et $B\subset\eR^n$ compact. Si pour tout $i\in\{ i,\ldots,n \}$, la dérivée partielle $\frac{ \partial f }{ \partial x_i }$ existe dans $A\times B$ et est continue, alors \( F\) est de classe \( C^1\) et
    \begin{equation}
        (dF)_a=\int_B(df_t)_adt
    \end{equation}
    où \( f_t(x)=f(x,t)\).
\end{proposition}

\begin{proof}
    En vertu de la proposition \ref{PropDerrSSIntegraleDSD}, toutes les dérivées partielles de \( F\) sont continues. Cela implique que \( F\) est de classe \( C^1\) par la proposition \ref{PropDerContCun} et que la différentielle s'écrive en terme des dérivées partielles avec la formule usuelle. Nous avons alors
    \begin{subequations}
        \begin{align}
            (dF)_a(u)&=\sum_k\frac{ \partial F }{ \partial x_k }(a)u_k\\
            &=\int_B\sum_k\frac{ \partial f }{ \partial x_k }(a,t)dt\\
            &=\int_B\sum_k\frac{ \partial f_t }{ \partial x_k }(a)u_kdt\\
            &=\int_B (df_t)_a(u)dt.
        \end{align}
    \end{subequations}
    Cela est la formule annoncée.
\end{proof}

Un autre théorème tourne autour du pot, et me semble inutile.
\begin{theorem} \label{ThoOLAQyRL}
    Soit \( (\Omega,\mu)\) un espace mesuré, une fonction \( f\colon \eR^n\times \Omega\to \eR\) et \( a\in \eR^n\). Nous considérons la fonction
    \begin{equation}
        F(x)=\int_{\Omega}f(x,\omega)d\mu(\omega).
    \end{equation}
    Pour chaque \( k=1,\ldots, n\) nous supposons avoir
    \begin{equation}
        \frac{ \partial F }{ \partial x_k }(a)=F_{|_k}'(a)=\int_{\Omega}\frac{ \partial f_{|_k} }{ \partial t }(a_k,\omega)d\mu(\omega)
    \end{equation}
    où \( F_{|_k}(t)=F(a_1,\ldots, t,\ldots, a_n)\) et \( f_{|_k}\) est définie de façon similaire.

    Nous supposons de plus que les fonctions \( \partial_{x_k}F\) sont continues.

    Alors \( F\) est de classe \( C^1\) et sa différentielle est donnée par
    \begin{equation}
        df_a=\int_{\Omega}(df_{\omega})_ad\omega
    \end{equation}
    où \( f_{\omega}\) est définie par \( f_{\omega}(x)=f(x,\omega)\).
\end{theorem}

\begin{proof}
    Étant donné que les dérivées partielles de \( F\) en \( a\) existent et sont continues, la proposition \ref{PropDerContCun} dit que \( F\) est différentiable et que
    \begin{equation}
        dF_a(u)=\sum_{k=1}^n\frac{ \partial F }{ \partial x_k }(a)u_k.
    \end{equation}
    La linéarité de l'intégrale et les hypothèses nous donnent alors
    \begin{subequations}
        \begin{align}
            df_a(u)&=\sum_{k=1}^n\frac{ \partial F }{ \partial x_k }(a)u_k\\
            &=\int_{\Omega}\sum_k\frac{ \partial f_{|_k} }{ \partial t }(a_k;\omega)u_kd\mu(\omega)\\
            &=\int_{\Omega}\sum_k\frac{ \partial f }{ \partial x_k }(a;\omega)u_kd\mu(\omega)\\
            &=\int_{\Omega}(df_{\omega})_a(u)d\mu(\omega),
        \end{align}
    \end{subequations}
    et donc \( df_a=\int_{\Omega}(df_{\omega})_ad\mu(\omega)\).
\end{proof}
Notons qu'en passant aux composantes, ce théorème fonctionne tout aussi bien pour des fonctions à valeurs dans un espace vectoriel normé de dimension finie plutôt que dans \( \eR\).

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Formes différentielles exactes et fermées}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Nous avons déjà parle de formes différentielles et de leurs intégrales sur un chemin dans la section \ref{SecFormDiffRappel}.

\begin{definition}  \label{DefEFKQmPs}
La forme différentielle $\omega$ est \defe{exacte}{forme!différentielle!exacte} si il existe une fonction $f$ telle que $\omega=df$; elle est dite \defe{fermée}{forme!différentielle!fermée} si $d\omega=0$.
\end{definition}

Une forme différentielle $\omega$ continue de degré $1$ sur $D$ est \defe{exacte}{forme!différentielle!exacte} si il existe $F\colon D\to \eR$ telle que $\omega=dF$. On dit que la forme est \defe{fermée}{forme!différentielle!fermée} si $d\omega=0$. Dire que la forme différentielle $\omega=fdx+gdy$ est fermée, c'est dire que
\begin{equation}
    \frac{ \partial g }{ \partial x }=\frac{ \partial f }{ \partial y }.
\end{equation}

\begin{theorem}        \label{ThoFermeExactFormRappel}
Supposons que $D\subset\eR^n$ soit un ouvert simplement connexe. Alors toute forme différentielle de degré $1$ et de classe $C^1$ sur $D$ qui est fermée est exacte.
\end{theorem}

Nous allons prouver ce théorème dans un cas un peu moins général : celui d'un domaine étoilé de \( \eR^2\) plutôt que simplement connexe de \( \eR^n\).

\begin{theorem} \label{ThoMSofFxL}
Soit $D\subset\eR^2$, une ouvert étoilé, et $\omega$, une $1$-forme fermée de classe $C^1$. Alors $\omega$ est exacte.
\end{theorem}
\begin{proof}

Soit $D\subset\eR^2$, un ouvert étoilé par rapport à l'origine. Soient $f\colon D\to \eR$, $g\colon D\to \eR$, des fonctions de classe $C^1$ telles que
\begin{equation}
	\frac{ \partial f }{ \partial y }=\frac{ \partial g }{ \partial x }
\end{equation}
sur $D$, et
\begin{equation}		\label{EqIMDefFformI33}
	F(x,y)=\int_0^1\big[  f(tx,ty)x+g(tx,ty)y  \big]dt
\end{equation}
pour tout $(x,y)\in D$. 

Étant donné que nous ne définissons $F(x,y)$ que pour des $(x,y)\in D$, la fonction $t\mapsto f(tx,ty)$ est $C^1$ sur tout le compact $[0,1]$ et aucune divergence de l'intégrale n'est à craindre. Nous sommes donc dans le cadre de la proposition \ref{PropDerrSSIntegraleDSD}, et nous pouvons dériver sous le signe intégral.

Nous calculons, en utilisant la règle de dérivation de fonctions composées
\begin{equation}		\label{EqIMI33dsdsFlolo}
	\begin{aligned}[]
		\frac{ \partial F }{ \partial x }(x,t)	&=\int_0^1\left[   f\frac{ \partial f }{ \partial x }(tx,ty)x+f(tx,ty)+t\frac{ \partial g }{ \partial x }(tx,ty)y  \right]dt\\
		&=\int_0^1\left[ t\Big( x\frac{ \partial f }{ \partial x }(tx,ty)+y\frac{ \partial f }{ \partial y }(tx,ty) \Big)+f(tx,ty) \right]dt
	\end{aligned}
\end{equation}
où nous avons utilisé l'hypothèse $\partial_yf=\partial_xg$. Ce qui se trouve dans la parenthèse n'est autre que $\partial_t\big( f(tx,ty) \big)$, plus précisément, si nous posons $\mF(x,y,t)=f(tx,ty)$, nous avons
\begin{equation}
	\frac{ \partial \mF }{ \partial t }(x,y,t)= x\frac{ \partial f }{ \partial x }(tx,ty)+y\frac{ \partial f }{ \partial y }(tx,ty).
\end{equation}
En recopiant le résultat \eqref{EqIMI33dsdsFlolo} en termes de $\mF$, nous avons
\begin{equation}
	\begin{aligned}[]
		\frac{ \partial F }{ \partial x }(x,t)	&=\int_0^1\left( t\frac{ \partial \mF }{ \partial t }(x,y,t)+\mF(x,y,t) \right)dt\\
		&=\int_0^1\partial_t\big( t\mF(x,y,t) \big)dt\\
		&=\big[ f\mF(x,y,t) \big]_0^1\\
		&=\mF(x,y,1)\\
		&=f(x,y).
	\end{aligned}
\end{equation}
Le résultat correspondant pour $\frac{ \partial F }{ \partial y }(x,y)=g(x,y)$ s'obtient de la même manière. Nous avons donc obtenu que
\begin{equation}		\label{EqIMFormI33Fffdd}
	\begin{aligned}[]
		\frac{ \partial F }{ \partial x }&=f,  &\text{et}&& \frac{ \partial F }{ \partial y }=g.
	\end{aligned}
\end{equation}
En ayant prouvé cela, nous avons prouvé que si $\omega=fdx+gdy$ avec $\partial_yf=\partial_xg$, alors $\omega=dF$ où $F$ est définie par \eqref{EqIMDefFformI33}.
\end{proof}

\begin{proof}[Démonstration alternative du théorème \ref{ThoMSofFxL}]
Nous posons $u=tx$ et $v=ty$, ainsi que $\mF(x,y,t)=f(u,v)$ et $\mG(x,y,t)=g(u,v)$. Avec cette notation, nous avons $F(x,y)=\int_0^1\big( x\mF(x,y,t)+y\mG(x,y,t) \big)dt$, et
\begin{equation}
	\begin{aligned}[]
		\frac{ \partial \mF }{ \partial x }&=\frac{ \partial f }{ \partial u }\frac{ \partial u }{ \partial x }+\frac{ \partial f }{ \partial v }\frac{ \partial v }{ \partial x }=t\frac{ \partial f }{ \partial u },\\
		\frac{ \partial \mG }{ \partial x }&=t\frac{ \partial g }{ \partial u }.
	\end{aligned}
\end{equation}
Ainsi,
\begin{equation}
	\begin{aligned}[]
		\frac{ \partial F }{ \partial x }	&=\int_0^1\left( x\frac{ \partial \mF }{ \partial x }+\mF+y\frac{ \partial G }{ \partial x } \right)dt\\
							&=\int_0^1\left( xt\frac{ \partial f }{ \partial u } +\mF+yt\frac{ \partial g }{ \partial u } \right)dt\\
							&=\int_0^1\left[  t\left( x\frac{ \partial f }{ \partial u }+y\frac{ \partial f }{ \partial v } \right)+\mF  \right]dt.
	\end{aligned}
\end{equation}
où nous avons utilisé le fait que, par hypothèse, $\frac{ \partial g }{ \partial u }=\frac{ \partial f }{ \partial v }$. Nous calculons par ailleurs que
\begin{equation}
	\frac{ \partial F }{ \partial t }=\frac{ \partial f }{ \partial u }\frac{ \partial u }{ \partial t }+\frac{ \partial f }{ \partial v }\frac{ \partial v }{ \partial t }=x\frac{ \partial f }{ \partial u }+y\frac{ \partial f }{ \partial v }.
\end{equation}
Donc, nous avons
\begin{equation}
	\frac{ \partial F }{ \partial x }=\int_0^1\left( t\frac{ \partial \mF }{ \partial t }+\mF \right)dt=\int_0^1\frac{ \partial  }{ \partial t }(t\mF)dt.
\end{equation}
Par conséquent,
\begin{equation}
	\frac{ \partial F }{ \partial x }=[t\mF]_0^1=\mF(x,y,1)=f(x,y).
\end{equation}
Le même genre de calculs fournit $\frac{ \partial F }{ \partial y }=g(x,y)$.
\end{proof}
    
%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Formes différentielles exactes et fermées}
%---------------------------------------------------------------------------------------------------------------------------

Considérons une fonction différentiable $f\colon D\to \eR$. Pour chaque $x\in D$, nous avons l'application différentielle
\begin{equation}
	\begin{aligned}
		df(x)\colon \eR^n&\to \eR \\
		v&\mapsto \sum_{i=1}^n\frac{ \partial f }{ \partial x_i }(x)v_i, 
	\end{aligned}
\end{equation}
c'est à dire que $df$ est une $1$-forme différentielle dont les composantes sont
\begin{equation}
	df(x)=\frac{ \partial f }{ \partial x_1 }(x)dx_1+\ldots+\frac{ \partial f }{ \partial x_n }(x)dx_n.
\end{equation}

Il est naturel de se demander si toutes les formes différentielles sont des différentielles de fonctions. Une réponse complète est délicate à établir, mais a d'innombrables conséquences en physique, notamment en ce qui concerne l'existence d'un potentiel vecteur pour le champ magnétique dans les équations de Maxwell.
\begin{definition}
	Deux classes importantes de formes différentielles sont à mettre en évidence
	\begin{enumerate}
		\item
			Une forme différentielle $\omega$ sur un ouvert $D\subset\eR^n$ est \defe{exacte}{forme!différentielle!exacte} si il existe une fonction différentiable $f\colon D\to \eR$ telle que
			\begin{equation}
				 \omega_x=df(x)
			\end{equation}
			pour tout $x\in D$.
		\item
			Une $1$-forme de classe $C^1$ sur l'ouvert $D$ est \defe{fermée}{forme!différentielle!fermée} si pour tout $i,j=1,\ldots n$, nous avons
			\begin{equation}
				\frac{ \partial a_i }{ \partial x_j }=\frac{ \partial a_j }{ \partial x_i }.
			\end{equation}
	\end{enumerate}
\end{definition}

\begin{proposition}
	Si $\omega$ est une $1$-forme exacte de classe $C^1$, alors $\omega$ est fermée.
\end{proposition}

\begin{proof}
	Le fait que $\omega$ soit exacte implique l'existence d'une fonction $f$ telle que $\omega=df$, c'est à dire
	\begin{equation}
		\omega_x=\sum_i a_i(x)dx_i=\sum_i\frac{ \partial f }{ \partial x_i }(x)dx_i,
	\end{equation}
	c'est à dire que $a_i(x)=\frac{ \partial f }{ \partial x_i }(x)$. L'hypothèse que $\omega$ est $C^1$ implique que $f$ est $C^2$, et donc que nous pouvons inverser l'ordre de dérivation pour les dérivées secondes $\partial^2_{ij}f=\partial^2_{ji}f$. Nous pouvons donc faire le calcul suivant :
	\begin{equation}
		\frac{ \partial a_i }{ \partial x_j }=\frac{ \partial  }{ \partial x_j }\frac{ \partial f }{ \partial x_i }=\frac{ \partial  }{ \partial x_i }\frac{ \partial f }{ \partial x_j }=\frac{ \partial a_j }{ \partial x_i },
	\end{equation}
	ce qu'il fallait démontrer.
\end{proof}

Ceci est assez pour les formes différentielles pour cette année.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Théorème d'Abel angulaire}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{theorem}[Abel angulaire\cite{KXjFWKA}]   \label{ThoTGjmeen}
    Soit \( \sum_{n}a_nz^n\) une série entière de rayon de convergence plus grand ou égal à \( 1\) et de somme \( f\). Soit \( \theta_0\in\mathopen[ 0 , \frac{ \pi }{2} \mathclose[\). Nous posons
    \begin{equation}
        \Delta_{\theta_0}=\{ z=1-\rho e^{i\varphi}\tq \rho>0,\varphi\in\mathopen[ \theta_0 , \theta_0 \mathclose],| z |<1 \}.
    \end{equation}
    Nous supposons de plus que \( \sum_na_n\) converge. Alors
    \begin{equation}
        \lim_{\substack{z\to1\\z\in\Delta_0}}f(z)=\sum_{k=0}^{\infty}a_k.
    \end{equation}
\end{theorem}
\index{Abel!angulaire}
\index{convergence!suite numérique!Abel angulaire}
\index{somme partielles!Abel angulaire}
\index{série!entière!Abel angulaire}

\begin{proof}

    Le résultat de ce théorème est que l'on peut calculer la limite \( z\to 1\) avec des chemins contenus dans un domaine de la forme de celui dessiné à la figure \ref{LabelFigJGuKEjH}. % From file JGuKEjH
    \newcommand{\CaptionFigJGuKEjH}{La zone dans laquelle peut être le chemin qui va vers \( z=1\).}
    \input{Fig_JGuKEjH.pstricks}

    De façon très classique nous posons
    \begin{equation}
        \begin{aligned}[]
            S&=\sum_{k=0}^{\infty}a_k&S_n&=\sum_{k=0}^na_k,
        \end{aligned}
    \end{equation}
    et \( R_n=S-S_n\). En particulier \( a_n=R_{n-1}-R_n\). 

    Le but du théorème est de montrer que \( \sum a_nz^n\) converge vers \( S\) lorsque \( z\) converge vers \( 1\) à l'intérieur de \( \Delta_{\theta_0}\). Pour cela nous calculons pour un \( N\) donné la différence \( \sum_{n=0}^{N}a_nz^n-S_N\) en triant les termes par ordre de \( R_n\), en isolant le terme \( R_0\) et le terme \( R_N\) :
    \begin{subequations}
        \begin{align}
            \sum_{n=0}^Na_nz^n-S_N&=\sum_{n=1}^Na_n(z^n-1)\\
            &=\sum_{n=1}^N(R_{n-1}-R_n)(z^n-1)\\
            &=R_0(z-1)+\sum_{n=1}^{N-1}R_n(z^{n+1}-1-z^n+1)+R_N(z^N-1)\\
            &=R_0(z-1)+\sum_{n=1}^{N-1}R_nz^n(z-1)+R_N(z^N-1)\\
            &=(z-1)\sum_{n=0}^{N-1}R_nz^n+R_N(z^N-1).
        \end{align}
    \end{subequations}
    Cela est valable pour tout \( N\) et \( | z |<1\). Nous avons donc
    \begin{equation}
        \sum_{n=0}^Na_nz^n-S_N=(z-1)\sum_{n=0}^{N-1}R_nz^n+R_N(z^N-1).
    \end{equation}
    Par hypothèse nous avons \( \lim_{N\to \infty} R_N=0\). Et de plus le membre de gauche converge parce que chacun des deux termes converge séparément. En passant à la limite nous avons pour tout \( | z |<1\) :
    \begin{equation}
        f(z)-S=(z-1)\sum_{n=0}^{\infty}R_nz^n.
    \end{equation}
    Nous voudrions étudier le comportement de la différence \( f(z)-S\) lorsque \( z\) tend vers \( 1\). Pour cela nous nous fixons \( \epsilon>0\) et \( N\geq 1\) tel que \( | R_n |<\epsilon\) dès que \( n\geq N\). Alors pour tout \( | z |<1\) nous avons
    \begin{subequations}
        \begin{align}
            | f(z)-S |&\leq | z-1 |\left( \sum_{n=0}^N| R_n | \underbrace{|z^n |}_{\leq 1} +\sum_{n=N+1}^{\infty}\underbrace{| R_n |}_{\leq \epsilon} |z^n | \right)\\
            &\leq | z-1 |\sum_{n=0}^N| R_n |+\epsilon\frac{ | z-1 | }{ 1-| z | }
        \end{align}
    \end{subequations}
    où nous avons utilisé la somme de la série géométrique \eqref{EqASYTiCK} et l'égalité \( | z^n |=| z |^n\). Avant de nous particulariser à \( z\in\Delta_{\theta_0}\) nous devons anticiper un problème au dénominateur en multipliant par le binôme conjugué :
    \begin{equation}
        \frac{ | z-1 | }{ 1-| z | }=\frac{ | z-1 |(1+| z |) }{ 1-| z |^2 }.
    \end{equation}
    C'est maintenant que nous nous particularisons à \( z\in\Delta_{\theta_0}\) en posant \( z=\rho e^{i\varphi}\) et en remarquant que \( | z |^2=1-2\rho\cos(\varphi)+\rho^2\). Nous avons le calcul suivant :
    \begin{subequations}
        \begin{align}
            \frac{ | z-1 | }{ 1-| z | }&=\frac{ \rho(1+| z |) }{ 2\rho\cos(\varphi)-\rho^2 }\\
            &=\frac{ 1+| z | }{ 2\cos(\varphi)-\rho}\\
            &\leq\frac{ 2 }{ 2\cos(\varphi)-\rho }\\
            &\leq\frac{ 2 }{ 2\cos(\varphi)-\cos(\theta_0) }\\
            &\leq\frac{ 2 }{ 2\cos(\theta_0)-\cos(\theta_0) }\\
            &=\frac{ 2 }{ \cos(\theta_0) }.
        \end{align}
    \end{subequations}
    Quelque justifications.
    \begin{itemize}
        \item Vu que nous avons dans l'idée de faire \( \rho\to 0\) nous supposons que \( \rho<\cos(\theta_0)\).
        \item Nous avons \( \cos(\varphi)>\cos(\theta_0)\) parce que \( z\) est dans \( \Delta_{\theta_0}\).
    \end{itemize}
    Nous avons donc, pour tout \( z\in\Delta_{\theta_0}\) que
    \begin{equation}
        | f(z)-S |\leq | z-1 |\sum_{n=0}^N| R_n |+\epsilon\frac{ 2 }{ \cos(\theta_0) }.
    \end{equation}
    Il suffit de prendre \( \rho\) assez petit pour que 
    \begin{equation}
        | z-1 |\sum_{n=0}^N| R_n |<\epsilon
    \end{equation}
    et nous avons
    \begin{equation}
        | f(z)-S |\leq \epsilon\left( 1+\frac{ 2 }{ \cos(\theta_0) } \right).
    \end{equation}
    Nous avons donc bien \( \lim_{\substack{z\to 1\\z\in\Delta_0}}f(z)=S\), comme nous le voulions.
\end{proof}

La réciproque du théorème d'Abel angulaire est que si \( f(z)=\sum_na_nz^n\) sur \( B(0,1)\) se prolonge par continuité en \( z=1\) alors cette prolongation se fait par \( f(1)=\sum_na_n\). Cela est faux comme le montre l'exemple suivant.

\begin{example}
    Nous considérons la série entière \( \sum_{n=0}^{\infty}(-1)^nz^n\) qui converge\footnote{C'est la série géométrique de raison \( -z\).} vers
    \begin{equation}
        f(z)=\frac{1}{ 1+z }
    \end{equation}
    sur \( B(0,1)\). De plus nous avons
    \begin{equation}
        \lim_{\substack{z\to 1\\    | z |<1}}\frac{1}{ 1+z }=\frac{ 1 }{2}.
    \end{equation}
    Donc la fonction converge bien vers quelque chose lorsque \( z\) tend vers \( 1\). La fonction \( f\) se prolonge par continuité en \( 1\). Pourtant la série es coefficients \( \sum_n(-1)^n\) ne converge pas.
\end{example}

Le théorème suivant donne une espèce d'inverse au théorème d'Abel angulaire. En effet il dit que si la série converge  en allant vers \( 1\) le long de l'axe réel, alors ça converge vers la somme des coefficients. Il faut cependant une hypothèse en plus sur les \( a_n\).
\begin{theorem}[Théorème taubérien faible\cite{KXjFWKA}]
    Soit \( \sum_na_nz^n\) une série entière de rayon de convergence \( 1\) et de somme \( f\). Nous supposons
    \begin{enumerate}
        \item
            Il existe \( S\in \eC\) tel que \( \lim_{\substack{x\to 1\\x\in\mathopen] -1 , 1 \mathclose[}}f(x)=S\).
            \item
                \( \lim_{n\to \infty} na_n=0\).
    \end{enumerate}
    Alors la série \( \sum_{n=0}^{\infty}a_n\) converge et vaut \( S\).
\end{theorem}
\index{théorème!taubérien faible}

\begin{proof}
    Nous notons \( S_n=\sum_{k=0}a_k\) et \( M=\sup_{k\geq 1}k| a_k |\), qui est fini par hypothèse. Pour \( x\in \mathopen] 0 , 1 \mathclose[\) et \( n\geq 0\) nous avons
    \begin{equation}
        S_n-f(x)=\sum_{k=1}^na_k-\sum_{k=1}^na_kx^k-\sum_{k=n+1}^{\infty}a_kx^k=\sum_{k=1}^na_k(1-x^k)-\sum_{k=n+1}^{\infty}a_kx^k.
    \end{equation}
    Nous utilisons la série géométrique sous la forme \( 1-x^k=(1-x)\sum_{i=0}^nx^i\) pour écrire
    \begin{subequations}
        \begin{align}
            S_n-f(x)&=\sum_{k=1}^na_k(1-x)\underbrace{\sum_{i=0}^{k-1}x^i}_{\leq k}-\sum_{k=n+1}^{\infty}a_kx^k\\
            &\leq\sum_{k=1}^nka_k(1-x)-\sum_{k=n+1}^{\infty}a_kx^k,
        \end{align}
    \end{subequations}
    donc en passant à la norme
    \begin{subequations}
        \begin{align}
            \big| S_n-f(x) \big|&\leq (1-x)Mn+\sum_{k=n+1}| a_k |x^k\\
            &\leq (1-x)Mn+\sum_{k=n+1}^{\infty}\underbrace{\frac{ k }{ n }| a_k |}_{\leq M/n}x^k\\
            &\leq (1-x)Mn+\frac{ M }{ n }\sum_{k=n+1}^{\infty}x^k\\
            &\leq (1-x)Mn+\frac{ M }{ n }\frac{1}{ 1-x }.
        \end{align}
    \end{subequations}
    Ce que nous cherchons à étudier est le comportement \( x\to 1\) et montrer que \( S_n\to S\), ce qui nous incite à calculer \( | S_n-f(1-\frac{ \epsilon }{n  }) |\) avec \( 0<\epsilon<1\) :
    \begin{equation}
        \big| S_n-f\big( 1-\frac{ \epsilon }{ n } \big) \big|\leq \epsilon M+\epsilon.
    \end{equation}
    Nous choisissons \( N_1\) tel que \( \frac{ M }{ n }\leq \epsilon^2\) dès que \( n\geq N_1\). En sus nous savons que 
    \begin{equation}
        \lim_{\epsilon\to 0}f(1-\epsilon)=S.
    \end{equation}
    Nous choisissons \( N_2\) de telle sorte à avoir
    \begin{equation}
        \left| f\left( 1-\frac{ \epsilon }{ n } \right)-S \right| <\epsilon,
    \end{equation}
    et en prenant \( n\geq\max(N_1,N_2)\) nous avons
    \begin{equation}
        | S_n-S |\leq \left| S_n-f\left( 1-\frac{ \epsilon }{ n } \right) \right| +\left| f\left( 1-\frac{ \epsilon }{ n } \right)-S \right|  \leq \epsilon M+2\epsilon.
    \end{equation}
    Il suffit de choisit \( \epsilon\) suffisamment petit (en particulier pour que \( \epsilon M\) soit petit) pour montrer que \( | S_n-S |\) est borné par un nombre arbitrairement petit.
\end{proof}
