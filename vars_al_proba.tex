% This is part of Agregation : modélisation
% Copyright (c) 2011-2013
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

Une bonne référence pour ce chapitre est \cite{ProbaDanielLi}.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Espace de probabilité}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Une \defe{mesure de probabilité}{mesure!probabilité} sur un espace mesuré \( (\Omega,\tribA)\) est une mesure positive telle que \( P(\Omega)=1\). Dans ce cas, le triple \( (\Omega,\tribA,P)\) est un \defe{espace de probabilité}{espace!de probabilité}.

Un point \( \omega\in\Omega\) est une \defe{observation}{observation}, une partie mesurable \( A\in\tribA\) est un \defe{événement}{événement}. L'ensemble \( A\cup B\) représente l'événement \( A\) ou \( B\) tandis que l'ensemble \( A\cap B\) représente l'événement \( A\) et \( B\).

Si les \( A_n\) sont des événements, nous définissons la \defe{limite supérieur}{limite!supérieure} et la \defe{limite inférieure}{limite!inférieure} de la suite \( A_n\) par
\begin{equation}
    \limsup_{n\to\infty}A_n=\bigcap_{n\geq 1}\bigcup_{k\geq n}A_k
\end{equation}
et
\begin{equation}
    \liminf_{n\to\infty}A_n=\bigcup_{n\geq 1}\bigcap_{k\geq n}A_k
\end{equation}
Si \( \omega\in\liminf A_n\), alors \( \omega\) réalise tous les \( A_n\) sauf un nombre fini.

Nous avons
\begin{equation}
    \limsup A_n=\{ \omega\in\Omega\tq \omega\in A_n\text{pour une infinité de \( n\)} \}.
\end{equation}

\begin{theorem}[Borel-Cantelli]\index{théorème!Borel-Cantelli}
    Si
    \begin{equation}
        \sum_{n=1}^{\infty}P(A_n)<\infty
    \end{equation}
    alors \( P(\limsup A_n)=0\).
\end{theorem}
%TODO : une conséquence de Borel-Cantelli a l'air d'être le théorème des nombres normaux,
% prouvé sur la page https://fr.wikipedia.org/wiki/Nombre_normal

\begin{proof}
    La condition \( \sum_{n\geq 1}P(A_n)<\infty\) signifie que la fonction
    \begin{equation}
        \varphi=\sum_{n\geq 1}\caract_{A_n}
    \end{equation}
    est \( P\)-intégrable. Par conséquent, elle est finie presque partout (au sens de \( P\)), c'est à dire
    \begin{equation}
        P(\varphi=\infty)=0.
    \end{equation}
    Les points \( \omega\) sur lesquels \( \varphi(\omega)=\infty\) sont ceux tels que
    \begin{equation}
        \sum_{n\geq 1}\caract_{A_n}(\omega)=\infty,
    \end{equation}
    c'est à dire les \( \omega\) qui appartiennent à une infinité d'ensembles \( A_n\), ou encore les \( \omega\in\limsup A_n\). Nous avons donc montré que
    \begin{equation}
        \{ \omega\tq \varphi(\omega)=\infty \}=\{ \omega\in\Omega\tq \omega\in A_n\text{pour une infinité de \( n\)} \}=\limsup A_n.
    \end{equation}
    Or l'hypothèse signifie que la probabilité du membre de gauche est nulle.
\end{proof}

\begin{corollary}
    Si \( \sum_{n=1}^{\infty}P(\complement A_n)<\infty\), alors presque surement tous les \( B_n\) sont réalisés à l'exception d'un nombre fini.
\end{corollary}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Variables aléatoires}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{definition}
    Une \defe{variable aléatoire}{variable aléatoire} est une application mesurable
    \begin{equation}
        X\colon (\Omega,\tribA)\to (\eR^d,\Borelien(\eR^d)).
    \end{equation}
\end{definition}
Nous convenons que \( \eR^1=\bar\eR\), c'est à dire que dans le cas où la variable aléatoire \( X\) est réelle, nous acceptons les valeurs \( \pm\infty\).


\begin{definition}      \label{DefAbsoluCont}
    Une fonction \( F\colon \eR\to \eR\) est \defe{absolument continue}{absolument continue} sur \( \mathopen[ a , b \mathclose]\) si il existe une fonction \( f\) sur \( \mathopen[ a , b \mathclose]\) telle que
    \begin{equation}
        F(x)=\int_a^xf(t)dt
    \end{equation}
    pour tout \( x\in\mathopen[ a , b \mathclose]\).

    Une variable aléatoire réelle \( X\) est \defe{absolument continue}{variable aléatoire!absolument continue} si il existe une fonction positive et intégrable \( f\colon \eR\to \eR\) telle que pour tout intervalle \( I\subset\eR\),
    \begin{equation}
        P(X\in I)=\int_If(t)dt.
    \end{equation}
    Nous disons alors que \( f\) est la \defe{densité}{densité} de \( X\).
\end{definition}


%---------------------------------------------------------------------------------------------------------------------------
\subsection{Indépendance}
%---------------------------------------------------------------------------------------------------------------------------

La définition suivante vient de l'instructive motivation de \cite{CourgGudRennes}. La définition d'indépendance de deux événements se généralise à \( n\) événements de la façon suivante.
\begin{definition}
    Nous disons que les événements \( A_1,\ldots,A_n\) sont \defe{indépendants}{indépendance!événements} si pour tout choix \( \{ i_1,\ldots,i_k \}\subset\{ 1,\ldots,n \}\) nous avons
    \begin{equation}
        P(A_{i_1}\cap\ldots\cap A_{i_k})=P(A_{i_1})\ldots P(A_{i_k}).
    \end{equation}
    Les sous tribus \( \tribA_1,\ldots,\tribA_n\) sont \defe{indépendantes}{indépendance!sous tribus} si pour tout choix \( A_i\in \tribA_i\), les événements \( A_i\) sont indépendants.
\end{definition}

\begin{example}
    Soit \( \Omega=\mathopen[ 0 , 1 \mathclose]\times \mathopen[ 0 , 1 \mathclose]\) muni de la mesure de Lebesgue. Soient \( A=\mathopen[ 0 , a \mathclose]\times \mathopen[ 0 , 1 \mathclose]\) et \( B=\mathopen[ 0 , 1 \mathclose]\times \mathopen[ 0 , b \mathclose]\). Nous avons \( P(A)=a\) et \( P(B)=b\) ainsi que \( P(A\cup B)=ab\).
\end{example}

\begin{lemma}       \label{LemTribIndepProdProb}
    Les tribus \( \tribA_1,\ldots,\tribA_n\) sont indépendantes si et seulement si
    \begin{equation}
        P(A_1\cap\ldots\cap A_n)=P(A_1)\ldots P(A_n)
    \end{equation}
    pour tout \( A_i\in\tribA_i\).
\end{lemma}

\begin{proof}
    L'implication dans le sens direct découle immédiatement des définitions.

    Nous supposons avoir un choix \( (A_i)_{i=1,\ldots,n}\) avec \( A_i\in\tribA_i\) et nous devons montrer que ces événements sont indépendants, c'est à dire que si \( J\subset\{ 1,\ldots,n \}\) alors les événements \( (A_j)_{j\in J}\) sont indépendants. Sans perte de généralité, nous pouvons supposer que si \( i\notin J\), \( A_i=\Omega\). Alors nous avons
    \begin{equation}
        P\big( \bigcap_{j\in J}A_j \big)=P\big( \bigcap_{i=1}^nA_i \big)=\prod_{i=1}^nP(A_i)=\prod_{j\in J}P(A_j)
    \end{equation}
    parce que \( P(A_i)=P(\Omega)=1\) lorsque \( i\) n'est pas dans \( J\).
\end{proof}

Si \( A\) est un événement, la \defe{tribu engendrée}{tribu!engendrée!par un événement} par \( A\) est
\begin{equation}
    \sigma(A)=\{ \emptyset,A,\complement A,\Omega \}.
\end{equation}

Soit \( X\colon \Omega\to \eR^d\) une variable aléatoire. La \defe{tribu engendrée}{tribu!engendrée!par une variable aléatoire} est
\begin{equation}
    \tribA_X=\{ X^{-1}(B)\tq B\in\Borelien(\eR^d) \}.
\end{equation}
Cela est la plus petite tribu sous tribu de \( \tribA\) pour laquelle \( X\) est mesurable.

Nous disons que les variables aléatoires \( X_k\colon \Omega\to \eR^d\) sont \defe{indépendantes}{indépendance!variables aléatoires} si les tribus \( \tribA_{X_1},\ldots,\tribA_{X_n}\) le sont.

\begin{proposition}
    Soient \( (X_k\colon \Omega\to \eR^{d_k})\) des variables aléatoires indépendantes et \( B_k\in \Borelien(\eR^{d_k})\). Alors
    \begin{equation}
        P(X_k\in B_k\forall k\leq n)=P(X_1\in B_1)\ldots P(X_n\in B_n).
    \end{equation}
\end{proposition}

\begin{proof}
    Lorsque nous écrivons \( X_i\in B_i\), nous parlons de l'événement
    \begin{equation}
        (X_i\in B_i)=\{ \omega\in\Omega\tq X_i(\omega)\in B_i \}=X_i^{-1}(B_i)\in \tribA_{X_i}.
    \end{equation}
    Vu que par hypothèse les tribus \( (\tribA_i)\) sont indépendantes, le lemme \ref{LemTribIndepProdProb} nous montre que
    \begin{equation}
        P\big( \bigcap_{i=1}^nX_i\in B_i \big)=\prod_iP(X_i\in B_i).
    \end{equation}
    Il reste à voir que l'ensemble \( X_i^{-1}(B_i)\) fait partie de la tribu \( \tribA\) de départ. Cela est la définition du fait que l'application \( X_i\) soit une variable aléatoire : elle doit être mesurable en tant qu'application
    \begin{equation}
        X_i\colon (\Omega,\tribA)\to (\eR^d,\Borelien(\eR^d)).
    \end{equation}
\end{proof}

\begin{lemma}       \label{LemIndepEvenCompl}
    Les événements \( (A_i)_{i=0,\ldots,n}\) sont indépendants si et seulement si les événements obtenus en remplaçant certains des \( A_i\) par \( \complement A_i\).
\end{lemma}

\begin{proof}
    Sans perte de généralité, nous pouvons nous contenter de prouver que les événements \( \complement A_0,A_1,\ldots,A_n\) sont indépendants sous l'hypothèse que les événements \( A_0,A_1,\ldots,A_n\) sont indépendants. Soit \( I\) un sous-ensemble de \( \{ 1,\ldots,n \}\). Nous avons
    \begin{subequations}
        \begin{align}
            P\big( \complement A_0\bigcap_{i\in I}A_i \big)&=P\big( \bigcap_{i\in I}A_i\setminus\bigcap_{i\in I}A_i\cap A_0 \big)\\
            &=P\big( \bigcap_{i\in I}A_i \big)-P\big( \bigcap_{i\in I}A_i\cap A_0 \big)\\
            &=P\big( \bigcap_{i\in I}A_i \big)\big( 1-P(\complement A_0) \big)\\
            &=P\big( \bigcap_{i\in I}A_i \big)P(\complement A_0).
        \end{align}
    \end{subequations}
\end{proof}

\begin{proposition}
    Les événements \( (A_i)_{i=1,\ldots,n}\) sont indépendants si et seulement si les variables aléatoires \( \mtu_{A_1},\ldots,\mtu_{A_n}\) le sont.
\end{proposition}

\begin{proof}
    La tribu engendrée par la variable aléatoire \( \mtu_{A_k}\) est
    \begin{equation}    \label{EqtribAAimtu}
        \tribA_{\mtu_{A_k}}=\{ \emptyset,A_k,\complement A_k,\Omega \}.
    \end{equation}
    En effet si \( 1\in B\), alors \( A_i\subset\mtu_{A_i}^{-1}(B)\), et si \( 0\in B\), alors \( \complement A_i\subset\mtu_{A_i}^{-1}(B)\). Les éléments \( 0\) et \( 1\) sont tous deux soit dans \( B\), soit hors de \( B\). Cela donne les \( 4\) possibilités énumérées dans \eqref{EqtribAAimtu}.

    Supposons que les événements \( (A_i)\) sont indépendants. Nous devons vérifier que les tribus le soient, c'est à dire que les événements \( A_i\) et \( \complement A_j\) sont indépendants. Cela est une conséquence du lemme \ref{LemIndepEvenCompl}.
\end{proof}

\begin{theorem}[Doob\cite{ProbaDanielLi}]     \label{ThofrestemesurablesXYYX}
    Soit \( X\colon \Omega\to \eR^d\) une variable aléatoire. Une fonction \( Y\colon \Omega\to \eR^{p}\) est une variable aléatoire \( \tribA_X\)-mesurable si et seulement si il existe une fonction borélienne \( f\colon \eR^d\to \eR^{p}\) telle que \( Y=f(X)\).
\end{theorem}

\begin{proposition}
    Soient des variables aléatoires \( X_k\colon \Omega\to \eR^{d_k}\) des variables aléatoires indépendantes et des fonctions boréliennes \( f_k\colon \eR^{d_k}\to \eR^{p_k}\). Alors les variables aléatoires \( f_k(X_k)\) sont indépendantes.
\end{proposition}

\begin{proof}
    Le théorème \ref{ThofrestemesurablesXYYX} assure que les applications
    \begin{equation}
        f_k\circ X_k\colon \Omega\to \eR^{d_k}
    \end{equation}
    sont \( \tribA_{X_k}\)-mesurables. En particulier pour tout borélien \( B\subset\eR^{p_k}\), nous avons \( X^{-1}_k\circ f^{-1}_k(B)\in\tribA_{X_k}\). Nous avons donc
    \begin{equation}
        \sigma(f_k\circ X_k)\subset\sigma(X_k),
    \end{equation}
    et par conséquent les tribus \( \sigma(f_k\circ X_k)\) sont indépendantes étant donné que les tribus \( \sigma(X_k)\) le sont.
\end{proof}

\begin{lemma}[Lemme de regroupement]\index{lemme!regroupement}  \label{LemHOjqqw}
    Soit \( (\Omega,\tribA,P)\) un espace de probabilité et \( (\tribA)_{i\in I}\) une famille de tribus indépendantes dans \( \tribA\). Si \( (M_j)_{j\in J}\) est une partition de \( I\), alors les tribus
    \begin{equation}
        \tribB_j=\sigma\big( \bigcup_{i\in M_j}\tribA_i \big)
    \end{equation}
    sont indépendantes.

    Si les variables aléatoires \( \{ X_1,X_2,X_3,X_4,X_5 \}\) sont indépendantes, et si \( f\) et \( g\) sont des fonctions mesurables, alors les variables aléatoires \( f(X_2,x_3,X_5)\) et \( g(X_1,X_4)\) sont indépendantes.
\end{lemma}
Une preuve a l'air d'être donnée dans \cite{VincentBa}.
%TODO : lire cette preuve.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Lois conjointes et indépendance}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}
    Deux événements \( A\) et \( B\) sont dits \defe{indépendants}{indépendance} si
    \begin{equation}
        P(A\cap B)=P(A)P(B).
    \end{equation}
\end{definition}
Si nous considérons \( n\) variables aléatoires réelles \( X_1,\ldots,X_n\colon\Omega\to\eR\), la loi du \( n\)-uplet \( X=(X_1,\ldots,X_n)\) est une variable aléatoire \( X\colon \Omega\to \eR^n\) appelée la \defe{loi conjointe}{loi!conjointe} des lois \( X_i\). Dans ce cas, les variables aléatoires \( X_i\) elles-mêmes sont dites lois \defe{marginales}{loi!marginale} de \( X\).

\begin{proposition}     \label{PropPXXXPXPXPX}
    Les variables aléatoires \( \{ X_i \}\) sont indépendantes si et seulement si
    \begin{equation}
        P_{(X_1,\ldots,X_n)}=P_{X_1}\otimes\ldots\otimes P_{X_n}.
    \end{equation}
\end{proposition}

\begin{definition}      \label{DefFonrepConj}
    Soient \( \{ X_i \}_{1\leq i\leq n}\) des variables aléatoires réelles (pas spécialement indépendantes). La \defe{densité conjointe}{densité!conjointe} de \( X_1\),\ldots,\( X_n\) est la fonction \( f\colon \eR^n\to \eR\) qui satisfait
    \begin{enumerate}
        \item
            \( f(x_1,\ldots,x_n)\geq 0\) pour tout \( (x_1,\ldots,x_n)\in\eR^n\),
        \item
            \( \int_{\eR^n}f=1\),
        \item       \label{ItemDefFonrepConjiii}
            pour tout \( A_i\subset\eR \) nous avons
            \begin{equation}
                P(\bigcap_{i=1}^n X_i\in A_i)=\int_{\prod_i A_i}f(x_1,\ldots,x_n)dx_1\ldots dx_n.
            \end{equation}
    \end{enumerate}
\end{definition}

\begin{proposition}     \label{PropDensiteConjIndep}
    Si les variables aléatoires \( X_1\),\ldots \( X_n\) sont indépendantes et ont des densités \( f_{X_1}\),\ldots,\( f_{X_n}\), alors la variable aléatoire conjointe \( X=(X_1,\ldots,X_n)\) a pour densité conjointe la fonction
    \begin{equation}
        f_X(x_1,\ldots,x_n)=f_{X_1}(x_1)\ldots f_{X_n}(x_n).
    \end{equation}
\end{proposition}

\begin{proof}
    En partant de la définition de l'indépendance et de la fonction de densité conjointe, ainsi qu'en utilisant le théorème de Fubini,
    \begin{equation}
        \begin{aligned}[]
            \int_{A_1\times \ldots\times A_n}f_X(x_1,\ldots,x_n)dx_1\ldots dx_n&=
            P(X_1\in A_1,\ldots,X_n\in A_n)\\
            &=P(X_1\in A_1)\ldots P(X_n\in A_n)\\
            &=\left( \int_{A_1}f_{X_1}(x_1)dx_1 \right)\ldots\left( \int_{A_n}f_{X_n}(x_n)dx_n \right)\\
            &=\int_{A_1\times\ldots\times A_n}f_{X_1}(x_1)\ldots f_{X_n}(x_n)dx_1\ldots dx_n.
        \end{aligned}
    \end{equation}
    La fonction \( (x_1,\ldots,x_n)\mapsto f_{X_1}(x_1)\ldots f_{X_n}(x_n)\) vérifie donc la condition \ref{ItemDefFonrepConjiii} de la définition \ref{DefFonrepConj}. La vérification des autres conditions est immédiate.
\end{proof}


La proposition suivante\cite{ProbaDanielLi} provient du fait que la mesure d'une loi conjointe est le produit des mesures lorsque les variables aléatoires sont indépendantes (proposition \ref{PropPXXXPXPXPX}).
\begin{proposition}
    Si les variables aléatoires réelles \( X_1\),\ldots,\( X_n\) sont intégrables et indépendantes, alors leur produit est intégrable et l'espérance du produit est égal au produit des espérances :
    \begin{equation}
        E(X_1\cdots X_n)=E(X_1)\ldots E(X_n).
    \end{equation}
\end{proposition}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Somme et produit de variables aléatoires indépendantes}
%---------------------------------------------------------------------------------------------------------------------------
\label{subsecscnvommevariablsindep}


Soient \( X\) et \( Y\), deux variables aléatoires réelles indépendantes. Nous voudrions étudier la loi de la variable aléatoire \( S=X+Y\). Nous commençons par calculer la fonction de répartition en utilisant le résultat de la proposition \ref{PropDensiteConjIndep} :
\begin{subequations}
    \begin{align}
        F_{X+Y}(z)=P(X+Y\leq z)&=\int_{x+y\leq z}f_{X,Y}(x,y)dx\,dy\\
        &=\int_{-\infty}^{\infty}dx\int_{-\infty}^{z-x}dyf_X(x)f_Y(y)\\
        &=\int_{\eR}\left( \int_{-\infty}^{z-x}f_Y(y)dy \right)f_X(x)dx\\
        &=\int_{\eR}F_Y(z-x)f_X(x)dx.
    \end{align}
\end{subequations}
Pour calculer la fonction de densité de \( S\), nous dérivons la fonction de répartition :
\begin{subequations}
    \begin{align}
        f_{X+Y}(z)&=\frac{ d F_{X+Y} }{ d z }(z)\\
        &=\int_{\eR}f_Y(z-x)f_X(x)dx,
    \end{align}
\end{subequations}
ce qui nous amène à dire que la densité de la somme est le produit de convolution\index{convolution} des densités :
\begin{equation}        \label{EqdensitesooemXYint}
    f_{X+Y}(x)=\int_{\eR}f_Y(x-t)f_X(t)dt,
\end{equation}
ou encore \( f_{X+Y}=f_X\star f_Y\).

Notez que nous avons passé sous le silence la difficulté d'inverser la dérivée et l'intégrale. Un exemple sera donné au point \ref{subsecPoissonetexpo}.


\begin{lemma}       \label{LemEXYEXEYprodindep}
    Soient \( X\) et \( Y\), deux variables aléatoires indépendantes et identiquement distribuées. Alors
    \begin{equation}
        E(XY)=E(X)E(Y).
    \end{equation}
\end{lemma}

\begin{proof}
    Par indépendance, fonction de densité conjointe de \( X\) et \( Y\) vaut \( f_{X,Y}=f_Xf_Y\). Par conséquent l'utilisation de Fubini entraine
    \begin{equation}
        E(XY)=\int_{\eR\times\eR}xyf_{X,Y}(x,y)dxdy=E(X)E(Y).
    \end{equation}
\end{proof}

\begin{lemma}   \label{LemVarXpYsmindep}
    Soit \( X\) et \( Y\) deux variables aléatoires indépendantes et identiquement distribuées. Alors
    \begin{equation}
        \Var(X+Y)=\Var(X)+\Var(Y).
    \end{equation}
\end{lemma}

\begin{proof}
    Par définition, \( \Var(X+Y)=E\big( [X+Y-E(X)-E(Y)]^2 \big)\). En développant le carré et en utilisant le lemme \ref{LemEXYEXEYprodindep},
    \begin{equation}
        \Var(X+Y)=E(X^2)-E(X)^2+E(Y^2)-E(Y)^2=\Var(X)+\Var(Y).
    \end{equation}
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Espérance}
%---------------------------------------------------------------------------------------------------------------------------

Nous dirons que la variable aléatoire \( X\) a un \defe{moment d'ordre \( p\)}{moment} si \( X\in L^p(\Omega,\tribA,P)\) (\( 1\leq p<\infty\)). Si \( X\) est \defe{intégrable}{variable aléatoire!intégrable} (c'est à dire si \( X\in L^1\)), alors nous définissons l'\defe{espérance}{espérance} de \( X\) par
\begin{equation}        \label{EqdCBLst}
    E(X)=\int_{\Omega}XdP\in\eR^d.
\end{equation}
Si \( E(X)=0\) nous disons que la variable aléatoire est \defe{centrée}{variable aléatoire!centrée}. La variable aléatoire \( X-E(X)\) est la variable aléatoire centrée associée à \( X\).

Le \defe{moment}{moment} d'ordre \( p\) de la variable aléatoire \( X\) est l'espérance
\begin{equation}
    m_n(X)=E(X^n).
\end{equation}

\begin{proposition}
    Si \( X\) et \( Y\) sont deux variables aléatoires (pas spécialement indépendantes), nous avons
    \begin{equation}
        E(X+Y)=E(X)+E(Y).
    \end{equation}
\end{proposition}

Nous donnons la preuve dans le cas de variables aléatoires indépendantes. Le cas plus général de variable aléatoires non indépendantes peut être trouvé dans \cite{Marazzi}.
\begin{proof}
    Nous avons le calcul suivant :
    \begin{subequations}
        \begin{align}
            E(X+Y)&=\int_{\eR}xf_{X+Y}(x)dx\\
            &=\int_{\eR}x\int_{\eR}f_Y(x-t)f_X(t)dtdx\\
            &=\int_{\eR}f_X(t)\underbrace{\int_{\eR}xf_Y(x-t)dx}_{=E(Y)+t}\,dt\\
            &=\int_{\eR}f_X(t)\big( E(Y)+t \big)dt\\
            &=E(Y)+\int_{\eR}tf_X(t)dt\\
            &=E(Y)+E(X)
        \end{align}
    \end{subequations}
    où nous avons utilisé la proposition \ref{EqdensitesooemXYint} et le fait que l'intégrale sur \( \eR\) d'une densité vaut \( 1\).
\end{proof}

Une application de l'inégalité de Hölder (proposition \ref{ProptYqspT}) est la suivante. Si \( X\) et \( Y\) sont des variables aléatoires intégrables alors
\begin{equation}
    E(XY)\leq E(X^2)^{1/2}E(Y^2)^{1/2}.
\end{equation}
En effet
\begin{equation}    \label{EqEXYleqXdYdNormHolder}
    E(XY)\leq \| XY \|_{L^1(\Omega)}\leq \| X \|_{L^2(\Omega)}\| Y \|_{L^2(\Omega)}.
\end{equation}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Variance}
%---------------------------------------------------------------------------------------------------------------------------

Si \( X\in L^2(\Omega,\tribA,P)\) alors nous définissons la \defe{variance}{variance} de \( X\) par
\begin{equation}
    \Var(X)=E\big( [X-E(X)]^2 \big).
\end{equation}

\begin{proposition}     \label{PrropVarAlterfrom}
    La variance de la variable aléatoire \( X\) peut être exprimée par la formule
    \begin{equation}        \label{EqtWqMGB}
        \Var(X)=E(X^2)-[E(X)]^2
    \end{equation}
    où \( X^2=X\cdot X\) et \( E(X)^2=\) sont des produits scalaires dans \( \eR^d\).
\end{proposition}

\begin{proof}
    De façon explicite, nous avons
    \begin{equation}
        E\big( [X-E(X)]^2 \big)=\int_{\Omega}\big( X(\omega)-E(X) \big)\cdot\big( X(\omega)-E(X) \big)dP(\omega)
    \end{equation}
    où \( E(X)\in\eR^d\) est une constante. En développant le produit scalaire nous avons
    \begin{subequations}
        \begin{align}
            E\big( [X-E(X)]^2 \big)&=E\big( X^2-2X\cdot E(X)+E(X)^2 \big)\\
            &=E(X^2)-2E(X)^2+E(X)^2\\
            &=E(X^2)-E(X)^2.
        \end{align}
    \end{subequations}
\end{proof}


Nous définissons l'\defe{écart-type}{écart-type} de \( X\) par
\begin{equation}
    \sigma_X=\sqrt{\Var(X)}.
\end{equation}
En d'autres termes,
\begin{equation}
    \sigma_X=\| X-E(X) \|_{L^2}.
\end{equation}
On définit encore la \defe{moyenne quadratique}{moyenne!quadratique} de \( X\) par
\begin{equation}
    \| X \|_{L^2}=\big[ E(X^2) \big]^{1/2}.
\end{equation}

La variable aléatoire 
\begin{equation}
    \bar V_n=\frac{1}{ n }\sum_i(X_i-\bar X_n)^2
\end{equation}
est la \defe{variance empirique}{variance!empirique} de l'échantillon \( (X_i)\).

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Covariance}
%---------------------------------------------------------------------------------------------------------------------------

Soient \( X\) et \( Y\), deux variables aléatoires réelles. Leur \defe{covariance}{covariance} est définie par
\begin{equation}
    \Cov(X,Y)=E\Big[ \big( X-E(X) \big)\big( Y-E(Y) \big) \Big]
\end{equation}
L'idée est que la covariance devient grande si \( X\) et \( Y\) s'écartent de leurs moyennes dans le même sens. Il existe une formule alternative :
\begin{equation}
    \Cov(X,Y)=E(XY)-E(X)E(Y)
\end{equation}

En ce qui concerne les dimensions plus hautes, si \( X\colon \Omega\to \eR^d\) est un vecteur aléatoire de carré intégrable, nous définissons
\begin{equation}    \label{EqZlvLWx}
    \Cov(X)=E\Big[ \big(  X-E(X) \big)\otimes\big( X-E(X)\big) \Big]
\end{equation}
où par \( a\otimes b\) nous entendons la matrice \( (a\otimes b)_{ij}=a_ib_j\). Cela peut aussi être noté \( a^tb\) si l'on fait bien attention à qui est un vecteur colonne et qui est un vecteur ligne.

\begin{proposition}     \label{PropoVarXpYCov}
    Si \( X\) et \( Y\) sont deux variables aléatoires non spécialement indépendantes, nous avons
    \begin{equation}
        \Var(X+Y)=\Var(X)+\Var(Y)+2\Cov(X+Y).
    \end{equation}
\end{proposition}

\begin{proof}
    Il s'agit d'un calcul en partant de
    \begin{equation}
        \begin{aligned}[]
            \Var(X+Y)&=E\big( (X+Y)^2 \big)-E(X+Y)^2\\
            &=E(X^2)+E(Y^2)+2E(XY)\\
            &\quad+\big( E(X)+E(Y) \big)^2-2E(X)^2-2E(X)E(Y)\\
            &\quad-2 E(Y)E(X)-2E(Y)^2.
        \end{aligned}
    \end{equation}
    À partir d'ici il s'agit de recombiner tous les termes pour former la formule annoncée.
\end{proof}

Plus généralement nous avons la formule
\begin{equation}
    \Var(\sum_i X_i)=\sum_i\Var(X_i)+2\sum_{1\leq i< j\leq n}\Cov(X_i,X_j).
\end{equation}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Probabilité conditionnelle, première}
%---------------------------------------------------------------------------------------------------------------------------

Soit \( (\Omega,\tribA,P)\) un espace de probabilité et \( B\in\tribA\) avec $P(B)>0$. Nous pouvons introduire une nouvelle loi de probabilité \( P_B\) sur \( (\Omega,\tribA)\) en définissant
\begin{equation}    \label{EqProbCond}
    P_B(A)=\frac{ P(A\cap B) }{ P(B) }=P(A|B).
\end{equation}
La première égalité est la définition de \( P_B\). La seconde est une notation. On vérifie que \( (\Omega,\tribA,P)\) est un espace de probabilité parce que \( P_B(\Omega)=1\) et 
\begin{equation}
    P_B(\bigcup_iA_i)=\sum_iP_B(A_i)
\end{equation}
si les \( A_i\) sont deux à deux disjoints.

Une conséquence immédiate de \eqref{EqProbCond} est que si \( A\) et \( B\) sont des événements indépendants alors
\begin{equation}
    P(A|B)=\frac{ P(A\cap B) }{ P(B) }=P(A).
\end{equation}

\begin{theorem}     \label{ThoBayesEtAutres}
    Soient \( (B_n)_{n\geq 1}\) une partition finie de \( \Omega\) telle que \( P(B_i)>0\). Soit \( A\in\tribA\) tel que \( P(A)>0\).
    \begin{enumerate}
        \item
            Si \( A\), \( B\) et \( C\) sont des événements, alors
            \begin{equation}
                P(A\cap B|C)=P(A|B\cap C)P(B|C).
            \end{equation}
        \item
            Si \( P(B)>0\), alors \( P(A\cap B)=P(A|B)P(B)=P(B|A)P(A)\).
        \item On a la \defe{formule des probabilités totales}{formule!probabilité totales} :
            \begin{equation}
                P(A)=\sum_{i=1}^nP(A|B_i)P(B_i)=\sum_iP(A\cap B_i).
            \end{equation}
        \item
            On a la \defe{formule de Bayes}{formule!Bayes} :
            \begin{equation}
                P(B_k|A)=\frac{ P(A|B_k)P(B_k) }{ \sum_iP(A|B_i)P(B_i) }.
            \end{equation}
    \end{enumerate}
\end{theorem}

\begin{proof}
    \begin{enumerate}
        \item
            En développant le membre de droite,
            \begin{equation}
                \begin{aligned}[]
                    P(A\cap B|C)&=\frac{ P(A\cap B\cap C) }{ P(B\cap C) }\frac{ P(B\cap C) }{ P(C) }\\
                    &=P(A\cap B|C).
                \end{aligned}
            \end{equation}
        \item
            C'est la définition de \( P(A|B)\) et \( P(B|A)\).
        \item
            Vu que les \( B_i\) forment une partition, nous avons
            \begin{equation}
                P(A)=\sum_iP(A\cap B_i)=\sum_iP(A|B_i)P(B_i).
            \end{equation}
        \item
            En utilisant les deux premiers points, nous trouvons
            \begin{equation}
                \begin{aligned}[]
                    P(A|B_k)P(B_k)&=P(A\cap B_k)\\
                    &=P(B_k|A)P(A)\\
                    &=P(B_k|A)\sum_iP(A|B_i)P(B_i).
                \end{aligned}
            \end{equation}
    \end{enumerate}
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Espérance conditionnelle}
%---------------------------------------------------------------------------------------------------------------------------

\begin{theorem}     \label{ThoMWfDPQ}
    Soit un espace de probabilité \( (\Omega,\tribA,P)\) et une variable aléatoire intégrable \( X\colon \Omega\to \eR\). Pour chaque sous tribu \( \tribF\) de \( \tribA\), il existe une (presque partout) unique variable aléatoire \( Y\colon \Omega\to \eR\) telle que
    \begin{enumerate}
        \item
            \( Y\) est \( \tribF\)-mesurable
        \item
            \( Y\) est \( P\)-intégrable
        \item
            pour tout \( B\in\tribF\),
            \begin{equation}        \label{EqBwBkgE}
                \int_{B}XdP=\int_B YdP.
            \end{equation}
    \end{enumerate}
    Cette variable aléatoire sera notée \( E(X|\tribF)\)\nomenclature[P]{\( E(X|\tribF)\)}{Espérance conditionnelle de \( X\) sachant \( \tribF\)} pour des raisons qui apparaîtront plus tard.
\end{theorem}

\begin{remark}
    Prendre \( Y=X\) ne fonctionne pas parce qu'en général si \( \mO\) est mesurable dans \( \eR\), alors \( X^{-1}(\mO)\) est dans la tribu \( \tribA\), mais n'est pas automatiquement dans la tribu \( \tribF\).
\end{remark}

\begin{proof}
    Cette preuve provient en bonne partie de \cite{ProbCOndutetz}.

    \begin{description}
        \item[Unicité] Si \( Y_1\) et \( Y_2\) vérifient tous les deux les conditions, l'ensemble \( \{ Y_1<Y_2 \}\) est un élément de \( \tribF\) et nous avons
            \begin{equation}
                \int_{\{ Y_1<Y_2 \}}X=\int_{Y_1<Y_2}Y_1=\int_{Y_1<Y_2}Y_2.
            \end{equation}
            En particulier nous avons \( \int_{\{ Y_1<Y_2 \}}(Y_1-Y_2)=0\) et donc
            \begin{equation}
                (Y_1-Y_2)\mtu_{Y_1-Y_2}=0
            \end{equation}
            presque partout. Le corollaire \ref{CorjLYiSm} montre alors que \( Y_1-Y_2\geq 0\) presque partout. De la même manière, l'ensemble \( \{ Y_2<Y_1 \}\) est dans \( \tribF\) et nous trouvons que \( Y_2-Y_1\geq 0\) presque partout. Par conséquent \( Y_1=Y_2\) presque partout.
        \item[Existence dans le cas de carré intégrable]

            Nous supposons que \( X\in L^2(\Omega,\tribA,P)\) et nous considérons \( K\), le sous ensemble de \( L^2(\Omega,\tribA,P)\) des fonctions \( \tribF\)-mesurables. Le théorème des projections \ref{ThoProjOrthuzcYkz} nous indique que
            \begin{equation}
                L^2(\Omega,\tribA,P)=K\oplus K^{\perp}
            \end{equation}
            par la décomposition \( X=\pr_{K}X+(X-\pr_KX)\). La variable aléatoire \( Y=\pr_KX\) a les propriétés d'être \( \tribF\)-mesurable et \( \langle Y-X, Z\rangle =0\) pour tout \( Z\in K\). Soit \( A\in\tribF\), si nous considérons \( Z=\mtu_A\), la dernière condition signifie que
            \begin{equation}
                \int_{\Omega}X\mtu_A=\int_{\Omega}Y\mtu_A,
            \end{equation}
            ou encore
            \begin{equation}
                \int_AY=\int_AX.
            \end{equation}
            La variable aléatoire \( Y=\pr_KX\) répond donc à la question dans le cas où \( X\in L^2(\Omega,\tribF,P)\).

        \item[Existence en général] 

            Nous considérons maintenant que \( X\in L^1(\Omega,\tribA,P)\). Quitte à décomposer \( X\) en deux fonctions positives \( X_+\) et \( X_-\) telles que \( X=X_++X_-\), nous pouvons supposer que \( X\) est positive. Par hypothèse \( X\in L^1(\Omega,\tribA,P)\); pour chaque \( n\in\eN\) nous posons
            \begin{equation}
                X_n(\omega)=\min\{ X(\omega),n \}.
            \end{equation}
            Étant donné que la mesure \( P\) est une mesure de probabilité, les constantes sont intégrables et \( X_n\in L^2(\Omega,\tribA,P)\). De plus la suite \( (X_n)\) est croissante et
            \begin{equation}
                \lim_{n\to \infty} X_n(\omega)=X(\omega).
            \end{equation}

            Si nous notons encore \( K\) l'ensemble des variables aléatoires dans \( L^2(\Omega,\tribA,P)\) qui sont \( \tribF\)-mesurables, pour chaque \( n\) nous avons donc la variable aléatoire 
            \begin{equation}
                Y_n=\pr_KX_n=E(X_n|\tribF)
            \end{equation}
            qui est \( \tribF\)-mesurable et telle que
            \begin{equation}
                \int_A X_n=\int_AY_n
            \end{equation}
            pour tout \( A\in\tribF\). Nous voudrions prouver que la variable aléatoire \( Y=\lim_nY_n\) existe et est la solution au problème, c'est à dire est \( E(X|\tribF)\). 

            Commençons par prouver que \( Y_n\geq 0\) presque partout. Pour cela nous remarquons que l'ensemble \( \{ Y_n<0 \}\) est mesurable et
            \begin{equation}
                0\geq\int_{Y_n<0}Y_n=\int_{Y_n<0}X_n\geq 0.
            \end{equation}
            La première inégalité est évidente et la dernière est due au fait que \( X_n\) est positive. Par conséquent
            \begin{equation}
                \int_{Y_n<0}Y_n=0
            \end{equation}
            et le lemme \ref{CorjLYiSm} conclu que \( P(Y_n<0)=0\).

            Soit \( Z\colon \Omega\to \eR\) une variable aléatoire positive dans \( L^2(\Omega,\tribA,P)\). Montrons que \( \pr_KZ\) est encore positive. Pour cela nous considérons l'ensemble \( A=\{ \pr_KZ<0 \}\) et les inégalités
            \begin{equation}
                0\leq \int_AZ=\int_A\pr_KZ\leq 0,
            \end{equation}
            ce qui montre que \( \int_A\pr_KZ=0\) et par conséquent que \( P\{ \pr_K(Z)<0 \}=0\). Cela nous montre que la projection depuis \( L^2\) conserve la positivité.

            Étant donné que \( X_{n-1}-X_n\geq 0\) nous avons aussi
            \begin{equation}
                Y_{n-1}-Y_{n}\geq 0
            \end{equation}
            La suite de fonctions
            \begin{equation}
                n\mapsto Y_n=E(X_n|\tribF)
            \end{equation}
            est croissante et vérifie le théorème de la convergence monotone :
            \begin{subequations}
                \begin{align}
                    \int_A X&=\lim_{n\to \infty} \int_A X_n\\
                    &=\lim_{n\to \infty} \int_A E(X_n|\tribF)\\
                    &=\int_A\lim_{n\to \infty } E(X_n|\tribF)\\
                    &=\int_A Y.
                \end{align}
            \end{subequations}
            Par conséquent \( E(X|\tribF)\) existe et
            \begin{equation}
                Y=\lim_{n\to \infty} E(X_n|\tribF)=E(X|\tribF).
            \end{equation}
    \end{description}
\end{proof}

\begin{proposition}[Transitivité de l'espérance conditionnelle]
    Si \( \tribB_2\subseteq\tribB_1\subset\tribA\) alors
    \begin{equation}
        E\Big( E(X|\tribB_1)|\tribB_2 \Big)=E(X|\tribB_2).
    \end{equation}
\end{proposition}

\begin{proof}
    Si \( B\in\tribB_2\), nous avons
    \begin{equation}
        \int_BE\big( E(X|\tribB_1)|\tribB_2 \big)dP=\int_B E(X|\tribB_1)dP=\int_BdP.
    \end{equation}
    La première égalité est la définition de l'espérance conditionnelle par rapport à \( \tribB_2\). La seconde égalité est celle de l'espérance conditionnelle par rapport à \( \tribB_1\) et le fait que \( B\in\tribB_2\subset\tribB_1\). Ce que nous avons prouvé est que
    \begin{equation}
        E\big( E(X|\tribB_1)|\tribB_2 \big)
    \end{equation}
    est une variable aléatoire \( \tribB_2\)-mesurable vérifiant la condition
    \begin{equation}
        \int_BE\big( E(X|\tribB_1)|\tribB_2 \big)=\int_BE(X|\tribB_2)
    \end{equation}
    pour tout \( B\in \tribB_2\). C'est donc \( E(X|\tribB_2)\) par la partie unicité du théorème \ref{ThoMWfDPQ}.
\end{proof}

\begin{proposition}
    Soit \( (\Omega,\tribF,P)\) un espace de probabilité, soit \( \tribA\) une sous tribu de \( \tribF\) et \( X\), une variable aléatoire \( \tribF\)-mesurable et intégrable. Alors la variable aléatoire \( E(X|\tribA)\) du théorème \ref{ThoMWfDPQ} est l'unique (presque partout) variable aléatoire à être \( \tribA\)-mesurable telle que nous ayons
    \begin{equation}
        E\big( E(X|\tribA)Y \big)=E(XY).
    \end{equation}  
    pour toute variable aléatoire \( Y\) \( \tribA\)-mesurable.
\end{proposition}

\begin{proof}
    Supposons pour commencer que \( Y\) soit une fonction simple positive, alors \( Y=\sum_{i=1}^na_i\mtu_{E_i}\) et nous avons
    \begin{subequations}
        \begin{align}
            \int_{\Omega}E(X|Y)&=\sum_{i}a_i\int_{E_i}E(X|\tribA)\\
            &=\sum_ia_i\int_{E_i}X\\
            &=\int_{\Omega}XY.
        \end{align}
    \end{subequations}
    Maintenant si \( Y\) est mesurable et bornée, elle est limite croissante de fonctions simples bornées (proposition \ref{PropWBavIf}) et le résultat tient par la convergence monotone, théorème \ref{ThoConvMonFtBoVh}.

    Si \( Y\) n'est pas positive, nous séparons \( Y=Y_+-Y_-\).

    Pour l'unicité, soit \( Z\) et \( Z'\) deux variables aléatoires telles que pour toute variable aléatoire \( Y\),
    \begin{equation}
        \int_{\Omega}ZY=\int_{\Omega}XY=\int_{\Omega}Z'Y.
    \end{equation}
    Si nous prenons \( Y=\mtu_{\{ Z\neq Z' \}}\), nous avons
    \begin{equation}
        0=\int_{\Omega}(Z-Z')\mtu_{Z\neq Z'}=\int_{Z\neq Z'}Z-Z',
    \end{equation}
    d'où le fait que \( P(Z\neq Z')=0\).
\end{proof}

Si \( X\) est une variable aléatoire dont la tribu engendrée est indépendante de la tribu \( \tribF\), nous voudrions que la connaissance de \( \tribF\) n'influence pas la connaissance de \( X\), c'est à dire que
\begin{equation}
    E(X|\tribF)=E(X).
\end{equation}
Ce que nous avons est même mieux. Nous avons le lemme suivant.
\begin{lemma}[\cite{ProbaDanielLi}]     \label{LemxUZFPV}
    Les tribus \( \tribF_1\) et \( \tribF_2\) sont indépendantes si et seulement si
    \begin{equation}
        E(U|\tribF_1)=E(U)
    \end{equation}
    pour toute variable aléatoire \( U\) étant \( \tribF_1\)-mesurable.
\end{lemma}
Ici, par \( E(U)\) nous entendons la variable aléatoire constante prenant la valeur numérique \( E(U)\) en tout point de \( \Omega\).

\begin{proof}
    Si \( \tribF_1\) et \( \tribF_2\) sont indépendantes, alors pour tout \( B\in\tribF_2\) nous avons
    \begin{subequations}    \label{EqGGqgxl}
            \begin{align}
                \int_B UdP&=E(U\mtu_B)\\
                &=E(U)E(\mtu_B)         \label{subeqBZWLNS}\\
                &=E(U)\int_{\Omega}\mtu_BdP\\
                &=\int_B E(U)dP.
            \end{align}
        \end{subequations}
    Justifications.
    \begin{itemize}
        \item L'intégrale \( \int_BUdP\) a un sens même si \( B\in\tribF_2\) alors que \( U\) est \( \tribF_1\)-mesurable. Le supremum \eqref{EqDefintYfdmu} définissant l'intégrale est tout de même bien défini, en particulier, l'ensemble sur lequel on prend le supremum est non vide.
        \item
            Pour \eqref{subeqBZWLNS}, la variable aléatoire \( U\) est \( \tribF_1\)-mesurable (donc la tribu engendrée par \( U\) est dans \( \tribF_1\)) alors que \( \mtu_B\) est \( \tribF_2\)-mesurable. Les tribus engendrées étant indépendantes, les variables aléatoires le sont et nous pouvons décomposer l'espérance.
    \end{itemize}
    Ce que montre le calcul \eqref{EqGGqgxl} est que \( E(U)\) est une variable aléatoire \( \tribF_2\)-mesurable (parce que constante) dont l'intégrale sur chaque élément de \( \tribF_2\) vaut l'intégrale de \( U\). Par la partie unicité du théorème \ref{ThoMWfDPQ}, nous déduisons que \( E(U)=E(U|\tribF_2)\).
\end{proof}

\begin{corollary}   \label{CorakyvMp}
    Si \( X\) est une variable aléatoire et si \( \tribF\) est une tribu, alors
    \begin{equation}
        E\big( E(X|\tribF) \big)=E(X).
    \end{equation}
\end{corollary}

\begin{proof}
    Il suffit d'appliquer la définition \eqref{EqBwBkgE} à \( B=\Omega\) :
    \begin{subequations}
        \begin{align}
            E\big( E(X|\tribF) \big)&=\int_{\Omega}E(X|\tribF)(\omega)dP(\omega)\\
            &=\int_{\Omega}X(\omega)dP(\omega)\\
            &=E(X).
        \end{align}
    \end{subequations}
\end{proof}

\begin{example}
    Soient \( X_1\), \( X_2\) deux variables aléatoires à valeurs dans \( \{ 0,1 \}\) avec probabilité \( 1/2\) et indépendantes. Nous considérons \( S=X_1+X_2\). La situation est modélisée par l'espace
    \begin{equation}
        \Omega=\{ (0,0),(0,1),(1,0),(1,1) \}
    \end{equation}
    et les variables aléatoires
    \begin{subequations}
        \begin{align}
            X_i(\omega_1,\omega_2)=\omega_{i}\\
            S(\omega_1,\omega_2)=\omega_1+\omega_2.
        \end{align}
    \end{subequations}
    Pour vérifier que de cette manière nous avons bien que \( X_1\) est indépendante de \( X_2\), nous commençons par voir les tribus associées. Un ouvert de \( \eR\) soit contient \( 0\) et \( 1\), soit contient un seul des deux soit n'en contient aucun des deux. En appliquant \( X_1^{-1}\) à chacune de ces quatre situations nous voyons que la tribu \( \sigma(X_1)\) est
    \begin{equation}
        \tribF_1=\sigma(X_1)=\big\{ \{ (0,0),(0,1) \},\{ (1,0),(1,1) \},\Omega,\emptyset \}.
    \end{equation}
    De la même façon nous avons
    \begin{equation}
        \tribF_2=\sigma(X_1)=\big\{ \{ (0,0),(1,0) \},\{ (0,1),(1,1) \},\Omega,\emptyset \}.
    \end{equation}
    Nous posons
    \begin{subequations}
        \begin{align}
            A_0&=\{ (0,0),(0,1) \}\\
            A_1&=\{ (1,0),(1,1) \}\\
            B_0&=\{ (0,0),(1,0) \}\\
            B_1&=\{ (0,1),(1,1) \}.
        \end{align}
    \end{subequations}
    Étant donné que \( A_i\cap B_j=(i,j)\), nous avons toujours que \( P(A_i\cap B_j)=\frac{1}{ 4 }=P(A_i)P(B_j)\). L'indépendance est donc assurée.

    Calculons l'espérance conditionnelle \( E(S|\tribF_1)\). Une fonction \( \tribF_1\)-mesurable doit être constante sur \( A_0\) et \( A_1\), donc l'espérance conditionnelle est une fonction constante sur \( A_0\) et \( A_1\) dont l'intégrale sur ces ensembles est égale à l'intégrale de \( S\). Nous avons en particulier
    \begin{equation}
        \int_{A_0}E(S|\tribF_1)=\int_{A_0}S,
    \end{equation}
    c'est à dire
    \begin{equation}
        E(S|\tribF_1)(0,0)+E(S|\tribF_1)(0,1)=S(0,0)+S(0,1)=1.
    \end{equation}
    Nous en concluons que \( E(S|\tribF_1)(0,0)=E(S|\tribF_1)(0,1)=\frac{ 1 }{2}\). Cela correspond à l'intuition que si on est au point \( (0,1)\) ou au point \( (0,0)\) en ne sachant que \( X_1\), nous ne savons que le premier zéro, et donc l'espérance de la somme est \( \frac{ 1 }{2}\).

    Un calcul très similaire montre que
    \begin{equation}
        E(S|\tribF_1)(1,0)=E(S|\tribF_1)(1,1)=\frac{ 3 }{2}.
    \end{equation}
    Cela correspond au fait qu'en ces points, nous ne savons que le fait que le premier tirage a donné \( 1\), et donc que l'espérance est \( \frac{ 3 }{2}\).

    Complétons ce tour d'horizon en mentionnant que la tribu engendrée par \( X_1\) et \( X_2\) est la tribu des parties de \( \Omega\), de telle façon que l'espérance conditionnelle de \( S\) sachant \( X_1\) et \( X_2\) est égale à \( S\).
\end{example}

\begin{definition}
    Soit \( Z\) une variable aléatoire. L'\defe{espérance conditionnelle}{espérance!conditionnelle} «\( X\) sachant \( Z\)» est la variable aléatoire
    \begin{equation}
        E(X|Z)=E(X|\sigma(Z))
    \end{equation}
    où \( \sigma(Z)\) est la tribu engendrée par \( Z\).
\end{definition}

\begin{proposition}
    Soit une variable aléatoire réelle \( X\in L^1(\Omega,\tribA,P)\). Pour toute variable aléatoire \( Y\colon \Omega\to \eR^d\), il existe une fonction borélienne \( \tribA_Y\)-mesurable \( h\colon \eR^d\to \eR\) telle que
    \begin{equation}
        E(X|Y)=h\circ Y.
    \end{equation}
\end{proposition}

\begin{proof}
    Nous utilisons le résultat de Doob (théorème \ref{ThofrestemesurablesXYYX}). Par définition \( E(X|Y)\) est une variable aléatoire réelle \( \tribA_Y\)-mesurable, et il existe une fonction borélienne \( h\colon \eR^d\to \eR\) telle que \( E(X|Y)=f\circ Y\).
\end{proof}

Cette fonction \( h\colon \eR^d\to \eR\) nous permet de définir\index{espérance!conditionnelle!variable aléatoire}
\begin{equation}
    E(X|Z=z)=h(z).
\end{equation}
Cela est l'espérance conditionnelle d'une variable aléatoire par rapport à une valeur donnée d'une autre variable aléatoire.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Probabilité conditionnelle, seconde}
%---------------------------------------------------------------------------------------------------------------------------

Soit \( A\in\tribA\) un événement et \( \tribF\) une sous tribu de \( \tribA\). Nous définissons\index{espérance!conditionnelle!événement} \( P(A|\tribF)\) par
\begin{equation}
    P(A|\tribF)=E(\mtu_{A}|\tribF).
\end{equation}
Notons que cela est une variable aléatoire et non un réel.

Pour la suite de la construction nous avons besoin du lemme suivant.
\begin{lemma}
    Soit \( (B_i)_{i\in\eN}\) une partition de \( \Omega\) en éléments de \( \tribA\) deux à deux disjoints tels que \( P(B_i)\neq 0\). Soit \( \tribF\) la tribu engendrée par les \( B_i\). Une variable aléatoire réelle est \( \tribF\)-mesurable si et seulement si elle est constante sur chaque \( B_i\).
\end{lemma}

Si \( X\) est une variable aléatoire, alors \( E(X|\tribF)\) est une variable aléatoire \( \tribF\)-mesurable et elle est donc constante sur les ensembles \( B_i\) :
\begin{equation}
    E(X|\tribF)=\sum_{i\in\eN}a_i\mtu_{B_i}.
\end{equation}
Étant donné que, par construction, \( B_i\) est \( \tribF\)-mesurable, nous avons 
\begin{subequations}
    \begin{align}
        \int_{B_i}XdP&=\in_{B_i}E(X|\tribF)\\
        &=\sum_ja_j\int_{B_i}\mtu_{B_j}\\
        &=\sum_ja_j\delta_{ij}P(B_j)\\
        &=a_iP(B_i).
    \end{align}
\end{subequations}
Par conséquent
\begin{equation}
    a_i=\frac{1}{ P(B_i) }\int_{B_i}XdP
\end{equation}
et
\begin{equation}    \label{EqCibwoG}
    E(X|\tribF)=\sum_{i\in \eN}\left( \frac{1}{ P(B_i) }\int_{B_i}XdP \right)\mtu_{B_i}.
\end{equation}
En particulier si \( B\in \tribA\) nous considérons la partition \( \{ B,\complement B \}\) de \( \Omega\) et la tribu engendrée
\begin{equation}
    \tribF=\{ \emptyset,B,\complement B,\Omega \}.
\end{equation}
La formule \eqref{EqCibwoG} devient
\begin{equation}
    E(X|\tribF)=\left( \frac{1}{ P(B) }\int_BXdP \right)\mtu_B+\left( \frac{1}{ P(\complement B) }\int_{\complement B}XdP \right)\mtu_{\complement B}.
\end{equation}
Si nous considérons \( A\in\tribA\), nous écrivons cette égalité avec \( X=\mtu_A\) pour obtenir
\begin{subequations}
    \begin{align}
        P(A|\tribF)=E(\mtu_A|\tribF)&=\frac{ P(A\cap B) }{ P(B) }\mtu_B+\frac{ P(A\cap\complement B) }{ P(\complement B) }\mtu_{\complement B}\\
        &=P(A|B)\mtu_B+P(A|\complement B)\mtu_{\complement B}
    \end{align}
\end{subequations}
où nous avons noté
\begin{equation}
    P(A|B)=\frac{ P(A\cap B) }{ P(B) }
\end{equation}
l'\defe{espérance conditionnelle}{espérance!conditionnelle!événements} de «\( A\) sachant \( B\)».

\begin{remark}
    La définition \(P(A|\tribF)=P(\mtu_A|\tribF)\) n'est pas la probabilité conditionnelle de \( A\) sachant \( B\), même si la tribu \( \tribF\) est la tribu engendrée par l'événement \( B\).
\end{remark}

Il nous reste à définir la probabilité conditionnelle d'un événement relativement à une variable aléatoire. Si la variable aléatoire \( X\) est à valeurs discrètes, nous disons que \( P(A|X)\) est la variable aléatoire de valeur
\begin{equation}
    P(A|X)(\omega)=P(A|X=X(\omega)).
\end{equation}
Dans le cas d'une variable aléatoire à valeurs continues, cette définition ne fonctionne pas parce que la condition \( X=X(\omega)\) est souvent de probabilité nulle, tandis que c'est toujours une mauvaise idée de conditionner par rapport à un événement de probabilité nulle. C'est la base du \wikipedia{en}{Borel's_paradox}{paradoxe de Borel}. La bonne définition du conditionnement de l'événement \( A\) par rapport à la variable aléatoire $X$ est
\begin{equation}
    P(A|X)=P(A|\sigma(X))=E\big( \mtu_A|\sigma(X) \big).
\end{equation}

\begin{proposition}
    Si \( X\) est une variable aléatoire et si \( A\) est un événement, alors
    \begin{equation}
        E\big( P(A|X) \big)=P(A).
    \end{equation}
\end{proposition}

\begin{proof}
    Nous commençons par le cas discret, c'est à dire \( X\colon \Omega\to \eN\). Nous notons \( p_k=P(X=k)\). En décomposant l'intégrale sur \( \Omega\) par rapport à l'union disjointe
    \begin{equation}
        \Omega=\bigcup_{k\in \eN}A_k=\bigcup_{k\in \eN}\{ \omega\in\Omega \tq X(\omega)=k\},
    \end{equation}
    nous obtenons
    \begin{subequations}
        \begin{align}
            E\big( P(A|X) \big)&=\int_{\Omega}P(A|X)(\omega)dP(\omega)\\
            &=\sum_{k=0}^{\infty}\int_{A_k}P(A|X=X(\omega))dP(\omega)\\
            &=\sum_k\int_{A_k}\frac{ P(A\cap X=k) }{ P(X=k) }dP(\omega) & \text{dans \( A_k\), \( X(\omega)=k\)}\\
            &=\sum_k\frac{1}{ p_k }P(A\cap X=k)\underbrace{\int_{A_k}1dP(\omega)}_{P(A_k)=p_k}\\
            &=\sum_{k}P(A\cap X=k)\\
            &=P(A).
        \end{align}
    \end{subequations}
    Nous devons maintenant prouver la propriété dans le cas où \( X\) prend des valeurs continues. Pour cela il suffit d'appliquer le corollaire \ref{CorakyvMp} :
    \begin{equation}
        E\big( E(\mtu_A|\sigma(A)) \big)=E(\mtu_A)=P(A).
    \end{equation}
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Résumé des choses conditionnelles}
%---------------------------------------------------------------------------------------------------------------------------

La probabilité conditionnelle d'un événement par rapport à un autre est un nombre :
\begin{equation}
    P(A|B)=\frac{ P(A\cap B) }{ P(B) }.
\end{equation}

La probabilité conditionnelle d'un événement vis-à-vis d'une variable aléatoire discrète est une variable aléatoire :
\begin{equation}
    P(A|X)(\omega)=P(A|X=X(\omega)).
\end{equation}
Dans le cas continu,
\begin{equation}
    P(A|X)=P(A|\sigma(X))=E(\mtu_A|\sigma(X)).
\end{equation}

L'espérance conditionnelle d'une variable aléatoire par rapport à une tribu \( E(X|\tribF)\) est la variable aléatoire \( \tribF\)-mesurable telle que
\begin{equation}
    \int_BE(X|\tribF)=\int_BX
\end{equation}
pour tout \( X\in \tribF\). Si \( X\in L^2(\Omega,\tribA,P)\) alors \( E(X|\tribF)=\pr_K(X)\) où \( K\) est le sous-ensemble de \( L^2(\Omega,\tribA,P)\) des fonctions \( \tribF\)-mesurables (théorème \ref{ThoMWfDPQ}). Cela au sens des projections orthogonales.

L'espérance conditionnelle d'une variable aléatoire par rapport à une autre est une variation sur le thème :
\begin{equation}
    E(X|Y)=E(X|\sigma(Y)).
\end{equation}

La probabilité conditionnelle d'un événement par rapport à une tribu est la variable aléatoire
\begin{equation}
    P(A|\tribF)=E(\mtu_A|\tribF).
\end{equation}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Fonction de répartition}
%---------------------------------------------------------------------------------------------------------------------------

Si \( X\) est une variable aléatoire réelle, nous définissons sa \defe{fonction de répartition}{fonction!de répartition} par
\begin{equation}
    \begin{aligned}
        F_X\colon \eR&\to \mathopen[ 0 , 1 \mathclose] \\
        F_X(x)&=P(X\leq x). 
    \end{aligned}
\end{equation}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Fonction caractéristique}
%---------------------------------------------------------------------------------------------------------------------------

La \defe{fonction caractéristique}{fonction!caractéristique!d'une variable aléatoire} de la variable aléatoire \( X\colon \Omega\to \eR\) est la fonction réelle définie par
\begin{equation}
    \Phi_X(t)=E( e^{itX}).
\end{equation}
Une autre façon d'écrire la définition est
\begin{equation}
    \Phi_X(t)=\int_{\eR} e^{itX}dP_X(x),
\end{equation}
ou encore, si \( X\) a une densité \( f_X\),
\begin{equation}        \label{EqFnCaractfncadens}
    \Phi_X(t)=\int_{\eR} e^{itx}f_X(x)dx
\end{equation}
Nous reconnaissons la transformée de Fourier :
\begin{equation}
    \Phi_X(t)=\hat f_X(-t/2\pi).
\end{equation}

La proposition suivante se déduit en utilisant le théorème de dérivation sous l'intégrale \ref{ThoDerSousIntegrale}.
\begin{proposition}     \label{PropDerFnCaract}
    Soit $X$ une variable aléatoire qui accepte un moment d'ordre \( r\geq 1\). Alors la fonction caractéristique \( \Phi_X\) est \( r\) fois continument dérivable et
    \begin{equation}
        \Phi_X^{(r)}(t)=E\big( (iX)^r e^{itX} \big).
    \end{equation}
\end{proposition}
\index{transformée!de Fourier}

\begin{proof}
    Nous étudions la fonction
    \begin{equation}
        \Phi(t)=\int_{\Omega} e^{itX(\omega)}dP(\omega).
    \end{equation}
    Nous considérons la fonction
    \begin{equation}
        \begin{aligned}
            f\colon \eR\times\Omega&\to \eR \\
            (t,\omega)&\mapsto  e^{itX(\omega)}. 
        \end{aligned}
    \end{equation}
    et nous regardons si ce contexte vérifie les hypothèses du théorème \ref{ThoDerSousIntegrale}.
    \begin{enumerate}
        \item
            Étant donné que \( X\) est mesurable, \( f\) sera mesurable.
        \item
            La fonction \( t\mapsto e^{itX(\omega)}\) est absolument continue pour chaque \( \omega\).
        \item
            Note : par rapport aux notations du théorème \ref{ThoDerSousIntegrale}, nous avons ici \( A=\eR\). Prenons donc un intervalle (compact) \( \mathopen[ a , b \mathclose]\subset\eR\) et calculons
            \begin{equation}        \label{EqfpfpttoiXieitXo}
                \frac{ \partial f }{ \partial t }(t,\omega)=iX(\omega) e^{itX},
            \end{equation}
            et
            \begin{equation}
                \int_a^b\int_{\Omega}\left| iX(\omega) e^{itX(\omega)} \right| d\omega\,dt=\int_a^b\int_{\Omega}| X(\omega) |d\omega\,dt.
            \end{equation}
            Par hypothèse \( X\) accepte un moment d'ordre \( 1\), de sorte que l'intégrale par rapport à \( \omega\) converge vers un nombre qui ne dépend pas de \( t\). L'intégrale sur \( t\) ne pose alors aucun problèmes.
    \end{enumerate}
    Par conséquent nous pouvons effectuer la première dérivation :
    \begin{equation}
        \Phi'(t)=\frac{ d\Phi }{ dt }(t)=\int_{\Omega}iX(\omega) e^{itX(\omega)}d\omega=E(iX e^{itX})
    \end{equation}
    et la fonction \( \Phi'\) est absolument continue. Ce dernier point est important parce que c'est lui qui permet de faire la récurrence et passer à l'ordre deux.

    Le résultat ressort alors en dérivant successivement l'expression \eqref{EqfpfpttoiXieitXo}.
\end{proof}

\begin{example}
    Sachant la fonction caractéristique de \( X\), nous pouvons calculer les moments. Par exemple
    \begin{equation}
        E(X^2)=\Phi''_X(0).
    \end{equation}
\end{example}

\begin{theorem}     \label{ThonMxtTy}
    Si \( \Phi_X=\Phi_Y\), alors \( P_X=P_Y\).
\end{theorem}
%TODO : trouver une preuve.
Notons que cela n'implique pas que \( X=Y\). En effet \( X\) et \( Y\) peuvent même être définis sur des espaces probabilisés différents.

Dans le cas d'une variable aléatoire vectorielle, nous définissons \( \Phi_X\colon \eR^d\to \eR\) par
\begin{equation}        \label{EqydvDxg}
    \Phi_X(v)=E\big(  e^{i\langle v, X\rangle } \big)
\end{equation}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Fonction génératrice des moments, transformée de Laplace}
%---------------------------------------------------------------------------------------------------------------------------

Soit \( X\) une variable aléatoire. Sa \defe{transformée de Laplace}{transformée!Laplace} ou \defe{fonction génératrice des moments}{moment!fonction génératrice} est la fonction
\begin{equation}
    M_X(t)=E( e^{tX})
\end{equation}
pour chaque \( t\) tel que cette espérance existe.

\begin{theorem}[\cite{LetacGen}]
    Soit \( X\) une variable aléatoire réelle et
    \begin{equation}
        I_X=\{ t\in \eR\tq \text{ $E( e^{tX})$ existe}\}.
    \end{equation}
    La fonction
    \begin{equation}
        \begin{aligned}
            M_X\colon I_X&\to \eR \\
            t&\mapsto E( e^{tX}) 
        \end{aligned}
    \end{equation}
    est la \defe{transformée de Laplace}{transformée!Laplace}\index{Laplace!transformée} de \( X\). 
    \begin{enumerate}
        \item
            \( I_X\) est un intervalle contenant \( 0\).
        \item
            Si \( I_X\) n'est pas réduit à \( \{ 0 \}\) alors \( M_X\) se développe en série entière
            \begin{equation}
                M_X(t)=\sum_{n=0}^{\infty}\frac{ E(X^n) }{ n! }t^n.
            \end{equation}
        \item
            Si \( X\) et \( Y\) sont des variables aléatoires indépendantes, alors \( I_{X+Y}=I_X\cap I_Y\) et 
            \begin{equation}
                M_{X+Y}=M_XM_Y
            \end{equation}
            sur \( I_{X+Y}\).
    \end{enumerate}
\end{theorem}
\index{transformée!Laplace}

\begin{proof}
    Le fait que \( 0\) soit dans \( I_X\) est évident : \( E(1)=1\). Pour montrer que \( I_X\) est un intervalle nous prenons \( z\in I_X\) et \( 0<s<z\) ou \( z<s<0\), puis nous montrons que \( s\in I_X\). Il faut remarquer que dans tous les cas,
    \begin{equation}
        e^{sX}\leq 1+ e^{zX}.
    \end{equation}
    En effet soit \( sX\) et \( zX\) sont tous deux à gauche de zéro et alors ils sont tous deux plus petit que \( 1\); soit ils sont tous deux à droite de \( 0\) et alors \( e^{zX}> e^{sX}\) par croissance de l'exponentielle. Nous avons donc dans tous les cas que
    \begin{equation}
        E( e^{sX})=\int_{\eR}f_X(x) e^{sX}dx\leq \int_{\eR}f_X(x)(1+ e^{zx})=1+E( e^{zX}).
    \end{equation}
    
    Soit maintenant \( a>0\) tel que \( \mathopen[ -a , a \mathclose]\in I_X\). Étant donné que \(  e^{a| X |}< e^{aX} e^{-aX}\), l'espérance \( E( e^{a| X |})\) existe toujours pour \( | t |\). Nous avons
    \begin{subequations}
        \begin{align}
            \left| M_X(t)-\sum_{n=0}^N\frac{ E(X^n) }{ n! }t^n \right| &=\left| E\Big(  e^{tX}-\sum_{n=0}^N\frac{ X^n }{ n! }t^n \Big) \right| \\
            &=\left| E\Big( \sum_{n=N+1}^{\infty}\frac{ X^n }{ n! }t^n \Big) \right| \\
            &\leq E\left( \sum_{n=N+1}^{\infty}\frac{ | tX |^n }{ n! } \right).
        \end{align}
    \end{subequations}
    Maintenant le but est de prendre la limite \( N\to\infty\) en inversant la limite et l'espérance par le théorème de la convergence dominée (\ref{ThoConvDomLebVdhsTf}). L'intégrale à traiter est
    \begin{equation}
        \lim_{N\to \infty} \int_{\Omega}\sum_{n=N+1}^{\infty}\frac{ | tX(\omega) |^n }{ n! }dP(\omega).
    \end{equation}
    L'intégrante est uniformément borné (en \( N\)) par \(  e^{tX(\omega)}\), qui est intégrable par hypothèse (choix de \( t\)). Du coup
    \begin{equation}
        \lim_{N\to \infty} \int_{\Omega}\sum_{n=N+1}^{\infty}\frac{ | tX(\omega) |^n }{ n! }dP(\omega)=E\left( \lim_{N\to \infty} \sum_{n=N+1}^{\infty}\frac{ | tX |^n }{ n! } \right)=0.
    \end{equation}
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Loi d'une variable aléatoire}
%---------------------------------------------------------------------------------------------------------------------------

La \defe{loi}{loi d'une variable aléatoire} de la variable aléatoire \( X\), notée \( P_X\) est la mesure image de \( P\) par \( X\), c'est à dire
\begin{equation}
    P_X(B)=P(X\in B)
\end{equation}
pour tout borélien \( B\subset\eR^d\). Note :
\begin{equation}
    P(X\in B)=P\big( \{ \omega\in\Omega\tq X(\omega)\in B \} \big)=P\big( X^{-1}(B) \big).
\end{equation}
En particulier \( P_X\) est une mesure de probabilité sur \( \eR^d\) parce que 
\begin{equation}
    P_X(\eR^d)=P(\Omega)=1.
\end{equation}
Si \( Q\) est une mesure de probabilité sur \( \eR^d\), nous notons \( X\sim Q\) si \( P_X=Q\). Nous disons alors que «\( X\) suit la loi \( Q\)».

La proposition suivante permet de calculer en pratique les intégrales qui définissent par exemple l'espérance mathématique d'une variable aléatoire.
\begin{proposition}[Théorème de transfert]\index{théorème!transfert}     \label{PropintdPintdPXeR}
    Si \( X\) est une variable aléatoire, alors
    \begin{equation}
        E(f\circ X)=\int_{\Omega}f\big( X(\omega) \big)dP(\omega)=\int_{\eR^d}f(x)dP_X(x)
    \end{equation}
    dès que \( f\colon \eR^d\to \bar\eR\) est telle qu'une des deux intégrales existe. En particulier, ça marche si \( f\) est borélienne.
\end{proposition}
% TODO : donner une preuve de ce théorème.
Je crois qu'il y a une preuve de ce théorème dans \cite{ThjoTrnSaada}.


En utilisant cette proposition nous trouvons une formule pratique pour l'espérance d'une variable aléatoire réelle:
\begin{equation}
    E(X)=\int_{\Omega}X(\omega)dP(\omega)=\int_{\eR}xdP_X(x),
\end{equation}
en vertu de la proposition \ref{PropintdPintdPXeR} appliquée à la fonction \( f(x)=x\).

\begin{proposition}
    Une variable aléatoire réelle \( X\) est intégrable si et seulement si \( P(x=\pm\infty)=0\) et
    \begin{equation}
        \int_{\eR}| x |dP_X(x)<\infty.
    \end{equation}
\end{proposition}

Le lien entre la densité \( f_X\) de la variable aléatoire \( X\) et sa loi est
\begin{equation}
    P_X(A)=\int_Af_X(x)dx
\end{equation}
pour tout ensemble mesurable \( A\subset\eR\). Le lien entre la mesure de Lebesgue et celle de la loi de \( X\) est alors donné par
\begin{equation}
    dP_X(x)=f_X(x)dx.
\end{equation}
En particulier l'espérance de \( X\) peut être calculée à partir de sa densité via la formule
\begin{equation}        \label{EqEspDensform}
    E(X)=\int_{\eR}xdP_X(x)=\int_{\eR}x f_X(x)dx.
\end{equation}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Changement de variables}
%---------------------------------------------------------------------------------------------------------------------------

\begin{theorem}
    Soit \( \mO\), un ouvert de \( \eR^n\) et \( \mO'\) un ouvert de \( \eR^m\) ainsi qu'un difféomorphisme \( C^1\) \( \varphi\colon \mO\to \mO'\). Soit \( X\colon \Omega\to \eR^n\) une variable aléatoire prenant presque surement ses valeurs dans \( \mO\). Si nous supposons que \( X\) a la densité \( f_X\), alors la variable aléatoire \( Y=\varphi(X)\) accepte la densité \( f_Y\colon \mO'\to \eR\) donnée par
    \begin{equation}
        f_Y(v)=f_X\big( \varphi^{-1}(v) \big)| J_{\varphi^{-1}}(v) |.
    \end{equation}
\end{theorem}

\begin{proof}
    Nous devons vérifier la relation 
    \begin{equation}
        P(Y\in B)=\int_Bf_Y(v)dv
    \end{equation}
    pour tout borélien \( B\subset \mO'\). Nous avons
    \begin{subequations}
        \begin{align}
            P(Y\in B)&=\int_{\eR^m}\mtu_{B}(v)dP_Y(v)\\
            &=E(\mtu_B\circ Y)\\
            &=E\big( (\mtu_B\circ \varphi)\circ X\big)\\
            &=\int_{\eR^n}(\mtu_B\circ\varphi)(u)dP_X(u)\\
            &=\int_{\eR^n}(\mtu_B \circ\varphi)(u)f_X(u)du.
        \end{align}
    \end{subequations}
    À ce niveau, nous utilisons la formule de changement de variables du théorème \ref{ThomFeRCi}. Nous trouvons alors
    \begin{equation}
        P(Y\in B)=\int_{\eR^m}\mtu_B\big( \varphi^{-1}(v) \big)f_X\big( \varphi^{-1}(v) \big)| J_{\varphi^{-1}}(v) |dv.
    \end{equation}
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Événements}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{lemma}       \label{LemEXYEXEYindep}\label{PropVarPropnnlin}
    Si \( X\) est une variable aléatoire,
    \begin{enumerate}
        \item
            $\Var(ax)=a^2\Var(X)$ pour tout \( a\in\eR\);
        \item
            Si de plus \( Y\) est une variable aléatoire indépendante de \( X\), alors $\Var(X+Y)=\Var(X)+\Var(Y)$.
    \end{enumerate}
\end{lemma}

\begin{proof}
    Nous avons
    \begin{subequations}
        \begin{align}
            \Var(X+Y)&=E(X^2+Y^2+2XY)-\big( E(X)+E(Y) \big)^2\\
            &=E(X^2)+E(Y^2)+2E(XY)-E(X)^2-E(Y)^2E(X)E(Y).
        \end{align}
    \end{subequations}
    Étant donné que \( X\) et \( Y\) sont indépendantes nous avons \( E(XY)=E(X)E(Y)\).
\end{proof}


Si les \( X_1,\ldots,X_n\) sont des variables aléatoires on considère la \defe{moyenne empirique}{moyenne!empirique}
\begin{equation}
    \bar X_n=\frac{ X_1+\ldots+X_n }{ n }.
\end{equation}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Convergence}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Soient \( X_i\) des variables aléatoires réelles définies sur le même espace de probabilité \( (\Omega,\tribA,P)\). Nous disons que \( X_i\) converge \defe{presque surement}{convergence!presque surement} vers la variable aléatoire \( X\) et nous notons 
\begin{equation}
    X_n\stackrel{p.s.}{\longrightarrow}X
\end{equation}
si
\begin{equation}
    P\big( \{ \omega\in\Omega\tq\,X_n(\omega)\to X(\omega) \} \big)=1
\end{equation}
où la convergence \( X_n(\omega)\to X(\omega)\) est la convergence usuelle dans \( \eR\).

\begin{lemma}
    Nous avons \( X_n\stackrel{p.s.}{\longrightarrow}X\) si et seulement si il existe un événement \( A\in\tribA\) tel que \( P(A)=1\) et tel que \( X_n(\omega)\to X(\omega)\) pour tout \( \omega\in A\).
\end{lemma}

Nous disons que les variables aléatoires réelles \( X_n\) convergent \defe{en probabilité}{convergence!en probabilité} vers la variable aléatoire \( X\) si pour tout \( \eta>0\), on a
\begin{equation}
    P\big( | X_n-X |\geq \eta \big)\to 0,
\end{equation}
et on note
\begin{equation}
    X_n\stackrel{P}{\longrightarrow}X.
\end{equation}

Nous disons que \( X_n\) converge vers \( X\) \defe{en loi}{convergence!en loi} vers la variable aléatoire \( X\) et nous notons
\begin{equation}
    X_n\stackrel{\hL}{\longrightarrow}X
\end{equation}
si pour toute fonction continue et bornée \( g\) nous avons
\begin{equation}
    E\big( g(X_n) \big)\to E\big( g(X) \big)=\int gdP_X.
\end{equation}


\begin{proposition}     \label{PrpopCaractCvL}
    Deux autres caractérisations de la convergence en loi.
    \begin{enumerate}
        \item
            Nous avons \( X_n\stackrel{\hL}{\longrightarrow}X\) si et seulement si
            \begin{equation}
                \Phi_{X_n}(v)\to\Phi_X(v)
            \end{equation}
            pour tout \( v\in\eR^d\). Ici \( \Phi_X\) est la fonction caractéristique de \( X\).
        \item
            Dans la définition de la convergence en loi nous pouvons indifféremment utiliser les fonctions continues et bornées, les fonctions continues à support compact ou les fonctions bornées uniformément continues.
    \end{enumerate}
\end{proposition}

\begin{proposition}
    La convergence presque sure entraine à la fois la convergence en probabilité et celle en loi. La convergence en probabilité entraine la convergence en loi.
\end{proposition}
La convergence en loi n'implique pas la convergence en probabilité, et par conséquent pas non plus la convergence presque certaine.

Dans le cas particulier \( d=1\) nous avons quelque critères supplémentaires. 

\begin{proposition}     \label{PropoFnrepCvL}
    Supposons que les variables aléatoires \( X_n\) soient réelles, et notons \( F_n\) la fonction de répartition de \( X_n\). Si \( F_n(x)\to F(x)\) pour tout \( x\) dans l'ensemble des points de continuité de \( F\), alors \( X_n\stackrel{\hL}{\longrightarrow}X\).
\end{proposition}

\begin{proposition}
    Si les \( X_n\) sont des variables aléatoires réelles positives, et si \( X\) est une variable aléatoire positive, alors \( X_n\stackrel{\hL}{\longrightarrow}X\) si les transformées de Laplace des fonctions de répartition convergent ponctuellement, c'est à dire si
    \begin{equation}
        E\big(  e^{-\alpha X_n} \big)\to E\big(  e^{-\alpha X} \big)
    \end{equation}
    pour tout \( \alpha\geq 0\).
\end{proposition}

\begin{proposition}
    Si les \( X_n\) et \( X\) sont des variables aléatoires réelles discrètes à valeurs dans \( \{ x_0,x_1,\ldots \}\) alors \( X_n\stackrel{\hL}{\longrightarrow} X\) si et seulement si
    \begin{equation}
        P(X_n=x_k)\to P(X=x_k)
    \end{equation}
    pour tout \( k\in\eN\).
\end{proposition}

\begin{proposition}[\cite{CourgGudRennes}]     \label{PropXncvXFXcvFxt}
    Soient \( X_n\) et \( X\) des variables aléatoires réelles. Nous avons
    \begin{equation}
        X_n\stackrel{\hL}{\longrightarrow}X
    \end{equation}
    si et seulement si pour tout \( t\) où \( F_X\) est continue,
    \begin{equation}
        \lim_{n\to \infty} F_{X_n}(t)=F_X(t).
    \end{equation}
\end{proposition}

\begin{proposition}[\cite{CourgGudRennes}]     \label{PropCvLfcvPsicst}
    Soit \( X_n\) une suite de variables aléatoires \( \Omega\to \eR^d\) et \( a\in\eR^d\). Si \( X_n\stackrel{\hL}{\longrightarrow}a\), alors
    \begin{equation}
        X_n\stackrel{P}{\longrightarrow}a.
    \end{equation}
\end{proposition}

\begin{proof}
    Quitte à passer aux composantes, nous pouvons supposer que \( d=1\). Nous avons
    \begin{subequations}
        \begin{align}
           P\big( | X_n-a |>\eta \big)&=P(X_n-a>\eta)+P(-X_n-a>\eta)\\
           &=P(X_n>\eta+a)+1-P(X_n>a-\eta)  \label{EqPXngeqetaapumP}\\
           &=1-F_{X_n}(\eta+a)+F_{X_n}(a-\eta).
        \end{align}
    \end{subequations}
    Nous allons utiliser la proposition \ref{PropXncvXFXcvFxt}. La fonction de répartition de la variable aléatoire constante \( X=a\) est donnée par
    \begin{equation}
        F_a(t)=P(a<t)=\caract{\eR^+}(t-a).
    \end{equation}
    Par conséquent, la convergence en loi \( X_n\stackrel{\hL}{\longrightarrow}a\) nous montre que
    \begin{equation}
        F_{X_n}(t)\to \caract_{\eR^+}(t-a)
    \end{equation}
    pour tout \( t\neq a\) parce que \( t=0\) est un point de discontinuité de \( \caract_{\eR^+}\). Nous avons par conséquent
    \begin{equation}
        P\big( | X_n-a |>\eta \big)=1-\caract_{\eR^+}(\eta)+\caract_{\eR^+}(-\eta)=0
    \end{equation}
    parce que \( \eta>0\).
\end{proof}

% TpijUi
\begin{probleme}
    Dans \cite{CourgGudRennes}, l'équation \eqref{EqPXngeqetaapumP} arrive avec une inégalité. Pourquoi ?
\end{probleme}

\begin{lemma}[Slutsky]\index{lemme!de Slutsky}  \label{LemgXDlhs}
    Soient \( X_n\) et \( Y_n\) des suites de variables aléatoires réelles telles que
    \begin{equation}
        \begin{aligned}[]
            X_n&\stackrel{\hL}{\longrightarrow} X\\
            Y_n&\stackrel{P}{\longrightarrow}a\in\eR.
        \end{aligned}
    \end{equation}
    Alors \( (X_n,Y_n)\stackrel{\hL}{\longrightarrow}(X,a)\).
\end{lemma}

\begin{proof}
    La preuve qui suit provient de \cite{MPSmaitrise}. Étant donné que \( Y_n\stackrel{\hL}{\longrightarrow} a\), nous avons \( Y_n\stackrel{P}{\longrightarrow} a\) par la proposition \ref{PropCvLfcvPsicst}. Soit une fonction \(f\colon \eR^2\to \eR^2 \); nous devons prouver que
    \begin{equation}
        E\big( f(X_n,Y_n) \big)\to E\big( f(X,a) \big).
    \end{equation}
    Soit \( \epsilon>0\). Nous avons
    \begin{equation}    \label{EqEparXnYnfXa}
        E\big( \| f(X_n,Y_n)-f(X,a) \| \big)\leq E\big(  \| f(X_n,Y_n)-f(X_n,a) \|  \big)+E\big(   \| f(X_n,a)-f(X,a) \|  \big).
    \end{equation}
    La fonction\( g(t)=f(t,a)\) étant continue et bornée, la convergence en loi \( X_n\stackrel{\hL}{\longrightarrow}X\) donne
    \begin{equation}
        E\big( \| f(X_n,a)-f(X,a) \| \big)\to 0.
    \end{equation}
    Étudions à présent le premier terme du membre de droite de \eqref{EqEparXnYnfXa}. Pour tout \( \eta> 0\) et toute variables aléatoires \( Z\) et \( Z'\) nous avons
    \begin{equation}
        E(Z)=E(Z\caract_{| Z' |<\eta})+E(Z\caract_{| Z' |\geq \eta}).
    \end{equation}
    Nous décomposons donc le premier terme de \eqref{EqEparXnYnfXa} en
    \begin{equation}    \label{EqEXnADecomsecvolta}
        \begin{aligned}[]
            E\big( \| f(X_n,Y_n)-f(X_n,a) \| \big)&=E\big( \| f(X_n,Y_n)-f(X_n,a) \|\caract_{| Y_n-a |<\eta} \big)\\
            &\quad+E\big( \| f(X_n,Y_n)-f(X_n,a) \|\caract_{| Y_n-a |\geq\eta} \big).
        \end{aligned}
    \end{equation}
    Choisissons maintenant une valeur de \( \eta\) telle que
    \begin{equation}
        | (x,y)-(x',y') |<\eta\Rightarrow| f(x,y)-f(x',y') |\leq \epsilon.
    \end{equation}
    Un tel \( \eta\) existe par l'uniforme continuité de \( f\). Dans le premier terme, \( | Y_n-a |<\eta\), par conséquent
    \begin{equation}
        \| (X_n,Y_n)-(X_n,a) \|=| Y_n-a |<\eta
    \end{equation}
    et donc
    \begin{equation}
        \| f(X_n,Y_n)-f(X_n,a) \|\leq \epsilon.
    \end{equation}
    Le premier terme devient donc
    \begin{equation}
        E\big( \| f(X_n,Y_n)-f(X_n,a) \|\caract_{| Y_n-a |<\eta} \big)\leq \epsilon E(\caract_{| Y_n-a |<\eta})\leq \epsilon
    \end{equation}
    parce que \( E(\caract_A)=P(A)\leq 1\). Pour le second terme de \eqref{EqEXnADecomsecvolta} nous effectuons la majoration
    \begin{equation}
        \| f(X_n,Y_n)-f(X_n,a) \|\leq 2\| f \|_{\infty}
    \end{equation}
    tandis que la convergence \( Y_n\stackrel{P}{\longrightarrow} a\) entraine 
    \begin{equation}
        P\big( | Y_n-a |\geq \eta \big).
    \end{equation}
\end{proof}

\begin{proposition}     \label{PropcvLsousfonc}
    Soient \( X_n\) des variables aléatoires telles que
    \begin{equation}
        X_n\stackrel{\hL}{\longrightarrow} X
    \end{equation}
    et \( h\), une fonction mesurable sur l'espace d'arrivée de \( X_n\). Soit \( C\) l'ensemble des points de continuité de \( h\). Alors si \( P(X\in C)=1\), nous avons 
    \begin{equation}
        h(X_n)\stackrel{\hL}{\longrightarrow}h(X).
    \end{equation}
\end{proposition}
Une démonstration a l'air d'être donnée sur \wikipedia{en}{Continuous_mapping_theorem}{wikipédia}.

Une conséquence de cette proposition couplée au lemme de Slutsky est le résultats suivant, qui est donné sous le nom de \wikipedia{en}{Slutsky's_theorem}{théorème de Slutsky} sur wikipédia.
\begin{corollary}       \label{CorINgTPH}
    En reprenant les notations du lemme de Slutsky, si
    \begin{subequations}
        \begin{align}
            X_n&\stackrel{\hL}{\longrightarrow} X\\
            Y_n&\stackrel{P}{\longrightarrow} a,
        \end{align}
    \end{subequations}
    alors
    \begin{subequations}
        \begin{align}
            X_n+Y_n&\stackrel{\hL}{\longrightarrow}X+a\\
            X_nY_n&\stackrel{\hL}{\longrightarrow}aX\\
            Y_n^{-1}X_n&\stackrel{\hL}{\longrightarrow}a^{-1}X\\
        \end{align}
    \end{subequations}
    pourvu que \( a\) soit inversible.
\end{corollary}


\begin{lemma}[Borel-Cantelli]\index{lemme!de Borel-Cantelli}
    Soit \( (A_n)\) une suite d'événements (avec \( A_n\in\tribA\) pour tout \( n\)).
    \begin{enumerate}
        \item
            Si \( \sum_{n=0}^{\infty}P(A_n)\) converge, alors
            \begin{equation}
                P(A_n\,\text{i.s.})=0.
            \end{equation}
        \item
            Si la somme \( \sum_nP(A_n)\) diverge, et si de plus les \( A_i\) sont indépendants, alors
            \begin{equation}
                P(A_n\,\text{i.s.})=1.
            \end{equation}
    \end{enumerate}
\end{lemma}
La notation \( P(A_n\,\text{i.s.})\) signifie «infiniment souvent», c'est à dire
\begin{equation}
    P(A_n\,\text{i.s.})=P\big( \bigcap_{N\in\eN}\bigcup_{k\geq N}A_k \big)=P(\limsup A_n)
\end{equation}

Une façon de paraphraser le lemme de Borel-Cantelli est que nous avons l'alternative
\begin{equation}    \label{EqparaphrCantelli}
    P(\limsup A_n)=\begin{cases}
        0    &   \text{si $\sum_{n\geq 0}P(A_n)<\infty$}\\
        1    &    \text{sinon}.
    \end{cases}
\end{equation}

\begin{proposition}
    Soit \( X_n\), une suite de variables aléatoires et \( X\) une variable aléatoires. Si
    \begin{equation}
        \sum_nP\big( \| X_n-X \|>\eta \big)<\infty
    \end{equation}
    pour tout \( \epsilon\), alors \( X_n\stackrel{p.s.}{\longrightarrow}X\).
\end{proposition}

\begin{proof}
    Fixons \( \epsilon\) et considérons les événements \( A_{n}=\| X_n-X \|>\epsilon\). L'hypothèse dit que
    \begin{equation}
        \sum_nP(A_{n,\epsilon})<\infty
    \end{equation}
    et le lemme de Borel-Cantelli implique que
    \begin{equation}
        P(\limsup\| X_n-X \|>\epsilon)=0.
    \end{equation}
    Un élément \( \omega\) est dans \( \limsup A_n\) si il est contenu dans tous les \( A_n\), par conséquent, pour chaque \( \epsilon\) nous avons l'inclusion
    \begin{equation}
        \{ \omega\in\Omega\tq X_n(\omega)\to X(\omega) \}\subset\complement\limsup A_n.
    \end{equation}
    Nous pouvons aller plus loin et écrire
    \begin{equation}        \label{EqProbomOmXnmXforalleps}
        \{ \omega\in\Omega\tq X_n(\omega)\to X(\omega) \}=\complement\{ \omega\in\Omega\tq \| X_n-X \|>\epsilon,\forall\epsilon>0 \}.
    \end{equation}
    Or la probabilité de l'ensemble
    \begin{equation}
        \{ \omega\in\Omega\tq\| X_n-X \|>\epsilon \}
    \end{equation}
    est \( 0\) pour chaque \( \epsilon\), et par conséquent la probabilité du membre de droite de \eqref{EqProbomOmXnmXforalleps} est \( 1\).
\end{proof}

\begin{example}
    Considérons une suite de \( 0\) et de \( 1\) dans laquelle le \( 1\) arrive avec une probabilité \( p\) et le \( 0\) avec une probabilité \( 1-p\). Une telle suite est modélisée par une suite de variables aléatoires de Bernoulli \( (X_n)_{n\in\eN}\) indépendantes de paramètre \( p\).

    Question : une telle suite contient elle une infinité de \( 1\) ? Considérons les événements indépendants \( A_n=\{ X_n=1 \}\). Nous avons
    \begin{equation}
        \sum_n P(A_n)=\sum_nP(X_n=1)=\sum_np=\infty.
    \end{equation}
    Par Borel-Cantelli et son expression \eqref{EqparaphrCantelli}, nous avons alors
    \begin{equation}
        P(\limsup A_n)=1.
    \end{equation}
    Donc une infinité d'événements \( A_n\) se produisent, et nous avons bien une infinité de \( 1\) dans la suite.

    Remarque : dans ce raisonnement nous pouvons considérer une probabilité non constante \( p_n\) tant que la série \( \sum_np_n\) diverge.
\end{example}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Loi des grands nombres, théorème central limite}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Loi des grands nombres}
%---------------------------------------------------------------------------------------------------------------------------

\begin{lemma}[Inégalité de Markov]\index{Markov (inégalité)}
    Soit une variable aléatoire \( X\in L^p\) et \( \epsilon>0\). Nous avons
    \begin{equation}
        P(| X |\geq \epsilon)\leq \frac{1}{ \epsilon^r }E(| X |^r).
    \end{equation}
\end{lemma}

\begin{proof}
    Nous avons
    \begin{equation}
        E(| X |^r)\geq\int_{| X |\geq \epsilon}X(\omega)dP(\omega)\geq \epsilon^r\int_{| X |\geq\epsilon}dP=\epsilon^rP(| Y |\geq\epsilon).
    \end{equation}
\end{proof}

\begin{theorem}[Loi forte des grands nombres]\index{loi!des grands nombres (forte)}     \label{ThoefQyKZ}
    Soit \( (X_n)\) une suite de variables aléatoires réelles
    \begin{enumerate}
        \item
            indépendantes et identiquement distribuées,
        \item
            intégrables (c'est à dire dans \( L^1\)),
    \end{enumerate}
    alors
    \begin{equation}
        \frac{1}{ n }\sum_{i=1}^nX_i  \stackrel{p.s.}{\longrightarrow} E(X_1).
    \end{equation}
\end{theorem}
Note : étant donné que les variables aléatoires sont identiquement distribuées, nous avons évidemment \( E(X_1)=E(X_2)=\ldots\)

\begin{probleme}
    Est-ce que les variables aléatoires doivent vraiment être réelles ?
\end{probleme}

\begin{corollary}
    Si les variables aléatoires réelles \( X_n\) sont
    \begin{enumerate}
        \item
            indépendantes et identiquement distribuées,
        \item
            dans \( L^2\)
    \end{enumerate}
    alors
    \begin{equation}
        \bar X_n\stackrel{P}{\longrightarrow}E(X_1).
    \end{equation}
\end{corollary}

\begin{proof}
    Nous voulons prouver que pour tout \( \eta>0\),
    \begin{equation}
        P\big( | \bar X_n-E(X_1) |>\eta \big)\to 0.
    \end{equation}
    Remarquons d'abord que les variables aléatoires \( X_n\) étant identiquement distribuées, \( E(\bar X_n)=E(X_1)\) parce que \( E(X_i)=E(X_1)\) pour tout \( i\). L'inégalité de Markov avec \( r=2\) nous donne
    \begin{equation}
        P\big( | \bar X_n-E(\bar X_n) |>\eta \big)\leq\frac{1}{ \eta^2 }E\big( | \bar X_n-E(\bar X_n) |^2 \big)
    \end{equation}
    où nous reconnaissons \( E\big( | \bar X_n-E(\bar X_n) |^2 \big)=\Var(\bar X_n)\). Par la proposition \ref{LemEXYEXEYindep} nous avons \( \Var(\bar X_n)=\Var(X_1)/n\) et par conséquent
    \begin{equation}
        P\big( | \bar X_n-E(\bar X_n) |>\frac{1}{ n\eta^2 }\Var(X_1),
    \end{equation}
    qui tend vers zéro lorsque \( n\to\infty\).
\end{proof}

\begin{proposition}
    Soient \( X_n\) des variables aléatoires indépendantes et identiquement distribuées avec \( X_n\geq 0\). Nous acceptons \( E(X_1)=\infty\), c'est à dire que nous relaxons la condition \( X_n\in L^1\) par rapport à la loi des grands nombres.

    Alors
    \begin{equation}
        \bar X_n\stackrel{p.s.}{\longrightarrow} E(X_1)\in\mathopen[ 0 , \infty \mathclose].
    \end{equation}
\end{proposition}

\begin{proof}
    Si \( E(X_1)<\infty\), nous sommes dans le cas de la loi des grands nombres. Pour chaque \( N\in\eN\) nous considérons la suite de variables aléatoires
    \begin{equation}
        X_n^{(N)}=\min(X_n,N).
    \end{equation}
    Nous avons évidement \( \bar X^{(N)}_n\leq \bar X_n\). Les variables aléatoires \( X^{(N)}_n\) étant bornées par \( N\), elles vérifient la loi des grands nombres pour chaque \( N\) séparément. Par conséquent nous avons pour chaque \( N\) la limite
    \begin{equation}        \label{EqbarXNbtoXnubus}
        \bar X^{(N)}_n\to E(X^{(N)}_1)
    \end{equation}
    Nous supposons que \( E(X_1)=\infty\), par conséquent  \( \lim_{N\to\infty}E(X_1^{(N)})=\infty\). Soit \( \eta>0\) et choisissons \( N\) de telle manière à avoir
    \begin{equation}
        E(X_1^{(N)})>\eta+1.
    \end{equation}
    La limite \eqref{EqbarXNbtoXnubus} nous permet de trouver \( n_0\) tel que pour tout \( n>n_0\) nous ayons \( \bar X^{(N)}_n>\eta\). Au final,
    \begin{equation}
        \eta<\bar X^{(N)}_n\leq \bar X_n,
    \end{equation}
    ce qui montre que \( \bar X_n\to\infty\).
\end{proof}

\begin{example}
    La loi des grands nombres justifie la pratique courante d'approximer une grandeur physique par la moyenne empirique d'un grand nombre de mesures.
\end{example}

\begin{example}
    Citons ici le dernier paragraphe de \emph{Le mystère de Marie Roget} par Edgar Allan Poe, traduit par Charles Baudelaire\footnote{Disponible sur \url{https://fr.wikisource.org/wiki/Le_Mystère_de_Marie_Roget}}.

    \begin{quote}
Rien, par exemple, n’est plus difficile que de convaincre le lecteur non spécialiste que, si un joueur de dés a amené les six deux fois coup sur coup, ce fait est une raison suffisante de parier gros que le troisième coup ne ramènera pas les six. Une opinion de ce genre est généralement rejetée tout d’abord par l’intelligence. On ne comprend pas comment les deux coups déjà joués, et qui sont maintenant complètement enfouis dans le Passé, peuvent avoir de l’influence sur le coup qui n’existe que dans le Futur. La chance pour amener les six semble être précisément ce qu’elle était à n’importe quel moment, c’est-à-dire soumise seulement à l’influence de tous les coups divers que peuvent amener les dés. Et c’est là une réflexion qui semble si parfaitement évidente, que tout effort pour la controverser est plus souvent accueilli par un sourire moqueur que par une condescendance attentive. 
    \end{quote}
    Dans le cours de la nouvelle, Edgar Poe cite et utilise la théorie des probabilités avec une justesse inaccoutumée dans la littérature. Mais dans ce paragraphe final, Poe montre de façon la plus formelle qu'il n'a \emph{rien} compris à la loi des grands nombres.
\end{example}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Marche aléatoire}
%---------------------------------------------------------------------------------------------------------------------------

Nous considérons un mobile qui se déplace sur l'axe \( \eZ\). À chaque pas de temps, nous supposons qu'il va faire un pas à gauche avec une probabilité \( p\) et un pas à droite avec une probabilité \( (1-p)\). Nous nous demandons quel est le mouvement du mobile sur le long terme.

La position \( S_n\) du mobile à l'instant \( n\) est donnée par
\begin{equation}
    S_n=\sum_{i=1}^nX_i
\end{equation}
où \( X_i\) est le pas effectué à l'instant \( i\). Ce sont des variables de Bernoulli indépendantes avec
\begin{equation}
    X_i\stackrel{\hL}{=}p\delta_{-1}+(1-p)\delta_1
\end{equation}
c'est à dire
\begin{subequations}
    \begin{align}
        P(X_i=-1)&=p\\
        P(X_i=1)&=1-p.
    \end{align}
\end{subequations}
Ces variables vérifient les hypothèses de la loi des grands nombres :
\begin{enumerate}
    \item
        elles sont indépendantes et identiquement distribuées,
    \item
        elles sont intégrables.
\end{enumerate}
Pour le second point, le calcul est
\begin{equation}
    \int_{\Omega}| X_i |dP=\int_{\eR}| x |dP_X=\int_{\eR}| x |(p\delta_{-1}+(1-p)\delta_{1})=| 1-p |+| p |=1.
\end{equation}
Nous avons par conséquent
\begin{equation}
    \bar X_n=\frac{1}{ n }\sum_{i=1}^nX_i\stackrel{p.s.}{\longrightarrow} E(X_1)=(1-2p)
\end{equation}
et
\begin{equation}
    \frac{ S_n }{ n }\to(1-2p).
\end{equation}
Si \( p\neq 1/2\) nous pouvons conclure que
\begin{enumerate}
    \item
        si \( p>1/2\), alors \( S_n\stackrel{p.s.}{\longrightarrow}-\infty\)
    \item
        si \( p<1/2\), alors \( S_n\stackrel{p.s.}{\longrightarrow}\infty\).
\end{enumerate}
De plus nous connaissons la vitesse de divergence : elle est linéaire. Le mobile suit essentiellement l'équation
\( p(n)=(1-2p)n\).

\begin{remark}
    Cela ne traite pas le cas \( p=1/2\). Dans ce cas, nous pouvons simplement dire que \( S_n=o(n)\).
\end{remark}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Théorème central limite}
%---------------------------------------------------------------------------------------------------------------------------

\begin{lemma}       \label{Lemexpznznsurnton}
    Soit \( z_n\to z\) une suite convergente dans \( \eC\). Alors
    \begin{equation}
        \left( 1+\frac{ z_n }{ n } \right)^n\to e^z.
    \end{equation}
\end{lemma}

\begin{theorem}     \label{ThoOWodAi}
    Si les variables aléatoires \( X_n\) sont
    \begin{enumerate}
        \item
            indépendantes et identiquement distribuées de loi parente \( X\),
        \item
            \( X_1\in L^2(\Omega,\tribA)\),
    \end{enumerate}
    alors nous notons \( \bar X_n=\frac{1}{ n }\sum_{i=1}^{n}X_i\), \( m=E(X_1)\) et \( \sigma^2=\Var(X_1)\) et nous avons
    \begin{equation}
        \frac{ \bar X_n-E(X) }{ \sqrt{\Var(X)/n} }=\frac{ \bar X_n-m }{ \sigma/\sqrt{n} }\stackrel{\hL}{\longrightarrow}\dN(0,1).
    \end{equation}
    
\end{theorem}

\begin{proof}
    Nous allons écrire la démonstration dans le cas de variables aléatoires réelles. La proposition \ref{PrpopCaractCvL} dit que la suite \( X_n\) converge en loi vers \( X\) si et seulement si les fonctions caractéristiques convergent ponctuellement. Nous devons donc prouver, pour chaque\footnote{Chuck Norris peut \emph{vraiment} le faire pour \emph{chaque} $t\in\eR$} \( t\in\eR\) que
    \begin{equation}        \label{EqPhitophidNtznu}
        \Phi_{\frac{ S_n-nm }{ \sigma\sqrt{n} }}(t)\to\Phi_{\dN(0,1)}(t).
    \end{equation}
    Supposons dans un premier temps que \( E(X_i)=0\) et \( \sigma(X_i)=1\). Dans ce cas nous considérons la fonction 
    \begin{subequations}
        \begin{align}
            \Phi_{\frac{ S_n }{ \sqrt{n} }}&=E\big(  e^{i\frac{ t }{ \sqrt{n} }\sum_{k=1}^nX_k} \big)\\
            &=\prod_{k=1}^nE\big(  e^{i\frac{ t }{ \sqrt{n} }X_1} \big)\\
            &=\prod_{k=1}^n\Phi_{X_1}\left( \frac{ t }{ \sqrt{n} } \right)\\
            &=\Phi_{X_1}\left( \frac{ t }{ \sqrt{n} } \right)^n.
        \end{align}
    \end{subequations}
    Cette quantité est a priori complexe; nous ne pouvons donc pas immédiatement passer au logarithme. Nous pouvons par contre utiliser un développement en puissances de \( t\) en nous servant de la proposition \ref{PropDerFnCaract} et de l'hypothèse comme quoi \( X_1\in L^2\) :
    \begin{equation}
        \Phi_{X_1}(t)=\Phi_{X_1}(0)+\Phi_{X_1}'(0)t+\Phi_{X_1}''(0)\frac{ t^2 }{2}+\alpha(t)t^2
    \end{equation}
    où \( \alpha\) est une fonction qui a la propriété \( \lim_{x\to 0} \alpha(x)=0\).

    En utilisant les hypothèses et la formule de dérivation de la fonction caractéristique,
    \begin{subequations}
        \begin{align}
            \Phi_{X_1}(0)&=1\\
            \Phi'_{X_1}(0)&=E\big( (iX) \big)=0\\
            \Phi''_{X_1}(0)&=E(-X^2)=-\Var(X_1)=-1.
        \end{align}
    \end{subequations}
    Nous avons donc
    \begin{equation}
        \Phi_{X_1}\left( \frac{ t }{ \sqrt{n} } \right)=\underbrace{1-\frac{ 1 }{2}\frac{ t^2 }{ n }}_{\in\eR}+\underbrace{\frac{ t^2 }{ n }\alpha\left( \frac{ t }{ \sqrt{n} } \right)}_{\in\eC},
    \end{equation}
    de telle sorte que, en considérant une valeur fixée de \( t\),
    \begin{equation}        \label{EqPhifracfacbetanrigh}
        \Phi_{\frac{ S_n }{ \sqrt{n} }}(t)=\left( 1-\frac{ \frac{ t^2 }{ 2 }+\beta_n }{ n } \right)^n
    \end{equation}
    où \( \beta_n=t^2\alpha(t/\sqrt{n})\). Nous avons bien entendu \( \lim_{n\to \infty} \beta_n=0\).
    
    Nous pouvons appliquer le lemme \ref{Lemexpznznsurnton} pour obtenir la limite
    \begin{equation}        \label{EqlimninfySnsqrtntdsnd}
        \lim_{n\to \infty} \Phi_{\frac{ S_n }{ \sqrt{n} }}(t)= e^{-t^2/2}.
    \end{equation}
    La convergence \eqref{EqPhitophidNtznu} est par conséquent prouvée dans le cas où \( E(X_i)=0\) et $\Var(X_i)=1$.

    Considérons maintenant des variables aléatoires avec \( E(X_i)=m\) et \( \Var(X_i)=\sigma^2\). Elles peuvent être écrites sous la forme
    \begin{equation}
        X_i=\sigma X_i+m
    \end{equation}
    où \( X'_i\) est d'espérance nulle et de variance un. Nous avons alors
    \begin{equation}
        S_n=\sigma\sum_{i=1}^nX_i'+nm,
    \end{equation}
    et
    \begin{equation}
        \frac{ S_n-nm }{ \sigma\sqrt{n} }=\frac{ S'_n }{ \sqrt{n} }
    \end{equation}
    où \( S'_n=\sum_iX'_i\). L'étude de la variable aléatoire 
    \begin{equation}
        \frac{ S_n-nm }{ \sigma\sqrt{n} }
    \end{equation}
    revient donc à celle de \( S'_n/\sqrt{n}\) qui vient d'être effectuée.
\end{proof}

\begin{remark}
    Nous pouvons obtenir la limite \eqref{EqlimninfySnsqrtntdsnd} d'une façon alternative. Nous considérons la détermination du logarithme complexe sur \( \eC\setminus\eR^-\); cela est une fonction analytique vérifiant l'équation
    \begin{equation}
        e^{\ln(z)}=z
    \end{equation}
    pour tout \( z\in\eC\setminus\eR^-\) et le développement
    \begin{equation}
        \ln(1+z)=\sum_{n=1}^{\infty}(-1)^{n+1}\frac{ z^n }{ n }.
    \end{equation}
    En particulier, \( \ln(1+z)=z+z\alpha(z)\) où \( \lim_{z\to 0}\alpha(z)=0\). Nous reprenons à l'équation \eqref{EqPhifracfacbetanrigh} en fixant \( t\). Nous avons
    \begin{subequations}
        \begin{align}
            \Phi_{\frac{ S_n }{ \sqrt{n} }}(t)&=\exp\left[ \ln\big(\Phi_{\frac{ S_n }{ \sqrt{n} }}(t)\big) \right]\\
            &=\exp\left[ n\ln\left( 1+\frac{ -\frac{ t^2 }{2}-\beta_n }{ n } \right) \right]\\
            &=\exp\left[ -\frac{ t^2 }{2}-\beta_n+ \big( -\frac{ t^2 }{2}-\beta_n \big)\alpha\left( \frac{ -\frac{ t^2 }{2}-\beta_n }{ n } \right) \right].
        \end{align}
    \end{subequations}
    À la limite \( n\to 0\) nous tombons sur \(  e^{-t^2/2}\).
    
\end{remark}

\begin{remark}
    Étant donné que la variable aléatoire 
    \begin{equation}
        \frac{ S_n-nm }{ \sigma\sqrt{n} }
    \end{equation}
    converge en loi vers \( \dN(0,1)\), nous avons la convergence des fonctions de répartition partout où la fonction de répartition de la normale est continue (donc sur tout \( \eR\)). En particulier,
    \begin{equation}
        \left| P\left( \frac{ S_n-nm }{ \sigma\sqrt{n} }\leq x \right)-\int_{-\infty}^x\frac{1}{ \sqrt{2\pi} } e^{-y^2/2}dy \right| \to 0.
    \end{equation}
    Nous avons la borne de \defe{Berry-Esséen}{Berry-Esséen (borne)} qui donne une estimation de la vitesse de convergence: si \( X\in L^3\), alors  il existe une constante \( C\), indépendante de \( x\), des \( X_i\) et de \( n\) telle que
    \begin{equation}
        \left| P\left( \frac{ S_n-nm }{ \sigma\sqrt{n} }\leq x \right)-\int_{-\infty}^x\frac{1}{ \sqrt{2\pi} } e^{-y^2/2}dy \right| \leq\frac{ X\mu_3 }{ \sigma^3\sqrt{n} }
    \end{equation}
    où \( \mu_3=E\big( | X_1-m |^3 \big)\) est le moment d'ordre \( 3\) de \( X\). La chose à retenir est que la convergence est à la vitesse de \( 1/\sqrt{n}\).
\end{remark}

En dimension \( d>1\), nous avons encore un théorème central limite.
\begin{theorem}
    Si \( d>1\), et si nous avons des variables aléatoires \( X_n\) à valeurs dans \( \eR^d\) avec
    \begin{enumerate}
        \item
            les \( X_n\) sont indépendantes et identiquement distribuées
        \item
            les \( X_n\) sont dans \( L^2\).
    \end{enumerate}
    Alors nous notons \( X_1=(X_1^{(1)},\ldots,X_1^{(d)})\). Nous avons
    \begin{equation}
        \frac{ S_n-nm }{ \sqrt{n} }\stackrel{\hL}{\longrightarrow}\dN(0,\Sigma)
    \end{equation}
    où \( \Sigma\) est ma matrice de covariance du vecteur aléatoire \( X_1\) :
    \begin{equation}
        \Sigma=\big( \Cov(X_1^{(1),\ldots,X_1^{(d)}}) \big)_{i,j=1,\ldots,d}.
    \end{equation}
\end{theorem}
