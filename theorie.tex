% This is part of Mes notes de mathématique
% Copyright (C) 2010-2012
%   Laurent Claessens
% See the file LICENCE.txt for copying conditions.

D'autres lectures agréables dans \cite{GianlucaB,cmcsNum}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Méthodes d'approximations pas à pas}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Nous considérons une fonction continue \( f\colon \eR\to \eR\), en supposant qu'elle s'annule une seule fois sur l'intervalle \( \mathopen[ a , b \mathclose]\). Nous voulons résoudre \( f(x)=0\).

Étant donné que nous connaissons beaucoup de théorèmes de points fixes, une idée est de remplacer l'équation \( f(x)=0\) par \( x=g(x)\) en choisissant une bonne fonction continue \( g\). Ensuite nous considérons la suite
\begin{subequations}
    \begin{numcases}{}
        x_0\in\mathopen[ a , b \mathclose]\\
        x_{n+1}=g(x_n),
    \end{numcases}
\end{subequations}
et nous espérons qu'elle converge. Notons que par continuité, si elle converge, elle converge vers un point fixe de \( g\).

\begin{definition}
    Une méthode itérative est dite d'\defe{ordre}{ordre!d'une méthode itérative} (au moins) \( p\) si il existe \( M>0\) tel que
    \begin{equation}
        | e_{n+1} |\leq | e_n |^p
    \end{equation}
    où \( e_n=x-x_n\), \( x\) étant le point fixe recherché.
\end{definition}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Points fixes attractifs et répulsifs}
%---------------------------------------------------------------------------------------------------------------------------
Source : \cite{DemaillyNum}.

Soit \( I\) un intervalle fermé de \( \eR\) et \( \varphi\colon I\to I\) une application \( C^1\). Soit \( a\) un point fixe de \( \varphi\). Nous disons que \( a\) est \defe{attractif}{point fixe!attractif}\index{attractif!point fixe} si il existe un voisinage \( V\) de \( a\) tel que pour tout \( x_0\in V\) la suite \( x_{n+1}=\varphi(x_n)\) converge vers \( a\). Le point \( a\) sera dit \defe{répulsif}{répulsif!point fixe} si il existe un voisinage \( V\) de \( a\) tel que pour tout \( x_0\in V\) la suite \( x_{n+1}=\varphi(x_n)\) diverge.

\begin{lemma}   \label{LemfipGZG}
    Si \( | \varphi'(a) |<1\) alors \( a\) est attractif et la convergence est au moins exponentielle.

    Si \( | \varphi'(a) |>1\) alors \( a\) est répulsif et la divergence est au moins exponentielle.
\end{lemma}

\begin{proof}
    Si \( | \varphi'(a)<1 |\) alors il existe \( k\) tel que \( | \varphi'(a) |<k<1\) et par continuité il existe un voisinage \( V\) de \( a\) dans lequel \( | \varphi'(x) |<k\) pour tout \( x\in V\). En utilisant le théorème des accroissements finis nous avons
    \begin{equation}
        | x_n-a |=\big| f(x_{n-1}-a) \big|\leq k| x_{n-1}-a |
    \end{equation}
    et par récurrence
    \begin{equation}
        | x_n-a |\leq k^n| x_0-a |.
    \end{equation}

    Le cas \( | \varphi'(a)>1 |\) se traite de façon similaire.
\end{proof}

\begin{remark}
    Dans le cas \(| \varphi'(a) |=1\), nous ne pouvons rien conclure. Si \( \varphi(x)=\sin(x)\) nous avons \( \sin(x)<x\) et le point \( a=0\) est attractif. A contrario, si \( \varphi(x)=\sinh(x)\) nous avons \( |\sinh(x)|>|x|\) et le point \( a=0\) est répulsif.
\end{remark}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Méthode de dichotomie}
%---------------------------------------------------------------------------------------------------------------------------

La méthode de dichotomie suppose n'est pas une méthode de point fixe. Elle suppose que \( f(a)<0\) et \( f(b)>0\). Le théorème des valeurs intermédiaires nous assure qu'il y a une solution à \( f(x)=0\) entre \( a\) et \( b\). Nous considérons \( x_0=a\), \( y_0=b\) puis nous construisons les suites \( (x_n)\) et \( (y_n)\) de la façon suivante. Nous posons \( a_i=\frac{ 1 }{2}(x_i+y_i)\). Si \( f(a_i)>0\), alors \( y_{i+1}=a_i\), \( x_{i+1}=x_i\); si au contraire \( f(a_i)<0\) alors \( x_{i+1}=a_i\) et \( y_{i+1}=y_i\).

Cette méthode est très semblable à celle développée dans la preuve de l'existence d'un supremum à toute partie de \( \eR\) (proposition \ref{PropBorneSupInf}) et pour cause : la recherche de \( f(x)=0\) revient à trouver l'infimum de \( \{ x\in\mathopen[ a , b \mathclose]\tq f(x)>0 \}\).

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Méthode de Lagrange}
%---------------------------------------------------------------------------------------------------------------------------

La méthode de Lagrange\index{méthode!Lagrange}\index{Lagrange!méthode} consiste à prendre la fonction
\begin{equation}
    g(x)=\frac{ af(x)-xf(a) }{ f(x)-f(a) }.
\end{equation}
% TODO : faire un dessin

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Méthode de Newton}
%---------------------------------------------------------------------------------------------------------------------------

%TODO : parler du Carmack's reverse.

L'objectif de la méthode de Newton est d'évaluer une racine \( a\) de l'équation \( f(x)=0\) lorsque nous avons déjà une approximation \( x_0\) de \( a\).

\begin{lemma}       \label{LemXdObnV}
    Soient \( A\) et \( B\) deux matrices inversibles telles que la matrice \( (A+\epsilon B)\) soit inversible pour tout \( \epsilon\) assez petit. Alors il existe une matrice \( X(\epsilon)\) telle que
    \begin{equation}
        (A+\epsilon B)^{-1}=A^{-1}+\epsilon X
    \end{equation}
    et telle que \( \lim_{\epsilon\to 0}X(\epsilon)=-A^{-1} BA^{-1}\).
\end{lemma}

\begin{proof}
    Le candidat matrice \( X\) est relativement simple à trouver en écrivant
    \begin{equation}
        (A+\epsilon B)(A^{-1}+\epsilon X)=\mtu+\epsilon AX+\epsilon BA^{-1}+\epsilon^2BX.
    \end{equation}
    En imposant que cela soit \( \mtu\), nous trouvons
    \begin{equation}        \label{EqahWJUU}
        X(\epsilon)=-(A+\epsilon B)^{-1} BA^{-1}.
    \end{equation}
    La matrice \( X(\epsilon)\) donnant un inverse à droite de \( (A+\epsilon B)\), son déterminant est non nul et \( X\) est inversible. Par conséquent elle est également inversible au sens usuel. Le calcul de la limite est direct :
    \begin{equation}
        \lim_{\epsilon\to 0}-(A+\epsilon B)^{-1} BA^{-1}=A^{-1} BA^{-1}
    \end{equation}
    parce que l'inverse est une fonction continue sur \( \eM(n,\eR)\).

    Nous pouvons vérifier explicitement que \eqref{EqahWJUU} donne également un inverse à droite en calculant :
    \begin{subequations}
        \begin{align}
            (A^{-1}+\epsilon X)(A+\epsilon B)&=\big( A^{-1}-\epsilon(A+\epsilon B)^{-1} BZ^{-1} \big)(A+\epsilon B)\\
            &=1+\epsilon A^{-1} B-\epsilon(A+\epsilon B)^{-1} B-\epsilon^2(A+\epsilon B)^{-1} BA^{-1} B.
        \end{align}
    \end{subequations}
    Nous devons donc vérifier que
    \begin{equation}
        A^{-1} B-(A+\epsilon B)^{-1}B-\epsilon(A+\epsilon B)^{-1} BA^{-1} B=0.
    \end{equation}
    Pour le vérifier, il suffit de mettre \( B\) en facteur à droite et d'introduire \( AA^{-1}\):
    \begin{subequations}
        \begin{align}
            A^{-1} B-(A+\epsilon B)^{-1}B&-\epsilon(A+\epsilon B)^{-1} BA^{-1} B\\
            &=\left[ A^{-1}-\Big( (A+\epsilon B)^{-1}(A+\epsilon BA^{-1}) \Big) \right]AA^{-1} B\\
            &=\left[ 1-(A+\epsilon B)^{-1}(A+\epsilon B) \right]A^{-1}B\\
            &=0.
        \end{align}
    \end{subequations}
\end{proof}

\begin{remark}
    Un calcul naïf nous permet de trouver le même résultat de façon plus heuristique. En effet un développement usuel (dans \( \eR\)) est
    \begin{equation}
        \frac{1}{ a+\epsilon b }=\frac{1}{ a }-\frac{ \epsilon b }{ a^2 }+\ldots
    \end{equation}
    Si nous récrivons cela avec des matrices, nous écrivons (attention : passage heuristique!) :
    \begin{equation}
        (A+\epsilon B)^{-1}=A^{-1}-\epsilon A^{-1} BA^{-1}+\ldots
    \end{equation}
    Notons le choix de généraliser \( b/a^2\) par \( a^{-1} ba^{-1}\). Dans les réels les deux écritures sont équivalentes, mais pas dans les matrices.

    Étudions si \( A^{-1}-\epsilon A^{-1}BA^{-1}\) est bien un inverse à \( \epsilon^2\) près de \( (A+\epsilon B)\) :
    \begin{equation}
        (A+\epsilon B)(A^{-1}+\epsilon A^{-1} BA^{-1})=1-\epsilon BA^{-1}+\epsilon BA^{-1}-\epsilon^2BA^{-1}BA^{-1}=1-\epsilon^2BA^{-1} BA^{-1}.
    \end{equation}
    Par conséquent, à des termes en \( \epsilon^2\) près la matrice \( A^{-1}-\epsilon A^{-1}BA^{-1}\) est bien un inverse de \( A+\epsilon B\).
\end{remark}

\begin{theorem}[Méthode de Newton\cite{ChambertNewton}]\index{Newton!méthode}\index{méthode!Newton}
    Soit \( f\colon \eR^n\to \eR^n\) une application de classe \( C^2\) et un point \( a\in \eR^n\) tel que \( f(a)=0\). Nous supposons que \( df_a\) est inversible.

    Alors il existe un voisinage \( V\) de \( a\) tel que pour tout \( x_0\in V\) la suite définie par récurrence
    \begin{equation}
        x_{n+1}=x_n-(df_{x_n})^{-1}\big( f(x_n) \big)
    \end{equation}
    converge vers \( a\). De plus la vitesse est quadratique au sens où il existe \( C>1\) tel que 
    \begin{equation}        \label{EqtkiDXt}
        \| x_n-a \|\leq C^{-1-2^n}.
    \end{equation}
\end{theorem}

\begin{proof}
    Étant donné que \( df_a\) est inversible et que \( df\) est continue, l'application \( df_x\) est inversible\footnote{Nous pouvons voir \( df\) comme l'application qui à \( x\) fait correspondre la matrice \( df_x\in\eM(n,\eR)\). Cette application étant continue et la non inversibilité d'une matrice étant donnée par l'annulation du déterminant, les matrices inversibles forment un ouvert dans l'ensemble des matrices.} pour tout \( x\) dans un voisinage de \( a\). Nous prenons \( r>0\) tel que \( df_x\) soit inversible pour tout \( x\in B(a,r)\).

    Nous considérons la fonction 
    \begin{equation}
        \begin{aligned}
                F\colon B(a,r)&\to \eR^n \\
                x&\mapsto x-(df_x)^{-1}\big( f(x) \big). 
            \end{aligned}
        \end{equation}
        Cela est une application \( C^1\). Notons que \( F(a)=a\). La clef est de montrer que si on applique \( F\) à un point \( a+h\) proche de \( a\), alors le résultat est encore plus proche de \( a\) pourvu que \( h\) soit assez petit. Nous avons la formule suivante :
        \begin{equation}        \label{EqyDLQeE}
            F(a+h)-F(a)=h-\big( df_{a+h} \big)^{-1}\big( f(a+h) \big).
        \end{equation}
        Nous allons maintenant utiliser un développement de Taylor par rapport à \( h\) en suivant la formule \eqref{EquQtpoN}. Nous avons
        \begin{equation}
            f(a+h)=f(a)+df_a(h)+\| h \|^2\xi(h)
        \end{equation}
        où \( \xi\colon \eR^n\to \eR^n\) est une fonction qui tend vers une constante lorsque \( h\to 0\). Nous avons aussi
        \begin{equation}
            df_{a+h}=df_a+\| h \|\tau(h)
        \end{equation}
        où \( \tau\colon \eR^n\to \eM(n,\eR)\) est une application qui tend vers une constante lorsque \( h\to 0\). En ce qui concerne l'inverse nous utilisons le lemme\footnote{Pour l'inversibilité de \( \| h \|\tau(h)\), notons que \( df_a\) est inversible et que par hypothèse la somme \( df_a+\| h \|\tau(h)\) est inversible.} \ref{LemXdObnV} :
        \begin{equation}
            \big( df_a+\| h \|\tau(h) \big)^{-1}=(df_a)^{-1}+\| h \|A(h)
        \end{equation}
        où \( A\) est une autre matrice fonction de \(h\) qui tend vers une constante lorsque \( h\) tend vers zéro. En substituant le tout dans \eqref{EqyDLQeE} nous trouvons
        \begin{equation}
            F(a+h)-F(a)=\| h \|^2(df_a)^{-1}\xi(h)+\| h \|\big( A(h)\circ df_a \big)(h)+\| h \|^3A(h)\xi(h).
        \end{equation}
        En ce qui concerne la norme nous utilisons le fait que si \( T\) est un opérateur, \( \| Tx \|\leq \| T \|\| x \|\). Nous trouvons
        \begin{subequations}
            \begin{align}
                \| F(a+h)-F(a) \|&\leq \| h \|^2\| (df_a)^{-1} \|\| \xi(h) \|+\| h \|^2\| A(h)\circ df_a \|+\| h \|^3\| A(h) \|\| \xi(h) \|\\
                &=\| h \|^2\alpha(h)
            \end{align}
        \end{subequations}
    pour une certaine fonction \( \alpha\colon \eR^n\to \eR\) qui tend vers une constante lorsque \( h\to 0\). 

    En posant \( C=\lim_{h\to 0}\alpha(h) \) nous avons la majoration
    \begin{equation}        \label{EqSYiuYF}
        \| F(x)-a \|\leq C\| x-a \|^2.
    \end{equation}
    Nous pouvons également supposer que \( C>1\). Affin de prouver la vitesse de convergence \eqref{EqtkiDXt}, nous allons encore redéfinir \( r\) en demandant \( r<1/C^2\). De cette manière nous avons
    \begin{equation}
        \| x_0-a \|\leq \frac{1}{ C^2 }
    \end{equation}
    et nous prouvons par récurrence que 
    \begin{equation}
        \| x_{n+1}-a \|=\| F(x_n)-a \|\leq C\| x_n-a \|^2\leq C\big( C^{-1-2^n} \big)^2=C^{-1-2^{n+1}}.
    \end{equation}

\end{proof}

\begin{remark}  \label{RemOxOmln}
    La valeur de la constate \( C\) a été fixée par l'équation \eqref{EqSYiuYF}. Certes nous pouvons toujours choisir \( C\) plus grand affin d'augmenter la vitesse de convergence, mais le point de départ \( x_0\) devant être dans une boule de taille \( 1/C^2\) autour de \( a\), demander \( C \) plus grand revient à demander un point de départ plus précis.
\end{remark}

La remarque \ref{RemOxOmln} illustre un fait très général pour les méthodes itératives : le choix du point de départ est un problème délicat; d'aucuns diraient même que c'est le point le plus difficile à traiter si on veut implémenter une méthode itérative sur un ordinateur. Une chose qu'on peut faire est de commencer quelque itérations d'une méthode pas très efficace mais très générale (dichotomie) affin de trouver alors un bon point de départ pour l'algorithme plus efficace.

\begin{example}
    Le calcul de \( \sqrt{2}\) se fait en considérant la fonction \( f(x)=x^2-2\) et donc la récurrence 
    \begin{equation}
        x_{n+1}=x_n-\frac{ x_n^2-2 }{ 2x_n }=\frac{ x_n^2+2 }{ 2x_n }.
    \end{equation}
    Cette formule a une interprétation géométrique appelée \defe{\wikipedia{fr}{Méthode_de_Héron}{méthode} de \wikipedia{fr}{Babylone_(royaume)}{Babylone}}{méthode!Babylone}. L'idée de cette méthode pour calculer \( \sqrt{a}\) est de considérer un rectangle de côtés \( x\) et \( a/x\) (c'est à dire de surface \( a\)). Afin de trouver une nouvelle approximation de \( \sqrt{a}\), nous considérons le rectangle dont un côté est la moyenne entre \( x\) et \( x/a\) et l'autre côté est ce qu'il faut pour que la surface reste \( a\). En suivant cette idée, nous avons l'itération
    \begin{equation}
        x_{n+1}=\frac{ 1 }{2}(x_n+\frac{ a }{ x_n })=\frac{1}{ 2x_n }(x_n^2+a),
    \end{equation}
    ce qui est la même formule que la formule de Newton pour la fonction \( f(x)=x^2-a\).
\end{example}

À propos de la méthode de Babylone, il y a mieux. Ce que les anciens proposaient était de prendre la moyenne arithmétique entre les deux côtés du rectangle. Essayons mieux :
\begin{equation}    \label{EqCCJZtF}
    g_t(x)=tx+(1-t)\frac{ a }{ x }.
\end{equation}
Cela est une combinaison convexe générale de \( x\) et \( a/x\). Pour \( t=1/2\), on retrouve Babylone. Un calcul rapide montre que
\begin{equation}
    g_t'(\sqrt{a})=2t-1,
\end{equation}
et donc la méthode converge pour tout \( t\in\mathopen] 0 , 1 \mathclose[\). En vertu du lemme \ref{LemfipGZG}, plus \( | g'_t(\sqrt{a}) |\) est petit, mieux c'est. La méthode optimale parmi les méthodes \eqref{EqCCJZtF} est celle avec \( t=1/2\), déjà connue des babyloniens et redécouverte par Newton. Comme quoi parfois ce sont vraiment les vieilles casseroles qui font les meilleurs soupes.

\begin{remark}
    On dit souvent que la formule
    \begin{equation}
        x_{\pm}=\frac{ -b\pm\sqrt{b^2-4ac} }{ 2a }
    \end{equation}
    donne des solutions «exactes» de l'équation \( ax^2+bx+c=0\). Certes. Cependant pour calculer la racine, nous voyons que ce n'est absolument pas simple. La formule a un intérêt théorique, mais il faut se rendre compte que si on veut vraiment une solution numérique de l'équation, on n'échappe pas au calcul approché.
\end{remark}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Convergence exponentielle, c'est bien ?}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

La méthode de dichotomie donne une erreur de l'ordre de \( 1/2^k\) après \( k\) itérations. Woaw, c'est une convergence exponentielle ! 

Si nous prenons comme mesure de ce qui est «bien», le nombre de décimales exactes, alors monter de un cran en «bien» signifie diviser par \( 10\) l'erreur. Donc cette notion de «bien» est elle-même exponentielle.

Bref, la méthode de dichotomie ne fournit pas une décimale exacte par étape (sauf si on compte en base \( 2\)). Avec la méthode de Newton par contre, la formule \eqref{EqtkiDXt} nous dit que (en base \( C\)), le nombre de décimales exactes double à chaque pas. Ça, c'est de la vraie convergence bien virile.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Systèmes linéaires avec inversion de la matrice}
%---------------------------------------------------------------------------------------------------------------------------

Disons-le immédiatement : inverser la matrice est toujours une mauvaise idée pour résoudre \( Ax=b\). Les méthodes que nous allons présenter ici sont donc à comprendre comme étant des méthodes pour calculer l'inverse lorsqu'on en a besoin, et non pour résoudre le système.

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Décomposition LU}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Lorsqu'aucun pivot n'est nul, la méthode de Gauss fournit une matrice de la forme
\begin{equation}
    \begin{pmatrix}
        a_1    &   *    &   *    \\
        0    &   \ddots    &   *    \\
        0    &   0    &   a_n
    \end{pmatrix}.
\end{equation}
Cette matrice n'est pas loin d'être inversée. Il n'est donc pas étonnant qu'il existe un résultat d'inversion de matrice lorsque les pivots sont tous nuls.

\begin{theorem}
    Soit une matrice inversible \( A\in \eM(n,\eC)\) dont tous les pivots sont non nuls. Alors il existe une matrice inversible triangulaire inférieure \( L\) avec des \( 1\) sur la diagonale et une inversible triangulaire supérieure \( U\) telle que
    \begin{equation}
        A=LU.
    \end{equation}
    Cette décomposition est unique.
\end{theorem}

À partir de là, la résolution de \( Ax=b\) revient à résoudre \( Ly=b\) puis \( Ux=y\). La difficulté de cette méthode est de trouver \( U\) et \( L\).

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Systèmes linéaires sans inverser la matrice}
%---------------------------------------------------------------------------------------------------------------------------

Vu qu'il est en général très coûteux en calculs d'inverser une matrice, il existe toute sortes de méthodes pour résoudre des systèmes linéaires de la forme \( Ax=b\) sans inverser \( A\), même si \( A\) est inversible.

Supposons que la matrice \( A\) soit décomposable en \( A=M-N\) où \( M\) est inversible et «facile». Par «facile», nous entendons quelque chose comme triangulaire, diagonale ou n'importe quoi qui fait en sorte que résoudre \( Mx=c\) est facile. Dans ce cas nous considérons la méthode itérative
\begin{equation}    \label{EqHEcnkk}
    x_{k+1}=M^{-1}(Nx_k+b),
\end{equation}
également souvent notée \( Mx_{k+1}=Nx_k+b\). Si la suite \( (x_k)\) ainsi définie converge vers \( \ell\), alors \( \ell\) est une solution de \( Ax=b\).

Les questions sont maintenant de plusieurs ordres. D'abord comment décomposer \( A=M-N\) ? Quel point de départ choisir ? Comment on s'assure de la convergence ?

Nous allons voir deux\footnote{Parce que je n'en connais que deux; pas parce qu'il en existe que deux. Faites moi signe si vous pensez savoir quelque chose qui peut améliorer cette section.} choix de décomposition \( A=M-N\). Tous les deux se basent sur la décomposition
\begin{equation}
    A=D-E-F
\end{equation}
où \( D\) est la diagonale de \( A\), \( E\) est la triangulaire supérieure de \( A\) (avec changement de signe) et \( F\) est la partie triangulaire inférieure de \( A\) (avec changement de signe).

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Jacobi}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

La méthode de Jacobi consiste à prendre \( M=D\) et \( N=E+F\). La méthode proposée est alors
\begin{equation}
    Dx_{k+1}=(E+F)x_k+b.
\end{equation}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Gauss-Sieidel}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Le choix de Gauss-Sieidel est \( M=D-E\) et \( N=F\). La méthode est alors
\begin{equation}
    (D-E)x_{k+1}=Fx_k+b.
\end{equation}
Notons que \( D-E\) est une matrice triangulaire, donc «facile» à inverser.

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Choix ?}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Il peut arriver que pour une même matrice, la méthode de Gauss-Sieidel converge et Jacobi diverge ou le contraire. Nous allons maintenant donner des indices sur \( M\) et \( N\) permettant de savoir si la méthode \eqref{EqHEcnkk} va converger.

\begin{proposition}
    La méthode \( Mx_{k+1}=Nx_k+b\) converge pour tout \( x_0\) et pour tout \( b\) si et seulement si \( \rho(M^{-1}N)<1\).
\end{proposition}

\begin{proof}
    Supposons que \( \rho(M^{-1}N)<1\). Nous notons \( B=M^{-1}N\) et \( c=M^{-1}b\), de façon à ce que la méthode considérée soit \( x_{k+1}=Bx_k+c\). Nous avons
    \begin{subequations}
        \begin{align}
            x_{k+1}-x_k&=Bx_k+c-(Bx_{k-1}+c)\\
            &=B(x_k-x_{k-1})\\
            &=\ldots\\
            &=B^k(x_1-x_0).
        \end{align}
    \end{subequations}
    Donc si \( k>l\) alors
    \begin{equation}
        x_k-x_l=\sum_{j=l}^{k-1}x_{j+1}-x_j=\sum_{j=l}^{k-1}B^j(x_1-x_0).
    \end{equation}
    Par conséquent
    \begin{equation}
        \| x_k-x_l \|\leq \frac{ \| B \|^l }{ 1-\| B \| }\| x_1-x_0 \|.
    \end{equation}
    Donc si \( \| B \|\leq 1\) alors la suite est de Cauchy et converge.
\end{proof}

\begin{theorem}
    Si il existe une norme vectorielle sur \( \eC^n\) telle que pour la norme matricielle correspondante nous ayons \( \| M^{-1}N \|<1\), alors la méthode converge pour tout \( x_0\).
\end{theorem}

Il y aurait encore beaucoup à dire sur le lien entre les normes matricielles et le rayon spectral.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Conditionnement et stabilité}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{definition}
	Soit $F$ une fonction à valeurs réelles définie sur ${\bf X}\times{\bf D}$ o\`u ${\bf X}$ et ${\bf D}$ sont des espaces vectoriels réels normés. Le problème de la recherche des solutions de 
	\begin{equation}
		F(x,d)=0
	\end{equation}
	est dit \defe{stable}{stable} si 
	\begin{enumerate}
		\item 
			la solution $x=x(d)$ existe et est unique pour tout $d$;
		\item \label{ItemProbStableB}
			Pour tout $\eta>0$, et pour tout $d_0$, il existe un nombre $K>0$ tel que $|d-d_0|<\eta$ entraine $|x(d)-x(d_0)|\;\leq\;K\;|d-d_0|$.
	\end{enumerate}
\end{definition}
Le nombre 
\begin{equation}		\label{EqDefAABSOLU}
	K_{abs}(d_0,\eta):=\sup_{d\text{ tel que $|d_0-d|<\eta$}}\frac{|x(d)-x(d_0)|}{|d-d_0|}
\end{equation}
est appelé le \defe{conditionnement absolu}{Conditionnement!absolu} du problème autour de $d_0$.

\begin{definition}	
	Soit $F(x,d)=0$ un problème stable de conditionnement absolu $K_{\text{abs}}(d,\eta)$.  Le conditionnement relatif est défini par
	\begin{equation}
		K_{\text{rel}}(d,\eta):=K_{\text{abs}}(d,\eta)\frac{|d|}{|x(d)|}.
	\end{equation}
	Le problème est dit \defe{bien conditionné}{Bien conditionné} près de $d$ si $K_{\text{rel}}(d,\eta)$ est petit.
\end{definition}

Un résultat pratique pour étudier le conditionnement d'un problème est le suivant.
\begin{corollary}		\label{CorConditionnementNormeNabla}
	Soit $x=x(d)$ un problème stable. Supposons $\eD$ de dimension finie, supposons que $U$ est ouvert dans $\eD$. Supposons encore $x\colon U\to \eR$ différentiable en $d_0$. Alors quand $\eta$ est petit, on a
	\begin{equation}
		K_{\text{abs}}^{\eta}(d_0)\sim \| \nabla x(d_0) \|.
	\end{equation}
\end{corollary}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Comment choisir et penser le $K$?}
%---------------------------------------------------------------------------------------------------------------------------

La formule \eqref{EqDefAABSOLU} contient une formule qui ressemble étrangement à la dérivée. La stabilité d'un problème est très liée à la dérivée de $F$. La stabilité et la dérivée ne sont pas les mêmes choses, mais il n'est pas mauvais de penser au $K$ de la stabilité comme la dérivée. Ou plus précisément : le supremum de la dérivée.

Un fil conducteur des exercices \ref{exoSerieUn0002}, \ref{exoSerieUn0003} et \ref{exoSerieUn0001} est que l'on a un $K$ qui fonctionne lorsque la dérivée est bornée sur l'intervalle $\mathopen] d_0-\eta , d_0+\eta \mathclose[$. Dans le cas où ce supremum existe, le prendre en guise de $K$ fonctionne souvent.

Il faut cependant parfois faire acte d'imagination. La fonction $x\mapsto| x |$ n'est pas dérivable en $0$. Il n'empêche que $K=1$ fait fonctionner la définition de la stabilité. Remarquez que $K=1$ est le supremum de la dérivée là où elle existe.

À partir du moment où c'est clair que le $K$ est le supremum de la dérivée, on comprend pourquoi c'est le gradient qui arrive dans le corollaire \ref{CorConditionnementNormeNabla}. En effet, le gradient indique la direction de plus grande pente. C'est donc bien dans cette direction qu'il faut chercher la «plus grande dérivée».


\begin{proposition}	
	Pour le problème stable $x=x(d)$ avec $x\in C^1(\eR^n,\eR)$, on a
	\begin{equation}
		K_{abs}(d)\sim|x_{\star d}|_{\mbox{op}}
	\end{equation}
	où $x_{\star d}$ désigne la différentielle de $x$ en $d$.
\end{proposition}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Algorithmes, stabilité, convergence et conditionnement}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Méthode de Newton pour trouver une racine d'une fonction}
%---------------------------------------------------------------------------------------------------------------------------
\label{SubSecMethodeNewton}

La méthode de Newton consiste a exprimer la solution $x$ de $f(x)=0$ avec $f\in C^1(\eR)$ comme limite d'une suite $\{x_n\}_{n\in\eN}$ définie par récurrence par la formule
\begin{equation}
	x_{n+1}=x_n-\frac{f(x_n)}{f'(x_n)}.
\end{equation}
où $x_0$ est arbitraire.

Si on veut exprimer cela en termes d'algorithmes, nous disons que l'algorithme de Newton est donné par la suite de problèmes
\begin{equation}		\label{EqFPourNewtonUn}
	F_n(x_{n+1},x_n,f)=x_{n+1}-x_n+\frac{ f(x_n) }{ f'(x_n) }.
\end{equation}
La donnée du problème est la fonction $f$, et rien que elle.

Plus précisément, une fois que la fonction $f$ est donnée, il existe une infinité de problèmes : pour chaque $a\in \eR$ nous avons le problème
\begin{equation}
	G_a(x_n,f)=x-a+\frac{ f(a) }{ f'(a) }.
\end{equation}
La méthode de Newton consiste à sélectionner une partie de ces problèmes de la façon suivante :
\begin{subequations}
	\begin{numcases}{}
		F_0=G_{x_0}\\
		F_n=G_{x_n}.
	\end{numcases}
\end{subequations}
Le problème $F_0$ fournit un nombre $x_1$ qui nous permet de sélectionner le problème $G_{x_1}$ qui va fournir le nombre $x_2$, etc.

Au moment de calculer le conditionnement de $F_n$, nous ne devons pas voir $x_{n-1}$ comme fonction de $x_0$ et de la donnée $f$. Il ne faut donc pas dériver à travers les $x_n$.

L'algorithme de Newton a les caractéristiques suivantes :
\begin{enumerate}

	\item
		Pour résoudre le problème numéro $n$, il faut avoir résolu le problème numéro $n-1$.
	\item
		Aucune des solutions $x_n$ aux problèmes intermédiaires n'est une solution au problème de départ (à moins d'un coup de chance).
	\item
		Étant donné que la donnée du problème $F_n$ est la fonction $f$ de départ, nous avons $d_m=d_n=d$ pour tout $m$ et $n$.

\end{enumerate}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Résoudre un système linéaire}
%---------------------------------------------------------------------------------------------------------------------------

Pour résoudre un système linéaire d'équations, nous échelonnons la matrice du système. Soit à résoudre le système $Ax=b$ où
\begin{equation}
	\begin{aligned}[]
		A&=\begin{pmatrix}
			2	&	4	&	-6	\\
			1	&	5	&	3	\\
			1	&	3	&	2
		\end{pmatrix}, &\text{et}&&b=\begin{pmatrix}
			-4	\\ 
			10	\\ 
			5	
		\end{pmatrix}.
	\end{aligned}
\end{equation}
En termes de problèmes, on écrit $F\big( x,(A,b) \big)=Ax-b$. La donnée de ce problème est le couple $(A,b)$.

En ce qui concerne l'algorithme, on pose comme premier problème
\begin{equation}
	F_1\big(x_1,(A_1,b_1)\big)=A_1x_1-b_1=0
\end{equation}
avec $A_1=A$ et $b_1=b$.

Ensuite, on commence à échelonner et le second problème est
\begin{equation}
	F_2\big(x_2,(A_2,b_2)\big)=A_2x_2-b_2=0
\end{equation}
avec 
\begin{equation}
	\begin{aligned}[]
		A&=\begin{pmatrix}
			2	&	4	&	-6	\\
			0	&	3	&	6	\\
			0	&	1	&	5
		\end{pmatrix}, &\text{et}&&b=\begin{pmatrix}
			-4	\\ 
			12	\\ 
			13	
		\end{pmatrix}.
	\end{aligned}
\end{equation}
Le troisième problème sera
\begin{equation}
	F_3\big(x_3,(A_3,b_3)\big)=A_3x_3-b_3=0
\end{equation}
avec 
\begin{equation}
	\begin{aligned}[]
		A&=\begin{pmatrix}
			2	&	4	&	-6	\\
			0	&	3	&	6	\\
			0	&	0	&	3
		\end{pmatrix}, &\text{et}&&b=\begin{pmatrix}
			-4	\\ 
			12	\\ 
			3	
		\end{pmatrix}.
	\end{aligned}
\end{equation}
Ce problème est facile à résoudre «à la main». Nous nous arrêtons donc ici avec l'algorithme, et nous trouvons le $x_3$ qui résous le problème $F_3$.

L'algorithme de résolution de systèmes linéaires d'équations a les propriétés suivantes, à mettre en contraste avec celles de Newton :
\begin{enumerate}

	\item
		Pour résoudre le problème numéro $n$, il n'a pas fallu résoudre le problème numéro $n-1$.
	\item
		Toutes les solutions $x_n$ des problèmes intermédiaires sont solutions du problème de départ. Nous avons $F_n(x,d_n)=0$ pour tout $n$ (ici, $d_n=(A_n,b_n)$).
	\item
		D'un problème à l'autre, les données changent énormément : la matrice échelonnée peut être très différente de la matrice de départ.

\end{enumerate}


%---------------------------------------------------------------------------------------------------------------------------
\subsection{Définitions}
%---------------------------------------------------------------------------------------------------------------------------

	Nous allons maintenant formaliser en donnant quelque définitions pour nommer les propriétés que nous avons vues. D'abord, un algorithme est une suite de problèmes. Un \defe{algorithme}{algorithme} pour résoudre un problème $F(x,d)=0$ est une suite de problèmes $\{F_n(x_n,d_n)=0\}_{n\in\eN}$.  

\begin{definition}
	Un tel algorithme est dit  \defe{fortement consistant}{algorithme!fortement consistant} si pour toutes données admissibles $d_n$, on a
	\begin{equation}
		F_n(x,d_n)=0\quad\forall \;n,
	\end{equation}
	où $x$ est la solution de $F(x,d)=0$.
\end{definition}
L'algorithme des matrices est fortement consistant, mais pas l'algorithme de Newton.

\begin{definition}
	Un algorithme est \defe{consistant}{algorithme!consistant} si $\lim_{n\to\infty}F_n(x,d_n)=0$.
\end{definition}
Dans le cas de l'algorithme de Newton, c'est plutôt une telle consistance qu'on attend.

L'algorithme est dit \defe{stable}{algorithme!stable} si pour tout $n$ le problème correspondant est stable.  Dans ce cas, on note $K^{\mbox{num}}$ le  \defe{conditionnement relatif asymptotique}{Conditionnement!relatif asymptotique} défini par
\begin{equation}
	K^{\mbox{num}}=\limsup_nK_n
\end{equation}
où $K_n$ est le conditionnement relatif du problème $F_n(x_n,d_n)=0$.

\begin{definition}		\label{DefAlgoConverge}
	Un algorithme est dit \defe{convergent}{algorithme!convergent} (en $d$) si pour tout $\epsilon>0$, il existe $N=N(\epsilon)$ et $\delta=\delta(N,\epsilon)$ tels que pour $n\geq0$ et $|d-d_n|<\delta$, on ait $|x(d)-x_n(d_n)|<\epsilon$.
\end{definition}

\begin{remark}		\label{RemConvAlgoNewton}
Dans le cas de l'algorithme de Newton, nous avons vu que la donnée $d_n$ du problème $F_n$ était en fait la même que la donnée initiale $d$, donc nous avons $d_n=d$, et par conséquent nous avons toujours $| d-d_n |<\delta$. Dans ce cas, la définition de la convergence revient à demander que la suite numérique des $x_n$ converge vers la solution $x$.
\end{remark}

\begin{remark}
Dans le cas des matrices par contre, les données sont très différentes les unes des autres, nous avons donc en général que $| d-d_n |>\delta$. Mais en revanche nous savons que tous les problèmes intermédiaires $F_n$ acceptent une solution unique\footnote{Nous n'envisageons que le cas où le déterminant est non nul.} $x_n(d_n)=x(d)$. Par conséquent, $| x_n(d_n)-x(d) |$ est toujours plus petit que $\epsilon$. L'algorithme des matrice est donc toujours un algorithme convergent.
\end{remark}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Représentations numériques, erreurs}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{definition}
	Soit $x$ un réel. On définit sa \defe{représentation en virgule fixe}{Représentation!virgule fixe} par 
	\begin{equation}
		x=\{[x_nx_{n-1}...x_0,x_{-1}...x_{-m}], b, s\}
	\end{equation}
	avec  $b\in\eN, b\geq2$, $s\in\{0,1\}$ et $x_j\in\eN,x_j<b$ suivant la formule
	\begin{equation}
		x=(-1)^{s}\sum_{j=-m}^nx_j.b^j.
	\end{equation}
	On définit sa \defe{représentation en \href{http://docs.python.org/tutorial/floatingpoint.html}{virgule flottante} normalisée}{Représentation!virgule flottante normalisée} par 
	\begin{equation}
		\{[a_1...a_t],b,e,s\}
	\end{equation}
	où $e\in\eZ,e\in[L,U]$ et $a_j\in\eN;0\leq a_j<b; a_1\geq1$ suivant la formule
	\begin{equation}		\label{EqRepreFlotNOrm}
		x=(-1)^sb^e\sum_{j=1}^ta_jb^{-j}.
	\end{equation}
\end{definition}

\begin{definition}
	L'\defe{erreur relative}{Erreur relative} commise en remplaçant un nombre réel $x$ par une valeur approchée $\hat{x}$ est définie par 
	\begin{equation}
		\epsilon_x:=\left|\frac{x-\hat{x}}{x}\right|.
	\end{equation}
\end{definition}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Permutations}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

On rappelle que toute permutation de $N$ objets s'écrit de manière unique comme composée de cycles disjoints. De plus, tout cycle de longueur $k$ s'écrit comme composée de $k-1$ transpositions. En particulier, pour chaque permutation $\sigma$,  il existe un nombre bien défini $t(\sigma)$ de transpositions dont la composée est $\sigma$. Le signe $\epsilon(\sigma):=(-1)^{t(\sigma)}$ est appelé la \defe{signature}{signature} de la permutation $\sigma$.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Exercices}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


\Exo{SerieUn0002}
\Exo{SerieUn0003}
\Exo{SerieUn0001}
\Exo{SerieUn0004}
\Exo{SerieUn0005}
\Exo{SerieUn0006}
\Exo{SerieUn0007}
\Exo{SerieUn0008}
\Exo{SerieUn0009}

\Exo{SerieTrois0002}
\Exo{SerieDeux0001}
\Exo{SerieDeux0002}
\Exo{SerieDeux0003}
\Exo{SerieDeux0004}
\Exo{SerieDeux0005}
\Exo{SerieDeux0006}

\Exo{SerieTrois0001}
\Exo{SerieTrois0004}
\Exo{SerieTrois0003}	% Volontairement inversé avec le numéro 4.


\Exo{SerieQuatre0001}
\Exo{SerieQuatre0002}
\Exo{SerieQuatre0003}
\Exo{SerieQuatre0004}
\Exo{SerieQuatre0005}
\Exo{SerieQuatre0006}
\Exo{SerieQuatre0007}
\Exo{SerieQuatre0008}
\Exo{SerieCinq0001}
\Exo{SerieCinq0002}
\Exo{SerieCinq0003}
\Exo{SerieCinq0004}
\Exo{SerieCinq0006}
\Exo{SerieCinq0005}

Les exercices qui suivent proviennent d'examens d'années précédentes.

\Exo{examens-0000}
\Exo{examens-0001}
