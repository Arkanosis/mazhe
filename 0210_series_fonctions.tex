% This is part of Mes notes de mathématique
% Copyright (c) 2011-2015
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Série de fonctions}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Les séries de fonctions sont des cas particuliers de suites, étant donné que, par définition,
\begin{equation}
    \sum_{n=1}^{\infty}f_n=\lim_{N\to \infty} \sum_{n=1}^{N}f_n.
\end{equation}

\begin{definition}[Convergence normale] \label{DefVBrJUxo}
    Une série de fonctions \( \sum_{n\in \eN}u_n \) converge \defe{normalement}{convergence!normale} si la série de nombre \( \sum_n\| u_n \|_{\infty}\) converge. C'est à dire si la série converge absolument pour la norme \( \| f \|_{\infty}\).
\end{definition}
Cela n'est rien d'autre que la convergence absolue\footnote{Définition \ref{DefVFUIXwU}.} dans l'espace des fonctions muni de la norme uniforme.

La convergence normale est à ne pas confondre avec la convergence uniforme. La somme \( \sum_nf_n\) \defe{converge uniformément}{convergence!uniforme!série de fonctions} vers la fonction \( F\) si la suite des sommes partielles converge uniformément, c'est à dire si 
\begin{equation}
    \lim_{N\to \infty} \| \sum_{n=1}^Nf_n-F \|_{\infty}=0.
\end{equation}

\begin{lemma}
    Soient des fonctions \( u_n\colon \Omega\to \eC\). Si il existe une suite réelle positive \( (a_n)_{n\in \eN}\) telle que
    \begin{enumerate}
        \item
            pour tout \( z\in \Omega\) et pour tout \( n\in \eN\) nous avons \( | u_n(z) |\leq a_n\) (c'est à dire \( a_n\geq \| u_n \|_{\infty}\)),
        \item
            la somme \( \sum_{n}a_n\) converge,
    \end{enumerate}
    alors la série de fonctions \( \sum_{n=0}^{\infty}u_n\) converge normalement.
\end{lemma}

\begin{proof}
    Découle du lemme de comparaison \ref{LemgHWyfG}.
\end{proof}

\begin{theorem}				\label{ThoSerCritAbel}
	Soit $\sum_{k=1}^{\infty}g_k(x)$, une série de fonctions complexes où $g_k(x)=\varphi_k(x)\psi_k(x)$. Supposons que
	\begin{enumerate}

		\item
			$\varphi_k\colon A\to \eC$ et $| \sum_{k=1}^K\varphi_k(x) |\leq M$ où $M$ est indépendant de $x$ et $K$,
		\item
			$\psi_k\colon A\to \eR$ avec $\psi_k(x)\geq 0$ et pour tout $x$ dans $A$, $\psi_{k+1}(x)\leq \psi_k(x)$, et enfin supposons que $\psi_k(x)$ converge uniformément vers $0$.

	\end{enumerate}
	Alors $\sum_{k=1}^{\infty}g_k$ est uniformément convergente.
\end{theorem}

\begin{theorem}		\label{ThoAbelSeriePuiss}
	Si la série de puissances (réelle) converge en $x=x_0+R$, alors elle converge uniformément sur $\mathopen[ x_0-R+\epsilon , x_0+R \mathclose]$ ($\epsilon>0$) vers une fonction continue.
\end{theorem}


\begin{proposition}     \label{PropUEMoNF}
    Soit \( (u_n)\) une suite de fonctions continues \( u_n\colon \Omega\subset\eC\to \eC\). Si la série \( \sum_nu_n\) converge normalement alors la somme est continue.
\end{proposition}

\begin{proof}
    Nous posons \( u(z)=\lim_{N\to \infty} \sum_{n=0}^N u_n(z)\), et nous vérifions que la fonction ainsi définie sur \( \Omega\) est continue. Soit \( z\in \Omega\) et prouvons la continuité de \( u\) au point \( z\). Pour tout \( z'\) dans un voisinage de \( z\) nous avons 
    \begin{subequations}
        \begin{align}
            \big| u(z)-u(z') \big|&=\left| \sum_{n=0}^{N}u_n(z)-\sum_{n=0}^{N}u_n(z')+\sum_{n=N+1}^{\infty}u_n(z)-\sum_{n=N+1}^{\infty}u_n(z') \right| \\
            &\leq \left| \sum_{n=0}^N u_n(z)-\sum_{n=0}^Nu_n(z') \right| +\sum_{n=N+1}^{\infty}| u_n(z) |+\sum_{n=N+1}^{\infty}| u_n(z') |.
        \end{align}
    \end{subequations}
    Étant donné que les sommes partielles sont continues, en prenant \( N\) suffisamment grand, le premier terme peut être rendu arbitrairement petit. Si \( N\) est suffisamment grand, le second terme est également petit. Par contre, cet argument ne tient pas pour le troisième terme parce que nous souhaitons une majoration pour tout \( z'\) dans une boule autour de \( z\). Nous devons donc écrire
    \begin{equation}
        \sum_{n=N}^{\infty}| u_n(z) |\leq \sum_{n=N+1}^{\infty}\| u_n \|_{\infty}.
    \end{equation}
    Ce dernier est arbitrairement petit lorsque \( N\) est grand. Notons que nous avons utilisé l'hypothèse de convergence normale.
\end{proof}

La même propriété, avec la même démonstration, tient dans le cas d'espaces vectoriels normée.
\begin{proposition} \label{PropOMBbwst}
    Soient \( E\) et \( F\), deux espaces vectoriels normés, \( \Omega\) une partie ouverte de \( E\) et une suite de fonctions \( u_n\colon \Omega\to F\) convergeant normalement sur \( \Omega\), c'est à dire que \( \sum_n\| u_n \|_{\infty}\) converge, la norme \( \| . \|_{\infty} \) devant être comprise comme la norme supremum sur \( \Omega\). Alors la fonction \( u=\sum_nu_n\) est continue sur \( \Omega\).
\end{proposition}

\begin{proof}
    Soit \( x,x'\in \Omega\) en supposant que \( \| x-x' \|\) est petit. Soit encore \( \epsilon>0\). Nous allons montrer la continuité en \( x\). Pour cela nous savons que pour tout \( N\) l'inégalité suivante est correcte :
    \begin{equation}
        \| u(x)-u(x') \|\leq \left\|  \sum_{n=0}^Nu_n(x)-\sum_{n=0}^{N}u_n(x') \right\|+\sum_{n=N+1}^{\infty}\| u_n(x) \|+\sum_{n=N+1}^{\infty}\| u_n(x') \|.
    \end{equation}
    Les deux derniers termes sont majorés par \( \sum_{n=N+1}^{\infty}\| u_n \|_{\infty}\) qui, par hypothèse, peut être rendu aussi petit que souhaité en choisissant \( N\) assez grand. Nous choisissons donc un \( N\) tel que ces deux termes soient plus petits que \( \epsilon\). Ce \( N\) étant fixé, la fonction \( \sum_{n=0}^{N}u_n\) est continue et nous pouvons choisir \( x'\) assez proche de \( x\) pour que le premier terme soit majoré par \( \epsilon\).
\end{proof}

\begin{theorem}			\label{ThoSerUnifCont}
	Si les $g_k$ sont continues et si $\sum g_k$ converge uniformément, alors $\sum g_k$ est continue.
\end{theorem}

Le corollaire suivant permet de considérer des séries de fonctions indexées par exemple par \( \eZ\) plutôt que par \( \eN\).
\begin{corollary}
    Une famille dénombrable de fonctions continues convergeant normalement converge vers une fonction continue.
\end{corollary}

\begin{proof}
    Soit \( I\) dénombrable et considérons une famille de fonctions continues \( (f_n)_{n\in I}\) telles que la famille \( (\| f_i \|_{\infty})_{i\in I}\) soit sommable. Le proposition \ref{PropoWHdjw} nous permet d'utiliser une bijection entre \( I\) et \( \eN\). Le théorème \ref{PropUEMoNF} s'applique alors.
\end{proof}

\begin{theorem}[Critère de Weierstrass]\index{critère!Weierstrass!série de fonctions}		\label{ThoCritWeierstrass}
	Soit une suite de fonctions $f_k\colon A\to \eC$ telles que $| f_k(x) |\leq M_k\in\eR$, $\forall x\in A$. Si $\sum_{k=1}^{\infty}M_k$ converge, alors $\sum_{k=1}^{\infty}f_k$ converge absolument et uniformément.
\end{theorem}

\begin{proof}
    La convergence normale est facile : l'hypothèse dit que \( \| f_k \|_{\infty}\leq M_k\), et donc que
    \begin{equation}
        \sum_{k=1}^{\infty}\| f_k \|_{\infty}\leq \sum_kM_k<\infty.
    \end{equation}
    
    La convergence uniforme est à peine plus subtile. Nous nommons \( F\) la fonction somme. Pour tout \( x\) et pour tout \( N\), nous avons
    \begin{subequations}
        \begin{align}
            \left\| \sum_{n=1}^Nf_n(x)-F(x) \right\|&=\| \sum_{n=N}^{\infty}f_n(x) \|\\
            &\leq\sum_{n=N}^{\infty}\| f_k(x) \|\\
            &\leq \sum_{n=N}^{\infty}\| f_n \|_{\infty}.
        \end{align}
    \end{subequations}
    La convergence normale étant assurée, la série \( \sum_{n_1}^{\infty}\| f_n \|_{\infty}\) est finie, ce qui implique que la queue de somme \( \sum_{n=N}^{\infty}\| f_n \|_{\infty}\) tend vers zéro lorsque \( N\to \infty\). Pour tout \( \epsilon\), il existe donc un \( N\) (non dépendant de \( x\)) tel que
    \begin{equation}
        \| \sum_{n=1}^Nf_n(x)-F(x) \|\leq \epsilon.
    \end{equation}
    En prenant le supremum sur \( x\in A\) nous trouvons la convergence uniforme.
\end{proof}

\begin{remark}
    Il n'y a pas de critère correspondant pour les suites. Il n'est pas vrai que si \( \lim_{n\to \infty}\| f_n \| \) existe, alors \( \lim_{n\to \infty} f_n\) existe, comme le montre l'exemple
    \begin{equation}
        f_n(x)=\begin{cases}
            1    &   \text{si \( x\in\mathopen[ 0 , 1 \mathclose]\) et \( n\) est pair}\\
            1    &    \text{si \( x\in\mathopen[ 1 , 2 \mathclose]\) et \( n\) est impair}\\
             0   &    \text{sinon.}
        \end{cases}
    \end{equation}
\end{remark}

\begin{theorem}      \label{ThoCciOlZ}
    La somme uniforme de fonctions intégrables sur un ensemble de mesure fini est intégrable et on peut permuter la somme et l'intégrale.

    En d'autres termes, supposons que \( \sum_{n=0}^{\infty}f_n\) converge uniformément vers \( F\) sur \( A\) avec \( \mu(A)<\infty\). Si \( F\) et \( f_n\) sont des fonctions intégrables sur \( A\) alors
    \begin{equation}
        \int_AF(x)d\mu(x)=\sum_{n=0}^{\infty}\int_Af_n(x)d\mu(x).
    \end{equation}
\end{theorem}
\index{permuter!somme et intégrale}

\begin{proof}
    Ce théorème est une conséquence du théorème \ref{ThoUnifCvIntRiem}. En effet nous définissons la suite des sommes partielles
    \begin{equation}
        F_N=\sum_{n=0}^Nf_n.
    \end{equation}
    La limite \( \lim_{N\to \infty} F_N=F\) est uniforme. Par conséquent la fonction \( F\) est intégrable et
    \begin{equation}
        \int_A F=\lim_{N\to \infty} \int_AF_N=\lim_{N\to \infty} \int_A\sum_{n=0}^Nf_n=\lim_{N\to \infty} \sum_{n=0}^N\int_Af_n=\sum_{n=0}^{\infty}\int_Af_n.
    \end{equation}
    La première égalité est le théorème \ref{ThoUnifCvIntRiem}, les autres sont de simples manipulations rhétoriques.
\end{proof}


Le théorème suivant est une paraphrase du théorème de la convergence dominée de Lebesgue (\ref{ThoConvDomLebVdhsTf}).
\begin{theorem}     \label{ThoockMHn}
    Soient des fonctions \( (f_n)_{n\in \eN}\) telles que \( \sum_{n=0}^Nf_n\) soit intégrable sur \( (\Omega,\tribA,\mu)\) pour chaque \( N\). Nous supposons que la somme converge simplement vers
    \begin{equation}
        f(x)=\sum_{n=0}^{\infty}f_n(x)
    \end{equation}
    et qu'il existe une fonction \( g\) telle que
    \begin{equation}
        \left| \sum_{n=0}^Nf_n \right| <g
    \end{equation}
    pour tout \( N\in \eN\). Alors
    \begin{enumerate}
        \item
            \( \sum_{n=0}^{\infty}f_n\) est intégrable,
        \item
            on peut permuter somme et intégrale :
            \begin{equation}
                \lim_{N\to \infty} \int_{\Omega}\sum_{n=0}^Nf_nd\mu=\int_{\Omega}\sum_{n=0}^{\infty}f_n,
            \end{equation}
        \item
            \begin{equation}
                \lim_{N\to \infty} \int_{\Omega}\left| \sum_{n=0}^Nf_n-\sum_{n=0}^{\infty}f_n \right| =\lim_{N\to \infty} \int_{\Omega}\left| \sum_{n=N}^{\infty}f_n \right| =0.
            \end{equation}
    \end{enumerate}
\end{theorem}


\begin{theorem} \label{ThoCSGaPY}
    Soit \( f_n\) des fonctions \( C^1\mathopen[ a , b \mathclose]\) telles que
    \begin{enumerate}
        \item
            la série \( \sum_n f_n(x_0)\) converge pour un certain \( x_0\in\mathopen[ a , b \mathclose]\),
        \item
            la série des dérivées \( \sum_n f'_n\) converge uniformément sur \( \mathopen[ a , b \mathclose]\).
    \end{enumerate}
    Alors la série \( \sum_n f_n\) converge vers une fonction \( F\) et
    \begin{enumerate}
        \item
            La convergence est uniforme sur \( \mathopen[ a , b \mathclose]\).
        \item
            La fonction \( F\) est dérivable
        \item
            \( F'(x)=\sum_nf'_n(x)\).
    \end{enumerate}
\end{theorem}

\begin{lemma}
    Soient \( E\) et \( F\) deux espaces vectoriels normés. Si la suite \( (T_n)\) converge vers \( T\) dans \( \aL(E,F)\), alors pour tout \( v\in E\) nous avons
    \begin{equation}
        \left( \sum_{n=0}^{\infty}T_n \right)(v)=\sum_{n=0}^{\infty}T_n(v).
    \end{equation}
\end{lemma}

\begin{theorem}[\cite{DHdwZRZ}] \label{ThoLDpRmXQ}
    Soit \( E\) et \( F\), deux espaces vectoriels normés, \( \Omega\) un ouvert connexe par arcs de \( E\). Soit \( (u_n)\) une suite de fonctions \( u_n\colon \Omega\to F\) telle que
    \begin{enumerate}
        \item
            pour tout \( n\), la fonction \( u_n\) est de classe \( C^1\) sur \( \Omega\),
        \item
            la série \( \sum_nu_n\) converge simplement sur \( \Omega\),
        \item
            la série des différentielles \( \sum_n(du_n)\) converge normalement sur tout compact de \( \Omega\).
    \end{enumerate}
    Alors la somme \( u=\sum_nu_n\) est de classe \( C^1\) sur \( \Omega\) et sa différentielle est donnée par
    \begin{equation}
        du=\sum_{n=0}^{\infty}du_n.
    \end{equation}
\end{theorem}

\begin{proof}
    Pour chaque \( n\), la fonction \( du_n\colon \Omega\to \aL(E,F)\) est une fonction continue parce que \( u_n\) est de classe \( C^1\). La série convergeant normalement, la fonction \( \sum_{n=0}^{\infty}du_n\) est également continue par la proposition \ref{PropOMBbwst}. La difficulté de ce théorème est donc de prouver que cela est bien la différentielle de la fonction \( \sum_nu_n\).

    Soit \( a,x\in \Omega\) et \( \gamma\colon \mathopen[ 0 , 1 \mathclose]\to \Omega\) un chemin joignant \( a\) à \( x\). Nous considérons ce chemin en coordonnées normales et nous notons \( l\) sa longueur. Par définition \ref{EqEFIZyEe},
    \begin{equation}
        \clubsuit=\int_{\gamma}\sum_{n=0}^{\infty}du_n=\int_0^l\sum_n(du_n)_{\gamma(t)}\big( \gamma'(t) \big)dt
    \end{equation}
    Si nous notons \( f_n(t)=(du_n)_{\gamma(t)}\big( \gamma'(t) \big)\), sachant que la paramétrisation est normale (\( \| \gamma'(t) \|=1\)) nous avons\footnote{Histoire de ne pas s'embrouiller, il faut se rendre compte que \( \| du_n \|_{\infty}=\sup_{x\in \Omega}\| (du_n)_x \|\).}
    \begin{equation}
        \| f_n(t) \|\leq \|   (du_n)_{\gamma(t)}  \|\leq \| du_n \|_{\infty}.
    \end{equation}
    Or la série des \( \| du_n \|_{\infty}\) converge par hypothèse. L'intervalle \( \mathopen[ 0 , l \mathclose]\) étant compact, les fonctions \( f_n\) sont uniformément (en \( n\)) bornées par le nombre \( \sum_n\| du_n \|_{\infty}\) qui est intégrable sur \( \mathopen[ 0 , 1 \mathclose]\). Par la convergence dominée (théorème \ref{ThoConvDomLebVdhsTf}) nous permutons la somme et l'intégrale :
    \begin{equation}
        \clubsuit=\sum_{n=0}^{\infty}\int_0^l(du_n)_{\gamma(t)}\big( \gamma'(t) \big)dt=\sum_{n=0}^{\infty}u_n(x)-\sum_{n=0}^{\infty}u_n(a)=u(x)-u(a)
    \end{equation}
    où nous avons utilisé le théorème \ref{ThoUJMhFwU}. Jusqu'à présent nous avons montré que
    \begin{equation}
        u(x)=u(a)+\int_{\gamma}\sum_{n=0}^{\infty}du_n=u(a)+\int_0^l\sum_{n=0}^{\infty}(du_n)_{\gamma(t)}\big( \gamma'(t) \big)dt.
    \end{equation}
    Nous allons utiliser cela pour calculer \( du_x(v)\) selon la bonne vieille formule
    \begin{equation}
        du_x(v)=\Dsdd{ u(x+sv) }{s}{0}.
    \end{equation}
    Cela sera fait en considérant à nouveau un chemin \( \gamma_s \) joignant \( a\) à \( x+sv\) en paramétrisation normale; nous notons \( l_s\) sa longueur. Dans le calcul suivant, nous inversons la somme et l'intégrale de la même façon qu'avant. En piste maestro
    \begin{subequations}
        \begin{align}
            du_x(v)&=\frac{ d  }{ d s }\left.\int_0^{l_s}\sum_{n=0}^{\infty}(du_n)_{\gamma_s(t)}\big( \gamma'_s(t) \big)dt\right|_{s=0}\\
            &=\frac{ d  }{ d s }\left.\sum_{n=0}^{\infty}\int_{\gamma_s}du_n\right|_{s=0}\\
            &=\frac{ d  }{ d s }\sum_{n=0}^{\infty}\Big[ u_n\big( \gamma_s(l_s)\big)-u_n\big( \gamma_s(0) \big)  \Big]_{s=0}\\
            &=d\left( \sum_{n=0}^{\infty}u_n \right)_x(v).
        \end{align}
    \end{subequations}
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Lemme de Borel}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Fonctions plateaux}
%---------------------------------------------------------------------------------------------------------------------------

Soient \( a<b<c<d\) dans \( \eR\). Nous voulons trouver une fonction \( f\in C^{\infty}(\eR)\) à valeurs positives telle que
\begin{enumerate}
    \item
        \( f(x)=1\) si \( x\in\mathopen[ b , c \mathclose]\)
    \item
        \( \supp(f)\subset\mathopen[ a , d \mathclose]\).
\end{enumerate}

Nous commençons par l'exemple classique de fonction \(  C^{\infty}\) qui n'est pas nulle partout :
\begin{equation}
    \varphi(x)=\begin{cases}
        e^{-1/x}    &   \text{si \( x>0\)}\\
        0    &    \text{sinon}.
    \end{cases}
\end{equation}
Il est facile de vérifier que \( \varphi\) est de classe \(  C^{\infty}\) parce que
\begin{equation}
    \lim_{x\to 0^+} \frac{  e^{-1/x} }{ P(x) }=0 
\end{equation}
pour tout polynôme \( P\). De plus c'est une fonction qui vaut zéro sur \( \mathopen] -\infty , 0 \mathclose]\). Ensuite nous construisons la fonction
\begin{equation}
    \psi_m(x)=1-\frac{ \int_0^x \varphi(t)dt }{ \int_0^m\varphi(t)dt}=\begin{cases}
        1    &   \text{si \( x<0\)}\\
        0    &    \text{si \( x>m\)}\\
        \text{positive} &\text{si \( x\in\mathopen[ 0 , m \mathclose]\)}.
    \end{cases}
\end{equation}
Cette fonction est encore de classe $ C^{\infty}$. À partir de là nous considérons les fonctions
\begin{subequations}
    \begin{align}
        f_1(x)&=\psi_{d-c}(x-c)=\begin{cases}
            1    &   \text{si \( x<c\)}\\
            0    &    \text{si \( x>d\)}\\
            \text{positive} &\text{si \( x\in\mathopen[ c , d \mathclose]\)}.
        \end{cases}\\
        f_2(x)&=\psi(b-a)(b-x)=\begin{cases}
            0    &   \text{si \( x<a\)}\\
            1    &    \text{si \( x>b\)}\\
            \text{positive} &\text{si \( x\in \mathopen[ a , b \mathclose]\)}.
        \end{cases},
    \end{align}
\end{subequations}
et finalement la fonction suivante répond à la question des fonctions plateaux sur \( \eR\) :
\begin{equation}
    f(x)=f_1(x)f_2(x).
\end{equation}
\index{fonction!définie par une intégrale}

Une variation sur le même thème est l'existence de fonctions infiniment dérivables à support compact, c'est à dire des fonctions dans \(  C^{\infty}_c(\eR^d)=\swD(\eR^d)\). Ces espaces ne sont pas vides, par exemple nous avons la fonction
\begin{equation}    \label{EqOBYNEMu}
    \xi(x)=\begin{cases}
        e^{-1/(1-| x |^2)}    &   \text{si \( x\in B(0,1)\)}\\
        0    &    \text{sinon}.
    \end{cases}
\end{equation}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Le lemme de Borel}
%---------------------------------------------------------------------------------------------------------------------------

\begin{lemma}[Lemme de Borel\cite{KXjFWKA}] \label{LemRENlIEL}
    Soit \( (a_n)\) une suite dans \( \eR\). Il existe une fonction \( u\in C^{\infty}(\eR)\) telle que \( u^{(k)}(0)=a_k\) pour tout \( k\geq 0\).
\end{lemma}
\index{lemme!Borel}
\index{prolongement!de fonctions!lemme de Borel}
\index{dérivabilité!lemme de Borel}

\begin{proof}
    Soit \( \varphi\in C^{\infty}_c(\eR)\) une fonction telle que \( \varphi(x)=1\) si \( | x |\leq \frac{ 1 }{2}\) et telle que \( \supp(\varphi)\subset\mathopen] -1 , 1 \mathclose[\).

    Nous commençons par considérer une suite de réels strictement positifs \( (\lambda_k)\) dont nous fixerons une valeur précise plus tard, et nous posons
    \begin{equation}
        f_k(x)=\varphi(\lambda_k x)\frac{ a_k }{ k! }x^k.
    \end{equation}
    Nous allons étudier la convergence et les propriétés de \( u(x)=\sum_{k=0}^{\infty}f_k(x)\). 

    Calculons (formellement) la \( m\)\ieme dérivée de \( f_k\) :
    \begin{subequations}
        \begin{align}
            f_k^{(m)}(x)&=\frac{ a_k }{ k! }\sum_{l=0}^{m}\binom{ m }{ l }\lambda_k^{m-l}\varphi^{(m-l)}(\lambda_kx)(x^k)^{(l)}\\
            &=a_k\sum_{l=0}^{m}\binom{ l }{ m }\lambda_k^{m-l}\varphi^{(m-l)}(\lambda_kx)\frac{ x^{k-l} }{ (k-l)! }.
        \end{align}
    \end{subequations}
    Notons que nous travaillons à \( m\) fixé et que nous ne nous intéressons qu'aux termes avec \( k\) assez grand; nous pouvons donc supposer \( k\geq m\). De toutes façons pour \( \sum_{k=0}^mf_k\), on a la classe \(  C^{\infty}\), et la permutation de la somme avec tout ce qu'on veut. Vu que \( \varphi\) est continue à support compact nous pouvons poser
    \begin{equation}
        M_m=\max_{0\leq j\leq m}\| \varphi^{j} \|_{\infty}=\max_{0\leq j\leq m}\max_{x\in \eR}| \varphi^{(j)}(x) |.
    \end{equation}
    Nous continuons en nous fixant un \( x\in \eR\) et un \( k\geq m\).

    Si \( | x |>\frac{1}{ \lambda_k }\), alors \( \varphi^{(m)}(\lambda_kx)=0\) parce que \( \lambda_kx\) est strictement hors du support de \( \varphi\) qui est \( \mathopen] -1 , 1 \mathclose[\). Donc pour \( | x |>\frac{1}{ \lambda_k }\).

    Si par contre \( | x |\leq\frac{1}{ \lambda_k }\), nous avons les majorations
    \begin{subequations}
        \begin{align}
        | f^{(m)}_k(x) |&\leq  |a_k|\sum_{l=0}^{m}\binom{ l }{ m }|\lambda_k|^{m-l}\underbrace{\varphi^{(m-l)}(\lambda_kx)}_{\leq M_m}\frac{ 1 }{ (k-l)! }\underbrace{| x |^{k-l}}_{\leq (1/\lambda_k)^{k-l}}\\
        &\leq | a_k |M_m| \lambda_k |^{m-k}\frac{1}{ (k-m)! }\sum_{l=0}^{m}\binom{ m }{ l }\\
        &\leq \frac{ | a_k |M_m | \lambda_k |^{m-k}2^m }{ (k-m)! }\\
        &= \frac{ | a_k |M_m 2^m }{ (k-m)!  | \lambda_k |^{k-m} }       \label{EqQSPUaun}
        \end{align}
    \end{subequations}
    où pour faire disparaître la somme de coefficients binomiaux, nous avons remarqué que \( \sum_{l=0}^m\binom{ m }{ l }\) est le nombre total de termes dans le développement de \( (a+b)^m\), c'est à dire \( 2^m\). Nous voulons, pour \( m\) fixé, étudier la convergence de la somme de cela. Notons que le \( 2^m\) n'a en particulier strictement aucune importance parce qu'on travaille à \( m\) fixé.

    Nous fixons maintenant la valeur des \( \lambda_k\) :
    \begin{equation}
        \lambda_k=\max\{ | a_k |,1 \}.
    \end{equation}
    Avec cela, en nous souvenant que nous n'étudions que les termes \( k>m\), le dénominateur de \eqref{EqQSPUaun} est réellement croissant en \( k\), donc nous avons la majoration
    \begin{equation}
        | f^{(m)}_k(x) |\leq \frac{ M_m2^m }{ (k-m)! }.
    \end{equation}
    Au final nous avons
    \begin{equation}
        \| f_k^{(m)} \|_{\infty}\leq \frac{ 2^mM_m }{ (k-m)! }.
    \end{equation}
    Et la somme de cela converge sans difficultés. Donc la série
    \begin{equation}
        u(x)=\sum_{k=0}^{\infty}f_k^{(m)}(x)
    \end{equation}
    converge normalement et donc uniformément sur \( \eR\). Nous pouvons alors permuter la somme et la dérivation par le théorème \ref{ThoCSGaPY}. Donc
    \begin{equation}
        u^{(m)}=\sum_{k=0}^{\infty}f_k^{(m)}
    \end{equation}
    est continue. En particulier, pour évaluer en zéro, on peut faire
    \begin{equation}
        u^{(m)}(0)=\sum_{k=0}^{\infty}f_k^{(m)}(0).
    \end{equation}
    Nous avons
    \begin{equation}
        f_k(x)=\varphi(\lambda_kx)\frac{ a_k }{ k! }x^k.
    \end{equation}
    Pour calculer la dérivée en zéro, il suffit de la calculer sur un voisinage sur lequel \( \varphi(\lambda_kx)\) est la constante \( 1\); un tel voisinage existe pour tout \( k\). À ce moment le calcul est classique :
    \begin{equation}
        f_k^{(m)}(x)=\begin{cases}
            a_k    &   \text{si \( k=m\)}\\
            0    &    \text{sinon}.
        \end{cases}
    \end{equation}
    Finalement nous avons bien
    \begin{equation}
        u^{(m)}(0)=\sum_{k=0}^{\infty}f_k^{(m)}(0)=a_k.
    \end{equation}
    
\end{proof}

\begin{remark}
    Pour prouver le lemme de Borel, la première chose qui passe par la tête est la fonction toute simple
    \begin{equation}
        u(x)=\sum_{k=0}^{\infty}\frac{ a_k }{ k! }x^k.
    \end{equation}
    Évidemment si on calcule les dérivées successives de cette fonction, nous trouvons les bons résultats. Le problème est la convergence.  Rien qu'en prenant \( a_k=k!\), la série ne converge pour aucun \( x\) positifs. L'idée de multiplier chacun de \( f_k\) par une fonction plateau sur un petit intervalle autour de zéro a plusieurs avantages. D'abord on conserve les dérivées correctes parce qu'on ne touche pas à la valeur des \( f_k\) sur un petit voisinage. Ensuite cela ne modifie pas la continuité; et enfin en multipliant par \( \varphi(\lambda_kx)\), ça calme méchamment les divergences parce que \( \lambda_kx\) passe vite au-dessus de \( 1\) (et donc en dehors du support de \( \varphi\)) si \( \lambda_k\) est grand. D'où le fait qu'il soit normal que les \( \lambda_k\) soient de l'ordre des \( a_k\).
\end{remark}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Théorème de Stone-Weierstrass}
%---------------------------------------------------------------------------------------------------------------------------

Comme presque tous les théorèmes importants, le théorème de Stone-Weierstrass possède de nombreuses formulations à divers degrés de généralité.

Le lemme suivant est une cas particulier du théorème \ref{ThoGddfas}, mais nous en donnons une démonstration indépendante afin d'isoler la preuve de la généralisation \ref{ThoWmAzSMF}. Une version pour les polynômes trigonométrique sera donnée dans le lemme \ref{LemXGYaRlC}.

\begin{lemma}       \label{LemYdYLXb}
    Il existe une suite de polynômes sur \( \mathopen[ 0 , 1 \mathclose]\) convergent uniformément vers la fonction racine carré.
\end{lemma}

\begin{proof}
    Nous donnons cette suite par récurrence :
    \begin{subequations}
        \begin{align}
            P_0(t)&=0\\
            P_{n+1}(t)&=P_n(t)+\frac{ 1 }{2}\big( t-P_n(t)^2 \big).
        \end{align}
    \end{subequations}
    Nous commençons par montrer que pour tout \( t\in \mathopen[ 0 , 1 \mathclose]\), \( P_n(t)\in\mathopen[ 0 , \sqrt{t} \mathclose]\). Pour \( P_0\), c'est évident. Ensuite nous avons
    \begin{subequations}
        \begin{align}
            P_{n+1}(t)-\sqrt{t}&=P_n(t)-\sqrt{t}+\frac{ 1 }{2}(t-P_n(t)^2)\\
            &=\big( P_n(t)-\sqrt{t} \big)\left( 1-\frac{ 1 }{2}\frac{ t-P_n(t)^2 }{ P_n(t)-\sqrt{t} } \right)\\
            &=\big( P_n(t)-\sqrt{t} \big)\left( 1-\frac{ \sqrt{t}+P_n(t) }{2} \right)\\
            &\leq 0
        \end{align}
    \end{subequations}
    parce que \( \sqrt{t} \leq 1\) et \( P_n(t)\leq 1\) par hypothèse de récurrence.

    Nous savons au passage que \( P_n(t)\) est une suite réelle croissante parce que \( t-P_n(t)^2\geq t-(\sqrt{t})^2=0\). La suite \( P_n(t)\) est donc croissante et majorée par \( \sqrt{t}\); elle converge donc. Les candidats limites sont déterminés par l'équation
    \begin{equation}
        \ell=\ell+\frac{ 1 }{2}(t-\ell^2),
    \end{equation}
    dont les solutions sont \( \ell=\pm\sqrt{t}\). La suite étant positive, nous avons une convergence ponctuelle de \( P_n\) vers la racine carré. Cette suite étant une suite croissante de fonctions continues sur un compact, convergeant ponctuellement vers une fonction continue, la convergence est uniforme par le théorème de Dini \ref{ThoUFPLEZh}.
\end{proof}

\begin{lemma}           \label{LemUuxcqY}
    Soit \( K\), un compact de \( \eR\) et \( f_n\) une suite de fonctions sur \( K\) convergeant uniformément vers \( f\). Soit \( g\colon X\to K\) une fonction depuis un espace topologique \( K\). Alors \( f_n\circ g\) converge uniformément vers \( f\circ g\).
\end{lemma}

\begin{proof}
    En effet, pour tout \( x\in X\) nous avons
    \begin{equation}
        \| (f_n\circ g)-(f\circ g) \|_{\infty}=\sup_{x\in X} \| f_n\big( g(x) \big)-f\big( g(x) \big) \|\leq \| f_n-f \|_{\infty}.
    \end{equation}
    Par conséquent, si \( \epsilon\>0\) est donné, il suffit de choisir \( n\) de telle sorte à avoir \( \| f_n-f \|_{\infty}<\epsilon\) et nous avons \( \| (f_n\circ g)-(f\circ g) \|_{\infty}\leq \epsilon\).
\end{proof}

\begin{definition}
    Nous disons qu'une algèbre \( A\) de fonctions sur un espace \( X\) \defe{sépare les points}{sépare!les points} de \( X\) si pour tout \( x_1\neq x_2\) il existe \( g\in A\) telle que \( g(x_1)\neq g(x_2)\).
\end{definition}

Nous pouvons maintenant énoncer et démontrer une forme nettement plus générale du théorème de Stone-Weierstrass.
\begin{theorem}[Stone-Weierstrass\cite{MGecheleSW}] \label{ThoWmAzSMF}
    Soit \( X\), un espace compact et Hausdorff et \( A\) une sous algèbre de \( C(X,\eR)\) contenant une fonction constante non nulle. Alors \( A\) est dense dans \( \Big( C(X,\eR),\| . \|_{\infty}\Big)\) si et seulement si \( A\) sépare les points de \(X\).

    Nous pouvons remplacer \( \eR\) par \( \eC\) si de plus l'algèbre \( A\) est auto-adjointe : \( g\in A\) implique \( \bar g\in A\).
\end{theorem}
\index{théorème!Stone-Weierstrass}

\begin{proof}
    Nous allons écrire la démonstration en plusieurs étapes (dont la première est le lemme \ref{LemYdYLXb}).

    \begin{description}
        \item[Première étape] Pour tout \( x\neq y\in X\) et pour tout \( \alpha,\beta\in \eR\), il existe une fonction \( f\in A\) telle que \( f(x)=\alpha\) et \( f(y)=\beta\). 

            En effet, vu que \( A\) sépare les points nous pouvons considérer une fonction \( g\in A\) telle que \( g(x)\neq g(y)\) et ensuite poser
            \begin{equation}
                f(z)=\alpha+\frac{ \alpha-\beta }{ g(y)-g(x) }\big( g(z)-g(x) \big).
            \end{equation}
            Les constantes faisant partie de \( A\), cette fonction \( f\) est encore dans \( A\).

        \item[Seconde étape] Pour tout \( n\)-uples de fonctions \( f_1,\ldots, f_n\) dans \( \bar A\), les fonctions \( \min(f_1,\ldots, f_n)\) et \( \max(f_1,\ldots, f_n)\) sont dans \( \bar A\).

            Nous le démontrons pour \( n=2\); le reste allant évidemment par récurrence. Soient \( f,g\in \bar A\). Étant donné que
            \begin{subequations}
                \begin{align}
                    \max(f,g)&=\frac{ f+g }{2}+\frac{ | f-g | }{2}\\
                    \min(f,g)&=\frac{ f+g }{2}-\frac{ | f-g | }{2},
                \end{align}
            \end{subequations}
            if suffit de montrer que si \( f\in\bar A\) alors \( | f |\in \bar A\). Si \( f\) est nulle, c'est évident; supposons que \( f\neq 0\) et posons \( M=\| f \|_{\infty}\neq 0\). Pour tout \( x\in X\) nous avons
            \begin{equation}
                \frac{ f(x)^2 }{ M^2 }\in \mathopen[ 0 , 1 \mathclose].
            \end{equation}
            Nous considérons alors la suite
            \begin{equation}
                h_n=P_n\circ\frac{ f^2 }{ M^2 }
            \end{equation}
            où \( P_n\) est une suite de polynômes convergent uniformément vers la racine carré (voir lemme \ref{LemYdYLXb}). Le lemme \ref{LemUuxcqY} nous assure que \( h_n\) converge uniformément vers \( \frac{ | f | }{ M }\) dans \( C(X,\eR)\). Étant donné que \( \bar A\) est également une algèbre, \( h_n\) est dans \( \bar A\) pour tout \( n\) et la limite s'y trouve également (pour rappel, la fermeture \( \bar A\) est celle de la topologie de la convergence uniforme).

        \item[Troisième étape] Soit \( \epsilon>0\), \( f\in C(X,\eR)\) et \( x\in X\). Il existe une fonction \( g_x\in \bar A\) telle que 
            \begin{subequations}
                \begin{numcases}{}
                    g_x(x)=f(x)\\
                    g_x(y)\leq f(y)+\epsilon
                \end{numcases}
            \end{subequations}
            pour tout \( y\in X\).

            Soit \( z\in X\setminus\{ x \}\) et une fonction \( h_z\) telle que \( h_z(x)=f(x)\) et \( h_z(z)=f(z)\). Une telle fonction existe par une des étapes précédentes. Étant donné que \( f\) et \( h_z\) sont continues, il existe un voisinage ouvert \( V_z\) de \( z\) sur lequel
            \begin{equation}
                h_z(y)\leq f(y)+\epsilon
            \end{equation}
            pour tout \( y\in V_z\). Nous pouvons sélectionner un nombre fini de points \( z_1,\ldots, z_n\) tels que les ouverts \( V_{z_1},\ldots, V_{z_n}\) recouvrent \( X\) (parce que \( X\) est compact, de tout recouvrement par des ouverts, nous extrayons un sous recouvrement fini.). Nous posons 
            \begin{equation}
                g_x=\min(h_{z_1},\ldots, h_{z_n})\in \bar A.
            \end{equation}
            Si \( y\in X\), nous sélectionnons le \( i\) tel que \( h_{z_i}(y)\leq f(y)+\epsilon\) et nous avons
            \begin{equation}
                g_x(y)\leq h_{z_i}(y)\leq f(y)+\epsilon.
            \end{equation}
            
        \item[Étape \wikipedia{fr}{Final_Doom}{finale}] Soit \( \epsilon>0\) et \( f\in C(X,\eR)\). Pour chaque \( x\in X\) nous considérons une fonction \( g_x\in \bar A\) telle que
            \begin{subequations}
                \begin{numcases}{}
                    g_x(x)=f(x)\\
                    g_x(y)\leq f(y)+\epsilon
                \end{numcases}
            \end{subequations}
            pour tout \( y\in X\). Les fonctions \( f\) et \( g_x\) sont continues, donc il existe un voisinage ouvert \( W_x\) de \( x\) sur lequel
            \begin{equation}
                g_x(y)\geq f(y)-\epsilon.
            \end{equation}
            De ces \( W_x\) nous extrayons un sous recouvrement fini de \( X\) : \( W_{x_1},\ldots, W_{x_m}\) et nous posons
            \begin{equation}
                \varphi=\max(g_{x_1},\ldots, g_{x_n})\in \bar A.
            \end{equation}
            Si \( y\in X\), il existe un \( i\) tel que 
            \begin{equation}
                \varphi(y)\geq g_{x_i}(y)\geq f(y)-\epsilon.
            \end{equation}
            La première inégalité est le fait que \( \varphi\) est le maximum des \( g_{x_k}\), et la seconde est le choix de \( i\). Donc pour tout \( y\in X\) nous avons
            \begin{equation}        \label{EqJMxHaF}
                f(y)-\epsilon\leq \varphi(y)\leq f(y)+\epsilon.
            \end{equation}
            La première inégalité est ce que l'on vient de faire. La seconde est le fait que pour tout \( i\) nous ayons \( g_{x_i}(y)\leq f(y)+\epsilon\); le fait que \( \varphi\) soit le maximum sur les \( i\) ne change pas l'inégalité.

            Le fait que les inégalités \eqref{EqJMxHaF} soient vraies pour tout \( y\in X\) signifie que \( \| \varphi-f \|_{\infty}\leq \epsilon\), et donc que \( f\in \bar{\bar A}=\bar A\).
    \end{description}

    Tout cela prouve que \( C(X,\eR)\subset \bar A\). L'inclusion inverse est le fait que \( C(X,\eR)\) est fermé pour la norme \( \| . \|_{\infty}\), étant donné qu'une limite uniforme de fonctions continues est continue.

\end{proof}

Le théorème suivant est un des énoncés les plus classiques de Stone-Weierstrass. Il découle évidement du théorème général \ref{ThoWmAzSMF} (encore qu'il faut alors bien comprendre qu'il faut traiter la fonction \( x\mapsto \sqrt{x}\) séparément). Il en existe cependant une preuve indépendante.
%TODO : trouver cette preuve indépendante.
\begin{theorem}     \label{ThoGddfas}   \index{théorème!Stone-Weierstrass}
    Soit \( f\), une fonction continue de l'intervalle compact \( \mathopen[ a , b \mathclose]\) à valeurs dans \( \eR\). Alors pour tout \( \epsilon>0\), il existe un polynôme \( P\) tel que \( \| P-f \|_{\infty}<\epsilon\).

    Autrement dit, les polynômes sont denses dans \( C\mathopen[ a , b \mathclose]\) pour la norme uniforme.
\end{theorem}

\begin{corollary}   \label{CorRSczQD}
    Si \( X\subset \eR\) est compact et de mesure finie\footnote{Dans \( \eR\) cette hypothèse est évidemment superflue par rapport à l'hypothèse de compacité; mais ça suggère des généralisations \ldots}, alors l'ensemble des polynômes est denses dans \( \big( C(X,\eR),\| . \|_2 \big)\).
\end{corollary}

\begin{proof}
    Si \( f\) est une fonction dans \( C(X,\eR)\) et si \( \epsilon\geq 0\) est donné alors nous pouvons considérer un polynôme \( P\) tel que \( \| f-P \|_{\infty}\leq \epsilon\). Dans ce cas nous avons
    \begin{equation}
        \| f-P \|_2^2=\int_X| f(x)-P(x) |^2dx\leq \int_X\epsilon^2dx=\epsilon^2\mu(X)
    \end{equation}
    où \( \mu(X)\) est la mesure de \( X\) (finie par hypothèse).
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Primitive de fonction continue}
%---------------------------------------------------------------------------------------------------------------------------

\begin{proposition}[\cite{MQKDooSuEGxk}]    \label{PropQACVooBnHtRJ}
    Soit un intervalle compact \( K\) de \( \eR\) et une suite \( (f_n)\) de fonctions continues sur \( K\) telles que \( f_n\stackrel{unif}{\longrightarrow}f\). Si chacune des fonctions \( f_n\) a une primitive sur \( K\) alors \( f\) également.
\end{proposition}

\begin{proof}
    Soit \( x_0\in K\) et les primitives \( F_n\) choisies\footnote{Les fonctions \( F_n\) étant dérivables sont continues.} pour avoir \( F_n'f_n\) et \( F_n(x_0)=0\). Nous allons voir que \( (F_n)\) est une suite de Cauchy dans \( \big( K,\| . \|_{\infty} \big)\). Soient \( n,m\in \eN\) et \( x\in K\). Nous avons
    \begin{subequations}
        \begin{align}
            \| F_n-F_m \|_{\infty}&\leq \| F_n(x)-F_m(x) \|\\
            &=\| (F_n-F_m)(x) \|\\
            &\leq \| F'_n-F'_m \|_{[x,x_0]}\| x-x_0 \|
        \end{align}
    \end{subequations}
    où nous avons utilisé le théorème des accroissements finis \ref{ThoNAKKght}. Vu que \( x\in K\) et que \( K\) est borné, \( \| x-x_0 \|\) est majoré par \( \diam(K)\) et
    \begin{subequations}
        \begin{align}
            \| F_n-F_m \|_K\leq \| f_n-f_m \|_K\diam(K).
        \end{align}
    \end{subequations}
    Vu que \( (f_n) \) est de Cauchy, si \( n\) et \( m\) sont assez grands, cela tend vers zéro. La suite \( (F_n)\) converge donc vers une certaine fonction \( F\).

    Le théorème \ref{ThoSerUnifDerr} nous permet de permuter la limite et la dérivée pour conclure que \( F'=f\) et donc que \( f\) a une primitive sur \( K\).
\end{proof}

\begin{proposition}[\cite{MQKDooSuEGxk}]        \label{PropKKGAooDQYGKg}
    Soit un intervalle ouvert \( I\) de \( \eR\) et une fonction \( f\colon I\to \eR\) qui admet une primitive sur tout compact de \( I\). Alors \( f\) a une primitive sur \( I\).
\end{proposition}

\begin{proof}
    Nous considérons une suite exhaustive\footnote{Voir le lemme \ref{LemGDeZlOo}.} de compacts \( K_n\) pour \( I\) et \( x_0\in K_0\). Nous considérons aussi \( F_n\) la primitive de \( f\) sur \( K_n\) telle que \( F_n(x_0)=0\) (possible parce que \( x_0\in K_n\) pour tout \( n\)). Les fonctions \( F_n\) sont des restrictions les une des autres, et nous pouvons définir
    \begin{equation}
        \begin{aligned}
            F\colon I&\to \eR \\
            x&\mapsto F_n(x)\text{ si \( x\in K_n\)}. 
        \end{aligned}
    \end{equation}
    Nous avons évidemment \( F(x_0)=0\) et nous allons prouver que \( F\) est une primitive de \( f\) sur \( I\). Soit \( x\in I\) vu que \( I\) est ouvert, nous pouvons choisir \( n_0\) tel que \( x\in\Int(K_{n_0})\). Les fonctions \( F\) et \( F_{n_0}\) sont égales sur \( K_n\) et donc sur un ouvert autour de \( x\). Par conséquent \( F\) est dérivable en \( x\) et \( F'(x)=F'_{n_0}(x)=f(x)\).
\end{proof}


\begin{theorem}\label{ThoEOMRooZPUfJg}
    Soit \( I\) un intervalle ouvert de \( \eR\). Une fonction continue sur \( I\) admet une primitive\footnote{Définition \ref{DefXVMVooWhsfuI}.} sur \( I\).
\end{theorem}

\begin{proof}
    Sur chaque compact de \( I\), la fonction \( f\) est limite uniforme de polynômes\footnote{Si tu veux te passer de Stone-Weierstrass, tu peux prouver que toute fonction continue sur un compact est limite uniforme de fonctions affines par morceaux, par exemple. Voir \cite{MQKDooSuEGxk}.} (théorème de Stone-Weierstrass \ref{ThoGddfas}). Donc \( f\) est primitivable sur tout compact de \( I\) (proposition \ref{PropQACVooBnHtRJ}) et donc sur \( I\) par la proposition \ref{PropKKGAooDQYGKg}.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Théorème taubérien de Hardi-Littlewood}
%---------------------------------------------------------------------------------------------------------------------------

Un théorème \defe{taubérien}{taubérien}\index{théorème!taubérien} est un théorème qui compare les modes de convergence d'une série.

\begin{lemma}
    Si \( f\) et \( g\) sont des fonctions continues, alors \( s(x)=\max\{ f(x),g(x) \}\) est également une fonction continue.
\end{lemma}

\begin{proof}
    Soit \( x_0\) et prouvons que \( s\) est continue en \( x_0\). Si \( f(x_0)\neq g(x_0)\) (supposons \( f(x_0)>g(x_0)\) pour fixer les idées), alors nous avons un voisinage de \( x_0\) sur lequel \( f>g\) et alors \( s=f\) sur ce voisinage et la continuité provient de celle de \( f\).

    Si au contraire \( f(x_0)=g(x_0)=s(x_0)\) alors si \( (a_n)\) est une suite tendant vers \( x_0\), nous prenons \( N\) tel que \( \big| f(a_n)-f(x_0) \big|\leq \epsilon\) pour tout \( n>N\) et \( M\) tel que \( \big| g(a_n)-g(x_0) \big|\leq \epsilon\) pour tout \( n> M\). Alors pour tout \( n>\max\{ N,M \}\) nous avons
    \begin{equation}
        \big| s(a_n)-s(x_0) \big|\leq \epsilon,
    \end{equation}
    d'où la continuité de \( s\) en \( x_0\).
\end{proof}

La proposition suivante dit que si une fonction connaît un saut, alors on peut le lisser par une fonction continue.
\begin{proposition} \label{PropTIeYVw}
    Soit \( f\) continue sur \( \mathopen[ a , x_0 [\) et sur \( \mathopen[ x_0 , b \mathclose]\) avec \( f(x_0^-)<f(x_0)\). En particulier nous supposons que \( f(x^-)\) existe et est finie. Alors pour tout \( \epsilon>0\), il existe une fonction continue \( s\) telle que sur \( \mathopen[ a , b \mathclose]\) on ait \( s\leq f\) et
    \begin{equation}
        \int_a^bs(x)-f(x)\,dx\leq \epsilon.
    \end{equation}
\end{proposition}

\begin{proof}
    Nous notons \( A\) la taille du saut :
    \begin{equation}
        A=f(x_0)-f(x_0^-).
    \end{equation}
    Quitte à changer \( a\) et \( b\), nous pouvons supposer que
    \begin{equation}
        f(x)<f(x_0)+\frac{ A }{ 3 }
    \end{equation}
    pour \( x\in \mathopen[ a , x_0 [\) et 
    \begin{equation}
        f>f(x_0)+\frac{ 2A }{ 3 }
    \end{equation}
    pour \( x\in \mathopen[ x_0 , b \mathclose]\). C'est le théorème des valeurs intermédiaires qui nous permet de faire ce choix.

    Soit \( m(x)\) la droite qui joint le point \( \big( x_0-\epsilon, f(x_0-\epsilon) \big)\) au point \( \big( x_0,f(x_0^+) \big)\). Nous posons
    \begin{equation}
        s(x)=\begin{cases}
            f(x)    &   \text{si \( x<x_0-\epsilon\)}\\
            \max\{ m(x),f(x) \}    &   \text{si \( x_0-\epsilon\leq x\leq x_0\)}\\
            f(x)    &    \text{si $x>x_0$}.
        \end{cases}
    \end{equation}
    En vertu des différents choix effectués, c'est une fonction continue. En effet
    \begin{equation}
        s(x_0-\epsilon)=\max\{ f(x_0-\epsilon),f(x_0,\epsilon) \}=f(x_0-\epsilon)
    \end{equation}
    et 
    \begin{equation}
        s(x_0)=\max\{ m(x_0),f(x_0^+) \}=f(x_0^+)
    \end{equation}
    parce que \( m(x_0)=f(x_0^+)\). En ce qui concerne l'intégrale, si nous posons
    \begin{equation}
        M=\sup_{x,y\in \mathopen[ a , b \mathclose]}| f(x)-f(y) |,
    \end{equation}
    nous avons
    \begin{equation}
        \int_a^bs-f=\int_{x_0-\epsilon}^{x_0}s-f\leq \epsilon M.
    \end{equation}
\end{proof}

\begin{lemma}\label{LemauxrKN}
    Pour tout polynôme \( P\), nous avons la formule
    \begin{equation}
        \lim_{x\to 1^-} (1-x)\sum_{n=0}^{\infty}x^nP(x^n)=\int_0^1P(x)dx.
    \end{equation}
\end{lemma}

\begin{proof}
    D'abord pour \( P=1\), la formule se réduit à la série harmonique connue. Ensuite nous prouvons la formule pour le polynôme \( P=X^k\) et la linéarité fera le reste pour les autres polynômes. Nous avons
    \begin{equation}
        (1-x)\sum_nx^nx^{kn}=(1-x)\sum_n(x^{1+k})^n=\frac{ 1-x }{ 1-x^{1+k} }=\frac{1}{ 1+x+\ldots+x^k }.
    \end{equation}
    Donc
    \begin{equation}
        \lim_{x\to 1^-} (1-x)\sum_nx^nP(x^n)=\frac{1}{ 1+k }.
    \end{equation}
    Par ailleurs, c'est vite vu que
    \begin{equation}
        \int_0^1 x^kdx=\frac{1}{ k+1 }.
    \end{equation}
\end{proof}

\begin{theorem}[Hardy-Littlewood\cite{ytMOpe}]\index{théorème!Hardy-Littlewood}\index{Hardy-Littlewood (théorème)}      \label{ThoPdDxgP}
    Soit \( (a_n)\) une suite réelle telle que
    \begin{enumerate}
        \item
            \( \frac{ a_n }{ n }\) tends vers une constante,
        \item
            \( F(x)=\sum_{n=0}^{\infty}a_nx^n\) a un rayon de convergence \( \geq 1\),
        \item
            \( \lim_{x\to 1^-} F(x)=l\).
    \end{enumerate}
    Alors \( \sum_{n=0}^{\infty}a_n=l\).
\end{theorem}
\index{convergence!suite numérique}
\index{série!nombres}
\index{série!fonctions}
\index{limite!inversion}
\index{approximation!par polynômes}

\begin{proof}
    Quitte à prendre la suite \( b_0=a_0-l\) et \( b_n=a_n\), on peut supposer \( l=0\).

    Soit \( \Gamma\) l'ensemble des fonctions
    \begin{equation}
         \gamma\colon \mathopen[ 0 , 1 \mathclose]\to \eR 
    \end{equation}
    telles que 
    \begin{enumerate}
        \item
            $\sum_{n=0}^{\infty}a_n\gamma(x^n)$ converge pour \( 0\leq x<1\),
        \item
            \( \lim_{x\to 1^-} \sum_{n\geq 0}a_n\gamma(^n)=0\).
    \end{enumerate}
    Ce \( \Gamma\) est un espace vectoriel.
    \begin{subproof}
    \item[Les polynômes sont dans \( \Gamma\)]
        Soit \( \gamma(t)=t^s\). Pour \( 0\leq x<1\) nous avons
        \begin{equation}
            \sum_{n=0}^{\infty}a_n\gamma(x^n)=\sum_{n=0}^{\infty}a_nx^{ns}<\sum_{n=0}^{\infty}a_nx^n.
        \end{equation}
        Donc la condition de convergence est vérifiée. En ce qui concerne la limite,
        \begin{equation}
            \lim_{x\to 1^-} \sum_{n=0}^{\infty}a_nx^{ns}=\lim_{x\to 1^-} F(x^s)=0
        \end{equation}
        parce que par hypothèse, \( \lim_{x\to 1^-} F(x)=0\).

    \item[Définition de la fonction qui va donner la réponse]
        Nous considérons la fonction \( g=\mtu_{\mathopen[ \frac{ 1 }{2} , 1 \mathclose]}\), c'est à dire
        \begin{equation}
            g(t)=\begin{cases}
                0    &   \text{si \( 0\leq t<1/2\)}\\
                1    &    \text{si \( 1/2\leq t\leq 1\)}.
            \end{cases}
        \end{equation}
        Nous montrons que si \( g\in \gamma\), alors le théorème est terminé. Si \( 0\leq x\leq 1\), on a \( 0\leq x^n<1/2\) dès que
        \begin{equation}
            n>-\frac{ \ln(2) }{ \ln(x) }
        \end{equation}
        avec une note comme quoi \( \ln(x)<0\), donc la fraction est positive. Nous désignons par \( N_x\) la partie entière de ce \( n\) adapté à \( x\). L'idée est que la fonction  \( g(x^n)\) est la fonction indicatrice de \(0 \leq n\leq N_x\), et donc
        \begin{equation}
            \sum_{n\geq 0}a_ng(x^n)=\sum_{n=0}^{N_x}a_n.
        \end{equation}
        Mais si \( x\to 1^-\), alors \( N_x\to \infty\), donc
        \begin{equation}
            \lim_{N\to \infty} \sum_{n=0}^Na_n=\lim_{x\to 1^-} \sum_{n=0}^{N_x}a_n=\lim_{x\to 1^-} \sum_{n\in \eN}a_ng(x^n),
        \end{equation}
        et cela fait zéro si \( g\in \Gamma\).
        
    \item[Approximation de \( g\) par des polynômes]

        Nous considérons la fonction
        \begin{equation}
            h(t)=\frac{ g(t)-t }{ t(1-1) }=\begin{cases}
                \frac{1}{ t-1 }    &   \text{si \( t\in \mathopen[ 0 , 1/2 [\)}\\
                \frac{1}{ t }    &    \text{si \( t\in \mathopen[ 1/2 , 1 \mathclose]\)}.
            \end{cases}
        \end{equation}
        La seconde égalité est au sens du prolongement par continuité. La fonction \( h\) est une fonction non continue qui fait un saut de \( -2\) à \( 2\) en \( x=1/2\). En vertu de la proposition \ref{PropTIeYVw} (un peu adaptée), nous pouvons considérer deux fonctions continues \( s_1\) et \( s_2\) telles que
        \begin{equation}
            s_1\leq h\leq s_2
        \end{equation}
        et
        \begin{equation}
            \int_{0}^1s_2-s_1\leq \epsilon.
        \end{equation}
        Notons que l'inégalité \( s_1\leq s_2\) doit être stricte sur au moins un petit intervalle autour de \( x=1/2\). Soient \( P_1\) et \( P_2\), deux polynômes tels que \( \| P_1-s_1 \|_{\infty}\leq \epsilon\) et \( \| P_2-s_2 \|_{\infty}\leq \epsilon\) (ici la norme supremum est prise sur \( \mathopen[ 0 , 1 \mathclose]\)). C'est le théorème de Stone-Weierstrass (\ref{ThoGddfas}) qui nous permet de le faire.

        Nous posons aussi\footnote{À ce niveau, je crois qu'il y a une faute de frappe dans \cite{ytMOpe}.}
        \begin{subequations}
            \begin{align}
                Q_1=P_1+\epsilon\\
                Q_2=P_2-\epsilon.
            \end{align}
        \end{subequations}
        Nous avons
        \begin{equation}
            \int_0^1Q_1-Q_2\leq\int_0^1 Q_1-P_1+P_1-P_2+P_2-Q_2.
        \end{equation}
        Pour majorer cela, d'abord \( Q_1-P_1=P_2-Q2=\epsilon\), ensuite,
        \begin{equation}
            P_1-P_2=P_1-s_1+s_1-s_2+s_2-P_2
        \end{equation}
        dans lequel nous avons \( P_1-s_1\leq \epsilon\), \( s_2-P_2\leq \epsilon\) et \( \int_0^1s_1-s_2\leq\epsilon\). Au final, nous posons \( q=Q_2-Q_1\) et nous avons
        \begin{equation}
            \int_0^1q\leq 5\epsilon.
        \end{equation}
        Enfin nous posons aussi
        \begin{equation}
            R_i(x)=x+x(1-x)Q_i.
        \end{equation}
        Ces polynômes vérifient \( R_i(0)=0\), \( R_i(1)=1\) et
        \begin{equation}
            R_1\leq g\leq R_2
        \end{equation}
        parce que
        \begin{equation}
            Q_1\leq P_1\leq h\leq  P_2\leq Q_2
        \end{equation}
        et
        \begin{equation}
            t+t(1-t)Q_1\leq \underbrace{t+t(1-t)h(t)}_{g(t)}\leq t+t(1-t)Q_2.
        \end{equation}
        
    \item[Preuve que \( g\) est dans \( \Gamma\)]

        D'abord si \( 0\leq x<1\), \( x^N<\frac{ 1 }{2}\) pour un certain \( N\), et alors \( g(x^N)=0\). Du coup la série
        \begin{equation}
            \sum_{n=0}^{\infty}a_ng(x^n)=\sum_{n=0}^{N}a_n
        \end{equation}
        est une somme finie qui converge donc.

        D'autre part nous prenons \( M\) tel que \( | a_n |<\frac{ M }{ n }\) pour tout \( n\). Nous majorons \( \sum_{n \in \eN}a_ng(x^n)\) en utilisant \( R_1\). Mais vu que \( R_1\) est un polynôme, nous pouvons dire que \( | \sum_{n=0}^{\infty}a_nR_1(x^n) |\leq \epsilon\) en prenant \( x\in\mathopen[ \lambda , 1 [\) et \( \lambda\) assez grand. Nous avons :
        \begin{subequations}
            \begin{align}
                \left| \sum_{n=0}^{\infty}a_ng(x^n) \right| &\leq\left| \sum_{n=0}^{\infty}a_ng(x^n)-\sum_{n=0}^{\infty}a_nR_1(x^n) \right| +\underbrace{\left| \sum_{n=0}^{\infty}a_nR_1(x^n) \right|}_{\leq \epsilon} \\
                &\leq \epsilon+\sum_{n=0}^{\infty}| a_n |(g-R_1)(x^n)\\
                &\leq \epsilon+\sum_{n=0}^{\infty}| a_n |(R_2-R_1)(x^n)\\
                &\leq \epsilon+M\sum_{n=0}^{\infty}\frac{ x^n(1-x^n) }{ n }(Q_2-Q_1)(x^n)   &R_2-R_1=x(1-x)(Q_2-Q_1)\\
                &=\epsilon+M\sum_{n=0}^{\infty}\frac{ x^n(1-x^n) }{ n }q(x^n)\\
                &\leq \epsilon+M(1-x)\sum_nx^nq(x^n)   \label{subeqtZXDvu} 
            \end{align}
        \end{subequations}
        où la ligne \eqref{subeqtZXDvu} provient d'une majoration sauvage de \( 1/n\) par \( 1\) et de \( 1-x^n\) par \( 1-x\). Par le lemme \ref{LemauxrKN}, nous avons alors
        \begin{equation}
            \lim_{x\to 1^-} | \sum_na_ng(x^n) |\leq \epsilon+M\int_0^1q\leq 6\epsilon.
        \end{equation}
    \end{subproof}
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Théorème de Müntz}
%---------------------------------------------------------------------------------------------------------------------------

\begin{theorem}[Théorème de Müntz\cite{jqZSyG,oYGash}]  \label{ThoAEYDdHp}
    Soit \( C=C_0\big( \mathopen[ 0 , 1 \mathclose] \big)\), l'espace des fonctions continues sur \( \mathopen[ 0 , 1 \mathclose]\) muni de la norme \( \| . \|_{\infty}\) ou \( \| . \|_2\) et une suite \( (\alpha_n)\) strictement croissante de nombres positifs. Nous notons \( \phi_{\lambda}\) la fonction \( x\mapsto x^{\lambda}\).

    Alors l'espace \( \Span\{ \phi_{\alpha_n} \}\) est dense dans \( C\) si et seulement si \( \sum_{n=1}^{\infty}\frac{1}{ \alpha_n }\) diverge.
\end{theorem}

Nous prouvons le théorème pour la norme \( \| . \|_2\).
\begin{proof}
    Soit \( m\in \eR^+\); nous notons \( \Delta_N(m)\) la distance entre \( \phi_m\) et \( \Span\{ \phi_{\alpha_1},\ldots, \phi_{\alpha_N} \}\). Cette distance peut être évaluée avec le déterminant de Gram\index{déterminant!Gram} (proposition \ref{PropMsZhIK})
    \begin{equation}
        \Delta_N(m)^2=\frac{ G(\phi_m,\phi_{\alpha_1},\ldots, \phi_{\alpha_N}) }{ G(\phi_{\alpha_1},\ldots, \phi_{\alpha_N}) }.
    \end{equation}
    Pour calculer cela nous avons besoin des produits scalaires\footnote{C'est ici qu'on se particularise à la norme \( \| . \|_2\).}
    \begin{equation}
        \langle \phi_a, \phi_b\rangle =\int_0^1 x^{a+b}dx=\frac{1}{ a+b+1 }.
    \end{equation}
    Donc nous avons à calculer le déterminant
    \begin{equation}
        G(\phi_m,\phi_{\alpha_1},\ldots, \phi_{\alpha_N})=\det\begin{pmatrix}
            \frac{1}{ 2m+1 }   &   \frac{1}{ m+\alpha_1+1 }    &   \cdots    &   \frac{1}{ m+\alpha_N+1 }    \\
            \frac{1}{ m+\alpha_1+1 }   &   \frac{1}{ 2\alpha_1+1 }    &   \cdots    &   \frac{1}{ \alpha_1+\alpha_N+1 }    \\
             \vdots   &   \vdots    &   \ddots    &   \vdots    \\ 
             \frac{1}{ m+\alpha_N+1 }   &   \frac{1}{ \alpha_1+\alpha_N+1 }    &   \cdots    &   \frac{1}{ 2\alpha_N+1 }     
         \end{pmatrix}
    \end{equation}
    dans lequel nous reconnaissons un déterminant de Cauchy (proposition \ref{ProptoDYKA})\index{déterminant!Cauchy} en posant, dans \( \frac{1}{ \alpha_i+\alpha_j+1 }\), \( a_i=\alpha_i\) et \( b_j=\alpha_j+1\). Au passage nous nommons \( \alpha_0=m\) pour se simplifier les notations. Avec ces conventions, étant donné que \( b_j-b_i=a_j-a_i\), les facteurs des deux produits
    \begin{equation}
        \prod_{i<j}(a_j-a_i)\prod_{i<j}(b_j-b_i)
    \end{equation}
    sont les mêmes et donc le numérateur de \( G(\phi_m,\phi_{\alpha_1},\ldots, \phi_{\alpha_N})\) est donné par
    \begin{equation}
        \prod_{i<j}(\alpha_i-\alpha_j)^2\prod_i(\alpha_i-m)^2.
    \end{equation}
    En ce qui concerne le dénominateur, il faut prendre tous les couples \( (i,j)\) avec \( i\) et \( j\) éventuellement égaux à zéro. Nous décomposant cela en trois paquets. Le premier est \( (0,0)\); le second est \( (0,i)\) (chaque couple arrive en fait deux fois parce qu'il y a aussi \( (i,0)\)); et le troisième sont les \( i,j\) tous deux différents de zéro :
    \begin{equation}
        (2m+1)\prod_{ij}(\alpha_i+\alpha_j+1)\prod_i(\alpha_i+m+1)^2.
    \end{equation}
    Notons que dans le produit central, le carré est contenu dans le fait qu'on écrit \( \prod_{ij}\) et non \( \prod_{i<j}\). Nous avons donc
    \begin{equation}
        G(\phi_m,\phi_{\alpha_1},\ldots, \phi_{\alpha_N})=\frac{ \prod_{i<j}(\alpha_i-\alpha_j)^2\prod_i(\alpha_i-m)^2 }{ (2m+1)\prod_{ij}(\alpha_i+\alpha_j+1)\prod_i(\alpha_i+m+1)^2 }.
    \end{equation}
    
    Le calcul de \( G(\phi_{\alpha_1},\ldots, \phi_{\alpha_N})\) est plus simple\footnote{Je crois qu'il y a une faute de frappe dans le dénominateur de \cite{jqZSyG}.} :
    \begin{equation}
        G(\phi_{\alpha_1},\ldots, \phi_{\alpha_N})=\frac{ \prod_{i<j}(\alpha_i-\alpha_j)^2 }{ \prod_{ij}(\alpha_i+\alpha_j+1) }.    
    \end{equation}
    En divisant l'un par l'autre il ne reste que les facteurs comprenant \( m\) et en prenant la racine carré,
    \begin{equation}    \label{EqANiuNB}
        \Delta_N(m)=\frac{1}{ \sqrt{2m+1} }\prod_{i=1}^N\left| \frac{ \alpha_i-m }{ \alpha_i+m+1 } \right| .
    \end{equation}
    
    Nous passons maintenant à la preuve proprement dite. Supposons que \( V=\Span\{ \phi_{\alpha_i},i\in \eN \}\) est dense; alors nous avons en particulier que \( \phi_m\) peut être arbitrairement approché par les \( \phi_{\alpha_i}\), c'est à dire que
    \begin{equation}
        \lim_{N\to \infty} \Delta_N(m)=0
    \end{equation}
    Nous posons 
    \begin{equation}
        u_n=\ln\left( \frac{ \alpha_n-m }{ \alpha_n+m+1 } \right)
    \end{equation}
    et nous prouvons que la série \( \sum_nu_n\) diverge. En effet nous nous souvenons de la formule \( \ln(ab)=\ln(a)+\ln(b)\), de telle sorte que la \( N\)ième somme partielle de \( \sum_nu_n\) est
    \begin{equation}
        \ln\left( \frac{ \alpha_1-m }{ \alpha_1+m+1 }\cdot\ldots\cdot \frac{ \alpha_N-m }{ \alpha_N+m+1 } \right)=\ln\left( \sqrt{2m+1}\Delta_N(m) \right),
    \end{equation}
    qui tends vers \( -\infty\) lorsque \( N\to \infty\).

    Si la suite \( (\alpha_n)\) est majorée et plus généralement si nous n'avons pas \( \alpha_n\to \infty\), alors évidemment la série \( \sum_n\frac{1}{ \alpha_n }\) diverge. Nous supposons donc que \( \lim_{n\to \infty} \alpha_n=\infty\). Nous avons aussi\footnote{Je crois qu'il y a une faute de signe dans la dernière expression de \cite{oYGash}.}
    \begin{equation}
        u_n=\ln\left( \frac{ \alpha_n-m }{ \alpha_n+m+1 } \right)=\ln\left( 1-\frac{ 2m+1 }{ \alpha_n+m+1 } \right)\sim-\frac{ 2m+1 }{ \alpha_n }.
    \end{equation}
    Une justification est donné à l'équation \eqref{EqGICpOX}. Ce que nous avons surtout est
    \begin{equation}
        \sum_n u_n\sim -(2m+1)\sum_n\frac{1}{ \alpha_n }.
    \end{equation}
    Étant donné que la série de gauche diverge, celle de droite diverge\footnote{Nous utilisons le fait que si \( u_n\sum v_n\) en tant que suites et si \( \sum_nu_n\) diverge, alors \( \sum_nv_n\) diverge.}.

    Nous faisons maintenant le sens opposé : nous supposons que la série \( \sum_n1/\alpha_n\) diverge et nous nous posons
    \begin{equation}
        V=\Span\{ \phi_{\alpha_n}\tq n\in \eN \}.
    \end{equation}
    Si \( \alpha_n\to \infty\), alors il suffit de prouver que \( \phi_m\in \bar V\) pour tout \( m\) parce qu'un corollaire du théorème de Stone-Weierstrass \ref{CorRSczQD} montre que \( \Span\{ \phi_k\tq k\in \eN \}\) est dense dans \( C\) pour la norme \( \| . \|_2\). Nous avons :
    \begin{equation}
        u_n\sim\frac{ 2m+1 }{ \alpha }\to 0
    \end{equation}
    et alors \( \Delta_N(m)\to 0\). Dans ce cas nous avons immédiatement \( \phi_m\in \bar V\).

    Si par contre \( \alpha_n\) ne tend pas vers l'infini, nous repartons de l'expression \eqref{EqANiuNB}, nous posons \( \alpha=\sup_i\alpha_i\) et nous calculons :
    \begin{subequations}
        \begin{align}
            \sqrt{2m+1}\Delta_N(m)&=\prod_{i=1}^N\frac{ | \alpha_i-m | }{ \alpha_i+m+1 }\\
            &\leq \prod_{i=1}^N\frac{ \alpha_i+m }{ \alpha_i+m+1 }\\
            &=\prod_{i=1}^N\left( 1-\frac{ 1 }{ \alpha_i+m+1 } \right)\\
            &\leq \prod_{i=1}^N\left( 1-\frac{1}{ \alpha+m+1 } \right)\\
            &=\left( 1-\frac{1}{ \alpha+m+1 } \right)^N.
        \end{align}
    \end{subequations}
    Cette dernière expression tend vers \( 0\) lorsque \( N\to \infty\).
\end{proof}

\begin{example}
    Nous savons depuis le théorème \ref{ThonfVruT} que la somme des inverses des nombres premiers diverge.
\end{example}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Séries entières}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Source : \cite{RomainBoilEnt}. 

Dans cette section nous allons parler de séries complexes autant que de séries réelles. L'étude des propriétés à proprement parler complexes des séries entières (holomorphie) sera effectuée dans le chapitre dédié, voir le théorème \ref{ThomcPOdd} et ses conséquences.

Une \defe{série de puissance}{série!de puissance} est une série de la forme
\begin{equation}		\label{eqseriepuissance}
	\sum_{k=0}^{\infty}c_k(z-z_0)^k
\end{equation}
où $z_0\in \eC$ est fixé, $(c_k)$ est une suite complexe fixée, et $z$ est un paramètre complexe. Nous disons que cette série est \emph{centrée} en $z_0$.

\begin{definition}
    Une \defe{série entière}{série!entière} est une somme de la forme
    \begin{equation}
        \sum_{n=0}^{\infty}a_nz^n
    \end{equation}
    avec \( a_n,z\in\eC\).    
\end{definition}
Une série entière peut définir une fonction
\begin{equation}
    f(z)=\sum_na_nz^n.
\end{equation}
Le but de cette section est d'étudier des conditions sur la suite \( (a_n)\) qui assurent la continuité de \( f\) ou la possibilité de dériver ou intégrer la série terme à terme.


\begin{lemma}[Critère d'Abel]\index{critère!Abel}   \label{LemmbWnFI}
    Soit \( (a_n)\) une suite dans \( \eC\) et \( r>0\). Si la suite \( (a_nr^n)\) est bornée alors pour tout \( z\in B(0,r)\) la série \( \sum a_nz^n\) converge absolument.
\end{lemma}

\begin{proof}
    Soit \( M\in \eR\) tel que \( | a_n |r^n\leq M\) pour tout \( n\). Alors nous avons
    \begin{equation}
        | a_nz^n |=| a_n |r^n\big( \frac{ | z | }{ r } \big)^n\leq M\left( \frac{ | z | }{ r } \right)^n
    \end{equation}
    Si \( | z |<r\) alors nous tombons sur la série géométrique qui converge. Par le critère de comparaison la série \( \sum_{n=0}^{\infty}| a_nz^n |\) converge.
\end{proof}

\begin{definition}  \label{DefZWKOZOl}
    Soit \( \sum_{n\in \eN}a_nz^n\) une série entière. Le \defe{rayon de convergence}{rayon!de convergence} de cette série est le nombre
    \begin{equation}
        R=\sup\{ r\in \eR^+\tq \text{la suite \((a_nr^n)\) est bornée} \}\in\mathopen[ 0 , \infty \mathclose].
    \end{equation}
    Étant donné que cela est une propriété de la suite \( (a_n)\) et non réellement de la série \( \sum_ka_kz^k\), nous allons aussi dire que c'est le rayon de convergence de la suite \( (a_n)\).
\end{definition}
Le rayon de convergence d'une série ne dépend que des réels \( | a_n |\), même si à la base \( a_n\in \eC\).

\begin{theorem} \label{ThoLPWeIHE}
    Soit \( R>0\) le rayon de convergence de la somme \( \sum_na_nz^n\) et \( z\in \eC\).
    \begin{enumerate}
        \item
            Si \( | z |<R\) alors la série converge absolument.
        \item
            Si \( R<\infty\) et si \( | z |>R\) alors la suite \( (a_nz^n)\) n'est pas bornée et la série diverge.
    \end{enumerate}
\end{theorem}

\begin{proof}
    \begin{enumerate}
        \item
            Étant donné que \( | z |<R\), il existe \( r>0\) tel que \( | z |<r<R\). On a que \( (a_nr^n)\) est borné (parce que \( R\) est le supremum) et donc \( (a_n| z_n |)\) est bornée. Le critère d'Abel conclu.
        \item
            Par hypothèse la suite \( (a_n| z |^n)\) n'est pas bornée. La suite \( (a_nz^n)\) n'est donc pas bornée non plus et la série ne peut pas converger.
    \end{enumerate}
\end{proof}

Le théorème \ref{ThoLPWeIHE} parle bien de convergence absolue, et non de convergence normale. Pour chaque \( t\), la série \( \sum_k | a_nt^k |\) converge. Si par contre nous posons \( u_k(t)=a_kt^k\), nous n'avons a priori pas la convergence normale \( \sum_k\| u_k \|_{\infty}\), même pas si la norme est la norme supremum sur \( B(0,R)\)\quext{Il y aurait par contre bien convergence sur tout compact ? Cher lecteur, dites moi ce que vous en pensez}. Prenons comme exemple simplement \( a_k=1\) pour tout \( k\). Pour tout \( | t |<1\), la série \( \sum_k t^k\) converge absolument (série géométrique), mais nous aurions \( \| u_k \|_{\infty}=1\) et donc divergence évidente de \( \sum_k\| u_k \|_{\infty}\).

\begin{theorem}[Formule de Hadamard]\index{formule!Hadamard}\index{Hadamard!formule}		\label{ThoSerPuissRap}
Le rayon de convergence de la série entière \( \sum_n c_n z^n\) est donné par une des deux formules
\begin{equation}		\label{EqRayCOnvSer}
	\frac{1}{ R } =\limsup\sqrt[k]{| a_k |}
\end{equation}
ou
\begin{equation}		\label{EqAlphaSerPuissAtern}
	\frac{1}{ R }=\limite k \infty \abs{\frac{a_{k+1}}{a_k}}
\end{equation}
lorsque $a_k$ est non nul à partir d'un certain $k$.
\end{theorem}

Le disque $| z-z_0 |\leq R$ est le \defe{disque de convergence}{disque de convergence} de la série \( \sum_n a_n(z-z_0)^n\). Notons que le critère d'Abel ne dit rien pour les points tels que $| z-z_0 |=R$. Il faut traiter ces points au cas par cas. Et le pire, c'est qu'une série donnée peut converger pour certain des points sur le bord du disque, et diverger en d'autres. Le théorème d'Abel radial (théorème \ref{ThoLUXVjs}) nous donnera quelque informations sur le sujet.

Il y a un dessin à la figure \ref{LabelFigDisqueConv}.
\newcommand{\CaptionFigDisqueConv}{À l'intérieur du disque de convergence, la convergence est absolue. En dehors, la série diverge. Sur le cercle proprement dit, tout peut arriver.}
\input{Fig_DisqueConv.pstricks}

Si les suites \( a_n\) et \( b_n\) sont équivalentes, alors les séries correspondantes auront le même rayon de convergence. Cela ne signifie pas que sur le bord du disque de convergence, elles aient même comportement. Par exemple nous avons
\begin{equation}
    \frac{1}{ \sqrt{n} }\sim \frac{1}{ \sqrt{n} }+\frac{ (-1)^n }{ n }.
\end{equation}
En même temps, en \( z=-1\) la série 
\begin{equation}
    \sum_{n\geq 1}\frac{ z^n }{ \sqrt{n} }
\end{equation}
converge par le critère des séries alternées (corollaire \ref{CoreMjIfw}). Par contre la série
\begin{equation}
    \sum_{n\geq 1}\left( \frac{1}{ \sqrt{n} }+\frac{ (-1)^n }{ n } \right)z^n
\end{equation}
ne converge pas pour \( z=-1\).

\begin{example}
    Soit \( \alpha\in \eR\) et considérons la série \( \sum_{n\geq 1}a_nz^n\) où \( a_n\) est la \( n\)-ième décimale de \( \alpha\). Si \( \alpha\) est un nombre décimal limité, la suite \( (a_n)\) est finie et le rayon de convergence est infini. Sinon, pour tout \( N\) il existe un \( n>N\) tel que \( a_n\neq 0\) et la suite \( (a_n)\) ne tend pas vers zéro. Par conséquent la série
    \begin{equation}
        \sum_{n}a_nz^n
    \end{equation}
    diverge pour \( z=1\) et le rayon de convergence satisfait \( R\leq 1\). Nous avons aussi \( | a_n |\leq 9\), de telle manière à ce que la série soit bornée et par conséquent majorée en module par \( 9z^n\), ce qui signifie que \( R\geq 1\). 

    Nous déduisons alors \( R=1\).
\end{example}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Propriétés de la somme}
%---------------------------------------------------------------------------------------------------------------------------

\begin{theorem}     \label{ThokPTXYC}
    Soient \( \sum_na_nz^n\) et \( \sum b_nz^n\) deux séries de rayon de convergences respectivement \( R_a\) et \( R_b\).
    \begin{enumerate}
        \item   \label{IteWlajij}
            Si \( R_s\) est le rayon de convergence de \( \sum_n(a_n+b_n)z^n\), nous avons
            \begin{equation}
                R_s\geq \min\{ R_a,R_b \}
            \end{equation}
            et nous avons l'égalité si pour tout \( |z |\leq\min\{ R_a,R_b \}\), \( \sum (a_n+b_n)z^n=\sum_n a_nz^n+\sum_nb_nz^n\).
        \item
            Si \( \lambda\neq 0\) la série \( \sum_n(\lambda a_n)z^n\) a le même rayon de convergence que la série \( \sum_na_nz^n\) et si \( | z |<R_a\) nous avons
            \begin{equation}
                \sum_{n=0}^{\infty}(\lambda a_n)z^n=\lambda\sum_{n=0}^{\infty}a_nz^n.
            \end{equation}
        \item
            Le \defe{produit de Cauchy}{Cauchy!produit}\index{produit!de Cauchy} des deux séries est donné par
            \begin{equation}
                \sum_{n=0}^{\infty}\left( \sum_{i+j=n}a_ib_j \right)z^n=\sum_{n=0}^{\infty}\left( \sum_{k=0}^{n}a_kb_{n-k} \right)z^n.
            \end{equation}
            Si \( R_p\) est le rayon de convergence de ce produit nous avons
            \begin{equation}
                R_p\geq \min\{ R_a,R_b \}
            \end{equation}
            et si \( | z |<\min\{ R_a,R_b \}\) alors
            \begin{equation}
                \sum_{n=0}^{\infty}\left( \sum_{i+j=n}a_ib_j \right)z^n=\left( \sum_{n=0}^{\infty}a_nz^n \right)\left( \sum_{n=0}^{\infty}b_nz^n \right).
            \end{equation}
            
    \end{enumerate}
    
\end{theorem}

\begin{proof}
    Nous prouvons la partie sur le produit de Cauchy. En utilisant la propriété du produit de la somme par un scalaire nous avons
    \begin{subequations}
        \begin{align}
            \left( \sum_{n=0}^{\infty}a_nz^n \right)\left( \sum_{m=0}^{\infty}b_mz^m \right)&=\sum_{n=0}^{\infty}\left( \sum_{m=0}^{\infty}b_ma_nz^{m+n} \right)\\
            &=\lim_{N\to \infty} \lim_{M\to \infty} \sum_{n=0}^N\sum_{m=0}^Mb_ma_nz^{m+n}\\
            &=\lim_{N\to \infty} \lim_{M\to \infty} \sum_{k=0}^{N+M}\sum_{i+k=k}b_ia_jz^k\\
            &=\lim_{N\to \infty} \sum_{k=0}^{\infty}\sum_{i+k=k}b_ia_jz^k\\
            &=\sum_{k=0}^{\infty}\sum_{i+j=k}b_ia_jz^k.
        \end{align}
    \end{subequations}
\end{proof}

\begin{example}
    Montrons un produit de Cauchy dont le rayon de convergence est strictement plus grand que le minimum. D'abord nous considérons
    \begin{equation}
        A=1-z,
    \end{equation}
    c'est à dire \( a_0=1\), \( a_1=-1\), \( a_{n\geq 2}=0\) avec \( R_a=\infty\). Ensuite nous considérons
    \begin{equation}
        B=\sum_nz^n,
    \end{equation}
    c'est à dire \( B=(1-z)^{-1}\) et \( R_b=1\). Le produit de Cauchy de ces deux séries valant \( 1\), le rayon de convergence est infini.
\end{example}

\Exo{reserve0005}

\begin{theorem}
    Une série entière converge normalement sur tout disque fermé inclus au disque de convergence.
\end{theorem}

\begin{proof}
    Toute boule fermée inclue à \( B(0,R)\) est inclue à la boule \( \overline{ B(0,r) }\) pour un certain \( r<R\). Nous nous concentrons donc sur une telle boule fermée.

    Pour chaque \( n\) nous posons \( u_n(z)=a_nz^n\) que nous voyons comme une fonction sur \( \overline{ B(0,r) }\). Pour tout \( n\in \eN\) et tout \( z\in\overline{ B(0,r) }\) nous avons 
    \begin{equation}
        \| u_n \|_{\infty}\leq| a_nz^n |\leq | a_n |r^n.
    \end{equation}
    Étant donné que \( r<R\) la série \( \sum_n | a_n |r^n\) converge et la série \( \sum_n\| u_n \|\) est convergente. La série \( \sum_na_nz^n\) est alors normalement convergente.
\end{proof}

\begin{example}
    Encore une fois nous n'avons pas d'informations sur le comportement au bord. Par exemple la série \( \sum_nz^n\) a pour rayon de convergence \( R=1\), mais \( \sup_{z\in B(0,1)}| z^n |=1\) de telle façon à ce que nous n'avons pas de convergence normale sur la boule fermée.
\end{example}

La convergence normale n'est donc pas de mise sur tout l'intérieur du disque de convergence. La continuité, par contre est effective sur la boule. En effet si \( z_0\in B(0,R)\) alors il existe un rayon \( 0<r<R\) tel que \( B(z_0,r)\subset B(0,R)\). Sur \( B(z_0,r)\) nous avons convergence normale et donc continuité en \( z_0\).

La différence est que la continuité est une propriété locale tandis que la convergence normale est une propriété globale.

\begin{proposition}
    Soit \( f(z)=\sum_na_nz^n\) avec un rayon de convergence \( R\). Si \( \sum | a_n |R^n\) converge alors
    \begin{enumerate}
        \item
            la série \( \sum_na_nz^n\) converge normalement sur \( \overline{ B(0,R) }\),
        \item
            \( f\) est continue sur \( \overline{ B(0,R) }\).
    \end{enumerate}
\end{proposition}

\begin{proof}
    La conclusion est claire dans l'intérieur du disque de convergence. En ce qui concerne le bord, chacune des sommes partielles est une fonction continue. De plus nous avons \( \| u_n \|\leq | a_n |R^n\), dont la série converge. Par conséquent nous avons convergence normale sur le disque fermé.
\end{proof}

Le théorème suivant permet de donner, dans le cas de fonctions réelle, des informations sur la convergence en une des deux extrémités de l'intervalle de convergence.
\begin{theorem}[Convergene radiale de Abel]\index{Abel!convergence radiale} \label{ThoLUXVjs}
    Soit \( f(x)=\sum_na_nx^n\) une série réelle de rayon de convergence \( 0<R<\infty\).
    \begin{enumerate}
        \item
            Si \( \sum a_nR^n\) converge, alors \( f\) est continue sur \( \mathopen[ 0 , R \mathclose]\).
        \item
            Si \( \sum_na_n(-R)^n\) converge, alors \( f\) est continue sur \( \mathopen[ -R , 0 \mathclose]\).
    \end{enumerate}
\end{theorem}

\Exo{reserve0006}

Le résultat suivant permet d'identifier deux séries complexes lorsque leurs valeurs sur \( \eR\) sont identiques.
\begin{proposition}
    Soient les séries \( f(z)=\sum a_nz^n\) et \( g(z)=\sum b_n z^n\) convergentes dans \( B(0,R)\). Si \( f(x)=g(x)\) pour \( x\in \mathopen[ 0 , R [\) alors \( a_n=b_n\).
\end{proposition}

\begin{proof}
    Soit \( n_0\) le plus petit entier tel que \( a_{n_0}\neq b_{n_0}\). Pour tout \( z\in B(0,R)\) nous avons
    \begin{equation}
        f(z)-g(z)=\sum_{n=n_0}^{\infty}(a_n-b_n)z^n=z^{n_0}\varphi(z)
    \end{equation}
    où
    \begin{equation}
        \varphi(z)=\sum_{n\geq 0}(a_{n+n_0}-b_{n+n_0})z^n.
    \end{equation}
    Par le théorème \ref{ThokPTXYC}\ref{IteWlajij} le rayon de convergence de \( \varphi\) est plus grand que \( R\) et la fonction \( \varphi\) est continue en \( 0\). Étant donné que \( \varphi(0)=a_{n_0}-b_{n_0}\neq 0\) et que \( \varphi\) est continue nous avons un \( \rho\) tel que \( \varphi\neq 0\) sur \( B(0,\rho)\). Or cela n'est pas possible parce que au moins sur la partie réelle de cette dernière boule, \( \varphi\) doit être nulle.
\end{proof}

\begin{lemma}       \label{LemFVMaSD}
    Soit une série entière \( \sum a_nz^n\) de rayon de convergence \( R\). Les séries
    \begin{equation}
        \sum \frac{ a_n }{ n+1 }z^{n+1}
    \end{equation}
    et
    \begin{equation}
        \sum_{n\geq 1}na_nz^{n-1}
    \end{equation}
    ont même rayon de convergence \( R\).
\end{lemma}

Notons toutefois que nonobstant ce lemme, les séries dont il est question peuvent se comporter différemment sur le bord du disque de convergence. En effet la série
\begin{equation}
    \sum \frac{1}{ n }z^n
\end{equation}
diverge pour \( z=1\) alors que 
\begin{equation}
    \sum\frac{1}{ n(n+1) }z^{n+1}
\end{equation}
converge pour \( z=1\).

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Dérivation, intégration}
%---------------------------------------------------------------------------------------------------------------------------

Les théorèmes de dérivation et d'intégration de séries de fonctions (théorèmes \ref{ThoCciOlZ} et \ref{ThoCSGaPY}) fonctionnent bien dans le cas des séries entières.

\begin{proposition} \label{PropfeFQWr}
    Soit la série entière $\sum a_nx^n$ de rayon de convergence \( R\). Pour tout segment \( \mathopen[ a , b \mathclose]\subset\mathopen] -R , R \mathclose[\) nous pouvons intégrer terme à terme :
    \begin{equation}
        \int_a^b\sum_{n=0}^{\infty}a_nx^ndt=\sum_{n=0}^{\infty}a_n\int_a^bt^ndt.
    \end{equation}
\end{proposition}
\index{permuter!série entière et intégration}

\begin{proof}
    Ceci est un cas particulier du théorème général \ref{ThoCciOlZ}. Notons que par le lemme \ref{LemFVMaSD}, la série entière qui intègre la série de \( f\) terme à terme a le même rayon de convergence que celui de \( f\).
\end{proof}

\begin{proposition}     \label{ProptzOIuG}
    Soit la série entière
    \begin{equation}
        f(x)=\sum_{n=0}^{\infty}a_n x^n
    \end{equation}
    de rayon de convergence \( R\). Alors la fonction \( f\) est \( C^1\) sur \( \mathopen] -R , R \mathclose[\) et se dérive terme à terme :
    \begin{equation}
        f'(x)=\sum_{n=1}^{\infty}na_nx^{n-1}
    \end{equation}
    pour tout \( x\in\mathopen] -R , R \mathclose[\).
\end{proposition}
\index{permuter!série entière et dérivation}

\begin{proof}
    Nous savons que la série \( \sum_{n=1}^{\infty}na_nx^{n-1}\) a le même rayon de convergente que celui de la série \( f\). En particulier cette série des dérivées converge normalement sur tout compact dans \( \mathopen] -R , R \mathclose[\) et la somme est continue. Le théorème \ref{ThoCSGaPY} conclu.
\end{proof}

\begin{example}
    Montrons que la fonction
    \begin{equation}
        \begin{aligned}
            f\colon \eR_+\setminus\{ 0,1 \}&\to \eR \\
            x&\mapsto \frac{ \ln(x) }{ x-1 } 
        \end{aligned}
    \end{equation}
    admet un prolongement \( C^{\infty}\) sur \( \eR_+\setminus\{ 0 \}\).

    Nous allons étudier la fonction
    \begin{equation}
        f(x)=\frac{ \ln(1+x) }{ x }
    \end{equation}
    autour de \( x=0\). Le logarithme ne pose pas de problèmes à développer dans un voisinage :
    \begin{subequations}
        \begin{align}
            f(x)&=\frac{1}{ x }\sum_{n=1}^{\infty}\frac{ (-1)^{n+1} }{ n }x^n\\
            &=\sum_{n=1}^{\infty}\frac{ (-1)^{n+1} }{ n }x^{n-1}\\
            &=\sum_{n=0}^{\infty}\frac{ (-1)^k }{ k+1 }x^k.
        \end{align}
    \end{subequations}
    Cette série a un rayon de convergence égal à \( 1\), et donc définit sans problèmes une fonction \( C^{\infty}\) dans un voisinage de \( x=0\). Notons que par convention \( x^0=1\) même si \( x=0\).
\end{example}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Série génératrice d'une suite}
%---------------------------------------------------------------------------------------------------------------------------

Avant de commencer, une petite formule de dérivation toute simple que nous allons utiliser souvent :
\begin{equation}        \label{EqSOFdwhw}
    (z^k)^{(l)}=\begin{cases}
        0   &   \text{si \( l>k\)}\\
        \frac{ k! }{ (k-l)! }z^{k-l}    &    \text{sinon.}
    \end{cases}
\end{equation}

Soit \( u_n\) une suite telle que le rayon de convergence de
\begin{equation}
    f(z)=\sum_{n=0}^{\infty}u_nz^n
\end{equation}
soit strictement positif. Alors la série \( f\) est la \defe{série génératrice}{série!génératrice d'une suite} de la suite \( (u_n)\).

Grâce au théorème \ref{ProptzOIuG} nous pouvons la dériver terme à terme autour de \( z=0\). En utilisant la petite formule \eqref{EqSOFdwhw} nous trouvons
\begin{equation}    \label{EqNGhVCpP}
    f^{(l)}(z)=\sum_{n=l}^{\infty}u_n\frac{ n! }{ (n-l)! }z^{n-l},
\end{equation}
et donc
\begin{equation}
    u_l=\frac{ f^{(l)}(0) }{ l! }.
\end{equation}
D'où le nom de série génératrice. Cela est évidemment intéressant seulement si nous connaissons une autre forme pour \( f\) par ailleurs. 

Nous en utiliserons une pour déterminer les partitions d'un nombre en parts fixes, proposition \ref{PropWUFpuBR}.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Développement en série et Taylor}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}  \label{DefwmRzKh}
    Soit une fonction \( f\colon \eC\to \eC\) et \( z_0\in \eC\). Nous disons que \( f\) est \defe{développable en série entière}{développable!en série entière} dans un voisinage de \( z_0\) si il existe une série \( \sum_n a_nz^n\) de rayon de convergence \( R>0\) et \( r\leq R\) tel que
    \begin{equation}
        f(z)=\sum_{n=0}^{\infty}a_n(z-z_0)^n
    \end{equation}
    pour tout \( z\in B(z_0,r)\).
\end{definition}

\begin{proposition}
    Si \( V\) est un ouvert dans \( \eC\) alors l'ensemble des fonctions \( V\to \eC\) développables en série entière forme une \( \eC\)-algèbre.
\end{proposition}

\begin{proof}
    Les séries entières passent aux sommes et aux produits en gardant des rayons de convergence non nuls.
\end{proof}

\begin{proposition} \label{ThoTGPtDj}
    Si \( f\) est développable en série entière à l'origine alors elle est \( C^{\infty}\) sur un voisinage de l'origine et le développement est celui de \defe{Taylor}{Taylor!série entière} :
    \begin{equation}
        f(x)=\sum_{n=0}^{\infty}\frac{ f^{(n)}(0) }{ n! }x^n
    \end{equation}
    pour tout \( x\) dans un voisinage de \( 0\).
\end{proposition}

\begin{proof}
    Si \( f(x)=\sum a_nx^n\), nous savons que \( f\) est \( C^1\) et que nous pouvons dériver terme à terme (au moins dans un voisinage). De plus le fait de dériver ne change pas le domaine. Par récurrence, la fonction est \( C^{\infty}\) sur le voisinage. En dérivant \( k\) fois la série \( \sum a_nx^n\) nous trouvons
    \begin{equation}
        f^{(k)}(x)=\sum_{n=k}^{\infty}n(n-1)\ldots (n-k+1)a_nx^{n-k}.
    \end{equation}
    En calculant en \( x=0\) nous trouvons
    \begin{equation}
        f^{(k)}(0)=k! a_k,
    \end{equation}
    d'où le terme général
    \begin{equation}
        a_k=\frac{ f^{(k)}(0) }{ k! }.
    \end{equation}
\end{proof}

Si \( f\) est une fonction et si la série
\begin{equation}
    T_f(x)=\sum_{n=0}^{\infty}\frac{ f^{(n)}(0) }{ n! }x^n
\end{equation}
converge, alors cette série est la \defe{série de Taylor}{série!Taylor} de \( f\).

\begin{remark}
    La série de Taylor d'une fonction n'est pas liée à sa fonction de façon aussi raide qu'on pourrait le croire. Même dans le cas d'une fonction \( C^{\infty}\) il peut arriver que \( T_f(x)\neq f(x)\).
    
    Il peut aussi arriver que \( f\) ne soit pas développable en série entières.
\end{remark}

\begin{example}
    Nous considérons la fonction
    \begin{equation}
        f(x)=\begin{cases}
            e^{-1/x^2}    &   \text{si \( x\neq 0\)}\\
            0    &    \text{si \( x=0\).}
        \end{cases}
    \end{equation}
    Nous avons
    \begin{equation}
        f'(x)=\begin{cases}
            \frac{ 2 }{ x^3 } e^{-1/x^2}    &   \text{si \( x\neq 0\)}\\
            0    &    \text{si \( x=0\)}.
        \end{cases}
    \end{equation}
    Note : pour la seconde ligne nous devons faire explicitement le calcul
    \begin{equation}
        f'(0)=\lim_{t\to 0} \frac{ f(t)-f(0) }{ t }=\lim_{y\to 0} \frac{1}{ t } e^{-1/t^2}=0.
    \end{equation}
    Plus généralement nous avons \( f^{(k)}(0)=0\), et par conséquent la série de Taylor converge (trivialement) vers la fonction identiquement nulle.

    Cette fonction n'est donc pas développable en série entière vu qu'il n'existe aucun voisinage de zéro sur lequel la série de \( f\) coïncide avec \( f\).
\end{example}

\begin{example}     \label{ExwobBAW}
    Développement de \( f(x)=\arctan(x)\). Nous savons que
    \begin{equation}
        f'(x)=\frac{1}{ 1+x^2 },
    \end{equation}
    alors que nous connaissons le développement
    \begin{equation}    \label{EqVmuaqT}
        \frac{1}{ 1-x }=\sum_{n=0}^{\infty}x^n
    \end{equation}
    pour tout \( x\in B(0,1)\). Nous avons donc successivement
    \begin{subequations}
        \begin{align}
            \frac{1}{ 1+x }&=\sum_{n=0}(-x)^n\\
            \frac{ 1 }{ 1+x^2 }&=\sum_{n=0}(-1)^nx^{2n}\\
            \arctan(x)&=\sum_{n=1}^{\infty}(-1)^n\frac{ x^{2n+1} }{ 2n+1 }+C.
        \end{align}
    \end{subequations}
    Notons que dans la dernière nous avons évité d'écrire la somme depuis \( n=0\) (qui serait un terme constant) et nous avons écris explicitement «\( +C\)». Étant donné que \( \arctan(0)=0\), nous devons poser \( C=0\) et donc
    \begin{equation}
        \arctan(x)=\sum_{n=1}^{\infty}(-1)^n\frac{ x^{2n+1} }{ 2n+1 }.
    \end{equation}
\end{example}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Resommer une série}
%---------------------------------------------------------------------------------------------------------------------------

Nous avons vu comment trouver la série correspondant à une fonction donnée. Un exercice difficile consiste à trouver la fonction qui correspond à une somme donnée. Pour des techniques de calculs de sommes, voir \cite{DAnSerEntiere}.

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Les sommes du type \texorpdfstring{$ \sum_nP(n)x^n$}{P}}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Pour calculer 
\begin{equation}
    \sum_{n=0}^{\infty}P(n)x^n
\end{equation}
où \( P\) est un polynôme de degré \( m\) nous commençons par écrire
\begin{equation}
    P(n)=\alpha_0+\alpha_1(n+1)+\alpha_2(n+1)(n+2)+\ldots +\alpha_m(n+1)\ldots (n+m).
\end{equation}
Nous décomposons alors la somme en \( m\) sommes de la forme
\begin{equation}
    \sum_{n=0}^{\infty}\alpha_k\frac{ (n+k)! }{ n! }x^n=\alpha_k\left( \sum_{n=0}^{\infty}x^{n+k} \right)^{(k)}.
\end{equation}
Effectuons par exemple\footnote{Je crois qu'ici il y a une faute de signe dans \cite{DAnSerEntiere}.}
\begin{equation}
    \sum_{n=0}^{\infty}x^{n+3}=\frac{1}{ 1-x }-1-x-x^2
\end{equation}
Notons que dans un usage pratique, ce terme devra être ensuite dérivé trois fois, de telle manière à ce que les termes «correctifs» n'interviennent pas. Cette méthode ne demande donc que de calculer les dérivées successives de \( 1/(1-x)\).

\begin{example}
    Calculons la fonction
    \begin{equation}
        f(x)=\sum_{n=0}^{\infty}n^3x^n.
    \end{equation}
    D'abord nous écrivons
    \begin{equation}
        n^3=-1+7(n+1)-6(n+1)(n+2)+(n+1)(n+2)(n+3).
    \end{equation}
    Nous avons 
    \begin{equation}
        \sum_{n=0}^{\infty}(n+1)x^n=\left( \sum_{n=0}^{\infty}x^{n+1} \right)'=\left( \frac{1}{ 1-x }-1 \right)'=\frac{1}{ (x-1)^2 }.
    \end{equation}
    De la même façon,
    \begin{subequations}
        \begin{align}
            \sum_n (n+1)(n+2)x^n&=\left( \sum x^{n+2} \right)''=\frac{ -2 }{ (x-1)^3 }\\
            \sum_n (n+1)(n+2)(n+3)x^n=\frac{ 6 }{ (x-1)^4 }.
        \end{align}
    \end{subequations}
    En remettant tout ensemble nous obtenons
    \begin{equation}
        \sum_{n=0}^{\infty}n^3x^n=-\frac{1}{ 1-x }+\frac{ 7 }{ (x-1)^2 }+\frac{ 12 }{ (x-1)^3 }+\frac{ 6 }{ (x-1)^4 }.
    \end{equation}

    Nous pouvons vérifier ce résultat en traçant les deux courbes et en remarquant qu'elles coïncident.
\begin{verbatim}
----------------------------------------------------------------------
| Sage Version 4.7.1, Release Date: 2011-08-11                       |
| Type notebook() for the GUI, and license() for information.        |
----------------------------------------------------------------------
sage: n=var('n')
sage: S(x)=sum(  [ n**3*x**n for n in range(0,30)  ]   )
sage: f(x)=-1/(1-x)+7/((x-1)**2)+12/((x-1)**3)+6/( (x-1)**4  )
sage: S(0.1)
0.214906264288980
sage: f(0.1)
0.214906264288981
sage: f.plot(-0.5,0.5)+S.plot(-0.5,0.5)
\end{verbatim}

\end{example}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Les sommes du type \texorpdfstring{$ \sum_nx^n/P(n)$}{P}}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Si \( P(n)\) a des racines entières, nous pouvons le décomposer en fractions simples et utiliser la somme
\begin{equation}
    \sum_{n=1}^{\infty}\frac{ x^n }{ n }=-\ln(1-x).
\end{equation}
Nous avons par exemple
\begin{subequations}
    \begin{align}
        \sum_{n=0}^{\infty}\frac{x^n}{ n+1 }&=\frac{1}{ x }\sum_{n=0}\frac{ x^{n+1} }{ n+1 }\\
        &=\frac{1}{ x }\sum_{n=1}^{\infty}\frac{ x^n }{ n }=-\frac{ \ln(1-x) }{ x }.
    \end{align}
\end{subequations}
Notez le changement de point de départ de la somme au passage.

Autre exemple :
\begin{subequations}
    \begin{align}
        \sum_{n=0}^{\infty}\frac{ x^n }{ n+3 }&=\frac{1}{ x^3 }\left( \sum_{n=1}^{\infty}\frac{ x^n }{ n }-x-\frac{ x^2 }{ 2 } \right)\\
        &=-\frac{ \ln(x-1) }{ x^3 }-\frac{1}{ x^2 }-\frac{1}{ 2x }.
    \end{align}
\end{subequations}

Si le polynôme possède des racines non entières, les choses se compliquent. 

\begin{example}
Calculons
\begin{equation}
    \sum_{n=0}^{\infty}\frac{ x^n }{ 2n+1 }.
\end{equation}
Si \( x\geq\), en posant \( t=\sqrt{x}\) nous trouvons
\begin{equation}
    \sum_{n=0}^{\infty}\frac{ x^n }{ 2n+1 }=\frac{1}{ t }\sum_{n=0}^{\infty}\frac{ t^{2n+1} }{ 2n+1 }.
\end{equation}
Étudions
\begin{equation}
    H(t)=\sum_{n=0}^{\infty}\frac{ t^{2n+1} }{ 2n+1 }.
\end{equation}
Nous avons 
\begin{equation}     \label{EqBuPjcM}
    H'(t)=\sum_{n=0}^{\infty}t^{2n}=\sum_{n=0}(t^2)^n=\frac{1}{ 1-t^2 }.
\end{equation}
Une primitive de cette fonction est
\begin{equation}
    \frac{ 1 }{2}\ln\left| \frac{ t+1 }{ t-1 } \right|.
\end{equation}
En \( t=0\), cette fonction vaut \( 0\) qui est la bonne valeur. Donc nous avons bien
\begin{equation}
    H(t)=\frac{ 1 }{2}\ln\left| \frac{ t+1 }{ t-1 } \right|.
\end{equation}

Notons que ce que l'équation \eqref{EqBuPjcM} nous dit est que \( H(t)\) est une primitive de \( 1/(1-t^2)\). Il faut choisir la bonne primitive en fixant une valeur.





Nous avons donc
\begin{equation}
    \sum_{n=0}^{\infty}\frac{ x^n }{ 2n+1 }=\frac{ 1 }{2\sqrt{x}}\ln\left| \frac{ \sqrt{x}+1 }{ \sqrt{x}-1 } \right| 
\end{equation}
pour \( x>0\). Nous devons encore trouver ce que cela vaut pour \( x<0\).

    Nous posons successivement \( X=-x\) puis \( g(X)=f(-X)\). Ce que nous devons calculer est
    \begin{equation}
        g(t)=\frac{1}{ t }\sum_{n=0}^{\infty}\frac{ (-1)^nt^{2n+1} }{ 2n+1 }.
    \end{equation}
    Si nous posons
    \begin{equation}
        h(t)=\sum \frac{ (-1)^nt^{2n+1} }{ 2n+1 },
    \end{equation}
    alors
    \begin{equation}
        h'(t)=\sum (-1)^nt^{2n}=\sum (-t^2)^n=\frac{1}{ 1+t^2 },
    \end{equation}
    par conséquent \( h(t)=\arctan(t)\) (cela avait déjà été déduit à l'envers dans l'exemple \ref{ExwobBAW}).

    Au final
    \begin{equation}        \label{EqIHlDjG}
        f(x)=\sum_{n=0}^{\infty}\frac{ x^n }{ 2n+1 }=\begin{cases}
            \frac{ 1 }{2\sqrt{x}}\ln\left| \frac{ \sqrt{x}+1 }{ \sqrt{x}-1 } \right|     &   \text{si \( x>0\)}\\
            \frac{ \arctan(\sqrt{-x}) }{ \sqrt{-x} }    &    \text{si \( x<0\)}\\
            1   &\text{si \( x=0\)}.
        \end{cases}
    \end{equation}
    Notons qu'elle est continue en zéro à gauche et à droite.

\end{example}

\begin{example}
Nous considérons l'exemple suivant :
\begin{equation}
    f(x)=\sum_{n=0}^{\infty}\frac{ x^n }{ 3n+2 }.
\end{equation}
Nous posons \( t=\sqrt[3]{x}\), et nous substituons :
\begin{equation}
    \frac{ x^n }{ 3n+2 }=\frac{ t^{3n} }{ 3n+2 }=\frac{1}{ t^2 }\frac{ t^{3n+2} }{ 3n+2 }.
\end{equation}
Nous devons étudier la fonction
\begin{equation}
    g(t)=\sum_{n=0}^{\infty}\frac{ t^{3n+2} }{ 3n+2 }
\end{equation}
Nous avons
\begin{equation}
    g'(t)=\sum_{n=0}t^{3n+1}=t\sum_{n=0}t^{3n}=\frac{ t }{ 1-t^3 }.
\end{equation}
Notons que \( g(0)=0\). 
\end{example}

\begin{example}
    Calculer le nombre
    \begin{equation}        \label{EqgUyKYe}
        \sum_{n=0}^{\infty}\frac{ (-1)^n }{ 2n+1 }.
    \end{equation}
    Nous aurions envie de dire que cela est \( f(-1)\) pour la fonction \( f\) donnée en \eqref{EqIHlDjG}. Le problème est que le rayon de convergence de \( f\) étant \( 1\), rien n'est garantit quand au fait que la fonction y soit continue en \( x=-1\). En particulier nous devons justifier le fait que
    \begin{equation}
        \lim_{x\to -1} \sum_n\frac{ x^n }{ 2n+1 }=\lim_{x\to -1} \frac{1}{ \sqrt{-x} }\arctan(\sqrt{-x}).
    \end{equation}
    Ce qui nous sauve est le critère d'Abel radial (théorème \ref{ThoLUXVjs}). En effet la série
    \begin{equation}        \label{EqAFrXRB}
        \sum\frac{ r^n }{ 2n+1 }
    \end{equation}
    étant convergente avec \( r=-1\), la série correspondante est continue sur \( \mathopen[ -1 , 0 \mathclose]\). Nous pouvons donc calculer la série \eqref{EqgUyKYe} en posant \( x=-1\) dans \eqref{EqIHlDjG} :
    \begin{equation}       
        \sum_{n=0}^{\infty}\frac{ (-1)^n }{ 2n+1 }=\frac{ \pi }{ 4 }.
    \end{equation}

    Note : la série \eqref{EqAFrXRB} ne converge pas avec \( r=1\). La fonction \( f\) n'est pas continue en \( x=1\).
\end{example}

\begin{example}     \label{ExGxzLlP}
    Nous avons
    \begin{equation}
        \sum_{n=1}^{\infty}nx^{n-1}=\frac{1}{ (1-x)^2 }.
    \end{equation}
    En effet si nous désignons par \( f\) la somme à gauche, nous trouvons que \( f=g'\) avec
    \begin{equation}
        g(x)=\sum_{n=1}^{\infty}x^n.
    \end{equation}
    Nous savons par ailleurs que \( g(x)=1/(1-x)\). Par conséquent
    \begin{equation}
        f(x)=\left( \frac{1}{ 1-x } \right)'=\frac{1}{ (1-x)^2 }.
    \end{equation}
\end{example}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Sage, primitives et logarithme complexe}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\label{PgpXBuBh}

Attention : Sage pourrait nous induire en erreur si nous n'y prenions pas garde. En effet ce que vous ne savez pas mais que Sage sait, c'est que
\begin{equation}
    \ln(-1)=i\pi.
\end{equation}
Par conséquent Sage se permet de donner des primitives sans valeurs absolues dans le logarithme :
\begin{verbatim}
sage: f(x)=1/x
sage: f.integrate(x)
x |--> log(x)
\end{verbatim}
La primitive à laquelle on s'attend d'habitude est \( \ln(| x |)\). Ici la réponse est correcte parce que si \( x\) est négatif nous avons
\begin{equation}
    \ln(x)=\ln\big( (-1)| x | \big)=\ln(-1)+\ln(| x |).
\end{equation}
Cette fonction est donc décalée de la primitive usuelle seulement de la constante \( \ln(-1)\).

Un exemple plus élaboré :
\begin{verbatim}
sage: h(x)=1/(1-x**2)
sage: H=h.integrate(x)
sage: H
x |--> -1/2*log(x - 1) + 1/2*log(x + 1)
sage: H(0)
-1/2*I*pi
\end{verbatim}
    



\begin{example}
Encore une fois il faut faire attention en demandant la primitive à Sage :
\begin{verbatim}
----------------------------------------------------------------------
| Sage Version 4.7.1, Release Date: 2011-08-11                       |
| Type notebook() for the GUI, and license() for information.        |
----------------------------------------------------------------------
sage: f(x)=x/(1-x**3)
sage: F=f.integrate(x)
sage: F(0)
-1/3*I*pi - 1/3*sqrt(3)*arctan(1/3*sqrt(3))
\end{verbatim}
Cette fois la primitive proposée diffère de celle qu'on cherche de la constante complexe
\begin{equation}
    -\frac{ \pi }{ 3 }i.
\end{equation}
Mais il y a pire si nous voulons tracer. Nous voudrions définir la fonction \( F_2(x)=F(x)-F(0)\). Mathématiquement c'est bien de cette fonction que nous parlons, mais :
\begin{verbatim}
sage: F2(x)=F(x)-F(0)
sage: F2(x)
1/3*I*pi - 1/3*sqrt(3)*arctan(1/3*(2*x + 1)*sqrt(3)) + 
    +1/3*sqrt(3)*arctan(1/3*sqrt(3)) - 1/3*log(x - 1) + 1/6*log(x^2 + x + 1)
sage: F2.plot(x,-0.1,0.1)
verbose 0 (4101: plot.py, generate_plot_points) WARNING: When plotting, failed to evaluate function at 200 points.
verbose 0 (4101: plot.py, generate_plot_points) Last error message: 'unable to simplify to float approximation'
\end{verbatim}
Il refuse de tracer. Pourquoi ? La partie complexe de l'expression de \( F_2\) est mathématiquement nulle, mais elle est en deux parties :
\begin{equation}
    \frac{ \pi }{ 3 }+\text{la partie imaginaire de} -\frac{1}{ 3 }\ln(x-1).
\end{equation}
Lorsque Sage tente de tracer, il donne à \( x\) un certain nombre de valeurs et calcule une \emph{valeur approchée} de \( \ln(x-1)\). Cette dernière ne se simplifie pas avec le nombre \emph{exact} \( \pi/3\). Sage reste donc avec une partie imaginaire qu'il ne peut pas tracer.

Notez la nuance :
\begin{verbatim}
sage: ln(-0.1)
-2.30258509299405 + 3.14159265358979*I
sage: ln(-1/10)
I*pi + log(1/10)
\end{verbatim}
Du coup nous avons aussi
\begin{verbatim}
sage: F2(-0.1)
1/3*I*pi - 1/3*sqrt(3)*arctan(0.266666666666667*sqrt(3)) 
    + 1/3*sqrt(3)*arctan(1/3*sqrt(3)) - 0.0474885065133152 - 1.04719755119660*I
\end{verbatim}

\end{example}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Nombres de Bell}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Ici nous montrerions bien le théorème \ref{ThoYFAzwSg} sur les nombres de Bell parce que c'est essentiellement un résultat sur les séries entières et leurs manipulations. Hélas, il demande un tout petit peu d'équation différentielle (presque rien). Donc il est postposé jusqu'en page \pageref{ThoYFAzwSg}.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Séries entières de matrices}
%---------------------------------------------------------------------------------------------------------------------------
\label{subsecEVnZXgf}

Nous nous proposons d'étudier des séries de la forme
\begin{equation}
    \sum_{k=0}^{\infty}a_kA^k
\end{equation}
où \( A\) est une matrice. L'essentiel de la théorie va rester. Nous considérons une norme algébrique (définition \ref{DefJWRWQue}), c'est à dire \( \| AB \|\leq \| A \|\| B \|\).

La notion de rayon de convergence de cette série reste la même : c'est la définition \ref{DefZWKOZOl} qui ne dépend que des coefficients \( a_k\) et pas du tout de ce qu'on met à côté dans la somme. Évidemment il faudra montrer que dans le cas des matrices, le nom «rayon de convergence» n'est pas usurpé.

\begin{proposition} \label{PropFIPooSSmJDQ}
    Soit \( (a_n)\) une suite dans \( \eC\) de rayon de convergence \( R\) et \( A\in \eM(n,\eR)\) une matrice vérifiant \( \| A \|<R\). Alors la série
    \begin{equation}
        \sum_{k=0}^{\infty}a_kA^k
    \end{equation}
    converge absolument, c'est à dire que \( \sum_k\| a_kA^k \|<\infty\).
\end{proposition}

\begin{proof}
    Nous avons les majorations
    \begin{equation}
        \| a_n A^n\|\leq | a_n |\| A^n \|\leq | a_n |\| A \|^n.
    \end{equation}
    Par hypothèse \( \| A \|<R\) et \( R\) est un supremum, donc il existe \( r\) tel que \( \| A \|<r<R\) avec \( (a_nr^n)\) borné. Nommons \( M\) un majorant de la suite \( (a_nr^n)\). Alors nous avons
    \begin{equation}
        \| A_nA^n \|\leq | a_n |r^n\frac{ \| A \|^n }{ r^n }\leq M\left( \frac{ \| A \| }{ r } \right)^n.
    \end{equation}
    La série du membre de droite converge parce que c'est une série géométrique de raison plus petite que \( 1\); voir l'exemple \ref{ExZMhWtJS}.
\end{proof}

\begin{proposition} \label{PropAMBXKgV}
    Soit \( (a_n)\) une suite dans \( \eC\) de rayon de convergence \( R\) et la fonction
    \begin{equation}
        \begin{aligned}
            f\colon \eM(n,\eR)&\to \eM(n,\eR) \\
            A&\mapsto \sum_{k=0}^{\infty}a_kA^k 
        \end{aligned}
    \end{equation}
    Alors
    \begin{enumerate}
        \item
            La différentielle de \( f\) sur \( B(0,R)\) est
            \begin{equation}    \label{EqRDVodDa}
                df_A(U)=\sum_{k=0}^{\infty}a_k\sum_{l=0}^{k-1}A^lUA^{k-1-l},
            \end{equation}
            c'est à dire que l'on peut différentier terme à terme. (Ici c'est \( A\) qui est dans \( B(0,R)\))
        \item
            La convergence de la somme \ref{EqRDVodDa} est absolue.
        \item
            La convergence de la somme \ref{EqRDVodDa} est normale sur tout compact.
        \item
            La fonction \( f\) est de classe \( C^1\) sur \( B(0,R)\), c'est à dire que la fonction \( A\mapsto df_A\) est continue.
    \end{enumerate}
\end{proposition}
Notons que \( df_A\) n'est pas tout à fait une série entière. Cependant, en ce qui concerne les normes, c'est tout comme si ça l'était.

\begin{proof}
    Nous posons \( u_k(A)=a_kA^k\), qui est une fonction de classe \(  C^{\infty}\) et dont la différentielle est donnée par
    \begin{equation}
        (du_k)_A(U)=\Dsdd{ u_k(A+tU) }{t}{0}=a_k\Dsdd{ (A+tU)^k }{t}{0};
    \end{equation}
    en distribuant le produit nous trouvons tout un tas de termes dont seuls ceux contenant exactement une fois \( tU\) ne vont pas s'annuler. Étant donné que \( U\) et \( A\) ne commutent pas nous avons l'expression un peu moche
    \begin{equation}
        (du_k)_A(U)=\sum_{l=0}^{k-1}a_kA^lUA^{k-1-l}.
    \end{equation}
    En ce qui concerne la norme, nous regardons celle de \( (du_k)_A\) pour un \( A\) fixé; c'est à dire que nous en regardons la norme opérateur :
    \begin{equation}
        \| (du_k)_A \|=\sup_{\| U \|=1}\| \sum_{l=0}^{k-1}a_kA^lUA^{k-1-l} \|\leq \sum_{l=0}^{k-1}| a_k |\| A \|^{l}\| A \|^{k-1-l}\leq k| a_k |\| A \|^{k-1}.
    \end{equation}
    Pour donner la convergence nous considérons un nombre \( r\) tel que \( \| A \|<r<R\), de telle sorte que la suite \( (a_nr^n)\) soit bornée par un nombre \( M\) et que nous puissions écrire
    \begin{equation}    \label{EqTGEwhnL}
        \| (du_k)_A \|\leq k| a_k |\| A \|^{k-1}=\frac{ k| a_k |\| A \|^k }{ \| A \| }=\frac{ k| a_k | }{ \| A \| }r^k\left( \frac{ \| A \| }{ r } \right)^k\leq \frac{ M }{ \| A \| }k\left( \frac{ \| A \| }{ r } \right)^k,
    \end{equation}
    dont la série converge. Nous avons donc convergence absolue de la série
    \begin{equation}
        \sum_{k=0}^{\infty}(du_k)_A.
    \end{equation}
    Passons à la convergence normale sur tout compact. Nous nous fixons \( r<R\) et nous nous intéressons à la norme de \( du_k\) sur \( \overline{ B(0,r) }\), c'est à dire
    \begin{equation}
        \| du_k \|_{\infty}=\sum_{x\in\overline{ B(0,r) }}\| (du_k)_A \|.
    \end{equation}
    Vu que \( \overline{ B(0,r) }\) est compact, ce supremum est un maximum et nous pouvons noter \( A_k\) la matrice qui le réalise. Nous réalisons alors les mêmes manipulations que pour \eqref{EqTGEwhnL} :
    \begin{equation}
        \| du_k \|_{\infty}=\| (du_k)_{A_k} \|\leq k| a_k |\| A_k \|^{k-1}\leq  k| a_k |r^{k-1}=\frac{1}{ r }k| a_k |r^k.
    \end{equation}
    Nous prenons maintenant \( r<r_0<R\) et \( M\), un majorant de \( (a_nr_0^n)\), de telle sorte qu'en multipliant et divisant par \( r_0^k\),
    \begin{equation}
        \| du_k \|_{\infty}\leq \frac{ k| a_k |r_0^k }{ r }\frac{ r^k }{ r_0^k }\leq \frac{ kM }{ r }\left( \frac{ r }{ r_0 } \right)^k,
    \end{equation}
    dont la série converge. Nous avons donc convergence normale sur tout compact. Par voie de \sout{fait} conséquences nous avons continuité de la série
    \begin{equation}
        \sum_{k=0}^{\infty}(du_k)_A
    \end{equation}
    et convergence vers \( df_A\) par le théorème \ref{ThoLDpRmXQ}.
\end{proof}

\begin{proposition} \label{PropQIIURAh}
    Si le rayon de convergence de la série \( u(A)=\sum_{k=0}^{\infty}a_kA^k\) est \( R\), alors 
    \begin{enumerate}
        \item
            elle converge normalement sur tout compact de \( B(0,R)\);
        \item
            la fonction \( u\) y est de classe \(  C^{\infty}\).
    \end{enumerate}
\end{proposition}

\begin{proof}
    Nous posons 
    \begin{equation}
        \begin{aligned}
            u_k\colon \eM(n,\eR)&\to \eM(n,\eR) \\
            A&\mapsto a_kA^k 
        \end{aligned}
    \end{equation}
    qui est évidemment une fonction de classe \(  C^{\infty}\). Nous étudions la \( j\)\ieme\ différentielle en \( m\), pour \( k>j\) (dans une série, nous ne nous intéressons pas aux premiers termes). La \( j\)\ieme\ différentielle appliquée à \( v_1\) appliquée à \( v_2\), etc s'exprime de la façon suivante :
    \begin{equation}
        (d^ju_k)_m(v_1,\ldots, v_j)=\frac{ d  }{ d t_1 }\ldots\frac{ d  }{ d t_j }\Big( u_k(m+t_1v_1+\ldots +t_jv_j)    \Big)_{t_i=0}.
    \end{equation}
    Dans le produit \( (m+t_1v_1+\ldots +t_jv_j)^k\), seuls les termes contenant exactement une fois chacun des \( t_i\) ne s'annulera pas après avoir fait la dérivée et évalué en \( t_i=0\). Combien de termes cela fait ? Parmi les \( k\) facteurs, il faut en placer \( j\) qui ne sont pas \( m\) (cela fait \( \binom{ k }{ j }\) possibilités), et puis il faut ordonner ces \( j\) termes, cela fait encore \( j!\) possibilités. Au final,
    \begin{equation}
        \| (d^ju_k)_m \|\leq | a_k | \binom{ k }{ j }j!\| m \|^{k-j}=| a_k |P(k)\| m \|^{k-j}
    \end{equation}
    où \( P(k)=\frac{ k! }{ (k-j)! }\) est un polynôme de degré \( j\).

    Afin d'étudier la convergence normale sur tout compact de la série des \( d^ju_k\), nous considérons \( r<r_0<R\) et nous allons prouver la convergence normale sur \( \overline{ B(0,r) }\). Vu que c'est un compact, il existe une matrice \( m_k\in\overline{ B(0,r) }\) telle que
    \begin{subequations}
        \begin{align}
            \| d^ju_k \|_{\infty}&=\| (d^ju_k)_{m_k} \|\\
            &\leq | a_k |P(k)\| m_k \|^{k-j}\\
            &\leq | a_k |P(k)r^{k-j}\\
            &=\frac{ | a_k |P(k) }{ r^j }r^k\\
            &=\frac{ | a_k |r_0^kP(k) }{ r^j }\left( \frac{ r }{ r_0 } \right)^k\\
            &\leq \frac{ M }{ r^j }P(k)\left( \frac{ r }{ r_0 } \right)^k
        \end{align}
    \end{subequations}
    où \( M\) est un majorant de \( a_nr^n\). Vu que \( r_0/r<1\), la somme sur \( k\) converge et nous avons convergence normale sur tout compact de
    \begin{equation}
        d^j\sum_{k=0}^{\infty}a_kA^k=\sum_{k=0}^{\infty}d^j(a_kA^k)
    \end{equation}
    avec un peu d'abus de notation.
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Exponentielle}
%---------------------------------------------------------------------------------------------------------------------------

Note : le logarithme est définit comme primitive de la fonction \( 1/x\) en l'équation \eqref{EqTJZPooBmojAo}.

La méthode adoptée ici est la suivante :
\begin{itemize}
    \item L'exponentielle est définie par la série.
    \item Nous démontrons qu'elle vérifie l'équation différentielle \( y'=y\), \( y(0)=1\).
    \item Nous démontrons l'unicité de la solution à cette équation différentielle.
    \item Nous démontrons qu'elle est égale à \( x\mapsto y(1)^x\).
\end{itemize}
Il n'y a pas de passage par le logarithme.

\begin{theorem}[Existence de l'exponentielle] \label{ThoKRYAooAcnTut}
    La série entière
    \begin{equation}    \label{EqEIGZooKWSvPS}
        y(x)=\sum_{k=0}^{\infty}\frac{ x^k }{ k! }
    \end{equation}
    définit une fonction dérivable solution de
    \begin{subequations}
        \begin{numcases}{}
            y'=y\\
            y(0)=1.
        \end{numcases}
    \end{subequations}
\end{theorem}
\index{exponentielle!existence}

\begin{proof}
    La formule de Hadamard (théorème \ref{ThoSerPuissRap}) donne le rayon de convergence de la série \eqref{EqEIGZooKWSvPS} par
    \begin{equation}
        \frac{1}{ R }=\lim_{k\to \infty} \frac{ \frac{1}{ (k+1)! } }{ \frac{1}{ k! } }=\lim_{k\to \infty} \frac{1}{ k+1 }=0.
    \end{equation}
    Donc nous avons un rayon de convergence infini. La fonction \( y\) est définie sur \( \eR\) et la proposition \ref{ProptzOIuG} nous dit que \( y\) est dérivable. Nous pouvons aussi dériver terme à terme :
    \begin{equation}
            y'(x)=\sum_{k=0}^{\infty}\frac{ kx^{k-1} }{ k! }=\sum_{k=1}^{\infty}\frac{ kx^{k-1} }{ k! }=\sum_{k=1}^{\infty}\frac{ x^{k-1} }{ (k-1)! }=\sum_{k=0}^{\infty}\frac{ x^k }{ k! }=y(x).
    \end{equation}
    Notez le petit jeu d'indice de départ de \( k\). Dans un premier temps, nous remarquons que \( k=0\) donne un terme nul et nous le supprimons, et dans un second temps nous effectuons la simplification des factorielles (qui ne fonctionne pas avec \( k=0\)).
\end{proof}

Pour la suite nous notons \( y\) une solution de l'équation \( y'=y\), \( y(0)=1\), et nous allons en donner des propriétés indépendamment de l'existence, donnée par le théorème \ref{ThoKRYAooAcnTut}. Et qui peut être obtenue via les logarithmes en l'équation \eqref{EqNQDDooYBbARn}.

\begin{proposition}
    Quelque propriétés de \( y\) (si elle existe) :
    \begin{enumerate}
        \item
            Pour tout \( x\in \eR\) nous avons \( y(x)y(-x)=1\).
        \item
            \( y(x)>0\) pour tout \( x\).
        \item
            \( y\) est strictement croissante.
    \end{enumerate}
\end{proposition}

\begin{proof}
    Nous posons \( \varphi(x)=y(x)y(-x)\) et nous dérivons :
    \begin{equation}
        \varphi'(x)=y'(x)y(-x)-y(x)y'(-x)=0.
    \end{equation}
    Donc \( \varphi\) est constante\footnote{Proposition \ref{PropGFkZMwD}.}. Vu que \( \varphi(0)=1\) nous avons automatiquement \( y(x)y(-x)=1\) pour tout \( x\).

Les deux autres allégations sont simples : si \( y(x_0)<0\) alors il existe \( t\in\mathopen] x_0 , 1 \mathclose[\) tel que \( y(t)=0\), ce qui est impossible parce que \( y(t)y(-t)=1\). La stricte croissance de \( y\) s'ensuit.
\end{proof}

\begin{proposition}[Unicité de l'exponentielle] \label{PropDJQSooYIwwhy}
    Si elle existe, la solution au problème 
    \begin{subequations}
        \begin{numcases}{}
            y'=y\\
            y(0)=1
        \end{numcases}
    \end{subequations}
    est unique.
\end{proposition}
\index{exponentielle!unicité}

\begin{proof}
    Soient \( y\) et \( g\) deux solutions et considérions la fonction \( h(x)=g(x)y(-x)\). Un calcul immédiat donne
    \begin{equation}
        h'(x)=0
    \end{equation}
    et donc \( h\) est constante. Vu que \( h(0)=1\) nous avons \( g(x)y(-x)=1\) pour tout \( x\), c'est à dire
    \begin{equation}
        g(x)=\frac{1}{ y(-x) }=y(x).
    \end{equation}
\end{proof}

\begin{proposition}
    Quelque formules pour tout \( a,b\in \eR\) et \( n\in \eZ\) :
    \begin{enumerate}
        \item
            \( y(a+b)=y(a)y(b)\)
        \item
            \( y(na)=y(a)^n\)
        \item
            \( y\left( \frac{ a }{ n } \right)=\sqrt[n]{y(a)}\).
    \end{enumerate}
\end{proposition}

\begin{proof}
    Nous posons \( h(x)=y(a+b-x)y(x)\) et nous avons encore \( h'(x)=0\) dont nous déduisons que $h$ est constante. De plus
    \begin{equation}
        h(0)=y(a+b)y(0)=y(a+b)
    \end{equation}
    et
    \begin{equation}
        h(b)=y(a)y(b).
    \end{equation}
    Vu que \( h\) est constante, ces deux expressions sont égales : \( y(a+b)=y(a)y(b)\).

    Forts de cette relation, une récurrence donne \( y(na)=y(a)^n\) pour tout \( n\in \eN\). De plus
    \begin{equation}
        y(a)=y\left( \frac{ a }{ n }\times n \right)=y\left( \frac{ a }{ n } \right)^n,
    \end{equation}
    ce qui donne \( y(a)=y(a/n)^n\) ou encore \( y(a/n)=\sqrt[n]{y(a)}\).

    Enfin pour les négatifs, si \( n\in \eN\),
    \begin{equation}
        y(-na)=\frac{1}{ y(na) }=\frac{1}{ y(a)^n }=y(a)^{-n}.
    \end{equation}
    Et de la même façon,
    \begin{equation}
        y\left( -\frac{ a }{ n } \right)=\frac{1}{ y\left( \frac{ a }{ n } \right) }=\sqrt[n]{\frac{1}{ y(a) }}=\sqrt[-n]{y(a)}.
    \end{equation}
\end{proof}

\begin{proposition} \label{PropCELWooLBSYmS}
    Pour tout \( x\in \eR\), nous avons
    \begin{equation}
        y(x)=y(1)^x.
    \end{equation}
\end{proposition}

\begin{proof}
    Si \( q\in \eQ\) alors \( q=a/b\) et
    \begin{equation}
        y(q)=y\left( \frac{ a }{ b } \right)=y\left( a\times \frac{1}{ b } \right)=y\left( \frac{1}{ b } \right)^a=\big( \sqrt[b]{y(1)} \big)^a=y(1)^{a/b}=y(1)^{q}.
    \end{equation}

    Par ailleurs si \( a\in \eR\), alors la fonction \( x\mapsto a^x\) est continue. Les fonctions \( y\) et \( x\mapsto y(1)^x\) sont deux fonctions continues égales sur \( \eQ\). Elles sont donc égales.
\end{proof}
Nous notons \( y(1)=e\), le \defe{nombre de Néper}{nombre!de Néper}, de telle sorte que
\begin{equation}
    y(x)=e^x.
\end{equation}


Le théorème \ref{ThoKRYAooAcnTut}, la proposition \ref{PropDJQSooYIwwhy} et le théorème \ref{PropCELWooLBSYmS} nous donnent ceci.
\begin{theorem}[Définition de l'exponentielle]  \label{ThoRWOZooYJOGgR}
    L'équation différentielle
    \begin{subequations}
        \begin{numcases}{}
            y'=y\\
            y(0)=1
        \end{numcases}
    \end{subequations}
possède une unique solution bijective \( y\colon \eR\to \mathopen] 0 , \infty \mathclose[\) de classe \(  C^{\infty}\). Cette fonction est donnée par la série entière\nomenclature[Y]{\( \exp\)}{exponentielle}.
    \begin{equation}
        \exp(x)=\sum_{k=0}^{\infty}\frac{ x^k }{ k! }
    \end{equation}
    et par la formule
    \begin{equation}
        \exp(x)=e^x
    \end{equation}
    où \( e\) est définit par \( e=\exp(1)\).
\end{theorem}
Nous nommons \defe{exponentielle}{exponentielle} cette fonction.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Exponentielle et logarithme de matrice}
%---------------------------------------------------------------------------------------------------------------------------
\label{subsecXNcaQfZ}

\begin{proposition} \label{PropXFfOiOb}
    L'application
    \begin{equation}
        \begin{aligned}
            \exp\colon \eM(n,\eR)&\to \eM(n,\eR) \\
            A&\mapsto \sum_{k=0}^{\infty}\frac{ A^k }{ k! } 
        \end{aligned}
    \end{equation}
    est une application de classe \(  C^{\infty}\). Sa différentielle en zéro est l'identité : \( d\exp_0=\id\).
\end{proposition}
\index{exponentielle!de matrice}

\begin{proof}
    En ce qui concerne la continuité, nous savons que le rayon de convergence de la suite \( \frac{1}{ k! }\) est infini; la proposition \ref{PropQIIURAh} conclu.

    Pour la différentielle, c'est la proposition \ref{PropAMBXKgV} qui nous permet d'écrire
    \begin{equation}
        d\exp_0(U)=\Dsdd{ \exp(tU) }{t}{0}=\Dsdd{ \sum_{k=0}^{\infty}\frac{ t^kU^k }{ k! } }{t}{0}=\left. \sum_{k=0}^{\infty}\frac{ kt^{k-1}U^k }{ k! }\right|_{t=0}=U
    \end{equation}
    parce que seul le terme \( k=1\) n'est pas nul.
\end{proof}

Nous avons vu par la proposition \ref{PropKKdmnkD} que toute matrice complexe inversible a un logarithme. Nous allons maintenant parler de logarithme de matrices réelles avec une condition sur la norme. La formule ci-dessous montre explicitement que le logarithme est réel.
\begin{equation}
    \begin{aligned}
        \ln\colon \{ A\in \eM(n,\eR)\tq \| A-\mtu \| <1 \}&\to \eM(n,\eR) \\
        A&\mapsto \sum_{k=0}^{\infty}(-1)^k\frac{ (A-\mtu)^{k+1} }{ k+1 }. 
    \end{aligned}
\end{equation}

\begin{lemma}   \label{LemQZIQxaB}
    Si \( \| m \|<1\) dans \( \eM(n,\eR)\), alors nous posons
    \begin{equation}    \label{EqIKgMabb}
        \ln(\mtu+m)=\sum_{k=0}^{\infty}(-1)^k\frac{ m^{k+1} }{ k+1 }.
    \end{equation}
    Cette fonction a les propriétés suivantes.
    \begin{enumerate}
        \item
            Elle est de classe \(  C^{\infty}\).        
        \item
            Elle est un bon logarithme au sens où
            \begin{equation}
                e^{\ln(\mtu+m)}=\mtu+m.
            \end{equation}
        \item
            Elle vérifie l'approximation
            \begin{equation}
                \ln(1+m)=m+\sigma(m)
            \end{equation}
            où \( \sigma\) a la propriété que
            \begin{equation}
                \lim_{k\to \infty} k\sigma\left( \frac{ m }{ k } \right)=0.
            \end{equation}
    \end{enumerate}
\end{lemma}
\index{logarithme!de matrice}
%TODO : le reste de la preuve, en particulier le point avec l'exponentielle.

\begin{proof}
    
    Le rayon de convergence de la suite \( a_k=\frac{ (-1)^k }{ k+1 }\) est \( 1\). Donc l'application donnée est \(  C^{\infty}\) sur \( B(0,1)\) par le théorème \ref{PropQIIURAh}.

    D'après la formule \eqref{EqIKgMabb} nous avons
    \begin{equation}
        \sigma(m)=\sum_{l=1}^{\infty}(-1)^l\frac{ m^{l+1} }{ l+1 }.
    \end{equation}
    Nous avons alors
    \begin{equation}
        k\sigma(\frac{ m }{ k })=\sum_{l=1}^{\infty}(-1)^l\frac{ m^{l+1} }{ k^l(l+1) },
    \end{equation}
    et donc
    \begin{equation}
        \| k\sigma(\frac{ m }{ k }) \|\leq \sum_{l=1}^{\infty}\frac{ \| m \|^{l+1} }{ k^l(l+1) }\leq\frac{1}{ k }\sum_{l=1}^{\infty}\frac{ \| m \|^{l+1} }{ l+1 }\stackrel{k\to\infty}{\to} 0
    \end{equation}
    Cela prouve la dernière assertion.   
\end{proof}

\begin{proposition}
    Soit \( V\) un espace vectoriel de dimension finie et \( A\in\End(V)\). Nous considérons la fonction
    \begin{equation}
        \begin{aligned}
            f\colon \eR&\to \End(V) \\
            t&\mapsto  e^{tA}. 
        \end{aligned}
    \end{equation}
    Cette fonction vérifie
    \begin{equation}
        f'(t)=\big(  e^{tA} \big)'=A e^{tA}.
    \end{equation}
\end{proposition}

\begin{proof}
    Si nous posons \( f_k(t)=\frac{ t^kA^k }{ k! }\) alors la fonction \( f\) est la somme : \( f=\sum_{k=0}^{\infty}f_k\). Nous allons permuter la somme et la dérivation à l'aide du théorème \ref{ThoLDpRmXQ}. Vu que 
    \begin{equation}
        f'_k(t)=\frac{ kt^{k-1}A^k }{ k! },
    \end{equation}
    la suite suite des dérivées converge normalement sur \( \eR\), nous pouvons dériver terme à terme pour obtenir
    \begin{equation}
        \Big( \sum_{k=0}^{\infty}t^k\frac{ A^k }{ k! } \Big)=\sum_{k=0}^{\infty}kt^{k-1}\frac{ A^k }{ k! }=\sum_{k=1}^{\infty}kt^{k-1}\frac{ A^k }{ k! }=A\sum_{k=1}^{\infty}\frac{ A^{k-1}t^{k-1} }{ (k-1)! }=A e^{tA}.
    \end{equation}
    Notez le jeu au niveau du point départ de la somme : elle passe de \( 0\) à \( 1\) parce que le terme zéro est nul, mais la simplification \( \frac{ k }{ k! }=\frac{ 1 }{ (k-1)! }\) n'a pas de sens pour \( k=0\).
\end{proof}

\begin{lemma}[\cite{DOAooAgGKTi}]   \label{LemQEARooLRXEef}
    Soit \( A\in\End(V)\) où \( V\) est un espace vectoriel réel de dimension finie. Si nous notons \( \lambda_i\) (\( i=1,\ldots, r\)) les valeurs propres distinctes de $A$ alors il existe un polynôme \( P\in \eR[X]\) tel que
    \begin{equation}
        \|  e^{tA} \|\leq P\big( | t | \big)\sum_{i=1}^r e^{t\real(\lambda_i)}.
    \end{equation}
\end{lemma}

\begin{proof}
    Le polynôme caractéristique de \( A\) se note, d'après le corollaire \ref{CorUNZooAZULXT} de la façon suivante :
    \begin{equation}
        \chi_A(X)=\prod_{i=1}^r(X-\lambda_i)^{m_i}
    \end{equation}
    où \( m_i\) est la multiplicité de la valeur propre \( \lambda_i\). Le lemme des noyaux \ref{ThoDecompNoyayzzMWod} nous dit qu'en posant
    \begin{equation}
        V_i=\ker(A-\lambda_i\mtu)^{m_i}
    \end{equation}
    nous avons \( V=\bigoplus_{i=1}^rV_i\). Nous nommons \( p_i\colon V\to V\) la projection canonique de \( E\) sur \( V_i\) ainsi que \( x_i\) la composante de \( x\in V\) dans l'espace caractéristique \( V_i\) et nous posons \( A_i=p_i\circ A\). Les espaces caractéristiques sont stables par \( A\) (lemme \ref{LemBLPooHMAoyJ}), donc \( (Ax_i)_i=Ax_i\). Par conséquent \( \sum_i A_ip_i=A\) parce que
    \begin{equation}
        \big( \sum_ip_iAp_i \big)(x)=\sum_i(Ax_i)_i=\sum_iAx_i=A\sum_ix_i=Ax.
    \end{equation}
    En ce qui concerne les puissances de \( A\) nous avons de même
    \begin{equation}
        A_i^nx_I=A_i\underbrace{A_i^{n-1}x_i}_{\in V_i}=AA_i^{n-1}x_i=A^nx_i,
    \end{equation}
    et donc
    \begin{equation}
        \sum_{i=1}^rA_i^np_i=A^n.
    \end{equation}
    En particulier,
    \begin{equation}    \label{EqPVIooGxwFBH}
        e^{tA}=\sum_i e^{tA_i}p_i.
    \end{equation}
    C'est de cette exponentielle de matrice que nous devons étudier la norme.

    La décomposition de Dunford du théorème \ref{ThoRURcpW} est toujours un bon plan pour traiter avec les exponentielles : nous avons \( A=s+n\) avec
    \begin{equation}
        \begin{aligned}[]
            s&=\sum_k\lambda_kp_k,&n=\sum_k(A-\lambda_k\mtu)p_k.
        \end{aligned}
    \end{equation}
    Nous montrons que la décomposition de Dunford de \( p_iA\) est \( p_iA=p_is+p_in\). Nous avons
    \begin{equation}
        p_is=\sum_k\lambda_kp_ip_k=\lambda_ip_i
    \end{equation}
    qui est bien diagonalisable. De plus les espaces caractéristiques sont stables par \( n\), donc \( p_in\) est nilpotent. Enfin ils commutent :
    \begin{equation}    \label{EqNJIooDxKlxn}
        [p_is,p_in]=\lambda_i(p_in-p_inp_i).
    \end{equation}
    Vu que \( n\) préserve les espaces caractéristiques, lorsque \( v\in V_k\) avec \( k\neq i\) nous avons \( p_inp_iv=0\) et \( p_inv=0\). Mais si \( v\in V_i\) alors
    \begin{equation}
        p_inp_iv=p_inv=nv
    \end{equation}
    et \( p_inv=nv\), donc les opérateurs \( p_in\) et \( p_inp_i\) sont égaux et \eqref{EqNJIooDxKlxn} donne bien zéro. En ce qui concerne l'exponentielle de \( A_i\) nous avons
    \begin{equation}
        e^{p_iA}= e^{p_is} e^{p_in}= e^{\lambda_ip_i} \exp\big( (A-\lambda_i\mtu)p_i\big).
    \end{equation}

    Nous pouvons maintenant sérieusement nous attaquer à la norme de \(  e^{tA}\) de l'équation \eqref{EqPVIooGxwFBH}. D'abord nous avons \( \| p_i \|=1\) parce que l'opérateur \( p_i\) est l'identité sur au moins un vecteur (en fait tout ceux de l'espace caractéristique \( V_i\)). En utilisant les propriétés de la norme opérateur\footnote{Surtout le fait que ce soit une norme d'algèbre, proposition \ref{PropEDvSQsA}.}, nous trouvons dans un premier temps\footnote{Si les valeurs propres de \( A\) sont \( \lambda_i\), celles de \( tA\) sont \( t\lambda_i\).} :
    \begin{equation}
        \|  e^{tA} \|\leq \sum_{i=1}^r\|  e^{tA_i} \|\leq \sum_{i=1}^r|  e^{t\lambda_i} |\underbrace{\sum_{k=0}^{m_i}\frac{ | t |^k }{ k! }\| A-\lambda_i\mtu_i \|^k}_{=P_i( | t | }
    \end{equation}
    où \( \mtu_i\) est l'opérateur identité sur \( V_i\). Petit détail dans le calcul :
    \begin{equation}
        \|  e^{\lambda_ip_i} \|\leq \sum_{l=0}^{\infty}\frac{ \lambda_i^l }{ k! }\| p_i \|^l= e^{\lambda_i}.
    \end{equation}
    Notons que tous les termes de \( P_i(| t |)\) et \( P_i\big( | t | \big)\) sont positifs, de telle sorte que nous pouvons majorer en ajoutant des termes partout. À la place d'avoir \( P_i(| t |)\) comme coefficient de \( |  e^{t\lambda_i} |\) nous majorons en mettant \( \sum_{j=1}^rP_j(| t |)\) comme coefficient :
    \begin{equation}
        \|  e^{tA} \|\leq    \sum_{i=1}^r|  e^{t\lambda_i} |P_i\big( | t | \big)
        =\sum_{i=1}^r|  e^{t\lambda_i} |\sum_{j=1}^rP_j\big( | t | \big)=P\big( | t | \big)\sum_{i=1}^r e^{t\real(\lambda_i)}.
    \end{equation}
    L'arrivée de la partie réelle est une égalité usuelle pour les nombres complexes : $|  e^{a+bi} |= e^{a}|  e^{bi} |= e^{a}$.
\end{proof}
